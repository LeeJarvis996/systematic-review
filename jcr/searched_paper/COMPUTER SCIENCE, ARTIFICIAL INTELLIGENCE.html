<div xmlns:bean="http://ts.thomson.com/ua/bean" style="background-color: #000000; padding: 10px; color: #FFFFFF; font-family:  arial, sans-serif;">
<div style="height: 25px; width: 100px;">
<mat-icon data-mat-icon-name="clarivate" data-mat-icon-type="svg" aria-hidden="true" class="mat-icon notranslate clarivate-logo mat-icon-no-color" svgicon="clarivate" role="img">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" focusable="false" preserveAspectRatio="xMidYMid meet" version="1.1" viewBox="0 0 92 18" height="100%" width="100%">
<title>Clarivate</title>
<g fill-rule="evenodd" fill="none" stroke-width="1" stroke="none">
<g fill-rule="nonzero" fill="#FFFFFF" transform="translate(-19.000000, -8.000000)">
<g transform="translate(1.000000, 1.000000)">
<g transform="translate(18.000000, 7.000000)">
<path d="M26.6812194,13.2997252 C28.2949641,13.3845068 29.7591419,12.3596036 30.2318671,10.8143235 L33.0910469,10.8143235 C32.3628779,13.742285 29.6973379,15.7705498 26.6812194,15.6916944 C24.8651813,15.7485215 23.1057028,15.0559504 21.8156554,13.7764967 C20.5256081,12.4970431 19.8185526,10.7433351 19.8604035,8.9268901 C19.8185367,7.11043445 20.5255848,5.35671042 21.8156337,4.07724261 C23.1056826,2.7977748 24.8651702,2.10519376 26.6812194,2.16201887 C29.6973451,2.0831702 32.3628861,4.11144761 33.0910469,7.03941847 L30.2318671,7.03941847 C29.7591419,5.49413828 28.2949641,4.46923515 26.6812194,4.55401674 C25.5407067,4.54133389 24.4470406,5.00703241 23.6657805,5.83803342 C22.8845203,6.66903442 22.487126,7.78932829 22.5700912,8.9268901 C22.4871313,10.064447 22.8845287,11.184734 23.6657888,12.0157277 C24.447049,12.8467215 25.540712,13.312413 26.6812194,13.2997252 L26.6812194,13.2997252 Z"/>
<polygon points="36.8477342 15.4674945 34.4371264 15.4674945 34.4371264 2.38628571 36.8477342 2.38628571"/>
<path d="M43.5380316,9.76781183 C43.5380316,9.15114738 43.0522397,8.75870193 42.1178663,8.75870193 C41.2070757,8.82048057 40.3236107,9.0957548 39.5389268,9.5622602 L38.5858286,7.73092465 C39.6930919,7.06514423 40.9567617,6.70409618 42.2486241,6.68441302 C44.1921648,6.68441302 45.9674886,7.58137515 45.9674886,9.84255787 L45.9674886,15.4674945 L43.5380316,15.4674945 L43.5380316,14.6639362 C42.9494098,15.3673061 42.0613957,15.7488608 41.146005,15.6917231 C40.3900371,15.7421039 39.645831,15.484584 39.0826798,14.9777443 C38.5195286,14.4709046 38.1853154,13.7578403 38.1560675,13.0007601 C38.1560675,11.3749188 39.3519468,10.3658089 41.2581433,10.3658089 L42.9400537,10.3658089 C43.3511665,10.3658089 43.5379934,10.1789247 43.5379934,9.86128266 L43.5380316,9.76781183 Z M43.5380316,12.4027631 L43.5380316,11.786089 C43.321275,11.9402969 43.0543042,12.0070182 42.790485,11.9729159 L41.8748173,11.9729159 C41.1086607,11.9729159 40.6602036,12.3092922 40.6602036,12.9072893 C40.6602036,13.486619 41.1272707,13.9164566 41.8748173,13.9164566 C42.303867,13.9699481 42.7348632,13.8332333 43.0546312,13.5422121 C43.3743992,13.2511908 43.5509896,12.8349402 43.5380316,12.4027631 L43.5380316,12.4027631 Z"/>
<path d="M52.6579104,9.3006299 L51.6301236,9.3006299 C50.3966703,9.3006299 49.8361037,9.8799596 49.8361037,11.3749188 L49.8361037,15.4674945 L47.4066179,15.4674945 L47.4066179,6.90863203 L49.7612715,6.90863203 L49.7612715,8.27284306 C50.1001881,7.34759017 51.0007831,6.74968637 51.9850429,6.79648425 C52.2115562,6.79362484 52.4375557,6.81874947 52.6579104,6.87128771 L52.6579104,9.3006299 Z"/>
<path d="M57.4232866,15.4674945 L54.9939445,15.4674945 L54.9939445,8.96425355 L53.7979312,8.96425355 L53.7979312,6.90863203 L57.4232866,6.90863203 L57.4232866,15.4674945 Z M56.0964104,2.38628347 C56.5129556,2.38558064 56.9126431,2.55074046 57.2071855,2.84528284 C57.5017278,3.13982521 57.6668877,3.53951271 57.6661848,3.95605794 C57.6609778,4.814152 56.9638874,5.50702694 56.1057775,5.50702694 C55.2476677,5.50702694 54.5505773,4.814152 54.5453585,3.95605794 C54.5417726,3.09491157 55.2352828,2.39302469 56.0964104,2.38628347 Z"/>
<polygon points="62.8802456 12.8512776 64.8236715 6.90863203 67.3838767 6.90863203 64.33787 15.4674945 61.3292077 15.4674945 58.4139588 6.90863203 61.0488526 6.90863203"/>
<path d="M72.8783522,9.76781183 C72.8783522,9.15114738 72.3924359,8.75870193 71.4580625,8.75870193 C70.5472784,8.82049943 69.6638208,9.09577238 68.8791325,9.5622602 L67.9261491,7.73092465 C69.0333627,7.06513461 70.2969953,6.70408494 71.5888202,6.68441302 C73.5323609,6.68441302 75.3076848,7.58137515 75.3076848,9.84255787 L75.3076848,15.4674945 L72.8783522,15.4674945 L72.8783522,14.6639362 C72.2896971,15.3672586 71.4017035,15.7487939 70.4863256,15.6916944 C69.7303436,15.7420941 68.986117,15.4845835 68.4229464,14.9777426 C67.8597758,14.4709017 67.5255471,13.7578265 67.4962924,13.0007314 C67.4962924,11.3748901 68.6923056,10.3657802 70.5984925,10.3657802 L72.2802785,10.3657802 C72.6913914,10.3657802 72.8783426,10.1788959 72.8783426,9.86125395 L72.8783522,9.76781183 Z M72.8783522,12.4027631 L72.8783522,11.786089 C72.6615874,11.9402794 72.3946236,12.006999 72.1308056,11.9729159 L71.2151378,11.9729159 C70.4488664,11.9729159 70.0004093,12.3092922 70.0004093,12.9072893 C70.0004093,13.486619 70.4676008,13.9164566 71.2151378,13.9164566 C71.6441833,13.9699279 72.0751679,13.8332061 72.394931,13.5421893 C72.7146941,13.2511724 72.8912904,12.8349341 72.8783522,12.4027631 L72.8783522,12.4027631 Z"/>
<path d="M79.9985637,3.65701635 L79.9985637,6.90863203 L81.8485762,6.90863203 L81.8485762,8.96425355 L79.9985637,8.96425355 L79.9985637,12.8325433 C79.9985637,13.3745286 80.4282865,13.4492747 80.8020646,13.4492747 C81.418729,13.4492747 81.9232553,13.3932056 81.9232553,13.3932056 L81.9232553,15.4674945 C81.9232553,15.4674945 80.7459859,15.5796423 80.0357932,15.5796423 C78.8211795,15.5796423 77.5691354,15.3740811 77.5691354,13.6548263 L77.5691354,8.96425355 L76.22363,8.96425355 L76.22363,6.90863203 L77.5691163,6.90863203 L77.5691163,3.65701635 L79.9985637,3.65701635 Z"/>
<path d="M91.5475359,11.8981794 L85.1751771,11.8981794 C85.3031552,12.7204351 85.9194738,13.3815958 86.7307322,13.5669136 C87.5419905,13.7522314 88.3842592,13.4242593 88.856573,12.7391298 L91.3793191,13.0007601 C90.4933306,14.9536735 88.3725856,16.0321989 86.2725384,15.5978628 C84.1724912,15.1635268 82.6535603,13.3322361 82.6149337,11.188092 C82.567807,9.98960603 83.0193435,8.82515843 83.8621298,7.97175307 C84.7049161,7.1183477 85.8636189,6.65226701 87.0626009,6.68438432 C89.4171397,6.68438432 91.5475359,8.21674525 91.5475359,11.8047373 L91.5475359,11.8981794 Z M85.1189837,10.2723955 L88.9499864,10.2723955 C88.8059978,9.34848922 87.9973156,8.67588427 87.0626392,8.70263282 C86.1147409,8.67034807 85.2869107,9.33893202 85.1189837,10.2723955 Z"/>
<path d="M12.6820274,9.85132226 C10.6885049,11.8556057 8.11575776,13.1830474 5.32707189,13.6462054 C5.77780891,14.8758828 6.40559556,16.0331959 7.19058498,17.0815575 C10.3903106,16.2989026 13.3004311,14.619851 15.5794509,12.2414352 C15.0651988,11.0374085 14.3787129,9.91449973 13.5415112,8.90790698 C13.271174,9.23328 12.9846793,9.54772625 12.6820274,9.85124571"/>
<path d="M5.32722498,13.6460332 C4.21304566,10.5852611 4.22627578,7.22758116 5.3645406,4.17568425 C4.07298567,3.95802358 2.75701252,3.92542943 1.45626578,4.07888372 C0.536506305,7.22972054 0.525090565,10.5762272 1.42333236,13.7332656 C2.72217338,13.8896343 4.03666286,13.8602685 5.32722498,13.6460524"/>
<path d="M7.25919787,0.751096346 C6.46424104,1.79423541 5.8259601,2.94792723 5.36457887,4.17561728 C8.13918123,4.64457901 10.6977043,5.96938232 12.6820178,7.96458738 C12.9850078,8.2673988 13.2715025,8.58184824 13.5415017,8.90793568 C14.3788161,7.90142183 15.0653154,6.77849641 15.5794509,5.57440744 C13.3171586,3.21319806 10.4324457,1.54091896 7.25919787,0.751096346"/>
</g>
</g>
</g>
</g>
</svg>
</mat-icon>
</div>
<path d="M5.32722498,13.6460332 C4.21304566,10.5852611 4.22627578,7.22758116 5.3645406,4.17568425 C4.07298567,3.95802358 2.75701252,3.92542943 1.45626578,4.07888372 C0.536506305,7.22972054 0.525090565,10.5762272 1.42333236,13.7332656 C2.72217338,13.8896343 4.03666286,13.8602685 5.32722498,13.6460524"></path>
<path d="M7.25919787,0.751096346 C6.46424104,1.79423541 5.8259601,2.94792723 5.36457887,4.17561728 C8.13918123,4.64457901 10.6977043,5.96938232 12.6820178,7.96458738 C12.9850078,8.2673988 13.2715025,8.58184824 13.5415017,8.90793568 C14.3788161,7.90142183 15.0653154,6.77849641 15.5794509,5.57440744 C13.3171586,3.21319806 10.4324457,1.54091896 7.25919787,0.751096346"></path>
</div><div style="width: 180px; height: 40px; padding: 10px;">
<mat-icon data-mat-icon-name="wos" data-mat-icon-type="svg" aria-hidden="true" style="width: 180px;" class="mat-icon notranslate mat-icon-no-color" svgicon="wos" role="img">
<svg xmlns="http://www.w3.org/2000/svg" focusable="false" preserveAspectRatio="xMidYMid meet" viewBox="0 0 1868 332" height="100%" width="100%">
<title>Web of Science</title>
<path d="M 108.92,75.00            C 108.92,75.00 147.34,75.00 147.34,75.00              147.34,75.00 182.84,208.12 182.84,208.12              182.84,208.12 183.11,208.12 183.11,208.12              183.11,208.12 212.80,75.00 212.80,75.00              212.80,75.00 250.42,75.00 250.42,75.00              250.42,75.00 205.11,261.00 205.11,261.00              205.11,261.00 162.44,261.00 162.44,261.00              162.44,261.00 127.47,127.34 127.47,127.34              127.47,127.34 93.28,261.00 93.28,261.00              93.28,261.00 50.61,261.00 50.61,261.00              50.61,261.00 4.77,75.00 4.77,75.00              4.77,75.00 44.52,75.00 44.52,75.00              44.52,75.00 73.14,208.12 73.14,208.12              73.14,208.12 73.41,208.12 73.41,208.12              73.41,208.12 108.92,75.00 108.92,75.00 Z            M 379.00,210.00            C 379.00,210.00 288.41,210.00 288.41,210.00              289.29,216.78 292.30,222.48 297.44,227.09              302.57,231.70 308.86,234.00 316.30,234.00              327.80,234.00 335.95,230.00 340.73,222.00              340.73,222.00 376.61,225.58 376.61,225.58              371.30,238.39 363.32,248.00 352.69,254.41              342.06,260.80 329.75,264.00 315.77,264.00              297.52,264.00 282.32,257.98 270.19,245.94              258.06,233.90 252.00,218.59 252.00,200.00              252.00,181.42 257.98,166.11 269.94,154.06              281.89,142.02 296.99,136.00 315.23,136.00              333.47,136.00 348.66,142.21 360.80,154.64              372.93,167.06 379.00,185.51 379.00,210.00 Z            M 333.30,171.28            C 328.34,167.09 322.32,165.00 315.23,165.00              308.15,165.00 302.12,167.01 297.16,171.03              292.20,175.04 289.02,180.37 287.61,187.00              287.61,187.00 342.06,187.00 342.06,187.00              341.19,180.71 338.27,175.47 333.30,171.28 Z            M 433.72,245.31            C 433.72,245.31 433.72,261.00 433.72,261.00              433.72,261.00 399.00,261.00 399.00,261.00              399.00,261.00 399.00,75.00 399.00,75.00              399.00,75.00 433.45,75.00 433.45,75.00              433.45,75.00 433.45,134.94 433.45,134.94              433.45,137.95 433.45,141.85 433.45,146.64              433.45,151.42 433.45,154.17 433.45,154.88              436.43,149.39 441.34,144.87 448.17,141.33              455.02,137.78 462.82,136.00 471.59,136.00              488.26,136.00 502.16,142.07 513.30,154.20              524.43,166.33 530.00,181.59 530.00,200.00              530.00,218.41 524.37,233.68 513.11,245.81              501.86,257.94 487.88,264.00 471.17,264.00              462.91,264.00 455.39,262.22 448.62,258.66              441.85,255.09 436.88,250.65 433.72,245.31 Z            M 485.39,176.23            C 479.65,169.98 472.34,166.86 463.45,166.86              454.58,166.86 447.27,169.98 441.53,176.23              435.79,182.48 432.92,190.37 432.92,199.88              432.92,209.20 435.79,217.07 441.53,223.50              447.27,229.93 454.58,233.14 463.45,233.14              472.34,233.14 479.65,229.93 485.39,223.50              491.13,217.07 494.00,209.20 494.00,199.88              494.00,190.37 491.13,182.48 485.39,176.23 Z            M 707.69,245.81            C 695.19,257.94 679.86,264.00 661.72,264.00              643.58,264.00 628.26,257.94 615.75,245.81              603.25,233.68 597.00,218.41 597.00,200.00              597.00,181.59 603.25,166.33 615.75,154.20              628.26,142.07 643.58,136.00 661.72,136.00              679.86,136.00 695.19,142.07 707.69,154.20              720.20,166.33 726.45,181.59 726.45,200.00              726.45,218.41 720.20,233.68 707.69,245.81 Z            M 661.84,166.86            C 652.85,166.86 645.54,170.00 639.91,176.28              634.27,182.55 631.45,190.46 631.45,200.00              631.45,209.54 634.27,217.45 639.91,223.73              645.54,230.01 652.85,233.14 661.84,233.14              670.66,233.14 677.89,230.01 683.53,223.73              689.18,217.45 692.00,209.54 692.00,200.00              692.00,190.46 689.18,182.55 683.53,176.28              677.89,170.00 670.66,166.86 661.84,166.86 Z            M 757.00,139.00            C 757.00,139.00 757.00,104.34 757.00,104.34              757.00,93.15 760.17,84.98 766.52,79.83              772.86,74.67 781.14,72.09 791.36,72.09              791.36,72.09 816.50,73.69 816.50,73.69              816.50,73.69 816.50,105.33 816.50,105.33              809.47,104.45 804.72,104.00 802.27,104.00              798.58,104.00 795.85,104.71 794.09,106.14              792.33,107.57 791.45,110.24 791.45,114.16              791.45,114.16 791.45,139.00 791.45,139.00              791.45,139.00 815.00,139.00 815.00,139.00              815.00,139.00 815.00,168.00 815.00,168.00              815.00,168.00 791.45,168.00 791.45,168.00              791.45,168.00 791.45,260.50 791.45,260.50              791.45,260.50 757.00,260.50 757.00,260.50              757.00,260.50 757.00,168.00 757.00,168.00              757.00,168.00 738.00,168.00 738.00,168.00              738.00,168.00 738.00,139.00 738.00,139.00              738.00,139.00 757.00,139.00 757.00,139.00 Z            M 1004.30,97.27            C 1004.30,97.27 983.11,124.06 983.11,124.06              969.92,111.36 956.73,105.00 943.53,105.00              937.11,105.00 931.59,106.60 926.95,109.80              922.32,112.98 920.00,117.24 920.00,122.56              920.00,131.06 926.74,138.42 940.22,144.62              940.22,144.62 955.66,151.80 955.66,151.80              971.60,159.25 983.48,167.31 991.28,176.00              999.09,184.68 1003.00,195.67 1003.00,208.97              1003.00,223.87 997.13,236.76 985.39,247.66              973.66,258.55 958.09,264.00 938.67,264.00              913.45,264.00 891.31,254.56 872.25,235.67              872.25,235.67 892.52,208.02 892.52,208.02              899.27,214.90 906.74,220.29 914.92,224.17              923.10,228.06 930.83,230.00 938.11,230.00              945.94,230.00 952.21,228.09 956.92,224.28              961.64,220.47 964.00,215.64 964.00,209.80              964.00,203.95 961.65,198.93 956.95,194.77              952.25,190.60 944.85,186.21 934.73,181.61              934.73,181.61 921.70,175.48 921.70,175.48              894.57,162.73 881.00,145.36 881.00,123.38              881.00,107.59 887.05,94.92 899.17,85.36              911.29,75.79 925.91,71.00 943.06,71.00              963.93,71.00 984.34,79.76 1004.30,97.27 Z            M 1082.92,166.86            C 1073.91,166.86 1066.58,170.00 1060.92,176.28              1055.27,182.55 1052.45,190.46 1052.45,200.00              1052.45,209.54 1055.27,217.45 1060.92,223.73              1066.58,230.01 1073.91,233.14 1082.92,233.14              1095.82,233.14 1104.74,226.95 1109.69,214.58              1109.69,214.58 1142.02,224.66 1142.02,224.66              1138.13,236.72 1130.75,246.29 1119.89,253.38              1109.02,260.46 1096.61,264.00 1082.66,264.00              1064.46,264.00 1049.13,257.94 1036.67,245.81              1024.22,233.68 1018.00,218.41 1018.00,200.00              1018.00,181.59 1024.22,166.33 1036.67,154.20              1049.13,142.07 1064.46,136.00 1082.66,136.00              1096.61,136.00 1109.02,139.59 1119.89,146.77              1130.75,153.95 1138.13,163.56 1142.02,175.61              1142.02,175.61 1109.69,185.42 1109.69,185.42              1107.39,179.77 1103.91,175.26 1099.22,171.91              1094.54,168.54 1089.11,166.86 1082.92,166.86 Z            M 1170.31,112.67            C 1166.10,108.45 1164.00,103.27 1164.00,97.12              1164.00,90.98 1166.15,85.76 1170.45,81.45              1174.75,77.15 1179.89,75.00 1185.86,75.00              1192.02,75.00 1197.24,77.15 1201.55,81.45              1205.85,85.76 1208.00,90.98 1208.00,97.12              1208.00,103.27 1205.85,108.45 1201.55,112.67              1197.24,116.89 1192.02,119.00 1185.86,119.00              1179.71,119.00 1174.53,116.89 1170.31,112.67 Z            M 1205.00,139.00            C 1205.00,139.00 1205.00,261.00 1205.00,261.00              1205.00,261.00 1170.55,261.00 1170.55,261.00              1170.55,261.00 1170.55,168.00 1170.55,168.00              1170.55,168.00 1153.50,168.00 1153.50,168.00              1153.50,168.00 1153.50,139.00 1153.50,139.00              1153.50,139.00 1205.00,139.00 1205.00,139.00 Z            M 1353.00,210.00            C 1353.00,210.00 1262.41,210.00 1262.41,210.00              1263.29,216.78 1266.30,222.48 1271.44,227.09              1276.57,231.70 1282.86,234.00 1290.30,234.00              1301.80,234.00 1309.95,230.00 1314.73,222.00              1314.73,222.00 1350.61,225.58 1350.61,225.58              1345.30,238.39 1337.32,248.00 1326.69,254.41              1316.06,260.80 1303.75,264.00 1289.77,264.00              1271.52,264.00 1256.32,257.98 1244.19,245.94              1232.06,233.90 1226.00,218.59 1226.00,200.00              1226.00,181.42 1231.98,166.11 1243.94,154.06              1255.89,142.02 1270.99,136.00 1289.23,136.00              1307.47,136.00 1322.66,142.21 1334.80,154.64              1346.93,167.06 1353.00,185.51 1353.00,210.00 Z            M 1307.30,171.28            C 1302.34,167.09 1296.32,165.00 1289.23,165.00              1282.15,165.00 1276.12,167.01 1271.16,171.03              1266.20,175.04 1263.02,180.37 1261.61,187.00              1261.61,187.00 1316.06,187.00 1316.06,187.00              1315.19,180.71 1312.27,175.47 1307.30,171.28 Z            M 1406.39,153.36            C 1415.92,141.79 1428.27,136.00 1443.45,136.00              1456.87,136.00 1467.72,140.04 1476.02,148.11              1484.30,156.17 1488.45,167.20 1488.45,181.20              1488.45,181.20 1488.45,261.00 1488.45,261.00              1488.45,261.00 1454.00,261.00 1454.00,261.00              1454.00,261.00 1454.00,189.86 1454.00,189.86              1454.00,182.57 1452.00,177.11 1448.00,173.47              1444.01,169.82 1439.09,168.00 1433.25,168.00              1423.50,168.00 1414.90,172.62 1407.45,181.86              1407.45,181.86 1407.45,261.00 1407.45,261.00              1407.45,261.00 1373.00,261.00 1373.00,261.00              1373.00,261.00 1373.00,139.00 1373.00,139.00              1373.00,139.00 1406.39,139.00 1406.39,139.00              1406.39,139.00 1406.39,153.36 1406.39,153.36 Z            M 1573.92,166.86            C 1564.91,166.86 1557.58,170.00 1551.92,176.28              1546.27,182.55 1543.45,190.46 1543.45,200.00              1543.45,209.54 1546.27,217.45 1551.92,223.73              1557.58,230.01 1564.91,233.14 1573.92,233.14              1586.82,233.14 1595.74,226.95 1600.69,214.58              1600.69,214.58 1633.02,224.66 1633.02,224.66              1629.13,236.72 1621.75,246.29 1610.89,253.38              1600.02,260.46 1587.61,264.00 1573.66,264.00              1555.46,264.00 1540.13,257.94 1527.67,245.81              1515.22,233.68 1509.00,218.41 1509.00,200.00              1509.00,181.59 1515.22,166.33 1527.67,154.20              1540.13,142.07 1555.46,136.00 1573.66,136.00              1587.61,136.00 1600.02,139.59 1610.89,146.77              1621.75,153.95 1629.13,163.56 1633.02,175.61              1633.02,175.61 1600.69,185.42 1600.69,185.42              1598.39,179.77 1594.91,175.26 1590.22,171.91              1585.54,168.54 1580.11,166.86 1573.92,166.86 Z            M 1773.00,210.00            C 1773.00,210.00 1682.41,210.00 1682.41,210.00              1683.29,216.78 1686.30,222.48 1691.44,227.09              1696.57,231.70 1702.86,234.00 1710.30,234.00              1721.80,234.00 1729.95,230.00 1734.73,222.00              1734.73,222.00 1770.61,225.58 1770.61,225.58              1765.30,238.39 1757.32,248.00 1746.69,254.41              1736.06,260.80 1723.75,264.00 1709.77,264.00              1691.52,264.00 1676.32,257.98 1664.19,245.94              1652.06,233.90 1646.00,218.59 1646.00,200.00              1646.00,181.42 1651.98,166.11 1663.94,154.06              1675.89,142.02 1690.99,136.00 1709.23,136.00              1727.47,136.00 1742.66,142.21 1754.80,154.64              1766.93,167.06 1773.00,185.51 1773.00,210.00 Z            M 1727.30,171.28            C 1722.34,167.09 1716.32,165.00 1709.23,165.00              1702.15,165.00 1696.12,167.01 1691.16,171.03              1686.20,175.04 1683.02,180.37 1681.61,187.00              1681.61,187.00 1736.06,187.00 1736.06,187.00              1735.19,180.71 1732.27,175.47 1727.30,171.28 Z" stroke-width="1" stroke="black" fill="black"/>
<path d="M 1769.00,76.00            C 1769.00,76.00 1800.00,76.00 1800.00,76.00              1800.00,76.00 1800.00,82.42 1800.00,82.42              1800.00,82.42 1788.00,82.42 1788.00,82.42              1788.00,82.42 1788.00,115.00 1788.00,115.00              1788.00,115.00 1780.84,115.00 1780.84,115.00              1780.84,115.00 1780.84,82.42 1780.84,82.42              1780.84,82.42 1769.00,82.42 1769.00,82.42              1769.00,82.42 1769.00,76.00 1769.00,76.00 Z            M 1827.27,106.64            C 1827.27,106.64 1818.95,106.64 1818.95,106.64              1818.95,106.64 1811.16,87.42 1811.16,87.42              1811.16,87.42 1811.16,115.00 1811.16,115.00              1811.16,115.00 1804.00,115.00 1804.00,115.00              1804.00,115.00 1804.00,76.00 1804.00,76.00              1804.00,76.00 1814.61,76.00 1814.61,76.00              1814.61,76.00 1823.25,98.11 1823.25,98.11              1823.25,98.11 1832.08,76.00 1832.08,76.00              1832.08,76.00 1842.00,76.00 1842.00,76.00              1842.00,76.00 1842.00,115.00 1842.00,115.00              1842.00,115.00 1834.84,115.00 1834.84,115.00              1834.84,115.00 1834.84,87.42 1834.84,87.42              1834.84,87.42 1827.27,106.64 1827.27,106.64 Z" stroke-width="1" stroke="black" fill="black"/>
</svg>
</mat-icon>
</div><table cellspacing="0" cellpadding="2" border="0">
<tr>
<td>51 record(s) printed from Clarivate Web of Science</td>
</tr>
</table><hr>
<table>
<tr>
<td><b>Record 1 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Uncertainty-guided weakly supervised segmentation of cardiac substructures with adapter fine-tuning and Fourier feature extraction</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, SQ (Liu, Siqi); Zhou, SJ (Zhou, Shoujun); Wang, YQ (Wang, Yuanquan); Lu, K (Lu, Ke); Liu, WP (Liu, Weipeng); Wang, ZD (Wang, Zhida)</td>
</tr>

<tr xmlns:bean="http://ts.thomson.com/ua/bean" xmlns:exsl="http://exslt.org/common" xmlns:set="http://exslt.org/sets">
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>283</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>127583</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2025.127583</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>APR 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JUL 15</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
5</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>52</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Accurate delineation of cardiac substructures is crucial for computer-aided diagnosis of heart-related diseases. However, due to the inherent variability and complexity of medical images, achieving accurate segmentation of the complex structures of the whole heart still poses a challenge. Furthermore, labeled medical imaging data with high quality is scarce. To address these challenges, we have developed a novel weakly supervised framework capable of effectively segmenting the whole heart separately in CT and MR images, ensuring outstanding segmentation performance specific to each modality. This framework uses partial pixel-level annotations and bounding box weak labels, employing an uncertainty-guided Mean-Teacher (MT) strategy to reduce reliance on detailed pixel-level annotations. Additionally, to further refine the model's performance, we enhanced it by incorporating the Convolutional Local Spatial Perception Adapter (ConvLSP Adapter) and the Frequency Domain Feature Extraction (FDFE) module. These adaptations specifically boost the model's capability to capture local features, overcoming the limitations of traditional attention layers. To validate the effectiveness of our approach, we conducted experiments using the MICCAI 2017 MM-WHS cardiac dataset. Experimental results show that our method outperforms the boundary-box prompted SAM fully supervised segmentation method, increasing the Dice coefficient by approximately 0.5% for CT and 1.4% for MR. Compared to the MT series segmentation methods, our approach shows improvements of 3.4% for CT and 3% for MR in the Dice coefficient.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001485486900001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Weakly supervised segmentation; SAM; Adapter; Uncertainty estimation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
MEDICAL IMAGE SEGMENTATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Siqi; Wang, Yuanquan; Liu, Weipeng] Hebei Univ Technol HeBUT, Sch Artificial Intelligence, Tianjin 300401, Peoples R China. <br>
[Zhou, Shoujun] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China. <br>
[Lu, Ke] Univ Chinese Acad Sci, Sch Engn Sci, Beijing, Peoples R China. <br>
[Wang, Zhida] Tianjin Med Univ, Chu Hsien I Mem Hosp, NHC Key Lab Hormones &amp; Dev, Tianjin 300134, Peoples R China. <br>
[Wang, Zhida] Tianjin Med Univ, Tianjin Inst Endocrinol, Tianjin Key Lab Metab Dis, Tianjin 300134, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Wang, YQ (corresponding author), Hebei Univ Technol HeBUT, Sch Artificial Intelligence, Tianjin 300401, Peoples R China.<br>Lu, K (corresponding author), Univ Chinese Acad Sci, Sch Engn Sci, Beijing, Peoples R China.<br>Wang, ZD (corresponding author), Tianjin Med Univ, Chu Hsien I Mem Hosp, NHC Key Lab Hormones &amp; Dev, Tianjin 300134, Peoples R China.<br>Wang, ZD (corresponding author), Tianjin Med Univ, Tianjin Inst Endocrinol, Tianjin Key Lab Metab Dis, Tianjin 300134, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
liuweipeng@hebut.edu.cn; sj.zhou@siat.ac.cn; wangyuanquan@scse.hebut.edu.cn; luk@ucas.ac.cn; liuweipeng@hebut.edu.cn; wangyuanquan@scse.hebut.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Tianjin Medical University; Tianjin Medical University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Yuanquan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9232-5392&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>2LM3N</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Science Foundation of China (NSFC)</grant_agency>&nbsp;</td><td>
<div>62472142&nbsp;</div>
<div>61976241&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of Hebei Province</grant_agency>&nbsp;</td><td>
<div>H2024202009&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>International Science and technology cooperation plan project of Zhenjiang</grant_agency>&nbsp;</td><td>
<div>GJ2021008&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Science Foundation of China (NSFC) under Grants 62472142, 61976241, in part by the Jing-Jin-Ji Incorporation Project of the Natural Science Foundation of Hebei Province under Grants H2024202009, and in part by the International Science and technology cooperation plan project of Zhenjiang under grant GJ2021008.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 2 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>DDDG: A dual bi-directional knowledge distillation method with generative self-supervised pre-training and its hardware implementation on SoC for ECG</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhang, HC (Zhang, Huaicheng); Liu, WH (Liu, Wenhan); Guo, QX (Guo, Qianxi); Shi, JG (Shi, Jiguang); Chang, S (Chang, Sheng); Wang, H (Wang, Hao); He, J (He, Jin); Huang, QJ (Huang, Qijun)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>244</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>122969</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2023.122969</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>DEC 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 JUN 15</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>4</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>4</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
20</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>37</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Nowadays, the increase in computing power and data volume boosts the development of deep learning. However, computational resources and the high cost of data labeling are two main obstacles to employing algorithms in various applications. Therefore, a novel method naming Dual Distillation Double Gains (DDDG) is proposed, it is a dual bi-directional knowledge distillation (KD) method with generative self-supervised pre-training. In a self-supervised manner, models are pre-trained with unlabeled data. KD can transfer knowledge from a large model to a lightweight one, which is more suitable for deployments on portable/mobile devices. Based on the teacher-student structure, a reconstructing teacher and a classifying teacher are pre-trained in advance. The reconstructing teacher distills knowledge for the student in pretext tasks by feature-based knowledge. The second distillation occurs in fine-tuning, the classifying teacher mentors the student with response-based knowledge. Both of the distillations are bi-directional, which also reinforce the teacher model in reverse. According to experimental results, F1 score of the student network in two datasets is improved by 8.69% and 9.26% respectively. This value for the teacher is 4.82% and 8.33%. Additionally, DDDG outperforms other state-of-the-art algorithms by 5.25% and 2.06% in F1. For practical applications, DDDG is deployed to a "system-on-a-chip"(SoC) in a heterogeneous manner. Employing ARM and FPGA, the designed system accelerates DDDG by 4.09 times than pure software deployment on the same SoC. The efficient model deployments in heterogeneous systems is promising to be applied to practical applications.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001142871800001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Knowledge distillation (KD); Self-supervised Learning (SSL); Masked time autoencoder (MTAE); Teaching others teaches yourself (TOTY); Cardiovascular diseases (CVD)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CLASSIFICATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhang, Huaicheng; Liu, Wenhan; Guo, Qianxi; Shi, Jiguang; Chang, Sheng; Wang, Hao; He, Jin; Huang, Qijun] Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Huang, QJ (corresponding author), Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
zhuaicheng@whu.edu.cn; WHliu@whu.edu.cn; inge_2017@whu.edu.cn; shijig@whu.edu.cn; changsheng@whu.edu.cn; wanghao@whu.edu.cn; zhuaicheng@whu.edu.cn; huangqj@whu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Wuhan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Hao</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5279-3645&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chang, Sheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4875-5501&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Huaicheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6874-5530&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Shi, Jiguang</display_name>&nbsp;</td><td>LDN-4491-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Han</display_name>&nbsp;</td><td>A-5016-2011&nbsp;</td><td>0000-0001-5448-9903&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Huaicheng</display_name>&nbsp;</td><td>KFA-9029-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>EZ9G0</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>81971702&nbsp;</div>
<div>62074116&nbsp;</div>
<div>61874079&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>&lt;B&gt;Acknowledgments&lt;/B&gt; This work was supported by National Natural Science Foundation of China (81971702, 62074116, and 61874079) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 3 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Knowledge-enhanced meta-transfer learning for few-shot ECG signal classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Fan, LL (Fan, Lulu); Chen, BY (Chen, Bingyang); Zeng, XJ (Zeng, Xingjie); Zhou, JH (Zhou, Jiehan); Zhang, X (Zhang, Xin)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>263</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>125764</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2024.125764</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>NOV 2024</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 MAR 5</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>2</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>3</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
12</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
44</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>48</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Electrocardiogram (ECG) classification aims to identify abnormal cardiac activity that may result in severe damage. The challenge lies in the significant variability among individuals and insufficient data of the target subject. Most methods combine meta-learning and transfer learning to overcome the problem of small samples. However, the model may forget the learned transfer knowledge after several fine-tuning steps, resulting in ineffective transfer. In this paper, we propose a method named KEMT-MCAN, which combines Multilevel Cross-Attention Network (MCAN) and Knowledge-Enhanced Meta-Transfer (KEMT) to improve few-shot ECG classification. First, we develop the MCAN to extract foreground and background features from ECG signals during pre-training, which uses cross-attention to capture signal complexity. Second, we design a KEMT framework to introduce limited target auxiliary knowledge for preventing knowledge forgetting. The KEMT leverages a self-learning weighted fusion (SWF) strategy to extend meta-learning for promoting positive transfer. Results from public datasets show that KEMT-MCAN outperforms the current state-of-the-art works by achieving accuracy up to 91.45% and 80.78% in cross-subject and cross-disease scenarios. We also design noise and class imbalance experiments, totaling 12 cases, to simulate real ECG classification. Our method demonstrates excellent generalization, stability, and efficiency. It shows great potential for application in other time-series classification tasks.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001362031200001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Time series signal classification; Multilevel cross-attention network; Knowledge-enhanced meta transfer; Self-learning weighted fusion; ECG diagnosis</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Fan, Lulu] Zhengzhou Univ Sci &amp; Technol, Zhengzhou 450064, Peoples R China. <br>
[Chen, Bingyang] Henan Univ Technol, Coll Informat Sci &amp; Engn, Zhengzhou 450001, Peoples R China. <br>
[Zeng, Xingjie] Southwest Petr Univ, Sch Comp &amp; Informat Technol, Chengdu 163318, Peoples R China. <br>
[Zhou, Jiehan] Shandong Univ Sci &amp; Technol, Coll Comp Sci &amp; Engn, Qingdao 266590, Peoples R China. <br>
[Zhang, Xin] Hong Kong Univ Sci &amp; Technol, Mech &amp; Aerosp Engn, Hong Kong 999077, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Chen, BY (corresponding author), Henan Univ Technol, Coll Informat Sci &amp; Engn, Zhengzhou 450001, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
lulu_f@zit.edu.cn; bingyangchen@haut.edu.cn; zengxj@swpu.edu.cn; jiehan.zhou@ieee.org; mexzyl@ust.hk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Henan University of Technology; Southwest Petroleum University; Shandong University of Science &amp; Technology; Hong Kong University of Science &amp; Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Bingyang</display_name>&nbsp;</td><td>GXV-3240-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Bingyang</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-2415-8780&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Xin</display_name>&nbsp;</td><td>KIE-1710-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhou, Jiehan</display_name>&nbsp;</td><td>AGW-5302-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Fan, Lulu</display_name>&nbsp;</td><td>P-2168-2016&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Xin</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4236-7436&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>N1L5P</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Founda-tion of China</grant_agency>&nbsp;</td><td>
<div>62072469&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Innovative Funds Plan of Henan University of Technology, China</grant_agency>&nbsp;</td><td>
<div>31401698&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The research is supported by the National Natural Science Founda-tion of China (No. 62072469) , and the Innovative Funds Plan of Henan University of Technology, China (No. 31401698) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 4 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Multi-level semantic adaptation for few-shot segmentation on cardiac image sequences</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Guo, SD (Guo, Saidi); Xu, L (Xu, Lin); Feng, C (Feng, Cheng); Xiong, HH (Xiong, Huahua); Gao, ZF (Gao, Zhifan); Zhang, HY (Zhang, Heye)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>73</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>102170</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2021.102170</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>AUG 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>42</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>44</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
46</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>109</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Obtaining manual labels is time-consuming and labor-intensive on cardiac image sequences. Few-shot segmentation can utilize limited labels to learn new tasks. However, it suffers from two challenges: spatial-temporal distribution bias and long-term information bias. These challenges derive from the impact of the time dimension on cardiac image sequences, resulting in serious over-adaptation. In this paper, we propose the multi-level semantic adaptation (MSA) for few-shot segmentation on cardiac image sequences. The MSA addresses the two biases by exploring the domain adaptation and the weight adaptation on the semantic features in multiple levels, including sequence-level, frame-level, and pixel-level. First, the MSA proposes the dual-level feature adjustment for domain adaptation in spatial and temporal directions. This adjustment explicitly aligns the frame-level feature and the sequence-level feature to improve the model adaptation on diverse modalities. Second, the MSA explores the hierarchical attention metric for weight adaptation in the frame-level feature and the pixel-level feature. This metric focuses on the similar frame and the target region to promote the model discrimination on the border features. The extensive experiments demonstrate that our MSA is effective in f ew-shot segmentation on cardiac image sequences with three modalities, i.e. MR, CT, and Echo (e.g. the average Dice is 0.9243), as well as superior to the ten state-of-the-art methods. (c) 2021 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000697062100005</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34380105</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac image sequences; Few-shot segmentation; Domain adaptation; Attention mechanism</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CAROTID-ARTERY WALL; LEFT-VENTRICLE; MODALITY ADAPTATION; DOMAIN ADAPTATION; ATTENTION; NETWORK; MR; QUANTIFICATION; REGRESSION; DIAGNOSIS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Guo, Saidi; Gao, Zhifan; Zhang, Heye] Sun Yat Sen Univ, Sch Biomed Engn, Guangzhou, Peoples R China. <br>
[Xu, Lin] Gen Hosp Southern Theatre Command, PLA, Guangzhou, Guangdong, Peoples R China. <br>
[Xu, Lin] Southern Med Univ, Sch Clin Med 1, Guangzhou, Guangdong, Peoples R China. <br>
[Feng, Cheng] Third Peoples Hosp Shenzhen, Dept Ultrasound, Shenzhen, Guangdong, Peoples R China. <br>
[Xiong, Huahua] Shenzhen Univ, Shenzhen Peoples Hosp 2, Dept Ultrasound, Affiliated Hosp 1, Shenzhen, Guangdong, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Gao, ZF; Zhang, HY (corresponding author), Sun Yat Sen Univ, Sch Biomed Engn, Guangzhou, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
gaozhifan@mail.sysu.edu.cn; zhangheye@mail.sysu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Sun Yat Sen University; Southern Medical University - China; The Third People's Hospital of Shenzhen; Shenzhen University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Heye</display_name>&nbsp;</td><td>JPK-4651-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gao, Zhifan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1576-4439&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>XIONG, HUAHUA</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7468-7130&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xu, Lin</display_name>&nbsp;</td><td>JOK-8307-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>guo, saidi</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2945-2599&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gao, Zhifan</display_name>&nbsp;</td><td>O-9082-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xu, Lin</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7750-8011&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xiong, Huhahua</display_name>&nbsp;</td><td>HGV-0570-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>UR9LU</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>19</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key-Area Research and Development Program of Guangdong Province</grant_agency>&nbsp;</td><td>
<div>2019B010110001&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key Program for International Cooperation Projects of Guangdong Province</grant_agency>&nbsp;</td><td>
<div>2018A050506031&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of Guangdong Province</grant_agency>&nbsp;</td><td>
<div>2020B1515120061&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>U1801265&nbsp;</div>
<div>U1908211&nbsp;</div>
<div>61976222&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guang-dong Natural Science Funds for Distinguished Young Scholar</grant_agency>&nbsp;</td><td>
<div>2019B151502031&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This study was supported in part by the Key-Area Research and Development Program of Guangdong Province (2019B010110 0 01) , in part by the Key Program for International Cooperation Projects of Guangdong Province (2018A050506031) , in part by the Natural Science Foundation of Guangdong Province (2020B1515120061) , in part by the National Natural Science Foundation of China (U1801265 , U1908211 , 61976222) , and in part by the Guang-dong Natural Science Funds for Distinguished Young Scholar (2019B151502031) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 5 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Few-shot transfer learning for personalized atrial fibrillation detection using patient-based siamese network with single-lead ECG records</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Ng, YW (Ng, Yiuwai); Liao, MT (Liao, Min-Tsun); Chen, TL (Chen, Ting-Li); Lee, CK (Lee, Chih-Kuo); Chou, CY (Chou, Cheng-Ying); Wang, WC (Wang, Weichung)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>ARTIFICIAL INTELLIGENCE IN MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>144</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>102644</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.artmed.2023.102644</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>16</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>17</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
7</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
47</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>55</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
The proliferation of wearable devices has allowed the collection of electrocardiogram (ECG) recordings daily to monitor heart rhythm and rate. For example, 24-hour Holter monitors, cardiac patches, and smartwatches are widely used for ECG gathering and application. An automatic atrial fibrillation (AF) detector is required for timely ECG interpretation. Deep learning models can accurately identify AFs if large amounts of annotated data are available for model training. However, it is impractical to request sufficient labels for ECG recordings for an individual patient to train a personalized model. We propose a Siamese-network-based approach for transfer learning to address this issue. A pre-trained Siamese convolutional neural network is created by comparing two labeled ECG segments from the same patient. We sampled 30-second ECG segments with a 50% overlapping window from the ECG recordings of patients in the MIT-BIH Atrial Fibrillation Database. Subsequently, we independently detected the occurrence of AF in each patient in the Long-Term AF Database. By fine-tuning the model with the 1, 3, 5, 7, 9, or 11 ECG segments ranging from 30 to 180 s, our method achieved macro-F1 scores of 96.84%, 96.91%, 96.97%, 97.02%, 97.05%, and 97.07%, respectively.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001123888800001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37783539</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Atrial fibrillation; Arrhythmia detection; Electrocardiogram; Deep learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
TIME-SERIES; HEART-RATE; PROJECTIONS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Ng, Yiuwai; Wang, Weichung] Natl Taiwan Univ, Inst Appl Math Sci, Taipei, Taiwan. <br>
[Liao, Min-Tsun; Lee, Chih-Kuo] Natl Taiwan Univ, Dept Internal Med, Div Cardiol, Hosp Hsin Chu Branch, Hsinchu, Taiwan. <br>
[Liao, Min-Tsun] Natl Taiwan Univ, Coll Med, Dept Internal Med, Taipei, Taiwan. <br>
[Chen, Ting-Li] Acad Sinica, Inst Stat Sci, Taipei, Taiwan. <br>
[Chou, Cheng-Ying] Natl Taiwan Univ, Dept Biomechatron Engn, Taipei, Taiwan. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Wang, WC (corresponding author), Natl Taiwan Univ, Inst Appl Math Sci, Taipei, Taiwan.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
r09946020@ntu.edu.tw; liaomintsun@gmail.com; tlchen@stat.sinica.edu.tw; keitheva2009@gmail.com; chengying@ntu.edu.tw; wwang@ntu.edu.tw</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
National Taiwan University; National Taiwan University; National Taiwan University; Academia Sinica - Taiwan; National Taiwan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>CHOU, CHENG-YING</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5737-6960&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Wen-Ching</display_name>&nbsp;</td><td>ABI-2253-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Ting-Li</display_name>&nbsp;</td><td>AAF-5752-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Ting-Li</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1375-0164&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>LIAO, MIN-TSUN</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6283-6554&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Weichung</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6154-7750&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liao, Min-Tsun</display_name>&nbsp;</td><td>GPG-6828-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>CF7A2</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0933-3657</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-2860</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>ARTIF INTELL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Artif. Intell. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Science and Technology Council, Taiwan</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Center for Theoretical Sciences Mathematics Division</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>All Vista Healthcare Sub-center</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This study was supported by the National Science and Technology Council, Taiwan, MOST All Vista Healthcare Sub-center, and National Center for Theoretical Sciences Mathematics Division. The funding source had no role in study design, data collection, analysis or in-terpretation, report writing, or the decision to submit this paper for publication.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 6 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>ECG synthesis for cardiac arrhythmias: Integrating self-supervised learning and generative adversarial networks</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Simone, L (Simone, Lorenzo); Bacciu, D (Bacciu, Davide); Gervasi, V (Gervasi, Vincenzo)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>ARTIFICIAL INTELLIGENCE IN MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>167</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>103162</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.artmed.2025.103162</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 SEP</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
6</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
6</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>62</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Arrhythmia classifiers relying on supervised deep learning models usually require a substantial amount of labeled clinical data. The distribution of these labels is strictly related to the statistics of cardiovascular diseases among the population, which inherently narrows models' performance for classification tasks. Furthermore, during acquisition and data retrieval from electronic health records, concerns arise regarding patient anonymization due to stringent clinical policies. We introduce a conditional generative architecture for electrocardiography time series, which integrates self-supervision and generative adversarial principles. Empirical validation confirms the enhancement of morphological plausibility in synthetic data, showcasing its effectiveness in generating realistic signals. We propose a novel model (ECGAN), proving its capability of conditioning the probability distribution of ECG recordings. The proposed methodology is assessed upon various rhythm abnormalities including severe congestive heart failure, myocardial infarction, sinus rhythm, and premature ventricular contractions. Our proposed workflow for synthetic time series assessment demonstrates competitive performance compared to state-of-the-art models, achieving an average improvement of 2.4% in arrhythmia classification accuracy across MIT-BIH, BIDMC, and PTB datasets, while ensuring realistic synthetic data and improving training stability.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001504012300001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>40460597</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Generative deep learning; Electrocardiography; Self-supervision; Generative-adversarial networks; Data augmentation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
DYNAMICAL MODEL; COUPLED VAN; MECHANISMS; SIGNALS; IMPACT</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Simone, Lorenzo; Bacciu, Davide; Gervasi, Vincenzo] Univ Pisa, Dept Comp Sci, Largo Bruno Pontecorvo, I-56127 Pisa, Italy. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Simone, L (corresponding author), Univ Pisa, Dept Comp Sci, Largo Bruno Pontecorvo, I-56127 Pisa, Italy.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
lorenzo.simone@di.unipi.it</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Pisa</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bacciu, Davide</display_name>&nbsp;</td><td>A-3904-2013&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Simone, Lorenzo</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5010-7733&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>3MR9T</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0933-3657</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-2860</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>ARTIF INTELL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Artif. Intell. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 7 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Self-Supervised ECG Representation Learning for Emotion Recognition</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Sarkar, P (Sarkar, Pritam); Etemad, A (Etemad, Ali)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON AFFECTIVE COMPUTING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>13</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>3</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>1541-1554</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TAFFC.2020.3014842</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2022 JUL-SEP</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>192</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>214</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
24</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
354</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>54</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
We exploit a self-supervised deep multi-task learning framework for electrocardiogram (ECG) -based emotion recognition. The proposed solution consists of two stages of learning a) learning ECG representations and b) learning to classify emotions. ECG representations are learned by a signal transformation recognition network. The network learns high-level abstract representations from unlabeled ECG data. Six different signal transformations are applied to the ECG signals, and transformation recognition is performed as pretext tasks. Training the model on pretext tasks helps the network learn spatiotemporal representations that generalize well across different datasets and different emotion categories. We transfer the weights of the self-supervised network to an emotion recognition network, where the convolutional layers are kept frozen and the dense layers are trained with labelled ECG data. We show that the proposed solution considerably improves the performance compared to a network trained using fully-supervised learning. New state-of-the-art results are set in classification of arousal, valence, affective states, and stress for the four utilized datasets. Extensive experiments are performed, providing interesting insights into the impact of using a multi-task self-supervised structure instead of a single-task model, as well as the optimum level of difficulty required for the pretext self-supervised tasks.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000849263500030</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiography; Feature extraction; Emotion recognition; Task analysis; Machine learning; Affective computing; Stress; Self-supervised learning; ECG; emotion recognition; multi-task learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
STRESS; CLASSIFICATION; OFFICES</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Sarkar, Pritam; Etemad, Ali] Queens Univ, Dept Elect &amp; Comp Engn, Kingston, ON K7L 3N6, Canada. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Sarkar, P (corresponding author), Queens Univ, Dept Elect &amp; Comp Engn, Kingston, ON K7L 3N6, Canada.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
pritam.sarkar@queensu.ca; ali.etemad@queensu.ca</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Queens University - Canada</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Sarkar, Pritam</display_name>&nbsp;</td><td>AAK-5966-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Sarkar, Pritam</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4000-3604&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Etemad, Ali</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7128-0220&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Cybernetics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>4G5VJ</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1949-3045</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T AFFECT COMPUT</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Affect. Comput.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>14</value>
</td>
</tr>

<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>ESI Highly Cited Paper:</b>

<value>Y</value>
</td>
</tr>

<tr>
<td>
<b>ESI Hot Paper:</b>

<value>N</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 8 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Lead-fusion Barlow twins: A fused self-supervised learning method for multi-lead electrocardiograms</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, WH (Liu, Wenhan); Pan, SR (Pan, Shurong); Li, ZT (Li, Zhoutong); Chang, S (Chang, Sheng); Huang, QJ (Huang, Qijun); Jiang, N (Jiang, Nan)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>INFORMATION FUSION</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>114</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>102698</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.inffus.2024.102698</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>SEP 2024</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 FEB</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
9</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>50</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Nowadays, deep learning depends on large-scale labeled datasets, which limits its broader application in electrocardiogram (ECG) analysis, as manual labeling of ECGs is consistently costly. To overcome this issue, this paper proposes a fused self-supervised learning (SSL) method for multi-lead ECGs: lead-fusion Barlow twins (LFBT). It utilizes unlabeled ECG datasets to pretrain an encoder group using a fused loss. This loss fuses intra-lead and inter-lead BT loss. By employing BT, LFBT avoids the need for additional techniques to prevent trivial solutions (collapse) in pretraining. Moreover, multi-branch concatenation (MBC) fuses information from all leads when transferring pretrained encoders to downstream tasks. According to the experiments, LFBT can extract prior knowledge from unlabeled ECG datasets, making a deep learning model yield comparable performances with its supervised counterpart (trained from scratch) using 3 similar to 5x fewer labels. Furthermore, LFBT is robust when applied to uncurated ECGs from real-world hospitals, with no significant performance decline observed after pretraining. Model interpretation based on gradient-weighted class activation mapping (GradCAM) indicates that LFBT helps models focus on critical waveform changes when training data and labels are insufficient. Compared with previous methods, LFBT demonstrates advantages in performance and implementation. To summarize, LFBT shows considerable potential in reducing the need for manual labeling of ECGs, thereby advancing deep learning applications in real-world ECG-based diagnoses. Code is available at https://github.com/Aiwiscal/ECG_SSL_LFBT.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001320537500001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram (ECG); Self-supervised learning (SSL); Deep learning; Multi-lead fusion</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CONVOLUTIONAL NEURAL-NETWORK; CLASSIFICATION; MORPHOLOGY</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Wenhan; Jiang, Nan] East China Jiaotong Univ, Sch Informat &amp; Software Engn, Nanchang 330013, Peoples R China. <br>
[Pan, Shurong; Chang, Sheng; Huang, Qijun] Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Peoples R China. <br>
[Li, Zhoutong] Shanghai Jiao Tong Univ, Shanghai Peoples Hosp 9, Sch Med, Huangpu Branch, Shanghai 200011, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liu, WH (corresponding author), East China Jiaotong Univ, Sch Informat &amp; Software Engn, Nanchang 330013, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
WHliu@ecjtu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
East China Jiaotong University; Wuhan University; Shanghai Jiao Tong University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chang, Sheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4875-5501&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Theory &amp; Methods</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>H0O9N</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1566-2535</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-6305</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>INFORM FUSION</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Inf. Fusion</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>14</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Founda-tion of China</grant_agency>&nbsp;</td><td>
<div>62062034&nbsp;</div>
<div>62172160&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NationalKey Research and Development Program of China</grant_agency>&nbsp;</td><td>
<div>2022YFB2602200&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Double Thousand Plan of Jiangxi Province</grant_agency>&nbsp;</td><td>
<div>JXSQ2023201010&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Jiangxi Province Key Laboratory ofAdvanced Network Computing</grant_agency>&nbsp;</td><td>
<div>2024SSY03071&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>Acknowledgments This work was supported by National Natural Science Founda-tion of China under Grant No. 62062034 and 62172160, NationalKey Research and Development Program of China under Grant No.2022YFB2602200, Double Thousand Plan of Jiangxi Province underGrant No. JXSQ2023201010 and Jiangxi Province Key Laboratory ofAdvanced Network Computing under Grant No. 2024SSY03071</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 9 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Semi-supervised learning for ECG classification without patient-specific labeled data</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhai, XL (Zhai, Xiaolong); Zhou, ZH (Zhou, Zhanhong); Tin, C (Tin, Chung)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>158</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>113411</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2020.113411</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 NOV 15</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>55</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>58</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
99</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>45</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
In this paper, we propose a semi-supervised learning-based ECG classification system for detection of supraventricular ectopic beats (SVEB or S beats) and ventricular ectopic beats (VEB or V beats) which does not require manual labeling of the patient-specific ECG data. Owing to inter-subject variability in ECG signal, patient-specific data is usually required to achieve good performance in ECG classification system. However, manual labeling of patient-specific data requires expert intervention, which is costly and time consuming. Our proposed system is based on a 2D convolutional neural network (CNN) with inputs generated from heartbeat triplets. The system also consists of two auxiliary modules: a normal beat estimation module and an iterative beat label update algorithm. The normal beat estimation selects a small amount of patient-specific normal beats accurately from the testing ECG record in an unsupervised manner. These estimated normal beats are used, together with a common pool dataset, to train a preliminary patient-specific CNN classifier which provides initial labels for the testing data. These labels then undergo a semi-supervised iterative update process for improved performance. Our proposed system was evaluated on the MIT-BIH arrhythmia database. The training of our proposed system is fully automatic, and its performance is comparable with several state-of-art supervised methods which require extra manual labeling of patient-specific ECG data. Our proposed system can be a useful tool for batch processing a large amount of ECG data in clinical applications. (C) 2020 Elsevier Ltd. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000571732700014</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Semi-supervised learning; Arrhythmia; CNN; ECG classification; Time series signal</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
HEARTBEAT CLASSIFICATION; BEAT CLASSIFICATION; ARRHYTHMIA DETECTION; MORPHOLOGY; FEATURES</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhai, Xiaolong; Zhou, Zhanhong; Tin, Chung] City Univ Hong Kong, Dept Biomed Engn, Hong Kong, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Tin, C (corresponding author), City Univ Hong Kong, Dept Biomed Engn, Hong Kong, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
xzhai9-c@my.cityu.edu.hk; zhzhou7-c@my.cityu.edu.hk; chungtin@cityu.edu.hk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
City University of Hong Kong</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>TIN, Chung</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5337-2578&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tin, Chung</display_name>&nbsp;</td><td>A-4457-2010&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhai, Xiaolong</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3126-7325&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>ZHOU, Zhanhong</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9361-9712&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>NR7HV</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Research Grants Council of Hong Kong SAR</grant_agency>&nbsp;</td><td>
<div>CityU 11213717&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by Research Grants Council of Hong Kong SAR (Project CityU 11213717).</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 10 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>MBSS-T1: Model-based subject-specific self-supervised motion correction for robust cardiac T1 mapping</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Hanania, E (Hanania, Eyal); Zehavi-Lenz, A (Zehavi-Lenz, Adi); Volovik, I (Volovik, Ilya); Link-Sourani, D (Link-Sourani, Daphna); Cohen, I (Cohen, Israel); Freiman, M (Freiman, Moti)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>102</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>103495</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2025.103495</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>FEB 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 MAY</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
3</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>41</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Cardiac T1 mapping is a valuable quantitative MRI technique for diagnosing diffuse myocardial diseases. Traditional methods, relying on breath-hold sequences and cardiac triggering based on an ECG signal, face challenges with patient compliance, limiting their effectiveness. Image registration can enable motion-robust cardiac T1 mapping, but inherent intensity differences between time points pose a challenge. We present MBSST1, a subject-specific self-supervised model for motion correction in cardiac T1 mapping. Physical constraints, implemented through a loss function comparing synthesized and motion-corrected images, enforce signal decay behavior, while anatomical constraints, applied via a Dice loss, ensure realistic deformations. The unique combination of these constraints results in motion-robust cardiac T1 mapping along the longitudinal relaxation axis. Ina 5-fold experiment on a public dataset of 210 patients (STONE sequence) and an internal dataset of 19 patients (MOLLI sequence), MBSS-T1 outperformed baseline deep-learning registration methods. It achieved superior model fitting quality (R2: 0.975 vs. 0.941, 0.946 for STONE; 0.987 vs. 0.982, 0.965 for MOLLI free- breathing; 0.994 vs. 0.993, 0.991 for MOLLI breath-hold), anatomical alignment (Dice: 0.89 vs. 0.84, 0.88 for STONE; 0.963 vs. 0.919, 0.851 for MOLLI free-breathing; 0.954 vs. 0.924, 0.871 for MOLLI breath-hold), and visual quality (4.33 vs. 3.38, 3.66 for STONE; 4.1 vs. 3.5, 3.28 for MOLLI free-breathing; 3.79 vs. 3.15, 2.84 for MOLLI breath-hold). MBSS-T1 enables motion-robust T1 mapping for broader patient populations, overcoming challenges such as suboptimal compliance, and facilitates free-breathing cardiac T1 mapping without requiring large annotated datasets. Our code is available at https://github.com/TechnionComputationalMRILab/MBSST1.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001432441300001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>39987819</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
T1 mapping; Motion correction; Myocardial imaging; Deep learning; Model-based deep learning; Free-breathing MRI</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
IMAGE REGISTRATION; MYOCARDIAL T-1; VOLUME; FRAMEWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Hanania, Eyal; Cohen, Israel] Technion IIT, Fac Elect &amp; Comp Engn, Haifa, Israel. <br>
[Zehavi-Lenz, Adi; Link-Sourani, Daphna; Freiman, Moti] Technion IIT, Fac Biomed Engn, Haifa, Israel. <br>
[Zehavi-Lenz, Adi; Link-Sourani, Daphna; Freiman, Moti] Technion IIT, Fac Biomed Engn, May Blum Dahl MRI Res Ctr, Haifa, Israel. <br>
[Volovik, Ilya] Bnai Zion Med Ctr, Haifa, Israel. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Hanania, E (corresponding author), Technion IIT, Fac Elect &amp; Comp Engn, Haifa, Israel.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
EyalHan@campus.technion.ac.il</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Technion Israel Institute of Technology; Technion Israel Institute of Technology; Technion Israel Institute of Technology; Bnai Zion Medical Center</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cohen, Israel</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-2556-3972&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Freiman, Moti</display_name>&nbsp;</td><td>B-2016-2013&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hanania, Eyal</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5268-8674&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>Y5H8V</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Israel-US Binational Science Foundation</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Israeli Ministry of Science and Technology</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Israel Innovation Authority</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Joint Microsoft Education</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Israel Inter-university Computation Center (IUCC) program</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by research grants from the Israel-US Binational Science Foundation, the Israeli Ministry of Science and Technology, the Israel Innovation Authority, and the joint Microsoft Education and the Israel Inter-university Computation Center (IUCC) program.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 11 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Self-supervised learning for Electrocardiogram classification using Lead Correlation and Decorrelation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, WH (Liu, Wenhan); Pan, SR (Pan, Shurong); Chang, S (Chang, Sheng); Huang, QJ (Huang, Qijun); Jiang, N (Jiang, Nan)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>APPLIED SOFT COMPUTING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>172</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>112871</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.asoc.2025.112871</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>FEB 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
8</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
11</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>41</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
In recent years, the development of deep learning has shown potential in the automatic analysis of electrocardiogram (ECG), aiding cardiologists in detecting cardiovascular diseases (CVDs). Generally, deep learning models depend on numerous labeled ECGs to train, but manual labeling of ECGs is costly as it requires considerable time and expertise. Self-supervised learning (SSL) can solve this problem by pretraining deep learning models with unlabeled ECGs, mitigating their reliance on labeled ECGs. This work proposes lead correlation and decorrelation (LCD) for effective and efficient SSL of ECGs. Concretely, LCD combines intra-lead correlation, inter-lead correlation, intra-lead and inter-lead decorrelation in pretraining. These mechanisms utilize multilead ECG characteristics: intra-lead invariance, inter-lead invariance, inter-lead variance, and intra-lead redundancy. After pretraining, LCD can provide a generic encoder for feature extraction of any ECG lead in a classification task. Benefitting from the effective pretraining mechanism, models with the encoders pretrained by LCD outperform most of the baselines. Compared with the best baseline, they achieve better/comparable classification performances in the same tasks with less pretraining time. Furthermore, LCD helps the models focus on critical features when training with insufficient labeled ECGs, reducing the reliance on labeled ECGs by 4 similar to 6x. All the results demonstrate that LCD is an effective and efficient method, boosting a broader application of deep learning to automatic ECG analysis. The code is available at https://github.com/Aiwiscal/ECG_SSL_LCD.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001429865400001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Self-supervised learning; Deep learning; Electrocardiogram; Representation learning</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Wenhan; Jiang, Nan] East China Jiaotong Univ, Sch Informat &amp; Software Engn, Nanchang 330013, Peoples R China. <br>
[Pan, Shurong; Chang, Sheng; Huang, Qijun] Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liu, WH (corresponding author), East China Jiaotong Univ, Sch Informat &amp; Software Engn, Nanchang 330013, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
WHliu@ecjtu.edu.cn; panshurong@whu.edu.cn; changsheng@whu.edu.cn; huangqj@whu.edu.cn; jiangnan@ecjtu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
East China Jiaotong University; Wuhan University</td>
</tr>

<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>Y1M9G</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1568-4946</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-9681</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>APPL SOFT COMPUT</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Appl. Soft. Comput.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Early Career Young Scientific and Tech-nological Talent Training Program of Jiangxi Province</grant_agency>&nbsp;</td><td>
<div>20244BCE52162&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62062034&nbsp;</div>
<div>62172160&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Devel-opment Program of China</grant_agency>&nbsp;</td><td>
<div>2022YFB2602200&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Double Thousand Plan of Jiangxi Province</grant_agency>&nbsp;</td><td>
<div>JXSQ2023201010&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Jiangxi Province Key Laboratory of Advanced Network Computing</grant_agency>&nbsp;</td><td>
<div>2024SSY03071&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by Early Career Young Scientific and Tech-nological Talent Training Program of Jiangxi Province under Grant No. 20244BCE52162, National Natural Science Foundation of China under Grant No. 62062034 and 62172160, National Key Research and Devel-opment Program of China under Grant No. 2022YFB2602200, Double Thousand Plan of Jiangxi Province under Grant No. JXSQ2023201010 and Jiangxi Province Key Laboratory of Advanced Network Computing under Grant No. 2024SSY03071.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 12 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Explainable cardiac pathology classification on cine MRI with motion characterization by semi-supervised learning of apparent flow</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zheng, Q (Zheng, Qiao); Delingette, H (Delingette, Herve); Ayache, N (Ayache, Nicholas)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>56</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>80-95</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2019.06.001</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2019 AUG</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>67</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>77</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
24</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>45</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
We propose a method to classify cardiac pathology based on a novel approach to extract image derived features to characterize the shape and motion of the heart. An original semi-supervised learning procedure, which makes efficient use of a large amount of non-segmented images and a small amount of images segmented manually by experts, is developed to generate pixel-wise apparent flow between two time points of a 2D+t cine MRI image sequence. Combining the apparent flow maps and cardiac segmentation masks, we obtain a local apparent flow corresponding to the 2D motion of myocardium and ventricular cavities. This leads to the generation of time series of the radius and thickness of myocardial segments to represent cardiac motion. These time series of motion features are reliable and explainable characteristics of pathological cardiac motion. Furthermore, they are combined with shape-related features to classify cardiac pathologies. Using only nine feature values as input, we propose an explainable, simple and flexible model for pathology classification. On ACDC training set and testing set, the model achieves 95% and 94% respectively as classification accuracy. Its performance is hence comparable to that of the state-of-the-art. Comparison with various other models is performed to outline some advantages of our model. (C) 2019 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000480375900007</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>31200290</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac pathology; Classification; Cine MRI; Motion; Deep learning; Semi-supervised learning; Neural network; Apparent flow</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
REGISTRATION; DEMONS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zheng, Qiao; Delingette, Herve; Ayache, Nicholas] Univ Cote dAzur, INRIA, 2004 Route Lucioles, F-06902 Sophia Antipolis, France. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zheng, Q (corresponding author), Univ Cote dAzur, INRIA, 2004 Route Lucioles, F-06902 Sophia Antipolis, France.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
qiao.zheng@inria.fr</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Inria; Universite Cote d'Azur</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Delingette, Herve</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6050-5949&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Delingette, Herve</display_name>&nbsp;</td><td>NOF-5139-2025&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>IP9NC</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>16</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>European Research Council (MedYMA)</grant_agency>&nbsp;</td><td>
<div>ERC-AdG-2011-291080&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The authors acknowledge the partial support from the European Research Council (MedYMA ERC-AdG-2011-291080).</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 13 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>SmartMatch: A semi-supervised framework for obstructive sleep apnea classification using single-lead electrocardiogram signals with limited annotations</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Gayen, S (Gayen, Soumyajit); Rao, NM (Rao, Nalla Maheswara); Sahu, DK (Sahu, Deepak Kumar); Sivaraman, J (Sivaraman, J.); Pal, K (Pal, Kunal); Vasamsetti, S (Vasamsetti, Srikanth); Neelapu, BC (Neelapu, Bala Chakravarthy)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>157</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>111226</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.engappai.2025.111226</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 OCT 1</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
7</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
7</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>50</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Obstructive Sleep Apnea (OSA) is a prevalent respiratory disorder with significant global health implications, affecting individuals of all ages and demographics. This underlines the demand for reliable diagnostic methods and computational models capable of accurately classifying OSA efficiently using single-lead electrocardiogram (ECG) with Limited Annotations. Recent progress in deep learning (DL) techniques, coupled with highperformance computing, has facilitated automatic classification in medical imaging, offering a viable solution for timely diagnosis. However, Traditional supervised learning (SL) requires large, expert-annotated datasets, which are costly and time-intensive to curate, which is a critical bottleneck in resource-constrained settings. To overcome these challenges, we proposed a semi-supervised learning (SSL) framework, SmartMatch. Our SSL framework minimizes reliance on annotated data by effectively leveraging unlabeled ECG signals, reducing annotation burdens while maintaining diagnostic accuracy. The proposed framework is inspired by hierarchical structures observed in real-world scenarios, where leader-follower dynamics play a crucial role in decision-making. Our approach integrates deep metric learning, employing Adaptive batch hard mining to enhance feature representation, alongside an Adaptive pseudo-labeling strategy to refine label quality, and an Adaptive temporal ensembling to stabilize learning while preserving consistency loss constraints. We conducted experiments on the PhysioNet Apnea-ECG repository (PA-ECG) dataset, which comprises 70 overnight recordings. The proposed SmartMatch achieved remarkable performance, yielding high accuracy, precision, recall, and F1-scores of 91.99% (+/- 0.08), 91.98% (+/- 0.10), 91.99% (+/- 0.11), and 91.97% (+/- 0.10) per-segment, respectively. The results highlight SSL's capability to strengthen DL models for OSA detection, particularly in applications involving home sleep apnea testing and wearable IoT devices.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001508289000005</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Adaptive batch hard mining; Adaptive pseudo-labeling; Collaborative knowledge distillation; Deep learning; Obstructive sleep apnea; Semi-supervised learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ALGORITHM</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Gayen, Soumyajit; Rao, Nalla Maheswara; Sahu, Deepak Kumar; Sivaraman, J.; Pal, Kunal; Neelapu, Bala Chakravarthy] Natl Inst Technol Rourkela, Dept Biotechnol &amp; Med Engn, Rourkela 769008, Odisha, India. <br>
[Vasamsetti, Srikanth] CSIR Cent Sci Instruments Org, Chennai 600113, Tamil Nadu, India. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Neelapu, BC (corresponding author), Natl Inst Technol Rourkela, Dept Biotechnol &amp; Med Engn, Biomed Signal &amp; Image Proc Lab, Rourkela 769008, Odisha, India.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
soumyajitgayen98@gmail.com; nallamaheshnitrkl@gmail.com; deepakkusahu13@gmail.com; jsiva@nitrkl.ac.in; palk@nitrkl.ac.in; srikanth.vasamsetti@csio.res.in; neelapubc@nitrkl.ac.in</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
National Institute of Technology (NIT System); National Institute of Technology Rourkela; Council of Scientific &amp; Industrial Research (CSIR) - India; CSIR - Central Scientific Instruments Organisation (CSIO)</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gayen, Soumyajit</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0009-8844-8136&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Sahu, Deepak kumar</display_name>&nbsp;</td><td>GMX-1850-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Automation &amp; Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Automation &amp; Control Systems; Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>3SZ6Q</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0952-1976</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6769</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>ENG APPL ARTIF INTEL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Eng. Appl. Artif. Intell.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>18</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Indian Council of Medical Research (ICMR), Government of India</grant_agency>&nbsp;</td><td>
<div>2021-10018&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work is supported by the Indian Council of Medical Research (ICMR) under the project grant number 2021-10018, Government of India. This research was conducted in the Biomedical Signal and Image Processing Laboratory, Department of Biotechnology and Medical Engineering, National Institute of Technology Rourkela, Odisha, India.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 14 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Inter-patient ECG arrhythmia heartbeat classification based on unsupervised domain adaptation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wang, GJ (Wang, Guijin); Chen, M (Chen, Ming); Ding, ZJ (Ding, Zijian); Li, JW (Li, Jiawei); Yang, HZ (Yang, Huazhong); Zhang, P (Zhang, Ping)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>NEUROCOMPUTING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>454</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>339-349</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.neucom.2021.04.104</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>MAY 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 SEP 24</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>52</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>55</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
8</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
150</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>33</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Electrocardiography (ECG) arrhythmia heartbeat classification is essential for automatic cardiovascular diagnosis system. However, the enormous differences of ECG signals among individuals and high price of labeled data have brought huge challenges for current classification algorithms based on deep neural networks and prevented these models from achieving satisfactory performance on new data. In order to build a classification system with better adaptability, we propose a novel Domain-Adaptative ECG Arrhythmia Classification (DAEAC) model based on convolutional network and unsupervised domain adaptation (UDA). Based on observation of clustering characteristics of data, we present two original objective functions to enhance the inter-patient performance. A Cluster-Aligning loss is presented to align the distributions of training data and test data. Simultaneously, a Cluster-Maintaining loss is proposed to reinforce the discriminability and structural information of features. The proposed method requires no expert annotations but a short period of unsupervised data in new records to make deep models more adaptive. Extensive experimental results on three public databases demonstrate that our method achieves competitive performance with other state-of-the-arts on the detection of ventricular ectopic beats (V), supraventricular ectopic beats (S) and fusion beats (F). The cross-dataset experimental results also verify the great generalization capability. CO 2021 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000672468800008</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
ECG heartbeat classification; Deep learning; Unsupervised domain adaptation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CONVOLUTIONAL NEURAL-NETWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wang, Guijin; Chen, Ming; Ding, Zijian; Li, Jiawei; Yang, Huazhong] Tsinghua Univ, Beijing, Peoples R China. <br>
[Wang, Guijin; Yang, Huazhong] Beijing Innovat Ctr Future Chips ICFC, Beijing, Peoples R China. <br>
[Zhang, Ping] Beijing Tsinghua Changgung Hosp, Beijing, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Wang, GJ (corresponding author), Tsinghua Univ, Beijing, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
wangguijin@tsinghua.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Tsinghua University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Ping</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9163-6191&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>huang, yinshan</display_name>&nbsp;</td><td>JRX-4534-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Ping</display_name>&nbsp;</td><td>HPG-6977-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>TI0KA</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0925-2312</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-8286</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>NEUROCOMPUTING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Neurocomputing</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Program of China</grant_agency>&nbsp;</td><td>
<div>2017YFB1401804&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing National Research Center for Information Science and Technology</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Innovation Center for Future Chip</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work is partially funded by the National Key Research and Development Program of China (2017YFB1401804). We also appreciate the support from Beijing National Research Center for Information Science and Technology and Beijing Innovation Center for Future Chip.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 15 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Cross-database and cross-channel electrocardiogram arrhythmia heartbeat classification based on unsupervised domain adaptation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Imtiaz, MN (Imtiaz, Md. Niaz); Khan, N (Khan, Naimul)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>244</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>122960</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2023.122960</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>DEC 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 JUN 15</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>10</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
33</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>36</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
The classification of electrocardiogram (ECG) plays a crucial role in the development of an automatic cardiovascular diagnostic system. However, the considerable variances in ECG signals between individuals pose a significant challenge. Changes in data distribution limit cross-domain utilization of a model. In this study, we propose a solution to classify ECG in an unlabeled dataset by leveraging knowledge obtained from labeled source domain. We present a domain-adaptive deep network based on cross-domain feature discrepancy optimization. Our method comprises three stages: pre-training, cluster-centroid computing, and adaptation. In pre-training, we employ a Distributionally Robust Optimization (DRO) technique to deal with the vanishing worst-case training loss. To enhance the richness of the features, we concatenate three temporal features with the deep learning features. The cluster computing stage involves computing centroids of distinctly separable clusters for the source using true labels, and for the target using confident predictions. We propose a novel technique for selecting confident predictions in the target domain. In the adaptation stage, we minimize compacting loss within the same cluster, separating loss across different clusters, inter-domain cluster discrepancy loss, and running combined loss to produce a domain-robust model. Experiments conducted in both cross-domain and cross-channel paradigms show the efficacy of the proposed method. Our method achieves superior performance compared to other state-of-the-art approaches in detecting ventricular ectopic beats (V), supraventricular ectopic beats (S), and fusion beats (F). Our method achieves an average improvement of 11.78% in overall accuracy over the non-domain-adaptive baseline method on the three test datasets.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001145786300001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram (ECG); Unsupervised domain adaptation; Arrhythmia heartbeat classification; Deep learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CONVOLUTIONAL NEURAL-NETWORK; RECOGNITION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Imtiaz, Md. Niaz; Khan, Naimul] Toronto Metropolitan Univ, Dept Elect Comp &amp; Biomed Engn, 350 Victoria St, Toronto, ON M5B 2K3, Canada. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Imtiaz, MN (corresponding author), Toronto Metropolitan Univ, Dept Elect Comp &amp; Biomed Engn, 350 Victoria St, Toronto, ON M5B 2K3, Canada.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
niaz.imtiaz@torontomu.ca; n77khan@torontomu.ca</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Toronto Metropolitan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Imtiaz, Md Niaz</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3056-6756&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>FK9B2</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Sciences and Engineering Research Council of Canada (NSERC)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>New Frontiers in Research Fund (NFRF), Canada</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The authors would like to thank the Natural Sciences and Engineering Research Council of Canada (NSERC) and the New Frontiers in Research Fund (NFRF), Canada for providing financial support.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 16 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Inter-Patient ECG Classification with I-Vector Based Unsupervised Patient Adaptation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Xu, SS (Xu, Sean Shensheng); Mak, MW (Mak, Man-Wai); Chang, CQ (Chang, Chunqi)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>210</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>118410</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2022.118410</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>AUG 2022</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2022 DEC 30</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
50</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>41</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This paper proposes an unsupervised patient adaptation approach to creating patient-specific deep neural network (DNN) classifiers for inter-patient ECG classification. The method exploits the information embedded in the patient-specific i-vectors derived from some unlabeled patient-specific ECG. The adaptation process comprises two stages of backpropagation (BP) fine-tuning, using the i-vector of a target patient as an auxiliary input to a middle layer of the DNN. In the first stage, labeled ECG data from a general population are used for creating a patient-adaptive DNN. Then, in the second stage, unlabeled ECG data from the target patient are used for further BP fine-tuning, using the labels hypothesized by the patient-adaptive DNN as the desired outputs. To ensure that only reliable data are used for adaptation, an information-theoretic heartbeat selector is employed to select the patients' ECG with high-confidence hypothesized labels. Evaluations on the MIT-BIH arrhythmia dataset show that the proposed unsupervised adaptation leads to patient-specific ECG classifiers that outperform existing patient-specific models. The classifiers also perform comparably to patient-specific models obtained via supervised adaption. This unsupervised adaptation approach can fully automate patient adaptation, making personalized ECG classification more practical.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000880668000007</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Unsupervised adaptation; Patient-specific i-vectors; Arrhythmia; ECG classification; DNN adaptation</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Xu, Sean Shensheng; Chang, Chunqi] Shenzhen Univ, Hlth Sci Ctr, Sch Biomed Engn, Shenzhen 518060, Peoples R China. <br>
[Xu, Sean Shensheng; Mak, Man-Wai] Hong Kong Polytech Univ, Dept Elect &amp; Informat Engn, Hong Kong, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Chang, CQ (corresponding author), Shenzhen Univ, Hlth Sci Ctr, Sch Biomed Engn, Shenzhen 518060, Peoples R China.<br>Mak, MW (corresponding author), Hong Kong Polytech Univ, Dept Elect &amp; Informat Engn, Hong Kong, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
sean.xu@connect.polyu.hk; enmwmak@polyu.edu.hk; cqchang@szu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Shenzhen University; Hong Kong Polytechnic University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chang, Chunqi</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1172-6491&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Mak, Man-Wai</display_name>&nbsp;</td><td>C-3750-2014&nbsp;</td><td>0000-0001-8854-3760&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Mak, Manwai</display_name>&nbsp;</td><td>C-3750-2014&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chang, CQ</display_name>&nbsp;</td><td>C-1845-2009&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>6A5AJ</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>23</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Na-tional Natural Science Foundation of China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shenzhen-Hong Kong Institute of Brain Science-Shenzhen Fundamental Research Institutions</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>&nbsp;</td><td>
<div>61971371&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>&nbsp;</td><td>
<div>61971289&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>&nbsp;</td><td>
<div>2019SHIBS0003&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was in part supported by National Natural Science Foundation of China under Grant 61971371, Na-tional Natural Science Foundation of China under Grant 61971289, and Shenzhen-Hong Kong Institute of Brain Science-Shenzhen Fundamental Research Institutions under Grant 2019SHIBS0003. Part of the work was done when S.S. Xu was the PostDoc Fellow at The Hong Kong Polytechnic University.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 17 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Adversarial Spatiotemporal Contrastive Learning for Electrocardiogram Signals</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wang, N (Wang, Ning); Feng, PP (Feng, Panpan); Ge, ZY (Ge, Zhaoyang); Zhou, YJ (Zhou, Yanjie); Zhou, B (Zhou, Bing); Wang, ZM (Wang, Zongmin)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>35</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>10</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>13845-13859</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TNNLS.2023.3272153</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JUL 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>19</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>20</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
6</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
62</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>62</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Extracting invariant representations in unlabeled electrocardiogram (ECG) signals is a challenge for deep neural networks (DNNs). Contrastive learning is a promising method for unsupervised learning. However, it should improve its robustness to noise and learn the spatiotemporal and semantic representations of categories, just like cardiologists. This article proposes a patient-level adversarial spatiotemporal contrastive learning (ASTCL) framework, which includes ECG augmentations, an adversarial module, and a spatiotemporal contrastive module. Based on the ECG noise attributes, two distinct but effective ECG augmentations, ECG noise enhancement, and ECG noise denoising, are introduced. These methods are beneficial for ASTCL to enhance the robustness of the DNN to noise. This article proposes a self-supervised task to increase the antiperturbation ability. This task is represented as a game between the discriminator and encoder in the adversarial module, which pulls the extracted representations into the shared distribution between the positive pairs to discard the perturbation representations and learn the invariant representations. The spatiotemporal contrastive module combines spatiotemporal prediction and patient discrimination to learn the spatiotemporal and semantic representations of categories. To learn category representations effectively, this article only uses patient-level positive pairs and alternately uses the predictor and the stop-gradient to avoid model collapse. To verify the effectiveness of the proposed method, various groups of experiments are conducted on four ECG benchmark datasets and one clinical dataset compared with the state-of-the-art methods. Experimental results showed that the proposed method outperforms the state-of-the-art methods.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001030681200001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37432818</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
~Adversarial learning; contrastive learning; data augmentation; electrocardiogram (ECG)</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wang, Ning; Feng, Panpan; Ge, Zhaoyang; Zhou, Bing; Wang, Zongmin] Zhengzhou Univ, Sch Comp &amp; Artificial Intelligence, Zhengzhou 450000, Peoples R China. <br>
[Zhou, Yanjie] Zhengzhou Univ, Sch Management, Zhengzhou 450000, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhou, YJ (corresponding author), Zhengzhou Univ, Sch Management, Zhengzhou 450000, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
wning@ha.edu.cn; ieyjzhou@zzu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Zhengzhou University; Zhengzhou University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhou, Bing</display_name>&nbsp;</td><td>X-2659-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>ZHOU, BING</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3446-3903&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Hardware &amp; Architecture; Computer Science, Theory &amp; Methods; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>K5W4Q</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2162-237X</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2162-2388</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T NEUR NET LEAR</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Neural Netw. Learn. Syst.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Program of China</grant_agency>&nbsp;</td><td>
<div>2017YFB1401200&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key Research, Development, and Dissemination Program of Henan Province (Science and Technology for the People)</grant_agency>&nbsp;</td><td>
<div>182207310002&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key Science and Technology Project of Xinjiang Production and Construction Corps</grant_agency>&nbsp;</td><td>
<div>2018AB017&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>&amp; nbsp;This work was supported in part by the National Key Research and Development Program of China under Grant 2017YFB1401200, in part by the Key Research, Development, and Dissemination Program of Henan Province (Science and Technology for the People) under Grant 182207310002, and in part by the Key Science and Technology Project of Xinjiang Production and Construction Corps under Grant 2018AB017.&amp; nbsp;</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 18 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Sparse representation of ECG signals for automated recognition of cardiac arrhythmias</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Raj, S (Raj, Sandeep); Ray, KC (Ray, Kailash Chandra)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>105</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>49-64</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2018.03.038</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2018 SEP 1</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>105</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>114</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
103</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>59</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
As per the report of the World Health Organization (WHO), the mortalities due to cardiovascular diseases (CVDs) have increased to 50 million worldwide. Therefore, it is essential to have an efficient diagnosis of CVDs to enhance the healthcare in the clinical cardiovascular domain. The ECG signal analysis of a patient is a very popular tool to perform diagnosis of CVDs. However, due to the non-stationary nature of ECG signal and higher computational burden of the existing signal processing methods, the automated and efficient diagnosis remains a challenge.
<br>This paper presents a new feature extraction method using the sparse representation technique to efficiently represent the different ECG signals for efficient analysis. The sparse method decomposes an ECG signal into elementary waves using an overcomplete gabor dictionary. Four features such as time delay, frequency, width parameter, and square of expansion coefficient are extracted from each of the significant atoms of the dictionary. These features are concatenated and analyzed to determine the optimal length of discriminative feature vector representing each of the ECG signal. These extracted features representing the ECG signals are further classified using machine learning techniques such as least-square twin SVM, k-NN, PNN, and RBFNN. Further, the learning parameters of the classifiers are optimized using ABC and PSO techniques. The experiments are carried out for the proposed methods (i.e. feature extraction along with all classifiers) using benchmark MIT-BIH data and evaluated under category and personalized analysis schemes.
<br>Experimental results show that the proposed ECG signal representation using sparse decomposition technique with PSO optimized least-square twin SVM (best classifier model among k-NN, PNN and RBFNN) reported higher classification accuracy of 99.11% in category and 89.93% in personalized schemes respectively than the existing methods to the state-of-art diagnosis. (C) 2018 Elsevier Ltd. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000432501900005</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram signal; Sparse representation; Overcomplete dictionary; Least-square twin support vector machines; Artificial bee colony; Particle swarm optimization</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NEURAL-NETWORK; HEARTBEAT CLASSIFICATION; BEAT CLASSIFICATION; TIME; DIAGNOSIS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Raj, Sandeep; Ray, Kailash Chandra] Indian Inst Technol Patna, Dept Elect Engn, Bihta 801103, India. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Raj, S (corresponding author), Indian Inst Technol Patna, Dept Elect Engn, Bihta 801103, India.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
srp@iitp.ac.in; kcr@iitp.ac.in</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Indian Institute of Technology (IIT) - Patna</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Raj, Sandeep</display_name>&nbsp;</td><td>G-5779-2018&nbsp;</td><td>0000-0001-6769-5589&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ray, Kc</display_name>&nbsp;</td><td>JLK-9098-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>GG2ED</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>16</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Department of Science and Technology, Government of India under DST-INSPIRE Fellowship Scheme</grant_agency>&nbsp;</td><td>
<div>IF 120841&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The authors acknowledge the Department of Science and Technology, Government of India for sponsoring this research work (IF 120841) under DST-INSPIRE Fellowship Scheme.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 19 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>CMRVAE: Contrastive margin-restrained variational auto-encoder for class-separated domain adaptation in cardiac segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Qiao, LH (Qiao, Lihong); Wang, R (Wang, Rui); Shu, YC (Shu, Yucheng); Xiao, B (Xiao, Bin); Xu, XD (Xu, Xidong); Li, BB (Li, Baobin); Yang, L (Yang, Le); Li, WS (Li, Weisheng); Gao, XB (Gao, Xinbo); Lei, BY (Lei, Baiying)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>KNOWLEDGE-BASED SYSTEMS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>304</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>112412</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.knosys.2024.112412</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>SEP 2024</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 NOV 25</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>4</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>4</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
6</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
21</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>48</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Unsupervised Domain Adaptation (UDA) is a promising strategy for representing unlabeled data through domain alignment. Nonetheless, a considerable number of whole-domain alignment techniques often neglect the essential interconnections between pixels and patches across distinct domains that exhibit analogous semantic characteristics. This oversight can hinder their ability to manage semantic variations across domains and to create a discriminative embedding for different classes, ultimately leading to reduced discrimination and poor generalization. This paper presents a novel UDA method for medical image analysis, termed CMRVAE. The proposed method is composed of a margin-restrained variational auto-encoder (MR-VAE) and a class-separation patch-level manifold clustering (CPMC) module. The MR-VAE embeds an adaptive margin-based enhancement technique through an innovative variational inference for optimal encoder mapping in UDA. The CPMC module integrates multi-granularity class information into the manifold for improved preparatory work before UDA. Experimental results on three cardiac datasets show that the proposed method achieves substantially enhanced accuracy compared to the state-of-the-art unsupervised approaches.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001308987700001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac segmentation; Unsupervised domain adaptation; Variational auto-encoder; Contrastive learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
IMAGE</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Qiao, Lihong; Shu, Yucheng; Xiao, Bin; Li, Weisheng; Gao, Xinbo] Chongqing Univ Posts &amp; Telecommun, Dept Chongqing Key Lab Computat Intelligence, Chongqing 400065, Peoples R China. <br>
[Wang, Rui; Xu, Xidong] Chongqing Univ Posts &amp; Telecommun, Dept Comp Sci, Chongqing, Peoples R China. <br>
[Qiao, Lihong] Chongqing Big Data Collaborat Innovat Ctr, Chongqing 401135, Peoples R China. <br>
[Li, Baobin] Univ Chinese Acad Sci, Sch Comp Sci &amp; Technol, Wuhan, Peoples R China. <br>
[Wang, Rui; Yang, Le] Hangzhou Changwang Intelligent Innovat Technol Co, Hangzhou, Peoples R China. <br>
[Lei, Baiying] Shenzhen Univ, Sch Biomed Engn, Natl Reg Key Technol Engn Lab Med Ultrasound, Guangdong Key Lab Biomed Measurements &amp; Ultrasound, Shenzhen, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Shu, YC (corresponding author), Chongqing Univ Posts &amp; Telecommun, Dept Chongqing Key Lab Computat Intelligence, Chongqing 400065, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
qiaolh@cqupt.edu.cn; s210201096@stu.cqupt.edu.cn; shuyc@cqupt.edu.cn; xiaobin@cqupt.edu.cn; s230233049@stu.cqupt.edu.cn; libb@ucas.ac.cn; leiby@szu.edu.cn; libb@ucas.ac.cn; gaoxb@cqupt.edu.cn; leiby@szu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Chongqing University of Posts &amp; Telecommunications; Chongqing University of Posts &amp; Telecommunications; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Shenzhen University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lei, Baiying</display_name>&nbsp;</td><td>A-8567-2013&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xiao, Bin</display_name>&nbsp;</td><td>AAD-5373-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>gao, xin</display_name>&nbsp;</td><td>OGO-6492-2025&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>F3P9K</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0950-7051</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-7409</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>KNOWL-BASED SYST</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Knowledge-Based Syst.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Project, China</grant_agency>&nbsp;</td><td>
<div>2019YFE0110800&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62276040&nbsp;</div>
<div>62276041&nbsp;</div>
<div>62221005&nbsp;</div>
<div>61976031&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research Instrument Development Program, China</grant_agency>&nbsp;</td><td>
<div>62027827&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Chongqing Education Commission Science and Technology Research Project, China</grant_agency>&nbsp;</td><td>
<div>KJQN202200624&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Chongqing Big Data Collaborative Innovation Center Funding</grant_agency>&nbsp;</td><td>
<div>CQBDCIC202303&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This research was partially funded by the National Key Research and Development Project, China (Grant 2019YFE0110800) , the National Natural Science Foundation of China (Grants 62276040, 62276041, 62221005 and 61976031) and the National Key Research Instrument Development Program, China (Grant 62027827) , Chongqing Education Commission Science and Technology Research Project, China (Grant KJQN202200624) , Chongqing Big Data Collaborative Innovation Center Funding, CQBDCIC202303.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 20 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Open-world electrocardiogram classification via domain knowledge-driven contrastive learning</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhou, S (Zhou, Shuang); Huang, X (Huang, Xiao); Liu, NH (Liu, Ninghao); Zhang, W (Zhang, Wen); Zhang, YT (Zhang, Yuan-Ting); Chung, FL (Chung, Fu-Lai)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>NEURAL NETWORKS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>179</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>106551</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.neunet.2024.106551</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JUL 2024</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 NOV</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>2</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>2</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
17</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
64</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>88</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Automatic electrocardiogram (ECG) classification provides valuable auxiliary information for assisting disease diagnosis and has received much attention in research. The success of existing classification models relies on fitting the labeled samples for every ECG type. However, in practice, well-annotated ECG datasets usually cover only limited ECG types. It thus raises an issue: conventional classification models trained with limited ECG types can only identify those ECG types that have already been observed in the training set, but fail to recognize unseen (or unknown) ECG types that exist in the wild and are not included in training data. In this work, we investigate an important problem called open-world ECG classification that can predict finegrained observed ECG classes and identify unseen classes. Accordingly, we propose a customized method that first incorporates clinical knowledge into contrastive learning by generating "hard negative"samples to guide learning diagnostic ECG features (i.e., distinguishable representations), and then performs multihypersphere learning to learn compact ECG representations for classification. The experiment results on 12-lead ECG datasets (CPSC2018, PTB-XL, and Georgia) demonstrate that the proposed method outperforms the state-of-the-art methods. Specifically, our method achieves superior accuracy than the comparative methods on the unseen ECG class and certain seen classes. Overall, the investigated problem (i.e., open- world ECG classification) helps to draw attention to the reliability of automatic ECG diagnosis, and the proposed method is proven effective in tackling the challenges. The code and datasets are released at https://github.com/betterzhou/Open_World_ECG_Classification.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001283682600001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>39068675</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
ECG classification; Open-world learning; Contrastive learning; Domain knowledge; Deep learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ARRHYTHMIA DETECTION; NEURAL-NETWORK; ECG; TRANSFORMATIONS; SIGNAL; MODEL</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhou, Shuang; Huang, Xiao; Chung, Fu-Lai] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China. <br>
[Liu, Ninghao] Univ Georgia, Dept Comp Sci, Athens, GA USA. <br>
[Zhang, Wen] Huazhong Agr Univ, Coll Informat, Wuhan, Peoples R China. <br>
[Zhang, Yuan-Ting] Chinese Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Chung, FL (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
shuang.zhou@connect.polyu.hk; korris.chung@polyu.edu.hk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Hong Kong Polytechnic University; University System of Georgia; University of Georgia; Huazhong Agricultural University; Chinese University of Hong Kong</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhou, Shuang</display_name>&nbsp;</td><td>KMY-7627-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>, Shuang Zhou</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5739-1637&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Huang, Xiao</display_name>&nbsp;</td><td>AAG-8302-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Huang, Xiao</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3867-900X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Yuan-Ting</display_name>&nbsp;</td><td>F-1759-2013&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Wen</display_name>&nbsp;</td><td>NOF-2036-2025&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Neurosciences</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Neurosciences &amp; Neurology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>A6N4W</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0893-6080</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-2782</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>NEURAL NETWORKS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Neural Netw.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>16</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>PolyU (UGC)</grant_agency>&nbsp;</td><td>
<div>P0030970&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the grant of DaSAIL under Grant P0030970 funded by PolyU (UGC) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 21 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Unlocking the diagnostic potential of electrocardiograms through information transfer from cardiac magnetic resonance imaging</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Turgut,&Ouml; (Turgut, Ozgun); M&uuml;ller, P (Mueller, Philip); Hager, P (Hager, Paul); Shit, S (Shit, Suprosanna); Starck, S (Starck, Sophie); Menten, MJ (Menten, Martin J.); Martens, E (Martens, Eimo); Rueckert, D (Rueckert, Daniel)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>101</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>103451</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2024.103451</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JAN 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 APR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
8</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>73</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Cardiovascular diseases (CVD) can be diagnosed using various diagnostic modalities. The electrocardiogram (ECG) is a cost-effective and widely available diagnostic aid that provides functional information of the heart. However, its ability to classify and spatially localise CVD is limited. In contrast, cardiac magnetic resonance (CMR) imaging provides detailed structural information of the heart and thus enables evidence- based diagnosis of CVD, but long scan times and high costs limit its use in clinical routine. In this work, we present a deep learning strategy for cost-effective and comprehensive cardiac screening solely from ECG. Our approach combines multimodal contrastive learning with masked data modelling to transfer domain-specific information from CMR imaging to ECG representations. In extensive experiments using data from 40,044 UK Biobank subjects, we demonstrate the utility and generalisability of our method for subject-specific risk prediction of CVD and the prediction of cardiac phenotypes using only ECG data. Specifically, our novel multimodal pre-training paradigm improves performance by up to 12.19% for risk prediction and 27.59% for phenotype prediction. Ina qualitative analysis, we demonstrate that our learned ECG representations incorporate information from CMR image regions of interest. Our entire pipeline is publicly available at https://github.com/oetu/MMCL-ECG-CMR.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001409219400001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>39793216</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram; Cardiac magnetic resonance imaging; Multimodal contrastive learning; Masked data modelling; Self-supervised learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
DIABETES-MELLITUS; HEART-FAILURE; SEGMENTATION; DYSFUNCTION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Turgut, Ozgun; Mueller, Philip; Hager, Paul; Starck, Sophie; Menten, Martin J.; Rueckert, Daniel] Tech Univ Munich, Sch Computat Informat &amp; Technol, Munich, Germany. <br>
[Turgut, Ozgun; Mueller, Philip; Hager, Paul; Starck, Sophie; Martens, Eimo; Rueckert, Daniel] Tech Univ Munich, Sch Med, Klinikum Rechts Isar, Munich, Germany. <br>
[Shit, Suprosanna] Univ Zurich, Dept Quant Biomed, Zurich, Switzerland. <br>
[Menten, Martin J.; Rueckert, Daniel] Munich Ctr Machine Learning, Munich, Germany. <br>
[Menten, Martin J.; Rueckert, Daniel] Imperial Coll London, Dept Comp, London, England. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Turgut,&Ouml; (corresponding author), Tech Univ Munich, Sch Computat Informat &amp; Technol, Munich, Germany.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
oezguen.turgut@tum.de</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Technical University of Munich; Technical University of Munich; University of Zurich; Imperial College London</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>M&uuml;ller, Philip</display_name>&nbsp;</td><td>HOH-3993-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hager, Paul</display_name>&nbsp;</td><td>KVZ-2285-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Shit, Suprosanna</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4435-7207&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Rueckert, Daniel</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5683-5889&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Menten, Martin</display_name>&nbsp;</td><td>JAO-3681-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Shit, Suprosanna</display_name>&nbsp;</td><td>AET-7423-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Martens, Eimo</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5801-0901&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hager, Paul</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2166-0262&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Martens, Eimo</display_name>&nbsp;</td><td>AAX-3975-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Turgut, Ozgun</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0002-8704-0277&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Muller, Philip</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-8186-6479&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>U1B0L</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>UK Biobank Resource</grant_agency>&nbsp;</td><td>
<div>87802&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This research has been conducted using the UK Biobank Resource under Application Number 87802.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>hybrid</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 22 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Super-Resolution of Cardiac MR Cine Imaging using Conditional GANs and Unsupervised Transfer Learning</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Xia, Y (Xia, Yan); Ravikumar, N (Ravikumar, Nishant); Greenwood, JP (Greenwood, John P.); Neubauer, S (Neubauer, Stefan); Petersen, SE (Petersen, Steffen E.); Frangi, AF (Frangi, Alejandro F.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>71</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>102037</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2021.102037</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>APR 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 JUL</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>46</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>50</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
39</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>60</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
High-resolution (HR), isotropic cardiac Magnetic Resonance (MR) cine imaging is challenging since it requires long acquisition and patient breath-hold times. Instead, 2D balanced steady-state free precession (SSFP) sequence is widely used in clinical routine. However, it produces highly-anisotropic image stacks, with large through-plane spacing that can hinder subsequent image analysis. To resolve this, we propose a novel, robust adversarial learning super-resolution (SR) algorithm based on conditional generative adversarial nets (GANs), that incorporates a state-of-the-art optical flow component to generate an auxiliary image to guide image synthesis. The approach is designed for real-world clinical scenarios and requires neither multiple low-resolution (LR) scans with multiple views, nor the corresponding HR scans, and is trained in an end-to-end unsupervised transfer learning fashion. The designed framework effectively incorporates visual properties and relevant structures of input images and can synthesise 3D isotropic, anatomically plausible cardiac MR images, consistent with the acquired slices. Experimental results show that the proposed SR method outperforms several state-of-the-art methods both qualitatively and quantitatively. We show that subsequent image analyses including ventricle segmentation, cardiac quantification, and non-rigid registration can benefit from the super-resolved, isotropic cardiac MR images, to produce more accurate quantitative results, without increasing the acquisition time. The average Dice similarity coefficient (DSC) for the left ventricular (LV) cavity and myocardium are 0.95 and 0.81, respectively, between real and synthesised slice segmentation. For non-rigid registration and motion tracking through the cardiac cycle, the proposed method improves the average DSC from 0.75 to 0.86, compared to the original resolution images.
<br>(c) 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ )</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000663615600008</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33910110</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac MRI; Deep learning; Super-resolution; Conditional generative adversarial net; Optical flow; Conditional batch normalisation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CARDIOVASCULAR MAGNETIC-RESONANCE; UK BIOBANK; RESOLUTION; RATIONALE; DESIGN</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Xia, Yan; Ravikumar, Nishant; Frangi, Alejandro F.] Univ Leeds, Sch Comp, Ctr Computat Imaging &amp; Simulat Technol Biomed CIS, Leeds, W Yorkshire, England. <br>
[Xia, Yan; Ravikumar, Nishant; Greenwood, John P.; Frangi, Alejandro F.] Univ Leeds, Sch Med, Leeds Inst Cardiovasc &amp; Metab Med LICAMM, Leeds, W Yorkshire, England. <br>
[Neubauer, Stefan] Univ Oxford, John Radcliffe Hosp, Div Cardiovasc Med, Oxford Ctr Clin Magnet Resonance Res, Oxford, England. <br>
[Petersen, Steffen E.] Queen Mary Univ London, NIHR Barts Biomed Res Ctr, William Harvey Res Inst, London, England. <br>
[Petersen, Steffen E.] Barts Hlth NHS Trust, St Bartholomews Hosp, Barts Heart Ctr, London, England. <br>
[Frangi, Alejandro F.] Katholieke Univ Leuven, Cardiovasc Sci Dept, Med Imaging Res Ctr MIRC, Leuven, Belgium. <br>
[Frangi, Alejandro F.] Katholieke Univ Leuven, Dept Elect Engn, Med Imaging Res Ctr MIRC, Leuven, Belgium. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Xia, Y (corresponding author), Univ Leeds, Sch Comp, Ctr Computat Imaging &amp; Simulat Technol Biomed CIS, Leeds, W Yorkshire, England.<br>Xia, Y (corresponding author), Univ Leeds, Sch Med, Leeds Inst Cardiovasc &amp; Metab Med LICAMM, Leeds, W Yorkshire, England.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
y.xia@leeds.ac.uk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Leeds; University of Leeds; University of Oxford; University of London; Queen Mary University London; Barts Health NHS Trust; University of London; Queen Mary University London; KU Leuven; KU Leuven</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Neubauer, Stefan</display_name>&nbsp;</td><td>B-8448-2011&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Neubauer, Stefan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9017-5645&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Frangi, Alejandro</display_name>&nbsp;</td><td>C-6500-2008&nbsp;</td><td>0000-0002-2675-528X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Greenwood, John</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-2861-0914&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ravikumar, Nishant</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0134-107X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Petersen, Steffen</display_name>&nbsp;</td><td>A-8389-2011&nbsp;</td><td>0000-0003-4622-5160&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>SV1WP</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>17</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Royal Academy of Engineering Chair in Emerging Technologies Scheme</grant_agency>&nbsp;</td><td>
<div>CiET1819/19&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EPSRC</grant_agency>&nbsp;</td><td>
<div>POC041&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>MedIAN Network</grant_agency>&nbsp;</td><td>
<div>EP/N026993/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Engineering and Physical Sciences Research Council (EPSRC)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EPSRC through TUSCA</grant_agency>&nbsp;</td><td>
<div>EP/V04799X/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>SmartHeart EPSRC programme</grant_agency>&nbsp;</td><td>
<div>EP/P001009/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>British Heart Foundation</grant_agency>&nbsp;</td><td>
<div>PG/14/89/31194&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Institute for Health Research (NIHR) Barts Biomedical Research Centre</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>European Union' s Horizon 2020 research and innovation programme</grant_agency>&nbsp;</td><td>
<div>825903&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>British Heart Foundation</grant_agency>&nbsp;</td><td>
<div>PG/14/89/31194&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Engineering and Physical Sciences Research Council</grant_agency>&nbsp;</td><td>
<div>EP/N026993/1&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This research has been conducted using the UK Biobank Resource under Application 11350. The cardiac MR images presented in Figs. 1, 2, 6, 7, 8, 9, 10, 11, 16 and 18 in the manuscript were reproduced with the permission of UK Biobank (c). The authors are grateful to all UK Biobank participants and staff. AFF acknowledges support from the Royal Academy of Engineering Chair in Emerging Technologies Scheme (CiET1819/19) , EPSRC-funded Grow MedTech CardioX (POC041) , and the MedIAN Network (EP/N026993/1) funded by the Engineering and Physical Sciences Research Council (EPSRC) . The work of AFF is also partially funded by EPSRC through TUSCA (EP/V04799X/1) . SN acknowledges the National Institute for Health Research (NIHR) Oxford Biomedical Research Centre based at The Oxford University Hospitals Trust at the University of Oxford, and the British Heart Foundation Centre of Research Excellence. SEP acknowledges support from the SmartHeart EPSRC programme grant ( www.nihr.ac.uk; EP/P001009/1) , the British Heart Foundation for funding the manual analysis to create a cardiovascular magnetic resonance imaging reference standard for the UK Biobank imaging resource in 5,0 0 0 CMR scans ( www.bhf.org.uk; PG/14/89/31194) , and the National Institute for Health Research (NIHR) Barts Biomedical Research Centre. SEP has received funding from the European Union' s Horizon 2020 research and innovation programme under grant agreement No 825903 (euCanSHare project) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Accepted, hybrid</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 23 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A novel unsupervised domain adaptation framework based on graph convolutional network and multi-level feature alignment for inter-subject ECG classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
He, ZY (He, Ziyang); Chen, YF (Chen, Yufei); Yuan, SY (Yuan, Shuaiying); Zhao, JH (Zhao, Jianhui); Yuan, ZY (Yuan, Zhiyong); Polat, K (Polat, Kemal); Alhudhaif, A (Alhudhaif, Adi); Alenezi, F (Alenezi, Fayadh); Hamid, A (Hamid, Arwa)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>221</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>119711</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2023.119711</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>FEB 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 JUL 1</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>29</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>30</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
72</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>60</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Electrocardiogram (ECG) is an effective non-invasive tool that can detect arrhythmias. Recently, deep learning (DL) has been widely used in ECG classification algorithms. However, differences between subjects lead to data shifts, hindering the further extension of DL algorithms. To solve this problem, we propose a novel multi-level unsupervised domain adaptation framework (MLUDAF) to diagnose arrhythmias. During feature extraction, we use the atrous spatial pyramid pooling residual (ASPP-R) module to extract spatio-temporal features of the samples. Then the graph convolutional network (GCN) module is used to extract the data structure features. During domain adaptation, we design three alignment mechanisms: domain alignment, semantic alignment, and structure alignment. The three alignment strategies are integrated into a unified deep network to guide the feature extractor to extract domain sharing and distinguishable semantic representations, which can reduce the differences between the source and target domains. Experimental results based on the MIT-BIH database show that the proposed method achieves an overall accuracy of 96.8% for arrhythmia detection. Compared to other methods, the proposed method achieves competitive performance. Cross-domain experiments between databases also demonstrate its strong generalizability. Therefore, the proposed method is promising for application in medical diagnosis systems.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000952522700001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
ECG classification; Individual differences; Multi-level unsupervised domain adaptation; Deep learning; Graph convolutional network</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NEURAL-NETWORK; INFORMATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[He, Ziyang; Yuan, Shuaiying; Zhao, Jianhui; Yuan, Zhiyong] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China. <br>
[Chen, Yufei] State Key Lab Math Engn &amp; Adv Comp, Zhengzhou 450001, Peoples R China. <br>
[Polat, Kemal] Bolu Abant Izzet Baysal Univ, Dept Elect &amp; Elect Engn, Bolu, Turkiye. <br>
[Alhudhaif, Adi] Prince Sattam bin Abdulaziz Univ, Coll Comp Engn &amp; Sci Al kharj, Dept Comp Sci, POB 151, Al Kharj 11942, Saudi Arabia. <br>
[Alenezi, Fayadh] Jouf Univ, Coll Engn, Dept Elect Engn, Jouf 72238, Saudi Arabia. <br>
[Hamid, Arwa] Arab Open Univ, Fac Comp Studies, Riyadh 11462, Saudi Arabia. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhao, JH; Yuan, ZY (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.<br>Polat, K (corresponding author), Bolu Abant Izzet Baysal Univ, Dept Elect &amp; Elect Engn, Bolu, Turkiye.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
heziyang@whu.edu.cn; yufeichen2019@outlook.com; yuanshuaiying@whu.edu.cn; jianhuizhao@whu.edu.cn; zhiyongyuan@whu.edu.cn; kpolat@ibu.edu.tr; a.alhudhaif@psau.edu.sa; fshenezi@ju.edu.sa; a.hamid@arabou.edu.sa</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Wuhan University; PLA Information Engineering University; Abant Izzet Baysal University; Prince Sattam Bin Abdulaziz University; Al Jouf University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Alenezi, Fayadh</display_name>&nbsp;</td><td>ABB-4871-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>He, Ziyang</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3286-7138&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>chen, yufei</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4508-9726&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhao, Jianhui</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5803-2564&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>He, Ziyang</display_name>&nbsp;</td><td>LFT-3209-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hamid, Arwa</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2750-536X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Alhudhaif, Adi</display_name>&nbsp;</td><td>AAN-6541-2021&nbsp;</td><td>0000-0002-7201-6963&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Yuan, Zhiyong</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9608-6037&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Polat, Kemal</display_name>&nbsp;</td><td>AGZ-2143-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>A1AI6</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>14</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62073248&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Science and Technology Major Project of Hubei Province, China (Next Generation Al Technologies)</grant_agency>&nbsp;</td><td>
<div>2019AEA170&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Deputyship for Research &amp; Innovation, Ministry of Education in Saudi Arabia</grant_agency>&nbsp;</td><td>
<div>223202&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China (No. 62073248) , in part by the Science and Technology Major Project of Hubei Province, China (Next Generation Al Technologies, No. 2019AEA170) . The authors extend their appreciation to the Deputyship for Research &amp; Innovation, Ministry of Education in Saudi Arabia for funding this research work through project number 223202.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 24 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>ECGFM: A foundation model for ECG analysis trained on a multi-center million-ECG dataset</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhang, ST (Zhang, Shaoting); Du, YS (Du, Yishan); Wang, WJ (Wang, Wenji); He, XY (He, Xianying); Cui, FF (Cui, Fangfang); Zhao, L (Zhao, Liang); Wang, B (Wang, Bei); Hu, ZQ (Hu, Zhiqiang); Zhao, J (Zhao, Jie)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>INFORMATION FUSION</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>124</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>103363</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.inffus.2025.103363</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 DEC</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
10</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
10</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>41</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
The electrocardiogram (ECG) is widely used for diagnosing heart conditions due to its cost-effectiveness, noninvasiveness, and accessibility. Between 2014 and 2017, the First Affiliated Hospital of Zhengzhou University collected over a million clinical ECGs from diverse primary hospitals, each accompanied by initial diagnostic results. Effectively utilizing this vast dataset with potential label inconsistencies is a key challenge. In this study, we introduce ECGFM, a foundation model pre-trained on over a million clinical ECGs to achieve deep ECG comprehension. ECGFM comprises a convolutional encoder, a transformer decoder, and task-specific heads, pre-trained through three complementary sub-tasks: (i) contrastive predictive learning for unsupervised representation learning, (ii) normal/abnormal classification, and (iii) diagnostic text generation. Given potential label unreliability, active learning is integrated with the classification task to select key data for re-annotation, enhancing supervision quality. To enable ECGFM's adaptability to downstream tasks with any-lead inputs, a transferred convolutional encoder is trained to align feature distributions. ECGFM's effectiveness is evaluated using diverse public datasets, including PTB-XL, Georgia, CPSC, CinC 2020, MITDB, and the "Hefei High-tech Cup" dataset. Fine-tuning ECGFM (training only a task-specific head) delivers strong performance across datasets, nearing fully supervised methods. Additionally, in a one-month online test with 7951 recordings, ECGFM achieved a recall of 0.9335, a precision of 0.9571, and an F1-score of 0.9451, underscoring its robustness and potential for real-world applications.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001522113200002</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
ECG foundation model; Pre-trained model; Contrastive learning; ECG classification; Text generation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
MORPHOLOGY</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhang, Shaoting; He, Xianying; Cui, Fangfang; Zhao, Jie] Zhengzhou Univ, Affiliated Hosp 1, Zhengzhou, Peoples R China. <br>
[Du, Yishan; Wang, Wenji; Zhao, Liang; Wang, Bei; Hu, Zhiqiang] SenseTime Res, Shanghai, Peoples R China. <br>
[Zhao, Jie] Shanghai Artificial Intelligence Lab, Shanghai, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhao, J (corresponding author), Zhengzhou Univ, Affiliated Hosp 1, Zhengzhou, Peoples R China.<br>Zhao, J (corresponding author), Shanghai Artificial Intelligence Lab, Shanghai, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
zhaojie@zzu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Zhengzhou University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhou, fan</display_name>&nbsp;</td><td>KIL-4066-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hu, Zhiqiang</display_name>&nbsp;</td><td>HIR-5043-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Theory &amp; Methods</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>4NI6H</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1566-2535</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-6305</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>INFORM FUSION</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Inf. Fusion</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key R&amp;D Program of China</grant_agency>&nbsp;</td><td>
<div>2022ZD0160704&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>&lt;B&gt;Acknowledgments&lt;/B&gt; This study is supported by the National Key R&amp;D Program of China (2022ZD0160704) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 25 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Automated cardiac segmentation of cross-modal medical images using unsupervised multi-domain adaptation and spatial neural attention structure</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, JP (Liu, Jinping); Liu, H (Liu, Hui); Gong, SB (Gong, Subo); Tang, ZH (Tang, Zhaohui); Xie, YF (Xie, Yongfang); Yin, HZ (Yin, Huazhan); Niyoyita, JP (Niyoyita, Jean Paul)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>72</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>102135</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2021.102135</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JUN 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 AUG</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>35</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>42</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
10</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
65</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>54</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Accurate cardiac segmentation of multimodal images, e.g., magnetic resonance (MR), computed tomography (CT) images, plays a pivot role in auxiliary diagnoses, treatments and postoperative assessments of cardiovascular diseases. However, training a well-behaved segmentation model for the cross-modal cardiac image analysis is challenging, due to their diverse appearances/distributions from different devices and acquisition conditions. For instance, a well-trained segmentation model based on the source domain of MR images is often failed in the segmentation of CT images. In this work, a cross-modal images oriented cardiac segmentation scheme is proposed using a symmetric full convolutional neural network (SFCNN) with the unsupervised multi-domain adaptation (UMDA) and a spatial neural attention (SNA) structure, termed UMDA-SNA-SFCNN, having the merits of without the requirement of any annotation on the test domain. Specifically, UMDA-SNA-SFCNN incorporates SNA to the classic adversarial domain adaptation network to highlight the relevant regions, while restraining the irrelevant areas in the cross modal images, so as to suppress the negative transfer in the process of unsupervised domain adaptation. In addition, the multi-layer feature discriminators and a predictive segmentation-mask discriminator are established to connect the multi-layer features and segmentation mask of the backbone network, SFCNN, to realize the fine-grained alignment of unsupervised cross-modal feature domains. Extensive confirmative and comparative experiments on the benchmark Multi-Modality Whole Heart Challenge dataset show that the proposed model is superior to the state-of-the-art cross-modal segmentation methods. (c) 2021 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000681314900010</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34182202</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cross-modal cardiac image segmentation; Unsupervised multi-domain adaptation; Spatial neural attention; Symmetric full convolutional neural; network</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
DOMAIN ADAPTATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Jinping; Liu, Hui; Yin, Huazhan] Hunan Normal Univ, Hunan Prov Key Lab Intelligent Comp &amp; Language In, Changsha 410081, Peoples R China. <br>
[Liu, Jinping; Liu, Hui] Hunan Normal Univ, Minist Educ, Key Lab Comp &amp; Stochast Math, Changsha 410081, Peoples R China. <br>
[Liu, Jinping] Hunan Normal Univ, Hunan Xiangjiang Artificial Intelligence Acad, Changsha 410081, Peoples R China. <br>
[Gong, Subo] Cent South Univ, Xiangya Hosp 2, Dept Geriatr Med, Changsha 410011, Peoples R China. <br>
[Tang, Zhaohui; Xie, Yongfang] Cent South Univ, Sch Automat, Changsha 410083, Peoples R China. <br>
[Yin, Huazhan] Hunan Normal Univ, Cognit &amp; Human Behav Key Lab Hunan Prov, Changsha 410081, Peoples R China. <br>
[Niyoyita, Jean Paul] Univ Rwanda, Coll Sci &amp; Technol, Kigali 3286, Rwanda. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liu, JP (corresponding author), Hunan Normal Univ, Coll Informat Sci &amp; Engn, Hunan Prov Key Lab Intelligent Comp &amp; Language In, HN731, Changsha, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
ljp202518@163.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Hunan Normal University; Hunan Normal University; Hunan Normal University; Central South University; Central South University; Hunan Normal University; University of Rwanda</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Jinping</display_name>&nbsp;</td><td>AAM-7723-2021&nbsp;</td><td>0000-0002-8669-882X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Hui</display_name>&nbsp;</td><td>G-2051-2014&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Niyoyita, Jean Paul</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5281-459X&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>TU8XW</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China (NSFC)</grant_agency>&nbsp;</td><td>
<div>61971188&nbsp;</div>
<div>61771492&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Science Fund for Distinguished Young Scholars</grant_agency>&nbsp;</td><td>
<div>61725306&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NSFC</grant_agency>&nbsp;</td><td>
<div>U1701261&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guangdong provincial government</grant_agency>&nbsp;</td><td>
<div>U1701261&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>project of Educational Commission of Hunan Province of China</grant_agency>&nbsp;</td><td>
<div>19B364&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the National Natural Science Foundation of China (NSFC) under Grant Nos. 61971188, 61771492, the National Science Fund for Distinguished Young Scholars under grant No. 61725306 and the joint fund of NSFC and Guangdong provincial government under grant No. U1701261, in part by the project of Educational Commission of Hunan Province of China un-der grant No. 19B364.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 26 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Universal ventricular coordinates: A generic framework for describing position within the heart and transferring data</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Bayer, J (Bayer, Jason); Prassl, AJ (Prassl, Anton J.); Pashaei, A (Pashaei, Ali); Gomez, JF (Gomez, Juan F.); Frontera, A (Frontera, Antonio); Neic, A (Neic, Aurel); Plank, G (Plank, Gernot); Vigmond, EJ (Vigmond, Edward J.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>45</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>83-93</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2018.01.005</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2018 APR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>79</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>87</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
0</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>26</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Being able to map a particular set of cardiac ventricles to a generic topologically equivalent representation has many applications, including facilitating comparison of different hearts, as well as mapping quantities and structures of interest between them. In this paper we describe Universal Ventricular Coordinates (UVC), which can be used to describe position within any biventricular heart. UVC comprise four unique coordinates that we have chosen to be intuitive, well defined, and relevant for physiological descriptions. We describe how to determine these coordinates for any volumetric mesh by illustrating how to properly assign boundary conditions and utilize solutions to Laplace's equation. Using UVC, we transferred scalar, vector, and tensor data between four unstructured ventricular meshes from three different species. Performing the mappings was very fast, on the order of a few minutes, since mesh nodes were searched in a KD tree. Distance errors in mapping mesh nodes back and forth between meshes were less than the size of an element. Analytically derived fiber directions were also mapped across meshes and compared, showing &lt;5 degrees difference over most of the ventricles. The ability to transfer gradients was also demonstrated. Topologically variable structures, like papillary muscles, required further definition outside of the UVC framework. In conclusion, UVC can aid in transferring many types of data between different biventricular geometries. (C) 2018 The Author(s). Published by Elsevier B.V.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000427664400007</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>29414438</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Mapping; Coordinates; Volumetric meshes; Deformation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
REPOLARIZATION GRADIENTS; FIBER ORIENTATION; MODELS; ANATOMY; FAILURE</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Bayer, Jason; Pashaei, Ali; Gomez, Juan F.; Frontera, Antonio; Vigmond, Edward J.] Bordeaux Fdn, LIRYC Electrophysiol &amp; Heart Modeling Inst, Ave Haut Leveque, F-33600 Pessac, France. <br>
[Bayer, Jason; Pashaei, Ali; Gomez, Juan F.; Vigmond, Edward J.] Univ Bordeaux, IMB Bordeaux Inst Math, 351 Cours Liberat, F-33405 Talence, France. <br>
[Prassl, Anton J.; Neic, Aurel; Plank, Gernot] Med Univ Graz, Gottfried Schatz Res Ctr, Biophys, Neue Stiftingtalstr 6, A-8010 Graz, Austria. <br>
[Frontera, Antonio] Hop Haut Leveque, Dept Electrophysiol, 1 Ave Magellan, F-33100 Pessac, France. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Vigmond, EJ (corresponding author), Bordeaux Fdn, LIRYC Electrophysiol &amp; Heart Modeling Inst, Ave Haut Leveque, F-33600 Pessac, France.<br>Vigmond, EJ (corresponding author), Univ Bordeaux, IMB Bordeaux Inst Math, 351 Cours Liberat, F-33405 Talence, France.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
jason.bayer@ihu-liryc.fr; anton.prassl@medunigraz.at; ali.pashaei@u-bordeaux.fr; juan.gomez@ihu-liryc.fr; a.frontera@gmail.com; aurel.neic@medunigraz.at; gernot.plank@medunigraz.at; edward.vigmond@u-bordeaux.fr</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
CHU Bordeaux; Universite de Bordeaux; Medical University of Graz; Universite de Bordeaux; CHU Bordeaux</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Neic, Aurel</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5192-1307&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>F Gomez, Juan</display_name>&nbsp;</td><td>B-5228-2017&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Frontera, Antonio</display_name>&nbsp;</td><td>AAG-6538-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Plank, Gernot</display_name>&nbsp;</td><td>C-9498-2011&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bayer, Jason</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0269-3499&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Vigmond, Edward</display_name>&nbsp;</td><td>E-8988-2012&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bayer, Jason</display_name>&nbsp;</td><td>HKV-2373-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gomez, Juan F</display_name>&nbsp;</td><td>B-5228-2017&nbsp;</td><td>0000-0003-0253-4842&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Frontera, Antonio</display_name>&nbsp;</td><td>HIR-6883-2022&nbsp;</td><td>0000-0002-0372-4480&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Vigmond, Edward</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1388-3589&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Prassl, Anton J</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1920-1377&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER SCIENCE BV</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>FZ5VM</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Agence Nationale de Recherche (ANR) as part of the Investissements d'Avenir program</grant_agency>&nbsp;</td><td>
<div>ANR-10-IAHU-04&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>ANR</grant_agency>&nbsp;</td><td>
<div>ANR-16-CE19-0009&nbsp;</div>
<div>ANR-13-MONU-0004-02&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Whitaker International Program</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Lefoulon-Delalande Foundation</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Austrian Science Fund (FWF)</grant_agency>&nbsp;</td><td>
<div>F3210-N18&nbsp;</div>
<div>12760-B30&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EU</grant_agency>&nbsp;</td><td>
<div>CardioProof 611232&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>ERACoSysMed PUSHCART project</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Austrian Science Fund (FWF)</grant_agency>&nbsp;</td><td>
<div>I2760&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Agence Nationale de la Recherche (ANR)</grant_agency>&nbsp;</td><td>
<div>ANR-16-CE19-0009&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was funded in part by the Agence Nationale de Recherche (ANR) as part of the Investissements d'Avenir program, grant ANR-10-IAHU-04. J.Bayer was supported in part by the ANR grant ANR-16-CE19-0009, the Whitaker International Program administered by the Institute of International Education, and by the Lefoulon-Delalande Foundation administered by the Institute of France. A. Pashaei was supported by the ANR grant ANR-13-MONU-0004-02. Funding to G Plank was provided by the grants F3210-N18 and 12760-B30 from the Austrian Science Fund (FWF) and the EU grant CardioProof 611232. E. Vigmond and G. Plank were also supported by the ERACoSysMed PUSHCART project. Simulations for this study were performed on the high performance computing platform Avakas, which is maintained by the Mesocentre de Calcul Intensif Aquitain (MCIA). We would also like to acknowledge PRACE support for computations performed on Marconi@CINECA, Italy and ARCHER, UK.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>hybrid, Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 27 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Patient-specific ECG classification by deeper CNN from generic to dedicated</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Li, YZ (Li, Yazhao); Pang, YW (Pang, Yanwei); Wang, J (Wang, Jian); Li, XL (Li, Xuelong)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>NEUROCOMPUTING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>314</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>336-346</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.neucom.2018.06.068</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2018 NOV 7</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>99</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>106</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
118</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>45</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This paper presents a new mechanism which is more effective for wearable devices to classify patient-specific electrocardiogram (ECG) heartbeats. In our method, a Generic Convolutional Neural Network (GCNN) is trained first using a large number of heartbeats without distinguishing patients. Based on the GCNN, fine-tuning technique is applied to modify the GCNN to a Tuned Dedicated CNN (TDCNN) for the corresponding individual. Notably, only the GCNN instead of common training data is required to be stored into wearable devices. Moreover, only fine-tuning with several seconds rather than dozens of minutes is needed before the TDCNN is used to monitor the long-term ECG signals in clinical. To accelerate the ECG classification, only the original ECG heartbeat is input to the CNN without other extended information from the neighbor heartbeats or FFT representation. A deeper CNN architecture with small-scale convolutional kernels is adopted to improve the speed and accuracy for classification. With deeper CNN, hierarchical features can be extracted to help improve the accuracy of ECG classification. The state-of-the-art performance on efficiency and accuracy for ECG classification over MIT-BIH dataset is achieved by the proposed method. The effectiveness and superiority for detecting ventricular ectopic beats (VEB) and supraventricular ectopic beats (SVEB) events are demonstrated. The proposed mechanism of fine-tuning the GCNN to TDCNN improves the efficiency for training patient-specific CNN classifier. Because of the computational efficiency of fine-tuning, ECG diagnosis and heart monitoring can be easily implemented with popular wearable devices in practice. (C) 2018 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000443718400033</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
ECG classification; Deep Convolutional Neural Networks (CNN); Generic CNN (GCNN); Tuned dedicated CNN (TDCNN); Heart monitoring; Wearable devices</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
HEARTBEAT CLASSIFICATION; ARRHYTHMIA DETECTION; MORPHOLOGY; NETWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Li, Yazhao; Pang, Yanwei; Wang, Jian] Tianjin Univ, Sch Elect &amp; Informat Engn, Tianjin 300072, Peoples R China. <br>
[Li, Xuelong] Chinese Acad Sci, Ctr OPT IMagery Anal &amp; Learning OPTIMAL, State Key Lab Transient Opt &amp; Photon, Xian Inst Opt &amp; Precis Mech, Xian 710119, Shaanxi, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Pang, YW (corresponding author), Tianjin Univ, Sch Elect &amp; Informat Engn, Tianjin 300072, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
lyztju@tju.edu.cn; pyw@tju.edu.cn; jianwang@tju.edu.cn; xuelong_li@opt.ac.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Tianjin University; State Key Laboratory of Transient Optics &amp; Photonics; Chinese Academy of Sciences; Xi'an Institute of Optics &amp; Precision Mechanics, CAS</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Li, Xuelong</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0019-4197&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Li, Xuelong</display_name>&nbsp;</td><td>Z-3785-2019&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER SCIENCE BV</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>GS5PJ</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0925-2312</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-8286</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>NEUROCOMPUTING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Neurocomputing</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61632018&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the National Natural Science Foundation of China (Grant No. 61632018).</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 28 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Bimodal Masked Autoencoders with internal representation connections for electrocardiogram classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wei, YF (Wei, Yufeng); Lian, C (Lian, Cheng); Xu, BR (Xu, Bingrong); Zhao, PB (Zhao, Pengbo); Yang, HG (Yang, Honggang); Zeng, ZG (Zeng, Zhigang)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>PATTERN RECOGNITION</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>161</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>111311</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.patcog.2024.111311</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JAN 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 MAY</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
8</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
16</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>35</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Time series self-supervised methods have been widely used, with electrocardiogram (ECG) classification tasks also reaping their benefits. One mainstream paradigm is masked data modeling, which leverages the visible part of data to reconstruct the masked part, aiding in acquiring useful representations for downstream tasks. However, traditional approach predominantly attends to time domain information and places excessive demands on the encoder for reconstruction, thereby hurting model's discriminative ability. In this paper, we present Bimodal Masked autoencoders with Internal Representation Connections (BMIRC) for ECG classification. On the one hand, BMIRC integrates the frequency spectrum of ECG into the masked pre-training process, enhancing the model's comprehensive understanding of the ECG. On the other hand, it establishes internal representation connections (IRC) from the encoder to the decoder, which offers the decoder various levels of information to aid in reconstruction, thereby allowing the encoder to focus on modeling discriminative representations. We conduct comprehensive experiments across three distinct ECG datasets to validate the effectiveness of BMIRC. Experimental results demonstrate that BMIRC surpasses the competitive baselines across the majority of scenarios, encompassing both intra-domain (pre-training and fine-tuning on the same dataset) and cross-domain (pre-training and fine-tuning on different datasets) settings. The code is publicly available at https://github.com/Envy-Clouds/BMIRC.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001392540200001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
ECG; Frequency spectrum; Bimodal; Masked autoencoders; Internal representation connections</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wei, Yufeng; Lian, Cheng; Xu, Bingrong; Zhao, Pengbo; Yang, Honggang] Wuhan Univ Technol, Sch Automat, Wuhan 430074, Peoples R China. <br>
[Zeng, Zhigang] Huazhong Univ Sci &amp; Technol, Sch Artificial Intelligence &amp; Automat, Wuhan 430074, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Lian, C (corresponding author), Wuhan Univ Technol, Sch Automat, Wuhan 430074, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
chenglian@whut.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Wuhan University of Technology; Huazhong University of Science &amp; Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lian, Cheng</display_name>&nbsp;</td><td>KIE-6538-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>wei, yufeng</display_name>&nbsp;</td><td>W-3423-2018&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zeng, Zhigang</display_name>&nbsp;</td><td>A-1794-2013&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER SCI LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>125 London Wall, London, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>R6L5G</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0031-3203</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-5142</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>PATTERN RECOGN</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Pattern Recognit.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Founda-tion of China</grant_agency>&nbsp;</td><td>
<div>62176193&nbsp;</div>
<div>62206204&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the National Natural Science Founda-tion of China under Grants 62176193 and 62206204.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 29 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Deep time-frequency representation and progressive decision fusion for ECG classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhang, J (Zhang, Jing); Tian, J (Tian, Jing); Cao, Y (Cao, Yang); Yang, YX (Yang, Yuxiang); Xu, XB (Xu, Xiaobin)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>KNOWLEDGE-BASED SYSTEMS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>190</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>105402</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.knosys.2019.105402</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 FEB 29</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>27</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>31</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
47</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>45</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Early recognition of abnormal rhythms in ECG signals is crucial for monitoring and diagnosing patients cardiac conditions, increasing the success rate of the treatment. Classifying abnormal rhythms into exact categories is very challenging due to the broad taxonomy of rhythms, noises and lack of large-scale real-world annotated data. Different from previous methods that utilize hand-crafted features or learn features from the original signal domain, we propose a novel ECG classification method by learning deep time-frequency representation and progressive decision fusion at different temporal scales in an end-to-end manner. First, the ECG wave signal is transformed into the time-frequency domain by using the Short-Time Fourier Transform. Next, several scale-specific deep convolutional neural networks are trained on ECG samples of a specific length. Finally, a progressive online decision fusion method is proposed to fuse decisions from the scale-specific models into a more accurate and stable one. Extensive experiments on both synthetic and real-world ECG datasets demonstrate the effectiveness and efficiency of the proposed method. (C) 2019 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000518492400028</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Decision-making; Electrocardiography; Fourier transforms; Neural networks</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NEURAL-NETWORK; EXPERT-SYSTEM; NOISE; TRANSFORM; FILTER; PCA</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhang, Jing; Tian, Jing; Xu, Xiaobin] Hangzhou Dianzi Univ, Sch Automat, Hangzhou, Peoples R China. <br>
[Cao, Yang] Univ Sci &amp; Technol China, Dept Automat, Hefei, Peoples R China. <br>
[Yang, Yuxiang] Hangzhou Dianzi Univ, Sch Elect &amp; Informat, Hangzhou, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Xu, XB (corresponding author), Hangzhou Dianzi Univ, Sch Automat, Hangzhou, Peoples R China.<br>Yang, YX (corresponding author), Hangzhou Dianzi Univ, Sch Elect &amp; Informat, Hangzhou, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
yyx@hdu.edu.cn; xuxiaobin1980@hdu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Hangzhou Dianzi University; Chinese Academy of Sciences; University of Science &amp; Technology of China, CAS; Hangzhou Dianzi University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cao, Yang</display_name>&nbsp;</td><td>G-4386-2016&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>ZHANG, JING</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6595-7661&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>ZHANG, JING</display_name>&nbsp;</td><td>HKF-4837-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>KS7NC</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0950-7051</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-7409</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>KNOWL-BASED SYST</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Knowledge-Based Syst.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China (NSFC)</grant_agency>&nbsp;</td><td>
<div>61806062&nbsp;</div>
<div>61873077&nbsp;</div>
<div>61872327&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NSFC-Zhejiang Joint Fund, China for the Integration of Industrialization and Informatization</grant_agency>&nbsp;</td><td>
<div>U1709215&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Fundamental Research Funds for the Central Universities, China</grant_agency>&nbsp;</td><td>
<div>WK2380000001&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Zhejiang Province Key R&amp;D Project, China</grant_agency>&nbsp;</td><td>
<div>2019C03104&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was partly supported by the National Natural Science Foundation of China (NSFC) under Grants 61806062, 61873077, and 61872327, the NSFC-Zhejiang Joint Fund, China for the Integration of Industrialization and Informatization under the Grant U1709215, the Fundamental Research Funds for the Central Universities, China under Grant WK2380000001, and the Zhejiang Province Key R&amp;D Project, China under Grant 2019C03104.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 30 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A MIL-based framework via contrastive instance learning and multimodal learning for long-term ECG classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Han, HZ (Han, Haozhan); Lian, C (Lian, Cheng); Xu, BR (Xu, Bingrong); Zeng, ZG (Zeng, Zhigang); Alhudhaif, A (Alhudhaif, Adi); Polat, K (Polat, Kemal)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>APPLIED SOFT COMPUTING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>167</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>112372</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.asoc.2024.112372</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>NOV 2024</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 DEC</value>&nbsp;&nbsp;<b>Part:</b> 
<value>B</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
7</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
21</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>47</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Recently, deep learning-based models are widely employed for electrocardiogram (ECG) classification. However, classifying long-term ECGs, which contain vast amounts of data, is challenging. Due to the limitation of memory with respect to the original data size, preprocessing techniques such as resizing or cropping are often applied, leading to information loss. Therefore, introducing multi-instance learning (MIL) to address longterm ECG classification problems is crucial. However, a major drawback of employing MIL is the destruction of sample integrity, which consequently hinders the interaction among instances. To tackle this challenge, we proposed a multimodal MIL neural network named CIMIL, which consists of three key components: an instance interactor, a feature fusion method based on attention mechanisms, and a multimodal contrastive instance loss. First, we designed an instance interactor to improve the interaction and keep continuity among instances. Second, we proposed a novel feature fusion method based on attention mechanisms to effectively aggregate multimodal instance features for final classification, which selects key instances within each class, not only enhances the performance of our model but also reduces the number of parameters. Third, a multimodal contrastive instance loss is proposed to enhance the model's ability to distinguish positive and negative multimodal instances. Finally, we evaluated CIMIL on both intrapatient and interpatient patterns of two commonly used ECG datasets. The experimental results show that the proposed CIMIL outperforms existing state-of-the-art methods on long-term ECG tasks.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001350540800001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Long-term ECG; Multi-instance learning; Attention mechanism; Multimodal learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CNN</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Han, Haozhan; Lian, Cheng; Xu, Bingrong] Wuhan Univ Technol, Sch Automat, Wuhan 430074, Peoples R China. <br>
[Zeng, Zhigang] Huazhong Univ Sci &amp; Technol, Sch Artificial Intelligence &amp; Automat, Wuhan 430074, Peoples R China. <br>
[Alhudhaif, Adi] Prince Sattam bin Abdulaziz Univ, Coll Comp Engn &amp; Sci Al kharj, Dept Comp Sci, POB 151, Al kharj 11942, Saudi Arabia. <br>
[Polat, Kemal] Bolu Abant Izzet Baysal Univ, Fac Engn, Dept Elect &amp; Elect Engn, Bolu, Turkiye. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Lian, C (corresponding author), Wuhan Univ Technol, Sch Automat, Wuhan 430074, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
chenglian@whut.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Wuhan University of Technology; Huazhong University of Science &amp; Technology; Prince Sattam Bin Abdulaziz University; Abant Izzet Baysal University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Polat, Kemal</display_name>&nbsp;</td><td>AGZ-2143-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Alhudhaif, Adi</display_name>&nbsp;</td><td>AAN-6541-2021&nbsp;</td><td>0000-0002-7201-6963&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zeng, Zhigang</display_name>&nbsp;</td><td>A-1794-2013&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lian, Cheng</display_name>&nbsp;</td><td>KIE-6538-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>L4P0D</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1568-4946</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-9681</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>APPL SOFT COMPUT</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Appl. Soft. Comput.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62176193&nbsp;</div>
<div>62206204&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>&lt;B&gt;Acknowledgments&lt;/B&gt; This work was supported by the Natural Science Foundation of China under Grants 62176193 and 62206204.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 31 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Multimodal fusion of spatial-temporal and frequency representations for enhanced ECG classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, CL (Liu, Chien-Liang); Xiao, B (Xiao, Bin); Hsieh, CH (Hsieh, Chiu-Hsun)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>INFORMATION FUSION</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>118</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>102999</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.inffus.2025.102999</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>FEB 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JUN</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>3</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>3</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
26</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
37</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>63</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Electrocardiogram (ECG) classification is pivotal in diagnosing and monitoring cardiovascular diseases (CVDs). However, existing methods predominantly rely on hand-crafted features or specific signal representations, often leading to incomplete and suboptimal analysis of ECG data. This paper addresses these limitations by identifying a significant research gap in the comprehensive utilization of ECG signals across both spatial- temporal and frequency domains. To bridge this gap, we propose a novel multimodal model that integrates these domains to fully capture the intricacies of ECG signals. The proposed model features a hierarchical dual- attention vision transformer for extracting detailed spatial-temporal features and a deep residual network for capturing frequency domain representations via wavelet packet coefficients. This innovative dual-input approach enables more accurate and robust ECG classification. Extensive experiments on multiple publicly available datasets validate the effectiveness of our model, demonstrating state-of-the-art performance with significant improvements in classification accuracy. Key contributions of this work include (1) the introduction of a multimodal model architecture that uniquely combines spatial-temporal and frequency domain features; (2) a comprehensive evaluation across several ECG datasets, confirming the model's superiority over existing methods; and (3) ablation studies that underscore the critical role of each component within the proposed model.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001426148600001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
ECG classification; Multimodal model; Spatial-temporal representation; Frequency representation; Discrete wavelet packet transformation; Hierarchical structure dual attention; transformer</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NEURAL-NETWORK; DEPTH; MODEL</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Chien-Liang; Hsieh, Chiu-Hsun] Natl Yang Ming Chiao Tung Univ, Dept Ind Engn &amp; Management, 1001 Univ Rd, Hsinchu 300, Taiwan. <br>
[Xiao, Bin] Natl Yang Ming Chiao Tung Univ, Dept Comp Sci, 1001 Univ Rd, Hsinchu 300, Taiwan. <br>
[Xiao, Bin] Univ Ottawa, Sch Elect Engn &amp; Comp Sci, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liu, CL (corresponding author), Natl Yang Ming Chiao Tung Univ, Dept Ind Engn &amp; Management, 1001 Univ Rd, Hsinchu 300, Taiwan.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
clliu@nycu.edu.tw</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
National Yang Ming Chiao Tung University; National Yang Ming Chiao Tung University; University of Ottawa</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xiao, Bin</display_name>&nbsp;</td><td>AAC-8030-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Chien-Liang</display_name>&nbsp;</td><td>KFR-0194-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xiao, Bin</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1992-4214&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Theory &amp; Methods</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>X6A3I</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1566-2535</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-6305</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>INFORM FUSION</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Inf. Fusion</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>17</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Science and Technology Council, Taiwan</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NSTC</grant_agency>&nbsp;</td><td>
<div>112-2221-E-A49-058-MY2&nbsp;</div>
<div>111-2221-E-A49-083-MY3&nbsp;</div>
<div>113-2622-E-030-002&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was partially supported by the National Science and Technology Council, Taiwan, under grant no. NSTC 112-2221-E-A49-058-MY2, 111-2221-E-A49-083-MY3 and 113-2622-E-030-002. We are grateful to the National Center for High-performance Computing for computer time and facilities.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 32 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Unsupervised Multimanifold Cross-Guided Diffusion Deformable Registration for Cardiac MRI</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhao, QF (Zhao, Qifeng); Wang, XC (Wang, Xuchu)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TNNLS.2025.3577483</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JUN 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JUN 18</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
5</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>54</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Diffusion networks demonstrate remarkable robustness in extracting complex structural features across various domains of medical image processing. In the task of cardiac image registration, diffusion networks excel at reconstructing intricate structural details, thereby enabling effective representation of cardiac anatomical motion. In this article, we propose an unsupervised diffusion registration framework named MCG-Reg for 3-D cardiac magnetic resonance (MR) image registration, employing a multimanifold cross-fusion strategy. MCG-Reg comprises two components: the multimanifold cross-fusion (MCF) module and the weighted fusion codec (WFC) module. MCF module decouples the cardiac image, leveraging multifrequency and multiscale features for cross-attention (CA) calculation, and fuses with the edge image to enable adaptive focus gathering and edge perception capabilities in the model, thereby enhancing the effective aggregation of local and global features. WFC module further processes cardiac features by utilizing offset attention to capture large displacement information, while employing feature energy maps for residual connections to enhance the model's attention perception ability, thus facilitating better topology maintenance and boundary constraint realization. The registration accuracy and model generalization of the proposed MCG-Reg are validated in publicly available ACDC, M&amp;Ms, and CAP datasets. The experimental results verify that it achieves state-of-the-art performance in comparison to related methods, highlighting the significant potential of the proposed framework in cardiac image analysis applications.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001512675400001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>40526546</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article; Early Access</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Deformation; Image registration; Feature extraction; Accuracy; Deep learning; Anatomical structure; Biomedical imaging; Image edge detection; Diffusion models; Correlation; Deformable image registration; diffusion model; multimanifold cross fusion (MCF); unsupervised learning; weighted fusion codec (WFC)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SEGMENTATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhao, Qifeng; Wang, Xuchu] Chongqing Univ, Coll Optoelect Engn, Chongqing 401331, Peoples R China. <br>
[Wang, Xuchu] Chongqing Univ, Key Lab Optoelect Technol &amp; Syst, Minist Educ, Chongqing 401331, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Wang, XC (corresponding author), Chongqing Univ, Coll Optoelect Engn, Chongqing 401331, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
xcwang@cqu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Chongqing University; Chongqing University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhao, Qifeng</display_name>&nbsp;</td><td>LNP-4731-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Hardware &amp; Architecture; Computer Science, Theory &amp; Methods; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>3ZL2S</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2162-237X</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2162-2388</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T NEUR NET LEAR</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Neural Netw. Learn. Syst.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61971076&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of Chongqing Municipality</grant_agency>&nbsp;</td><td>
<div>CSTB2024NSCQ-MSX0369&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under Grant 61971076 and in part by the Natural Science Foundation of Chongqing Municipality under Grant CSTB2024NSCQ-MSX0369</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 33 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Disentangled representation learning in cardiac image analysis</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Chartsias, A (Chartsias, Agisilaos); Joyce, T (Joyce, Thomas); Papanastasiou, G (Papanastasiou, Giorgos); Semple, S (Semple, Scott); Williams, M (Williams, Michelle); Newby, DE (Newby, David E.); Dharmakumar, R (Dharmakumar, Rohan); Tsaftaris, SA (Tsaftaris, Sotirios A.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>58</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>101535</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2019.101535</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2019 DEC</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>123</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>133</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
40</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>49</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Typically, a medical image offers spatial information on the anatomy (and pathology) modulated by imaging specific characteristics. Many imaging modalities including Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) can be interpreted in this way. We can venture further and consider that a medical image naturally factors into some spatial factors depicting anatomy and factors that denote the imaging characteristics. Here, we explicitly learn this decomposed (disentangled) representation of imaging data, focusing in particular on cardiac images. We propose Spatial Decomposition Network (SDNet), which factorises 2D medical images into spatial anatomical factors and non-spatial modality factors. We demonstrate that this high-level representation is ideally suited for several medical image analysis tasks, such as semi-supervised segmentation, multi-task segmentation and regression, and image-to-image synthesis. Specifically, we show that our model can match the performance of fully supervised segmentation models, using only a fraction of the labelled images. Critically, we show that our factorised representation also benefits from supervision obtained either when we use auxiliary tasks to train the model in a multi-task setting (e.g. regressing to known cardiac indices), or when aggregating multimodal data from different sources (e.g. pooling together MRI and CT data). To explore the properties of the learned factorisation, we perform latent-space arithmetic and show that we can synthesise CT from MR and vice versa, by swapping the modality factors. We also demonstrate that the factor holding image specific information can be used to predict the input modality with high accuracy. Code will be made available at https://github.comiagis85/anatomy_modality_decomposition. (C) 2019 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000496605700025</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>31351230</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Disentangled representation learning; Cardiac magnetic resonance imaging; Semi-supervised segmentation; Multitask learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
WHOLE HEART SEGMENTATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Chartsias, Agisilaos; Joyce, Thomas; Tsaftaris, Sotirios A.] Univ Edinburgh, Inst Digital Commun, Sch Engn, West Mains Rd, Edinburgh EH9 3FB, Midlothian, Scotland. <br>
[Papanastasiou, Giorgos; Semple, Scott; Williams, Michelle; Newby, David E.] Edinburgh Imaging Facil QMRI, Edinburgh EH16 4TJ, Midlothian, Scotland. <br>
[Papanastasiou, Giorgos; Semple, Scott; Williams, Michelle; Newby, David E.] Ctr Cardiovasc Sci, Edinburgh EH16 4TJ, Midlothian, Scotland. <br>
[Dharmakumar, Rohan] Cedars Sinai Med Ctr, Los Angeles, CA 90048 USA. <br>
[Tsaftaris, Sotirios A.] Alan Turing Inst, London, England. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Chartsias, A (corresponding author), Univ Edinburgh, Inst Digital Commun, Sch Engn, West Mains Rd, Edinburgh EH9 3FB, Midlothian, Scotland.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
agis.chartsias@ed.ac.uk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Edinburgh; Cedars Sinai Medical Center; Alan Turing Institute</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Newby, David</display_name>&nbsp;</td><td>AAB-1364-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Papanastasiou, Giorgos</display_name>&nbsp;</td><td>ABH-8943-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Williams, Michelle</display_name>&nbsp;</td><td>K-7555-2012&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Newby, David</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7971-4628&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tsaftaris, Sotirios</display_name>&nbsp;</td><td>E-3725-2010&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Papanastasiou, Giorgos</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1939-296X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Joyce, Thomas</display_name>&nbsp;</td><td>IWU-5793-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>JN0PE</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>US National Institutes of Health</grant_agency>&nbsp;</td><td>
<div>1R01HL136578-01&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>UK EPSRC</grant_agency>&nbsp;</td><td>
<div>EP/P022928/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Royal Academy of Engineering</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EPSRC</grant_agency>&nbsp;</td><td>
<div>EP/P022928/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>MRC</grant_agency>&nbsp;</td><td>
<div>G0701127&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>British Heart Foundation</grant_agency>&nbsp;</td><td>
<div>CH/09/002/26360&nbsp;</div>
<div>RG/16/10/32375&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Engineering and Physical Sciences Research Council</grant_agency>&nbsp;</td><td>
<div>EP/P022928/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Medical Research Council</grant_agency>&nbsp;</td><td>
<div>G0701127&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the US National Institutes of Health (1R01HL136578-01) and UK EPSRC (EP/P022928/1), and used resources provided by the Edinburgh Compute and Data Facility (http://www.ecdf.ed.ac.uk/). S.A.Tsaftaris acknowledges the support of the Royal Academy of Engineering and the Research Chairs and Senior Research Fellowships scheme.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted, Green Accepted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 34 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A probabilistic deep motion model for unsupervised cardiac shape anomaly assessment</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zakeri, A (Zakeri, Arezoo); Hokmabadi, A (Hokmabadi, Alireza); Ravikumar, N (Ravikumar, Nishant); Frangi, AF (Frangi, Alejandro F.); Gooya, A (Gooya, Ali)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>75</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>102276</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2021.102276</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>NOV 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2022 JAN</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>8</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>8</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
10</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>54</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Automatic shape anomaly detection in large-scale imaging data can be useful for screening suboptimal segmentations and pathologies altering the cardiac morphology without intensive manual labour. We propose a deep probabilistic model for local anomaly detection in sequences of heart shapes, modelled as point sets, in a cardiac cycle. A deep recurrent encoder-decoder network captures the spatio-temporal dependencies to predict the next shape in the cycle and thus derive the outlier points that are attributed to excessive deviations from the network prediction. A predictive mixture distribution models the inlier and outlier classes via Gaussian and uniform distributions, respectively. A Gibbs sampling Expectation Maximisation (EM) algorithm computes soft anomaly scores of the points via the posterior probabilities of each class in the E-step and estimates the parameters of the network and the predictive distribution in the M-step. We demonstrate the versatility of the method using two shape datasets derived from: (i) one million biventricular CMR images from 20,0 0 0 participants in the UK Biobank (UKB), and (ii) routine diagnostic imaging from Multi-Centre, Multi-Vendor, and Multi-Disease Cardiac Image (M&amp;Ms). Experiments show that the detected shape anomalies in the UKB dataset are mostly associated with poor segmentation quality, and the predicted shape sequences show significant improvement over the input sequences. Furthermore, evaluations on U-Net based shapes from the M&amp;Ms dataset reveals that the anomalies are attributable to the underlying pathologies that affect the ventricles. The proposed model can therefore be used as an effective mechanism to sift shape anomalies in large-scale cardiac imaging pipelines for further analysis. (c) 2021 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000718407400014</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34753021</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac shape quality control; Deep learning; Expectation-maximisation; Probabilistic model; Spatio-temporal anomaly detection; UK Biobank</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
MR-IMAGES; ATLAS; ABNORMALITIES</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zakeri, Arezoo; Hokmabadi, Alireza; Ravikumar, Nishant; Frangi, Alejandro F.; Gooya, Ali] Univ Leeds, Ctr Computat Imaging &amp; Simulat Technol Biomed CIS, Sch Comp, Leeds, W Yorkshire, England. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zakeri, A; Gooya, A (corresponding author), Univ Leeds, Ctr Computat Imaging &amp; Simulat Technol Biomed CIS, Sch Comp, Leeds, W Yorkshire, England.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
a.zakeri@leeds.ac.uk; a.gooya@leeds.ac.uk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Leeds</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hokmabadi, Alireza</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1407-4540&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gooya, Ali</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5135-4800&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Frangi, Alejandro</display_name>&nbsp;</td><td>C-6500-2008&nbsp;</td><td>0000-0002-2675-528X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zakeri, Arezoo</display_name>&nbsp;</td><td>HKV-6795-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ravikumar, Nishant</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0134-107X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zakeri, Arezoo</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6011-2333&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>WX2BN</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Engineering and Physical Sciences Research Council (EPSRC)</grant_agency>&nbsp;</td><td>
<div>EP/S012796/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Royal Academy of Engineering Chair in Emerging Technologies Scheme</grant_agency>&nbsp;</td><td>
<div>CiET1819/19&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>CardioX</grant_agency>&nbsp;</td><td>
<div>GrowMedTech POC041&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EPSRC</grant_agency>&nbsp;</td><td>
<div>EP/S012796/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Medical Research Council</grant_agency>&nbsp;</td><td>
<div>MC_PC_17228&nbsp;</div>
<div>MC_qA137853&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the Engineering and Physical Sciences Research Council (EPSRC) (grant number EP/S012796/1). AFF is partially supported by a Royal Academy of Engineering Chair in Emerging Technologies Scheme (CiET1819/19) and CardioX (GrowMedTech POC041). The authors would like to thank Dr. Rahman Attar for making the UKB shape dataset available. The UKB CMR dataset and the ground-truth contours have been provided under UK Biobank Access Application #11350. The authors thank all UK Biobank participants and staff.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 35 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Unsupervised classification of 12-lead ECG signals using wavelet tensor decomposition and two-dimensional Gaussian spectral clustering</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
He, H (He, Hong); Tan, YH (Tan, Yonghong); Xing, JF (Xing, Jianfeng)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>KNOWLEDGE-BASED SYSTEMS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>163</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>392-403</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.knosys.2018.09.001</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2019 JAN 1</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>35</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>36</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
75</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>49</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Due to high dimensionality and multiple variables, unsupervised classification of 12-lead ECG signals involves challenges and difficulties. In order to automatically discover unknown physiological features from raw multivariate signals and detect abnormal cardiac activities of a subject, we proposed an unsupervised classification scheme of 12-lead ECG signals using wavelet tensor decomposition and two-dimensional Gaussian spectral clustering. After filtering and segmentation, each ECG sample is converted into a wavelet tensor by the Discrete Wavelet Packet Transform (DWPT). Main features of ECG samples can be clearly investigated in a multiple feature space constructed by the ECG lead, time and frequency sub band. Then the Multilinear Principal Component Analysis (MPCA) is applied to reduce the dimensionality of ECG tensors as well as preserve the data interior structure. Taking account of both magnitude and orientation of feature vectors, a novel two-dimensional Gaussian spectral clustering (TGSC) is devised to cluster different 12-lead ECG samples. Furthermore, the dataset obtained from practical 12-lead ECG experiment and two datasets from PhysioBank are used to verify the efficiency of the proposed method. Clustering results show that more useful features of ECG signals can be extracted by the wavelet tensor-based MPCA than by vector-based PCA. With the two-dimensional Gaussian proximity matrix, the clustering accuracy of TGSC is also higher than that of the traditional spectral clustering. (C) 2018 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000454468200030</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
12-lead ECG signal; Spectral clustering; Dimensionality reduction; Wavelet packet transform; Tensor</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
PRINCIPAL COMPONENT ANALYSIS; MYOCARDIAL-INFARCTION; AUTOMATED DETECTION; NEURAL-NETWORK; RECOGNITION; ALGORITHM; MODEL</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[He, Hong; Tan, Yonghong; Xing, Jianfeng] Shanghai Normal Univ, Coll Informat Mech &amp; Elect Engn, Shanghai 200234, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
He, H (corresponding author), Shanghai Normal Univ, Coll Informat Mech &amp; Elect Engn, Shanghai 200234, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
heh@shnu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Shanghai Normal University</td>
</tr>

<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>HF8CJ</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0950-7051</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-7409</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>KNOWL-BASED SYST</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Knowledge-Based Syst.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61571302&nbsp;</div>
<div>61371145&nbsp;</div>
<div>61671303&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Project of the Science and Technology Commission of Shanghai, China</grant_agency>&nbsp;</td><td>
<div>18070503000&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Opening Research Project of Key Laboratory of Wireless Sensor Network &amp; Communication, SIMIT, Chinese Academy of Sciences</grant_agency>&nbsp;</td><td>
<div>2017005&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Industry-education research Project of Shanghai Normal University, China</grant_agency>&nbsp;</td><td>
<div>DCL201704&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work is supported by the National Natural Science Foundation of China (No. 61571302, No. 61371145, No. 61671303), the Project of the Science and Technology Commission of Shanghai, China (No. 18070503000), Opening Research Project of Key Laboratory of Wireless Sensor Network &amp; Communication, SIMIT, Chinese Academy of Sciences (No. 2017005) and Industry-education research Project of Shanghai Normal University, China (No. DCL201704).</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 36 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Class-specific weighted broad learning system-based domain adaptation for patient-specific ECG classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Fan, W (Fan, Wei); Si, YJ (Si, Yujuan); Sun, MQ (Sun, Meiqi); Zhou, L (Zhou, Lin); Yang, WY (Yang, Weiyi); Alhudhaif, A (Alhudhaif, Adi); Alenezi, F (Alenezi, Fayadh)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>273</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>126824</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2025.126824</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>FEB 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 MAY 10</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
16</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
23</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>47</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
With the growing prevalence of wearable devices, fast and accurate classification of patient-specific electrocardiogram (ECG) is crucial for daily heart monitoring. Despite the surge in generic arrhythmia detection methods, automated systems with real-time capabilities and satisfactory performance for patient-specific ECG classification remain rare. Particularly, the morphological differences in ECG waveforms among individuals and the imbalances between beat classes pose major challenges to any model. In this paper, we propose two novel domain adaptation algorithms by improving the previously established class-specific weighted broad learning system (CSWBLS) with high resistance to imbalance data, named one-step CSWBLS-based domain adaptation (OCSWBLS-DA) and two-step CSWBLS-based domain adaptation (TCSWBLS-DA). OCSWBLS-DA achieves individual adaptation by simultaneously learning knowledge from a large number of common heartbeats without distinguishing patients and a small number of patient-specific heartbeats in one step. TCSWBLS-DA is first pre- trained on common heartbeats and then fine-tuned on patient-specific heartbeats to adapt to the corresponding individual. Both algorithms not only inherit high learning efficiency and the ability to address imbalance problems from CSWBLS but also have better generalization. Experimental results on the MIT-BIH arrhythmia database following the recommendations of Association for the Advancement of Medical Instrumentation (AAMI) EC57: 2012 standard show that both methods outperformed state-of-the-art techniques in detecting ventricular and supraventricular ectopic beats, with TCSWBLS-DA achieving the highest F1-scores of 96.1% and 80.6%, respectively. Moreover, TCSWBLS-DA takes only 0.07 seconds to adapt to a new individual and 0.034 milliseconds to identify a single beat due to its simple structure, demonstrating significant potential for practical application.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001429962300001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Patient-specific ECG classification; Arrhythmia; Domain drift; Class imbalance; Class-specific weighted broad learning system; (CSWBLS); Domain adaptation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
MORPHOLOGY</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Fan, Wei] Fudan Univ, Sch Informat Sci &amp; Technol, Shanghai 200438, Peoples R China. <br>
[Si, Yujuan] Zhuhai Coll Sci &amp; Technol, Sch Elect &amp; Informat Engn, Zhuhai 519041, Peoples R China. <br>
[Si, Yujuan; Sun, Meiqi; Zhou, Lin] Jilin Univ, Coll Commun Engn, Changchun 130012, Peoples R China. <br>
[Yang, Weiyi] Nanjing Univ Informat Sci &amp; Technol, Sch Artificial Intelligence, Nanjing 210044, Peoples R China. <br>
[Alhudhaif, Adi] Prince Sattam bin Abdulaziz Univ, Coll Comp Engn &amp; Sci Al kharj, Dept Comp Sci, Al Kharj 11942, Saudi Arabia. <br>
[Alenezi, Fayadh] Jouf Univ, Coll Engn, Dept Elect Engn, Sakaka 72238, Saudi Arabia. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Si, YJ (corresponding author), Zhuhai Coll Sci &amp; Technol, Sch Elect &amp; Informat Engn, Zhuhai 519041, Peoples R China.<br>Si, YJ (corresponding author), Jilin Univ, Coll Commun Engn, Changchun 130012, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
siyj@jlu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Fudan University; Jilin University; Nanjing University of Information Science &amp; Technology; Prince Sattam Bin Abdulaziz University; Al Jouf University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Alenezi, Fayadh</display_name>&nbsp;</td><td>ABB-4871-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Alhudhaif, Adi</display_name>&nbsp;</td><td>AAN-6541-2021&nbsp;</td><td>0000-0002-7201-6963&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Sun, Meiqi</display_name>&nbsp;</td><td>ADI-7658-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>Y1Q6N</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>17</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of Guangdong Province</grant_agency>&nbsp;</td><td>
<div>2023A1515011302&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guang-dong Key Disciplines Project</grant_agency>&nbsp;</td><td>
<div>2022ZDJS140&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Featured Innovation Projects of the Guangdong Universities</grant_agency>&nbsp;</td><td>
<div>2022KTSCX189&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Startup Foundation for Introducing Talent of NUIST</grant_agency>&nbsp;</td><td>
<div>2023r058&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the Natural Science Foundation of Guangdong Province (grant number 2023A1515011302) , the Guang-dong Key Disciplines Project (grant number 2022ZDJS140) , the Featured Innovation Projects of the Guangdong Universities (grant number 2022KTSCX189) , and the Startup Foundation for Introducing Talent of NUIST (grant number 2023r058) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 37 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Designing ECG monitoring healthcare system with federated transfer learning and explainable AI</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Raza, A (Raza, Ali); Tran, KP (Kim Phuc Tran); Koehl, L (Koehl, Ludovic); Li, SJ (Li, Shujun)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>KNOWLEDGE-BASED SYSTEMS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>236</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>107763</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.knosys.2021.107763</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2022 JAN 25</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>107</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>124</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
7</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
150</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>77</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Deep learning plays a vital role in classifying different arrhythmias using electrocardiography (ECG) data. Nevertheless, training deep learning models normally requires a large amount of data and can lead to privacy concerns. Unfortunately, a large amount of healthcare data cannot be easily collected from a single silo. Additionally, deep learning models are like black-box, with no explainability of the predicted results, which is often required in clinical healthcare. This limits the application of deep learning in real-world health systems.
<br>In this paper, to address the above-mentioned challenges, we design a novel end-to-end framework in a federated setting for ECG-based healthcare using explainable artificial intelligence (XAI) and deep convolutional neural networks (CNN). The federated setting is used to solve challenges such as data availability and privacy concerns. Furthermore, the proposed framework effectively classifies different arrhythmias using an autoencoder and a classifier, both based on a CNN. Additionally, we propose an XAI-based module on top of the proposed classifier for interpretability of the classification results, which helps clinical practitioners to interpret the predictions of the classifier and to make quick and reliable decisions. The proposed framework was trained and tested using the baseline Massachusetts Institute of Technology - Boston's Beth Israel Hospital (MIT-BIH) Arrhythmia database. The trained classifier outperformed existing work by achieving accuracy up to 94.5% and 98.9% for arrhythmia detection using noisy and clean data, respectively, with five-fold cross-validation. We also propose a new communication cost reduction method to reduce the communication costs and to enhance the privacy of users' data in the federated setting. While the proposed framework was tested and validated for ECG classification, it is general enough to be extended to many other healthcare applications. (C) 2021 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000817713800016</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiography (ECG); Deep learning; Explainable AI (XAI); Privacy; Security; Federated learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
HYBRID NEURAL-NETWORK; BIG DATA; OPTIMIZATION ALGORITHM; ATRIAL-FIBRILLATION; DEEP; ANALYTICS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Raza, Ali; Kim Phuc Tran; Koehl, Ludovic] Univ Lille, ENSAIT, GEMTEX Lab Genie &amp; Mat Text, F-59000 Lille, France. <br>
[Raza, Ali; Li, Shujun] Univ Kent, Sch Comp, Canterbury, Kent, England. <br>
[Raza, Ali; Li, Shujun] Univ Kent, Inst Cyber Secur Soc iCSS, Canterbury, Kent, England. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Raza, A (corresponding author), Univ Lille, ENSAIT, GEMTEX Lab Genie &amp; Mat Text, F-59000 Lille, France.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
ali.raza@ensait.fr; kim-phuc.tran@ensait.fr; ludovic.koehl@ensait.fr; S.J.Li@kent.ac.uk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Universite de Lille; Ecole Nationale Superieure des Arts et Industries Textiles (ENSAIT); University of Kent; University of Kent</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tran, Kim</display_name>&nbsp;</td><td>I-8365-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Li, Shujun</display_name>&nbsp;</td><td>A-9032-2008&nbsp;</td><td>0000-0001-5628-7328&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>KOEHL, Ludovic</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3404-8462&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>RAZA, ALI</display_name>&nbsp;</td><td>AET-8892-2022&nbsp;</td><td>0000-0001-8326-8325&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>2M5BF</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0950-7051</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-7409</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>KNOWL-BASED SYST</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Knowledge-Based Syst.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>17</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>I-SITE Universite Lille Nord-Europe 2021 of France</grant_agency>&nbsp;</td><td>
<div>I-COTKEN-20-001-TRAN-RAZA&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EPSRC</grant_agency>&nbsp;</td><td>
<div>EP/S018964/1&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This research work was supported by the I-SITE Universite Lille Nord-Europe 2021 of France under grant No. I-COTKEN-20-001-TRAN-RAZA.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 38 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>SequenceMorph: A Unified Unsupervised Learning Framework for Motion Tracking on Cardiac Image Sequences</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Ye, M (Ye, Meng); Yang, D (Yang, Dong); Huang, QY (Huang, Qiaoying); Kanski, M (Kanski, Mikael); Axel, L (Axel, Leon); Metaxas, DN (Metaxas, Dimitris N.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>45</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>8</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>10409-10426</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TPAMI.2023.3243040</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 AUG</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>12</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>12</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
39</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>76</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Modern medical imaging techniques, such as ultrasound (US) and cardiac magnetic resonance (MR) imaging, have enabled the evaluation of myocardial deformation directly from an image sequence. While many traditional cardiac motion tracking methods have been developed for the automated estimation of the myocardial wall deformation, they are not widely used in clinical diagnosis, due to their lack of accuracy and efficiency. In this paper, we propose a novel deep learning-based fully unsupervised method, SequenceMorph, for in vivo motion tracking in cardiac image sequences. In our method, we introduce the concept of motion decomposition and recomposition. We first estimate the inter-frame (INF) motion field between any two consecutive frames, by a bi-directional generative diffeomorphic registration neural network. Using this result, we then estimate the Lagrangian motion field between the reference frame and any other frame, through a differentiable composition layer. Our framework can be extended to incorporate another registration network, to further reduce the accumulated errors introduced in the INF motion tracking step, and to refine the Lagrangian motion estimation. By utilizing temporal information to perform reasonable estimations of spatio-temporal motion fields, this novel method provides a useful solution for image sequence motion tracking. Our method has been applied to US (echocardiographic) and cardiac MR (untagged and tagged cine) image sequences; the results show that SequenceMorph is significantly superior to conventional motion tracking methods, in terms of the cardiac motion tracking accuracy and inference efficiency.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001022958600074</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37022840</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac; diffeomorphic; motion tracking; unsupervised</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
OPTICAL-FLOW; REGISTRATION; DISPLACEMENT; ROBUST; MODEL</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Ye, Meng; Metaxas, Dimitris N.] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA. <br>
[Yang, Dong] NVIDIA Corp, Bethesda, MD 95051 USA. <br>
[Huang, Qiaoying] Meta, Seattle, WA 98109 USA. <br>
[Kanski, Mikael; Axel, Leon] New York Univ, Grossman Sch Med, New York, NY 10016 USA. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Metaxas, DN (corresponding author), Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
my389@cs.rutgers.edu; don.yang.mech@gmail.com; charwinghuang@gmail.com; mikael.kanski@nyulangone.org; leon.axel@nyulangone.org; dnm@cs.rutgers.edu</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Rutgers University System; Rutgers University New Brunswick; Nvidia Corporation; New York University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Huang, Qiaoying</display_name>&nbsp;</td><td>AAU-7744-2021&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE COMPUTER SOC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>L4KG5</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0162-8828</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1939-3539</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T PATTERN ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Pattern Anal. Mach. Intell.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>18</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 39 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Unsupervised heart-rate estimation in wearables with Liquid states and a probabilistic readout</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Das, A (Das, Anup); Pradhapan, P (Pradhapan, Paruthi); Groenendaal, W (Groenendaal, Willemijn); Adiraju, P (Adiraju, Prathyusha); Rajan, RT (Rajan, Raj Thilak); Catthoor, F (Catthoor, Francky); Schaafsma, S (Schaafsma, Siebren); Krichmar, JL (Krichmar, Jeffrey L.); Dutt, N (Dutt, Nikil); Van Hoof, C (Van Hoof, Chris)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>NEURAL NETWORKS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>99</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>134-147</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.neunet.2017.12.015</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2018 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>51</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>58</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
38</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>94</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Heart-rate estimation is a fundamental feature of modern wearable devices. In this paper we propose a machine learning technique to estimate heart-rate from electrocardiogram (ECG) data collected using wearable devices. The novelty of our approach lies in (1) encoding spatio-temporal properties of ECG signals directly into spike train and using this to excite recurrently connected spiking neurons in a Liquid State Machine computation model; (2) a novel learning algorithm; and (3) an intelligently designed unsupervised readout based on Fuzzy c-Means clustering of spike responses from a subset of neurons (Liquid states), selected using particle swarm optimization. Our approach differs from existing works by learning directly from ECG signals (allowing personalization), without requiring costly data annotations. Additionally, our approach can be easily implemented on state-of-the-art spiking-based neuromorphic systems, offering high accuracy, yet significantly low energy footprint, leading to an extended battery-life of wearable devices. We validated our approach with CARLsim, a GPU accelerated spiking neural network simulator modeling Izhikevich spiking neurons with Spike Timing Dependent Plasticity (STDP) and homeostatic scaling. A range of subjects is considered from in-house clinical trials and public ECG databases. Results show high accuracy and low energy footprint in heart-rate estimation across subjects with and without cardiac irregularities, signifying the strong potential of this approach to be integrated in future wearable devices. (C) 2018 Elsevier Ltd. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000425969700012</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>29414535</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram (ECG); Spiking neural networks; Liquid state machine; Spike timing dependent plasticity (STDP); Homeostatic plasticity; Fuzzy c-Means clustering</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NEURAL-NETWORK ARCHITECTURE; SPIKING NEURONS; ECG; ALGORITHM; SYSTEM; IMPLEMENTATION; RECOGNITION; PREDICTION; SYNAPSES; DYNAMICS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Das, Anup; Pradhapan, Paruthi; Groenendaal, Willemijn; Adiraju, Prathyusha; Rajan, Raj Thilak; Catthoor, Francky; Schaafsma, Siebren; Van Hoof, Chris] Stichting IMEC Nederland, High Tech Campus 31, NL-5656 AE Eindhoven, Netherlands. <br>
[Adiraju, Prathyusha] Eindhoven Univ Technol, NL-5612 AZ Eindhoven, Netherlands. <br>
[Catthoor, Francky; Van Hoof, Chris] IMEC Leuven, Kapeldreef 75, B-3001 Heverlee, Belgium. <br>
[Krichmar, Jeffrey L.; Dutt, Nikil] Univ Calif Irvine, Irvine, CA 92697 USA. <br>
[Das, Anup] Drexel Univ, Philadelphia, PA 19104 USA. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Catthoor, F (corresponding author), IMEC Leuven, Kapeldreef 75, B-3001 Heverlee, Belgium.<br>Das, A (corresponding author), Drexel Univ, Dept Elect &amp; Comp Engn, 3120-40 Market St, Philadelphia, PA 19104 USA.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
anup.das@drexel.edu; Francky.Catthoor@imec.be</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Interuniversity Microelectronics Centre; Eindhoven University of Technology; Interuniversity Microelectronics Centre; University of California System; University of California Irvine; Drexel University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Rajan, Raj Thilak</display_name>&nbsp;</td><td>G-4387-2013&nbsp;</td><td>0000-0002-6443-9624&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Das, Anup</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5673-2636&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Van Hoof, Chris</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-4645-3326&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Das, Anup</display_name>&nbsp;</td><td>AAZ-4792-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Rajan, Raj</display_name>&nbsp;</td><td>G-4387-2013&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Neurosciences</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Neurosciences &amp; Neurology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>FX3KA</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0893-6080</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-2782</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>NEURAL NETWORKS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Neural Netw.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>14</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EU-H grant NeuRAM3 Cube (NEUral computing aRchitectures in Advanced Monolithic 3D-VLSI nano-technologies)</grant_agency>&nbsp;</td><td>
<div>687299&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EU-H grant ITEA3 proposal PARTNER (Patient-care Advancement with Responsive Technologies aNd Engagement togetheR)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>We would like to acknowledge our collaborators Dr. Federico Corradi and Prof. Giacomo Indiveri from the Institute of Neuroinformatics at University of Zurich for useful discussions related to this work. Our work is supported in parts by EU-H2020 grant NeuRAM3 Cube (NEUral computing aRchitectures in Advanced Monolithic 3D-VLSI nano-technologies) (Project ID: 687299) and ITEA3 proposal PARTNER (Patient-care Advancement with Responsive Technologies aNd Engagement togetheR).</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 40 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Fitbeat: COVID-19 estimation based on wristband heart rate using a contrastive convolutional auto-encoder</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, S (Liu, Shuo); Han, J (Han, Jing); Puyal, EL (Puyal, Estela Laporta); Kontaxis, S (Kontaxis, Spyridon); Sun, SX (Sun, Shaoxiong); Locatelli, P (Locatelli, Patrick); Dineley, J (Dineley, Judith); Pokorny, FB (Pokorny, Florian B.); Dalla Costa, G (Dalla Costa, Gloria); Leocani, L (Leocani, Letizia); Guerrero, AI (Guerrero, Ana Isabel); Nos, C (Nos, Carlos); Zabalza, A (Zabalza, Ana); Sorensen, PS (Sorensen, Per Soelberg); Buron, M (Buron, Mathias); Magyari, M (Magyari, Melinda); Ranjan, Y (Ranjan, Yatharth); Rashid, Z (Rashid, Zulqarnain); Conde, P (Conde, Pauline); Stewart, C (Stewart, Callum); Folarin, AA (Folarin, Amos A.); Dobson, RJB (Dobson, Richard J. B.); Bail&oacute;n, R (Bailon, Raquel); Vairavan, S (Vairavan, Srinivasan); Cummins, N (Cummins, Nicholas); Narayan, VA (Narayan, Vaibhav A.); Hotopf, M (Hotopf, Matthew); Comi, G (Comi, Giancarlo); Schuller, B (Schuller, Bjoern)</td>
</tr>

<tr>
<td>
<b>Group Author(s):</b>
RADAR-CNS Consortium</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>PATTERN RECOGNITION</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>123</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>108403</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.patcog.2021.108403</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>NOV 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2022 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>23</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>25</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
19</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>30</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This study proposes a contrastive convolutional auto-encoder (contrastive CAE), a combined architecture of an auto-encoder and contrastive loss, to identify individuals with suspected COVID-19 infection using heart-rate data from participants with multiple sclerosis (MS) in the ongoing RADAR-CNS mHealth research project. Heart-rate data was remotely collected using a Fitbit wristband. COVID-19 infection was either confirmed through a positive swab test, or inferred through a self-reported set of recognised symptoms of the virus. The contrastive CAE outperforms a conventional convolutional neural network (CNN), a long short-term memory (LSTM) model, and a convolutional auto-encoder without contrastive loss (CAE). On a test set of 19 participants with MS with reported symptoms of COVID-19, each one paired with a participant with MS with no COVID-19 symptoms, the contrastive CAE achieves an unweighted average recall of 95 . 3% , a sensitivity of 100% and a specificity of 90 . 6% , an area under the receiver operating characteristic curve (AUC-ROC) of 0.944, indicating a maximum successful detection of symptoms in the given heart rate measurement period, whilst at the same time keeping a low false alarm rate. (c) 2021 Elsevier Ltd. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000717961100004</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34720200</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
COVID-19; Respiratory tract infection; Anomaly detection; Contrastive learning; Convolutional auto-encoder</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Shuo; Han, Jing; Dineley, Judith; Pokorny, Florian B.; Cummins, Nicholas; Schuller, Bjoern] Univ Augsburg, EIHW Chair Embedded Intelligence Hlth Care &amp; Well, Augsburg, Germany. <br>
[Han, Jing] Univ Cambridge, Dept Comp Sci &amp; Technol, Cambridge, England. <br>
[Puyal, Estela Laporta; Kontaxis, Spyridon; Bailon, Raquel] Univ Zaragoza, Aragon Inst Engn Res I3A, IIS Aragon, BSICoS Grp, Zaragoza, Spain. <br>
[Puyal, Estela Laporta; Kontaxis, Spyridon; Bailon, Raquel] Biomat &amp; Nanomed CIBER BNN, CIBER Bioengn, Madrid, Spain. <br>
[Sun, Shaoxiong; Ranjan, Yatharth; Rashid, Zulqarnain; Conde, Pauline; Stewart, Callum; Folarin, Amos A.; Dobson, Richard J. B.; Cummins, Nicholas] Kings Coll London, Inst Psychiat Psychol &amp; Neurosci, Dept Biostat &amp; Hlth Informat, London, England. <br>
[Locatelli, Patrick] Univ Bergamo, Dept Engn &amp; Appl Sci, Bergamo, Italy. <br>
[Pokorny, Florian B.] Med Univ Graz, Div Phoniatr, Graz, Austria. <br>
[Dalla Costa, Gloria; Leocani, Letizia] Sci Inst Hosp San Raffaele, Univ Vita Salute San Raffaele &amp; Expt Neurophysiol, Inst Expt Neurol, Milan, Italy. <br>
[Guerrero, Ana Isabel; Nos, Carlos; Zabalza, Ana] Univ Autonoma Barcelona, Hosp Univ Vall dHebron, Multiple Sclerosis Ctr Catalonia Cemcat, Dept Neurol Neuroimmunol, Barcelona, Spain. <br>
[Sorensen, Per Soelberg; Buron, Mathias; Magyari, Melinda] Copenhagen Univ Hosp Rigshosp, Danish Multiple Sclerosis Ctr, Dept Neurol, Copenhagen, Denmark. <br>
[Folarin, Amos A.; Dobson, Richard J. B.] UCL, Inst Hlth Informat, London, England. <br>
[Vairavan, Srinivasan; Narayan, Vaibhav A.] Janssen Res &amp; Dev LLC, Titusville, NJ USA. <br>
[Hotopf, Matthew] Kings Coll London, Inst Psychiat Psychol &amp; Neurosci, Dept Psychol Med, London, England. <br>
[Hotopf, Matthew] South London &amp; Maudsley Natl Hlth Serv Fdn Trust, London, England. <br>
[Comi, Giancarlo] Univ Vita Salute San Raffaele, Casa Cura Privata Policlin, Milan, Italy. <br>
[Schuller, Bjoern] Imperial Coll London, GLAM Grp Language Audio &amp; Mus, London, England. <br>
[RADAR-CNS Consortium] RADAR CNS Consortium, London, England. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liu, S (corresponding author), Univ Augsburg, EIHW Chair Embedded Intelligence Hlth Care &amp; Well, Augsburg, Germany.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
shuo.liu@informatik.uni-augsburg.de</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Augsburg; University of Cambridge; University of Zaragoza; CIBER - Centro de Investigacion Biomedica en Red; CIBERBBN; University of London; King's College London; University of Bergamo; Medical University of Graz; Vita-Salute San Raffaele University; IRCCS Ospedale San Raffaele; Autonomous University of Barcelona; Hospital Universitari Vall d'Hebron; University of Copenhagen; Copenhagen University Hospital; Rigshospitalet; University of London; University College London; Johnson &amp; Johnson; Johnson &amp; Johnson USA; Janssen Biotech Inc; University of London; King's College London; South London &amp; Maudsley NHS Trust; Vita-Salute San Raffaele University; Imperial College London</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Stewart, Callum</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9947-8677&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Dineley, Judith</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5541-6853&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Vairavan, Srinivasan</display_name>&nbsp;</td><td>OHU-2732-2025&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zabalza, Ana</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3860-5251&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Leocani, Letizia</display_name>&nbsp;</td><td>ABH-4703-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Comi, Giancarlo</display_name>&nbsp;</td><td>AAN-1941-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bail&oacute;n, Raquel</display_name>&nbsp;</td><td>L-7781-2014&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Dobson, Richard</display_name>&nbsp;</td><td>C-9269-2011&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Schuller, Bjorn</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6478-8699&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zabalza, Ana</display_name>&nbsp;</td><td>AAX-5767-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Folarin, Amos</display_name>&nbsp;</td><td>IWE-0229-2023&nbsp;</td><td>0000-0002-0333-1927&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Pokorny, Florian</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9203-2904&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Sun, Shaoxiong</display_name>&nbsp;</td><td>GOK-0990-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Magyari, Melinda</display_name>&nbsp;</td><td>AAV-9058-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Costa, Gloria</display_name>&nbsp;</td><td>F-6440-2017&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bailon, Raquel</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1272-0550&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cummins, Nicholas</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1178-917X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Schuller, Bj&ouml;rn</display_name>&nbsp;</td><td>D-3241-2011&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>dobson, richard</display_name>&nbsp;</td><td>C-9269-2011&nbsp;</td><td>0000-0003-4224-9245&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Buron, Mathias</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1260-1156&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Magyari, Melinda</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0972-5222&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>, Ana Isabel</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5891-2123&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Han, Jing</display_name>&nbsp;</td><td>AAB-3944-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cummins, Nicholas</display_name>&nbsp;</td><td>AAC-6431-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Leocani, Letizia</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9326-6753&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hotopf, Matthew</display_name>&nbsp;</td><td>E-4971-2010&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER SCI LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>125 London Wall, London, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>WW5MS</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0031-3203</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-5142</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>PATTERN RECOGN</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Pattern Recognit.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Innovative Medicines Initiative6 2 Joint Undertaking</grant_agency>&nbsp;</td><td>
<div>115902&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>European Union's Horizon 2020 research and innovation programme</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EFPIA</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Medical Research Council</grant_agency>&nbsp;</td><td>
<div>HDR-9002&nbsp;</div>
<div>HDR-9003&nbsp;</div>
<div>HDR-9004&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Institute for Health Research</grant_agency>&nbsp;</td><td>
<div>NF-SI-0515-10102&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This project has received funding from the Innovative Medicines Initiative6 2 Joint Undertaking under grant agreement No 115902. This Joint Undertaking receives support from the European Union's Horizon 2020 research and innovation programme and EFPIA. This communication reflects the views of the RADAR-CNS consortium and neither IMI nor the European Union and EFPIA are liable for any use that may be made of the information contained herein.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 41 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Time-synchrosqueezing generalized W transform for high-resolution time-frequency representation and application in dual-domain ECG classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Li, R (Li, Rui); Chen, H (Chen, Hui); Chen, XP (Chen, Xuping); Liu, YQ (Liu, Yunqi); Xu, JF (Xu, Jinfeng); Lu, Y (Lu, Yao)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>280</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>127459</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2025.127459</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>APR 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JUN 25</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
18</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
18</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>48</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Time-frequency (TF) analysis has received considerable attention in electrocardiogram (ECG) classification, due to its superiority revealing subtle features between various frequencies and time of non-stationary signals. Most existing ECG classification methods employ traditional signal classification or feature extraction with traditional TF analysis methods for classification. However, current TF analysis methods either have low resolution for weak frequency modulation ECG signals, or cannot accurately characterize multi-component low-frequency features relevant to clinical ECG classification. Therefore, to overcome the above limitations, this paper proposed a new TF feature-based deep learning classification method. First, we proposed a timesynchrosqueezing generalized W transform to characterize clinically-relevant low-frequency features of ECG signals with high resolution in both time and frequency domains. Then, based on the generated multi-scale, sparse TF features, we selected a suitable image-based neural network and proposed a new ECG classification framework, which transforms the traditional ECG signal classification into a dual-domain (TF domain) image classification for arrhythmia, normal sinus rhythm, and congestive heart failure, thereby improving ECG classification performance. Furthermore, a three-class classification experiment on public ECG datasets of arrhythmia, normal sinus rhythm, and congestive heart failure illustrated the superior performance of the proposed framework over different state-of-the-art ECG classification methods, achieving an area under the curve (AUC) of 0.996, with accuracy, sensitivity, specificity, and F1 score of 0.987, 0.963, 0.984, and 0.972, respectively.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001470608000001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram (ECG); Generalized W transform; Time-synchrosqueezing; Dual-domain classification</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Li, Rui; Lu, Yao] Sun Yat Sen Univ, Sch Comp Sci &amp; Engn, Guangzhou 510275, Peoples R China. <br>
[Chen, Hui; Chen, Xuping] Chengdu Univ Technol, Sch Math Sci, Chengdu 610059, Peoples R China. <br>
[Liu, Yunqi] Guangzhou Med Univ, Affiliated Hosp 1, Dept Cardiac Surg, Guangzhou 510060, Peoples R China. <br>
[Xu, Jinfeng] City Univ Hong Kong, Dept Biostat, Hong Kong 999077, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Lu, Y (corresponding author), Sun Yat Sen Univ, Sch Comp Sci &amp; Engn, Guangzhou 510275, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
lirui256@mail2.sysu.edu.cn; huichencdut@cdut.edu.cn; xupingchen@stu.cdut.edu.cn; lyunq@mail.sysu.edu.cn; jinfenxu@cityu.edu.hk; luyao23@mail.sysu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Sun Yat Sen University; Chengdu University of Technology; Guangzhou Medical University; City University of Hong Kong</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Xuping</display_name>&nbsp;</td><td>T-5322-2017&nbsp;</td><td>0000-0003-0787-378X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>XU, Jinfeng</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0006-9397-2125&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>1PO1K</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>14</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>China Department of Science and Technology</grant_agency>&nbsp;</td><td>
<div>2023YFE0204300&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>R &amp;D project of Pazhou Lab (HuangPu) , China</grant_agency>&nbsp;</td><td>
<div>2023K0606&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NSFC, China</grant_agency>&nbsp;</td><td>
<div>82441027&nbsp;</div>
<div>62371476&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guangzhou Science and Technology bureau, China</grant_agency>&nbsp;</td><td>
<div>2023B03J1237&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Health Research Major Projects of Hunan Health Commission, China</grant_agency>&nbsp;</td><td>
<div>W20241010&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guangdong Province Key Laboratory of Computational Science at the Sun Yat-sen University, China</grant_agency>&nbsp;</td><td>
<div>2020B1212060032&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the China Department of Science and Technology under Key Grant 2023YFE0204300, in part by the R &amp;D project of Pazhou Lab (HuangPu) , China under Grant 2023K0606, in part by the NSFC, China under Grant 82441027, Grant 62371476, in part by the Guangzhou Science and Technology bureau, China under Grant 2023B03J1237, in part by the Health Research Major Projects of Hunan Health Commission, China under grant W20241010, in part by the Guangdong Province Key Laboratory of Computational Science at the Sun Yat-sen University, China under grant 2020B1212060032.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 42 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Co-attention spatial transformer network for unsupervised motion tracking and cardiac strain analysis in 3D echocardiography</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Ahn, SS (Ahn, Shawn S.); Ta, K (Ta, Kevinminh); Thorn, SL (Thorn, Stephanie L.); Onofrey, JA (Onofrey, John A.); Melvinsdottir, IH (Melvinsdottir, Inga H.); Lee, SP (Lee, Supum); Langdon, J (Langdon, Jonathan); Sinusas, AJ (Sinusas, Albert J.); Duncan, JS (Duncan, James S.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>84</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>102711</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2022.102711</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>DEC 2022</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 FEB</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
18</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>47</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Myocardial ischemia/infarction causes wall-motion abnormalities in the left ventricle. Therefore, reliable motion estimation and strain analysis using 3D+time echocardiography for localization and characterization of myocardial injury is valuable for early detection and targeted interventions. Previous unsupervised cardiac motion tracking methods rely on heavily-weighted regularization functions to smooth out the noisy displacement fields in echocardiography. In this work, we present a Co-Attention Spatial Transformer Network (STN) for improved motion tracking and strain analysis in 3D echocardiography. Co-Attention STN aims to extract inter-frame dependent features between frames to improve the motion tracking in otherwise noisy 3D echocardiography images. We also propose a novel temporal constraint to further regularize the motion field to produce smooth and realistic cardiac displacement paths over time without prior assumptions on cardiac motion. Our experimental results on both synthetic and in vivo 3D echocardiography datasets demonstrate that our Co-Attention STN provides superior performance compared to existing methods. Strain analysis from Co-Attention STNs also correspond well with the matched SPECT perfusion maps, demonstrating the clinical utility for using 3D echocardiography for infarct localization.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000911016400001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>36525845</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Unsupervised motion tracking; Spatiotemporal attention; Echocardiography</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
GLOBAL LONGITUDINAL STRAIN; SPECKLE-TRACKING; DEFORMATION; HEART; MRI</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Ahn, Shawn S.; Ta, Kevinminh; Onofrey, John A.; Sinusas, Albert J.; Duncan, James S.] Yale Univ, Dept Biomed Engn, New Haven, CT 06520 USA. <br>
[Thorn, Stephanie L.; Melvinsdottir, Inga H.; Lee, Supum; Sinusas, Albert J.] Yale Univ, Dept Internal Med, Sect Cardiovasc Med, New Haven, CT USA. <br>
[Onofrey, John A.; Langdon, Jonathan; Sinusas, Albert J.; Duncan, James S.] Yale Univ, Dept Radiol &amp; Biomed Imaging, New Haven, CT USA. <br>
[Duncan, James S.] Yale Univ, Dept Elect Engn, New Haven, CT USA. <br>
[Duncan, James S.] 300 Cedar St, New Haven, CT 06519 USA. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Ahn, SS; Duncan, JS (corresponding author), Yale Univ, Dept Biomed Engn, New Haven, CT 06520 USA.<br>Duncan, JS (corresponding author), Yale Univ, Dept Radiol &amp; Biomed Imaging, New Haven, CT USA.<br>Duncan, JS (corresponding author), Yale Univ, Dept Elect Engn, New Haven, CT USA.<br>Duncan, JS (corresponding author), 300 Cedar St, New Haven, CT 06519 USA.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
shawn.ahn@yale.edu; james.duncan@yale.edu</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Yale University; Yale University; Yale University; Yale University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lee, Supum</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5017-9032&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Onofrey, John</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9432-0448&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ahn, Shawn</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5961-3376&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Duncan, James</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5167-9856&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Langdon, Jonathan</display_name>&nbsp;</td><td>JGL-9505-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Onofrey, John</display_name>&nbsp;</td><td>T-9841-2019&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>7S8QJ</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NIH, USA</grant_agency>&nbsp;</td><td>
<div>R01HL121226&nbsp;</div>
<div>R01HL137365&nbsp;</div>
<div>T32HL098069&nbsp;</div>
<div>S10RR02555&nbsp;</div>
<div>1S10OD028738-01A1&nbsp;</div>
<div>F30HL158154&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NIH Medical Scientist Training Program</grant_agency>&nbsp;</td><td>
<div>T32GM007205&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The authors are immensely thankful for the past and present members of the Yale Translational Research Imaging Center (YTRIC) who were involved in the image acquisition process. This research was made possible through the utilization of the Yale Translational Research Imaging Center. This work was supported in part by the NIH, USA grants R01HL121226, R01HL137365, T32HL098069, S10RR02555, 1S10OD028738-01A1, F30HL158154 and NIH Medical Scientist Training Program Grant T32GM007205.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 43 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>RhythmNet: End-to-End Heart Rate Estimation From Face via Spatial-Temporal Representation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Niu, XS (Niu, Xuesong); Shan, SG (Shan, Shiguang); Han, H (Han, Hu); Chen, XL (Chen, Xilin)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON IMAGE PROCESSING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>29</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2409-2423</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIP.2019.2947204</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>263</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>303</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
104</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>43</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Heart rate (HR) is an important physiological signal that reflects the physical and emotional status of a person. Traditional HR measurements usually rely on contact monitors, which may cause inconvenience and discomfort. Recently, some methods have been proposed for remote HR estimation from face videos; however, most of them focus on well-controlled scenarios, their generalization ability into less-constrained scenarios (e.g., with head movement, and bad illumination) are not known. At the same time, lacking large-scale HR databases has limited the use of deep models for remote HR estimation. In this paper, we propose an end-to-end RhythmNet for remote HR estimation from the face. In RyhthmNet, we use a spatial-temporal representation encoding the HR signals from multiple ROI volumes as its input. Then the spatial-temporal representations are fed into a convolutional network for HR estimation. We also take into account the relationship of adjacent HR measurements from a video sequence via Gated Recurrent Unit (GRU) and achieves efficient HR measurement. In addition, we build a large-scale multi-modal HR database (named as VIPL-HR (1) ), which contains 2,378 visible light videos (VIS) and 752 near-infrared (NIR) videos of 107 subjects. Our VIPL-HR database contains various variations such as head movements, illumination variations, and acquisition device changes, replicating a less-constrained scenario for HR estimation. The proposed approach outperforms the state-of-the-art methods on both the public-domain and our VIPL-HR databases. (1) VIPL-HR is available at: http://vipl.ict.ac.cn/view_database.php?id=15</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000507869900016</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>31647433</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Heart rate; Estimation; Webcams; Databases; Skin; Image color analysis; Head; Remote heart rate estimation; rPPG; spatial-temporal representation; end-to-end learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
REMOTE-PPG; NONCONTACT</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Niu, Xuesong; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China. <br>
[Niu, Xuesong; Shan, Shiguang; Chen, Xilin] Univ Chinese Acad Sci, Sch Comp Sci &amp; Technol, Beijing 100049, Peoples R China. <br>
[Shan, Shiguang; Han, Hu] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China. <br>
[Shan, Shiguang] CAS Ctr Excellence Brain Sci &amp; Intelligence Techn, Shanghai 200031, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Shan, SG (corresponding author), Univ Chinese Acad Sci, Sch Comp Sci &amp; Technol, Beijing 100049, Peoples R China.<br>Shan, SG (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
xuesong.niu@vipl.ict.ac.cn; sgshan@ict.ac.cn; hanhu@ict.ac.cn; xlchen@ict.ac.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; Center for Excellence in Brain Science and Intelligence Technology, CAS</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Shan, Shiguang</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-8348-392X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Xilin</display_name>&nbsp;</td><td>I-4153-2014&nbsp;</td><td>0000-0003-3024-4404&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Han, Hu</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6010-1792&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Xilin</display_name>&nbsp;</td><td>A-1409-2012&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Han, Hu</display_name>&nbsp;</td><td>KKE-6424-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Niu, Xuesong</display_name>&nbsp;</td><td>MEO-3849-2025&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>KD4XT</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1057-7149</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1941-0042</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T IMAGE PROCESS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Image Process.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key R&amp;D Program of China</grant_agency>&nbsp;</td><td>
<div>2017YFA0700800&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61672496&nbsp;</div>
<div>61702486&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>External Cooperation Program of Chinese Academy of Sciences (CAS)</grant_agency>&nbsp;</td><td>
<div>GJHZ1843&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Key R&amp;D Program of China under Grant 2017YFA0700800, in part by the Natural Science Foundation of China under Grant 61672496 and Grant 61702486, and in part by the External Cooperation Program of Chinese Academy of Sciences (CAS) under Grant GJHZ1843.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>ESI Highly Cited Paper:</b>

<value>Y</value>
</td>
</tr>

<tr>
<td>
<b>ESI Hot Paper:</b>

<value>N</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 44 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Diffusion-prior based implicit neural representation for arbitrary-scale cardiac cine MRI super-resolution</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Lyu, J (Lyu, Jun); Wang, GM (Wang, Guangming); Wang, Z (Wang, Zi); Dong, SJ (Dong, Shunjie); Ding, WP (Ding, Weiping); Wang, CY (Wang, Chengyan)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>INFORMATION FUSION</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>126</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>103510</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.inffus.2025.103510</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JUL 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2026 FEB</value>&nbsp;&nbsp;<b>Part:</b> 
<value>A</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
8</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
8</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>69</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Cardiac cine MRI enables dynamic visualization of cardiac motion and provides functional measurements. However, its resolution is often constrained by acquisition window limitations and motion artifacts. Existing super-resolution methods often rely on fixed up-sampling scales, limiting their flexibility to meet diverse imaging requirements. While standard diffusion models have shown strong capabilities in image enhancement, they suffer from lengthy inference times and limited control over detail generation. To address these challenges, this paper introduces a novel diffusion-prior based implicit neural representation (DP-INR) for arbitrary-scale cine MRI super-resolution. DP-INR effectively combines the prior information learning capabilities of diffusion models with the global information integration capacity of spatio-temporal implicit attention. Specifically, reference frame features extracted by an encoder serve as temporal context information, guiding the diffusion model's decoding process of target frame latent features. This approach effectively constrains the inherent uncertainty in latent features during diffusion, thereby enhancing the model's ability to generate fine cardiac details. Subsequently, spatial-aware implicit attention decodes spatial coordinates to produce high-resolution images, while temporal-aware implicit attention facilitates motion estimation. By incorporating diffusion models into implicit neural representations, DP-INR generates high-quality priors with only a few time steps, thereby avoiding the time-consuming iterative optimization process of conventional diffusion models. Experiments on both in-house and public datasets demonstrate that DP-INR outperforms state-of-the-art methods in both quantitative and qualitative evaluations, highlighting its efficacy in improving the resolution of cardiac cine MRI.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001539969500004</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
MRI; Super-resolution; Diffusion; Implicit neural representation; Attention mechanism</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Lyu, Jun; Wang, Guangming; Wang, Chengyan] Fudan Univ, Shanghai Pudong Hosp, Shanghai, Peoples R China. <br>
[Lyu, Jun; Wang, Guangming; Wang, Chengyan] Fudan Univ, Human Phenome Inst, Shanghai, Peoples R China. <br>
[Wang, Zi] Imperial Coll London, Dept Bioengn &amp; Imperial X, London, England. <br>
[Dong, Shunjie] Shanghai Jiao Tong Univ, Sch Med, Coll Hlth Sci &amp; Technol, Fac Med Imaging Technol, Shanghai, Peoples R China. <br>
[Ding, Weiping] Nantong Univ, Sch Artificial Intelligence &amp; Comp Sci, Nantong, Peoples R China. <br>
[Ding, Weiping] City Univ Macau, Fac Data Sci, Taipa, Macao Special A, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Wang, CY (corresponding author), Fudan Univ, Shanghai Pudong Hosp, Shanghai, Peoples R China.<br>Wang, CY (corresponding author), Fudan Univ, Human Phenome Inst, Shanghai, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
wangcy@fudan.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Fudan University; Fudan University; Imperial College London; Shanghai Jiao Tong University; Nantong University; City University of Macau</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Zi</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-8635-8334&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Theory &amp; Methods</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>5NQ1P</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1566-2535</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-6305</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>INFORM FUSION</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Inf. Fusion</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 45 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Spore: Spatio-Temporal Collaborative Perception and representation space disentanglement for remote heart rate measurement</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhang, ZX (Zhang, Zexing); Lu, HM (Lu, Huimin); He, ZH (He, Zhihai); Al-Azzawi, A (Al-Azzawi, Adil); Ma, SZ (Ma, Songzhe); Lin, CL (Lin, Chenglin)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>NEUROCOMPUTING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>630</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>129717</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.neucom.2025.129717</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>FEB 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 MAY 14</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
17</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
22</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>52</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Remote Photoplethysmography (rPPG) leverages standard RGB cameras for contactless heart rate monitoring, overcoming the limitations of traditional PPG technology in telemedicine and offering a highly scalable, costeffective health monitoring solution. Despite the advancements of current deep learning methods, which utilize spatiotemporal convolutional networks to capture subtle rPPG signals, these approaches often fail to fully exploit local similarities and global quasi-periodicity in both spatial and temporal dimensions. Additionally, non-physiological noise remains prevalent in the representation space, impeding the accurate estimation of physiological parameters across diverse representation domains. To address these measurement challenges, we propose Spore, a novel training strategy that integrates a Spatio-Temporal Cooperative Perception Network (STCPNet) and a Separable Network (SpNet). Spore effectively disentangles noise and extracts physiological signals through differential orthogonal disentanglement and parallel approximation techniques, ensuring precise measurement of heart rate. STCPNet meticulously aggregates semantic context across spatial and temporal dimensions, enhancing global-level and trend cross-correlations in a fine-grained manner. Meanwhile, the resource-efficient SpNet identifies and constructs target representation spaces by realigning the distribution of the source latent space, thereby adaptively capturing disentangled physiological signal patterns from the computationally intensive STCPNet. For validation, extensive experiments were conducted not only on multiple benchmark datasets but also through deployment testing in real-world scenarios. The results demonstrate that our proposed training strategy achieves state-of-the-art performance in heart rate measurement while maintaining resource efficiency. The code will be released at https://github.com/zacheryzhang/spore.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001430770600001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Camera-based physiological measurement; Heart rate (HR); Contactless health monitoring; Deep learning; Remote Photoplethysmography (rPPG)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NONCONTACT</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhang, Zexing; Lu, Huimin; Ma, Songzhe; Lin, Chenglin] ChangChun Univ Technol, Sch Comp Sci &amp; Engn, Jilin 130102, Peoples R China. <br>
[He, Zhihai] Southern Univ Sci &amp; Technol, Shenzhen 518055, Peoples R China. <br>
[Al-Azzawi, Adil] Calif State Univ San Bernardino, San Bernardino, CA 92407 USA. <br>
[Zhang, Zexing; Lu, Huimin; Ma, Songzhe; Lin, Chenglin] Smart Hlth Joint Innovat Lab New Generat AI, Jilin 130102, Peoples R China. <br>
[Zhang, Zexing; Lu, Huimin; Ma, Songzhe; Lin, Chenglin] Jilin Prov Sci &amp; Technol Innovat Ctr Multimodal Co, Jilin 130102, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Lu, HM (corresponding author), ChangChun Univ Technol, Sch Comp Sci &amp; Engn, Jilin 130102, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
luhuimin@ccut.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Southern University of Science &amp; Technology; California State University System; California State University San Bernardino</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lu, Huimin</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3786-2363&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Al-Azzawi, Adil</display_name>&nbsp;</td><td>AAZ-2050-2020&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>Y2V7H</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0925-2312</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-8286</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>NEUROCOMPUTING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Neurocomputing</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>14</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Fundamental Research Funds for the Central Universities JLU, China</grant_agency>&nbsp;</td><td>
<div>93K172022K15&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>The 2023 Jilin Provincial Development and Reform Commission Industrial Technology Research and Development Project, China</grant_agency>&nbsp;</td><td>
<div>2023C042-6&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>The 2023 Jilin Provincial Department of Education Science and Technology Research Planning Key Project, China</grant_agency>&nbsp;</td><td>
<div>JJKH20230763KJ&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This research was supported by the Fundamental Research Funds for the Central Universities JLU, China (No. 93K172022K15), 2023 Jilin Provincial Development and Reform Commission Industrial Technology Research and Development Project, China (No. 2023C042-6) and the 2023 Jilin Provincial Department of Education Science and Technology Research Planning Key Project, China (No. JJKH20230763KJ).</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 46 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Heart failure disease stratification with temporal electronic health records: Patient representation and sub identification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liang, Y (Liang, Ye); Guo, CH (Guo, Chonghui); Li, HL (Li, Hailin)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>158</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>111429</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.engappai.2025.111429</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>OCT 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 OCT 22</value>&nbsp;&nbsp;<b>Part:</b> 
<value>B</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
6</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
6</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>76</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Heart failure disease stratification provides health status information for distinct patient subgroups, facilitating timely interventions. However, traditional techniques struggle with the complexity and longitudinality of electronic health records and require a predetermined number of groups, limiting their applicability. To address these challenges, we introduce a novel patient representation model using a temporal dual bidirectional neural network with an attention mechanism to effectively model electronic health records. We also propose a density peak-based clustering method that identifies distinct clinical heart failure sub-phenotypes with minimal manual intervention. Our deep learning model effectively processes electronic health records to generate patient representations. Our clustering method uses an adaptive cut-off distance to reduce manual input and employs affinity propagation's responsibility matrix to determine each patient's local density, automatically identifying sub-phenotype centroids. Evaluation using a real-world clinical dataset and various indicators shows our methods outperform existing approaches. Importantly, they can identify clinically meaningful heart failure sub-phenotypes, with statistical test results holding practical value for clinical decision-making.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001523163000003</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Heart failure; Electronic health records; Patient representation; Disease stratification; Density peak clustering</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
PREDICTION; PNEUMONIA</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liang, Ye; Guo, Chonghui] Dalian Univ Technol, Inst Syst Engn, Dalian, Peoples R China. <br>
[Li, Hailin] Huaqiao Univ, Coll Business Adm, Quanzhou, Peoples R China. <br>
[Li, Hailin] Huaqiao Univ, Res Ctr Appl Stat &amp; Big Data, Xiamen, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Guo, CH (corresponding author), Dalian Univ Technol, Inst Syst Engn, Dalian, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
liangye210@163.com; dlutguo@dlut.edu.cn; liangye210@163.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Dalian University of Technology; Huaqiao University; Huaqiao University</td>
</tr>

<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Automation &amp; Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Automation &amp; Control Systems; Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>4OW9C</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0952-1976</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6769</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>ENG APPL ARTIF INTEL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Eng. Appl. Artif. Intell.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>19</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>71771034&nbsp;</div>
<div>72371049&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Liaoning Province Applied Basic Research Program Project</grant_agency>&nbsp;</td><td>
<div>2023JH2/101300208&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Dalian High Level Talents Innovation Support Plan</grant_agency>&nbsp;</td><td>
<div>2021RD01&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This research is supported by the National Natural Science Foundation of China (Grant No. 71771034 and Grant No. 72371049) , the Liaoning Province Applied Basic Research Program Project (Grant No. 2023JH2/101300208) , and the Dalian High Level Talents Innovation Support Plan (Grant No. 2021RD01) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 47 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>QDRJL: Quaternion dynamic representation with joint learning neural network for heart sound signal abnormal detection</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Qiao, LH (Qiao, Lihong); Li, ZX (Li, Zhixiang); Xiao, B (Xiao, Bin); Shu, YC (Shu, Yucheng); Wang, L (Wang, Li); Shi, YH (Shi, Yuhang); Li, WS (Li, Weisheng); Gao, XB (Gao, Xinbo)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>NEUROCOMPUTING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>562</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>126889</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.neucom.2023.126889</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>OCT 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 DEC 28</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>2</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>2</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
7</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
31</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>29</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
At present, deep learning based heart sound diagnosis algorithms are mostly complex and large models for high accuracy, which are difficult to deploy on mobile devices due to the high number of parameters and large computational cost. The current mainstream approach for processing heart sound signals involves utilizing their Mel-frequency cepstral coefficients (MFCC) features. However, most existing methods have overlooked the multi-channel characteristics of MFCC. To address this issue, we propose a Quaternion Dynamic Representation with Joint Learning (QDRJL) neural network for learning MFCC multi-channel features. Our proposed approach combines quaternion dynamic convolution with dynamic weighting and the Quaternion Interior Learning Block (QILB). Finally, we present a global and energy joint learning branch for jointly learning MFCC features. The success of the proposed quaternion network depends on its ability to utilize the internal relations between quaternion-valued input features and the definition of the dynamic weight variables in the augmented quaternion domain. We assessed various state-of-the-art classification algorithms for detecting heart sounds and found that our proposed classifier achieved an accuracy of up to 97.2%, outperforming existing models. Our experimental evaluation, using the 2016 PhysioNet/CinC Challenge dataset, revealed that our model could reduce the number of network parameters to 25% due to quaternion properties.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001104000100001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Biomedical signal processing; Heart sounds abnormal detection; Quaternion neural network; Quaternion dynamic convolution</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Shu, Yucheng] Chongqing Univ Posts &amp; Telecommun, Chongqing 400065, Peoples R China. <br>
Xingtai Peoples Hosp, Dept Breast Surg, Xingtai 054000, Hebei, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Shu, YC (corresponding author), Chongqing Univ Posts &amp; Telecommun, Chongqing 400065, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
shuyc@cqupt.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Chongqing University of Posts &amp; Telecommunications</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>gao, xin</display_name>&nbsp;</td><td>OGO-6492-2025&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Li, Zhixiang</display_name>&nbsp;</td><td>LLM-5408-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xiao, Bin</display_name>&nbsp;</td><td>E-2722-2012&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>Y2ZM5</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0925-2312</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-8286</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>NEUROCOMPUTING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Neurocomputing</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Project, China</grant_agency>&nbsp;</td><td>
<div>2019YFE0110800&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62276040&nbsp;</div>
<div>62276041&nbsp;</div>
<div>62221005&nbsp;</div>
<div>61976031&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research Instrument Development Program, China</grant_agency>&nbsp;</td><td>
<div>62027827&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Chongqing Education Commission Science and Technology Research Project, China</grant_agency>&nbsp;</td><td>
<div>KJQN202200624&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This research was partially funded by the National Key Research and Development Project, China (Grant 2019YFE0110800) , the National Natural Science Foundation of China (Grants 62276040, 62276041, 62221005 and 61976031) and the National Key Research Instrument Development Program, China (Grant 62027827) , Chongqing Education Commission Science and Technology Research Project, China (Grant KJQN202200624)</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>hybrid</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 48 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A cascaded framework with cross-modality transfer learning for whole heart segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Ding, Y (Ding, Yi); Mu, D (Mu, Dan); Zhang, JQ (Zhang, Jiaqi); Qin, Z (Qin, Zhen); You, L (You, Li); Qin, ZG (Qin, Zhiguang); Guo, YK (Guo, Yingkun)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>PATTERN RECOGNITION</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>147</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>110088</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.patcog.2023.110088</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>NOV 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>16</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
8</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
35</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>39</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Automatic and accurate segmentation of the whole heart structure from 3D cardiac images plays an important role in helping physicians diagnose and treat cardiovascular disease. However, the time-consuming and laborious manual labeling of the heart images results in the inefficiency of utilizing the existing CT or MRI for training the deep learning network, which decrease the accuracy of whole heart segmentation. However, multi-modality data contains multi-level information of cardiac images due to different imaging mechanisms, which is beneficial to improve the segmentation accuracy. Therefore, this paper proposes a cascaded framework with cross-modality transfer learning for whole heart segmentation (CM-TranCaF), which consists of three key modules: modality transfer network (MTN), U-shaped multi-attention network (MAUNet) and spatial configuration network (SCN). In MTN, MRI images are transferred from MRI domain to CT domain, to increase the data volume by adopting the idea of adversarial training. The MAUNet is designed based on UNet, while the attention gates (AGs) are integrated into the skip connection to reduce the weight of background pixels. Moreover, to solve the problem of boundary blur, the position attention block (PAB) is also integrated into the bottom layer to aggregate similar features. Finally, the SCN is used to finetune the segmentation results by utilizing the anatomical information between different cardiac substructures. By evaluating the proposed method on the dataset of the MM-WHS challenge, CM-TranCaF achieves a Dice score of 91.1% on the testing dataset. The extensive experimental results prove the effectiveness of the proposed method compared to other state-of-the-art methods.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001111542700001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Whole heart segmentation; Modality transfer; Generative adversarial training; Unify data distribution; Attention mechanism</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Ding, Yi; Mu, Dan; Zhang, Jiaqi; Qin, Zhen; Qin, Zhiguang] Univ Elect Sci &amp; Technol China, Network &amp; Data Secur Key Lab Sichuan Prov, Sch Informat &amp; Software Engn, Chengdu 610054, Peoples R China. <br>
[You, Li] Erasmus MC, Dept Mol Genet, Rotterdam, Netherlands. <br>
[Guo, Yingkun] Sichuan Univ, West China Univ Hosp 2, Dept Radiol,Minist Educ, Key Lab Obstet &amp; Gynecol &amp; Pediat Dis &amp; Birth Defe, Chengdu 610041, Peoples R China. <br>
[Ding, Yi; Qin, Zhen] YIBIN GREAT Technol Co Ltd, Yibin 644000, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Qin, Z (corresponding author), Univ Elect Sci &amp; Technol China, Network &amp; Data Secur Key Lab Sichuan Prov, Sch Informat &amp; Software Engn, Chengdu 610054, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
yi.ding@uestc.edu.cn; heymudan@163.com; 916822436@qq.com; zhenqin@uestc.edu.cn; l.you@erasmusmc.nl; qinzg@uestc.edu.cn; gykpanda@163.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Electronic Science &amp; Technology of China; Erasmus University Rotterdam; Erasmus MC; Sichuan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>zhang, jiaqi</display_name>&nbsp;</td><td>JNR-7443-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Qin, Zhiguang</display_name>&nbsp;</td><td>MSX-2237-2025&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ding, Yi</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3406-9770&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER SCI LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>125 London Wall, London, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>Z4BJ0</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0031-3203</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-5142</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>PATTERN RECOGN</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Pattern Recognit.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62076054&nbsp;</div>
<div>62072074&nbsp;</div>
<div>62027827&nbsp;</div>
<div>62002047&nbsp;</div>
<div>62372083&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Sichuan Science and Technology Innovation Platform and Talent Plan</grant_agency>&nbsp;</td><td>
<div>2022JDJQ0039&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Sichuan Science and Technology Support Plan</grant_agency>&nbsp;</td><td>
<div>2022YFQ0045&nbsp;</div>
<div>2022YFS0220&nbsp;</div>
<div>2021YFG0131&nbsp;</div>
<div>2023YFS0020&nbsp;</div>
<div>2023YFS 0197&nbsp;</div>
<div>2023YFG0148&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Medico-Engineering Cooperation Funds from University of Electronic Science and Technology of China</grant_agency>&nbsp;</td><td>
<div>ZYGX2021YGLH212&nbsp;</div>
<div>ZYGX2022YGRH012&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>YIBIN Science and Technology Support Plan</grant_agency>&nbsp;</td><td>
<div>2021CG003&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>CCF-Baidu Open Fund</grant_agency>&nbsp;</td><td>
<div>202312&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China (No. 62076054, No. 62072074, No. 62027827, No. 62002047, No. 62372083) , the Sichuan Science and Technology Innovation Platform and Talent Plan (No. 2022JDJQ0039) , the Sichuan Science and Technology Support Plan (No. 2022YFQ0045, No. 2022YFS0220, No. 2021YFG0131, No. 2023YFS0020, No. 2023YFS 0197, No. 2023YFG0148) , the Medico-Engineering Cooperation Funds from University of Electronic Science and Technology of China (No. ZYGX2021YGLH212, No. ZYGX2022YGRH012) , the YIBIN Science and Technology Support Plan (No. 2021CG003) , the CCF-Baidu Open Fund (No. 202312) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 49 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Multi-source partial domain adaptation with Gaussian-based dual-level weighting for PPG-based heart rate estimation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Kim, J (Kim, Jihyun); Cho, HS (Cho, Hansam); Lee, MJ (Lee, Minjung); Kim, SB (Kim, Seoung Bum)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>KNOWLEDGE-BASED SYSTEMS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>309</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>112769</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.knosys.2024.112769</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>NOV 2024</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JAN 30</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
9</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>44</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Photoplethysmography (PPG) signals from wearable devices have expanded the accessibility of heart rate estimation. Recent advances in deep learning have significantly improved the generalizability of heart rate estimation from PPG signals. However, these models exhibit performance degradation when used for new subjects with different PPG distributions. Although previous studies have attempted subject-specific training and finetuning techniques, they require labeled data for each new subject, limiting their practicality. In response, we explore the application of domain adaptation techniques using only unlabeled PPG signals from the target subject. However, naive domain adaptation approaches do not adequately account for the variability in PPG signals among different subjects in the training dataset. Furthermore, they overlook the possibility that the heart rate range of the target subject may only partially overlap with that of the source subjects. To address these limitations, we propose a novel multi-source partial domain adaptation method, GAussian-based dUaL-level weighting (GAUL), designed for the PPG-based heart rate estimation, formulated as a regression task. GAUL considers and adjusts the contribution of relevant source data at the domain and sample levels during domain adaptation. The experimental results on three benchmark datasets demonstrate that our method outperforms existing domain adaptation approaches, enhancing the heart rate estimation accuracy for new subjects without requiring additional labeled data. The code is available at: https://github.com/Im-JihyunKim/GAUL.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001371448200001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
PPG signal; Heart rate estimation; Multi-source partial domain adaptation; Regression</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
FRAMEWORK; NETWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Kim, Jihyun; Cho, Hansam; Kim, Seoung Bum] Korea Univ, Seoul, South Korea. <br>
[Lee, Minjung] Elect &amp; Telecommun Res Inst, Daejeon, South Korea. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Lee, MJ (corresponding author), Elect &amp; Telecommun Res Inst, Daejeon, South Korea.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
minjunglee@etri.re.kr</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Korea University; Electronics &amp; Telecommunications Research Institute - Korea (ETRI)</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>, Jihyun</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0004-6814-9335&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lee, Minjung</display_name>&nbsp;</td><td>JCE-5601-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Kim, Seoung Bum</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-2205-8516&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>, Hansam</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0000-4631-5452&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>O5I0I</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0950-7051</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-7409</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>KNOWL-BASED SYST</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Knowledge-Based Syst.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Brain Korea 21 FOUR</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Ministry of Science and ICT (MSIT) in Korea under the ITRC support program</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Institute for Information Communication Technology Planning and Evaluation</grant_agency>&nbsp;</td><td>
<div>IITP-2020-0-01749&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Research Foundation of Korea - Korea government</grant_agency>&nbsp;</td><td>
<div>RS-2022-00144190&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by Brain Korea 21 FOUR, the Ministry of Science and ICT (MSIT) in Korea under the ITRC support program supervised by the Institute for Information Communication Technology Planning and Evaluation (IITP-2020-0-01749) , and the National Research Foundation of Korea grant funded by the Korea government (RS-2022-00144190) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>hybrid</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 50 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Low-dimensional representation of cardiac motion using Barycentric Subspaces: A new group-wise paradigm for estimation, analysis, and reconstruction</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Roh&eacute;, MM (Rohe, Marc-Michel); Sermesant, M (Sermesant, Maxime); Pennec, X (Pennec, Xavier)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>45</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>1-12</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2017.12.008</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2018 APR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>8</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>9</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
8</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>26</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
One major challenge when trying to build low-dimensional representation of the cardiac motion is its natural circular pattern during a cycle, therefore making the mean image a poor descriptor of the whole sequence. Therefore, traditional approaches for the analysis of the cardiac deformation use one specific frame of the sequence - the end-diastolic (ED) frame - as a reference to study the whole motion. Consequently, this methodology is biased by this empirical choice. Moreover, the ED image might be a poor reference when looking at large deformation for example at the end-systolic (ES) frame. In this paper, we propose a novel approach to study cardiac motion in 4D image sequences using low-dimensional sub-space analysis. Instead of building subspaces relying on a mean value we use a novel type of subspaces called Barycentric Subspaces which are implicitly defined as the weighted Karcher means of k + 1 reference images instead of being defined with respect to one reference image. In the first part of this article, we introduce the methodological framework and the algorithms used to manipulate images within these new subspaces: how to compute the projection of a given image on the Barycentric Subspace with its coordinates, and the opposite operation of computing an image from a set of references and coordinates. Then we show how this framework can be applied to cardiac motion problems and lead to significant improvements over the single reference method. Firstly, by computing the low-dimensional representation of two populations we show that the parameters extracted correspond to relevant cardiac motion features leading to an efficient representation and discrimination of both groups. Secondly, in motion estimation, we use the projection on this low-dimensional subspace as an additional prior on the regularization in cardiac motion tracking, efficiently reducing the error of the registration between the ED and ES by almost 30%. We also derive a symmetric and transitive formulation of the registration that can be used both for frame-to-frame and frame-to-reference registration. Finally, we look at the reconstruction of the images using our proposed low-dimensional representation and show that this multi-references method using Barycentric Subspaces performs better than traditional approaches based on a single reference. (C) 2018 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000427664400001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>29324241</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Low-dimensional analysis; Cardiac motion; Registration; Image synthesis</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
DIFFEOMORPHIC REGISTRATION; DEFORMATION ALGORITHMS; DEMONS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Rohe, Marc-Michel; Sermesant, Maxime; Pennec, Xavier] Univ Cote Dazur, INRIA, Asclepios Res Grp, Nice, France. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Roh&eacute;, MM (corresponding author), Univ Cote Dazur, INRIA, Asclepios Res Grp, Nice, France.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
marc-michel.rohe@inria.fr</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Inria; Universite Cote d'Azur</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Pennec, Xavier</display_name>&nbsp;</td><td>L-2537-2013&nbsp;</td><td>0000-0002-6617-7664&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Sermesant, Maxime</display_name>&nbsp;</td><td>AAC-4870-2019&nbsp;</td><td>0000-0002-6256-8350&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER SCIENCE BV</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>FZ5VM</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EU FP7</grant_agency>&nbsp;</td><td>
<div>600932&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The authors acknowledge the partial funding by the EU FP7-funded project MD-Paedigree (Grant agreement 600932)</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 51 of 51</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>DiT-SFDA: A source-free domain adaptation method for intelligent diagnosis of cardiovascular diseases with limited heart sound samples</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wang, SY (Wang, Suiyan); Liu, Y (Liu, Yang); Liu, ZX (Liu, Zhixiang); Yuan, XM (Yuan, Xiaoming); Ji, Y (Ji, Yun); Liang, PF (Liang, Pengfei)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>285</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>128118</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2025.128118</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>MAY 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 AUG 1</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
16</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
16</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>44</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
In recent years, the application of deep learning in intelligent diagnosis (ID) of cardiovascular diseases (CVDs) has significantly improved diagnostic efficiency and accuracy. However, in practice, owing to data privacy constraints, high labeling cost and specialized medical knowledge, collecting adequate labeled samples continues to present substantial technical difficulties, which makes ID of CVDs under limited samples a challenging issue. In this paper, a novel source-free domain adaptation (SFDA) approach for ID of CVDs, named DiT-SFDA, is proposed by integrating an improved diffusion model based on transformer (DiT) and a semi-supervised domain adaptation network (SDAN). Specifically, the method first converts heart sound (HS) signals into Mel spectrograms that can represent their time-frequency characteristics. Then, more realistic labeled samples are generated through DiT using limited real labeled data, effectively solving training data insufficiency. Subsequently, the generated labeled samples serve as the source domain, while the real samples serve as the limited labeled data in the target domain, and the SDAN based on minimax entropy is employed to further improve the performance of the model. Finally, experimental validation demonstrates that the DiT-SFDA method achieves significantly better diagnostic performance than other methods on two datasets. This innovative approach not only effectively addresses the critical challenge of data scarcity, but also provides an efficient and robust solution for the early screening and precise diagnosis of CVDs.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001492281000001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Diffusion model; Domain adaptation; Cardiovascular disease; Intelligent diagnosis</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wang, Suiyan; Liu, Yang; Liu, Zhixiang; Yuan, Xiaoming; Ji, Yun; Liang, Pengfei] Yanshan Univ, Sch Mech Engn, Qinhuangdao 066004, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liang, PF (corresponding author), Yanshan Univ, Sch Mech Engn, Qinhuangdao 066004, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
wangsy@stumail.ysu.edu.cn; lyang0216@stumail.ysu.edu.cn; zhixiang@stumail.ysu.edu.cn; yuanxiaoming@ysu.edu.cn; jiyun@ysu.edu.cn; liangpf@ysu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Yanshan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liang, Pengfei</display_name>&nbsp;</td><td>KEJ-1689-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liang, Pengfei</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1938-895X&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>2VL9J</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>52405076&nbsp;</div>
<div>52375134&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The work was supported by the National Natural Science Foundation of China No.52405076 and 52375134.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr>
<table xmlns:bean="http://ts.thomson.com/ua/bean">
<tr>
<td>End of File</td>
</tr>
</table><div style="background-color: #000000; padding: 10px; color: #FFFFFF; font-family: arial, sans-serif;">
<div style="height: 25px; width: 100px;">
<mat-icon data-mat-icon-name="clarivate" data-mat-icon-type="svg" aria-hidden="true" class="mat-icon notranslate clarivate-logo mat-icon-no-color" svgicon="clarivate" role="img">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" focusable="false" preserveAspectRatio="xMidYMid meet" version="1.1" viewBox="0 0 92 18" height="100%" width="100%">
<title>Clarivate</title>
<g fill-rule="evenodd" fill="none" stroke-width="1" stroke="none">
<g fill-rule="nonzero" fill="#FFFFFF" transform="translate(-19.000000, -8.000000)">
<g transform="translate(1.000000, 1.000000)">
<g transform="translate(18.000000, 7.000000)">
<path d="M26.6812194,13.2997252 C28.2949641,13.3845068 29.7591419,12.3596036 30.2318671,10.8143235 L33.0910469,10.8143235 C32.3628779,13.742285 29.6973379,15.7705498 26.6812194,15.6916944 C24.8651813,15.7485215 23.1057028,15.0559504 21.8156554,13.7764967 C20.5256081,12.4970431 19.8185526,10.7433351 19.8604035,8.9268901 C19.8185367,7.11043445 20.5255848,5.35671042 21.8156337,4.07724261 C23.1056826,2.7977748 24.8651702,2.10519376 26.6812194,2.16201887 C29.6973451,2.0831702 32.3628861,4.11144761 33.0910469,7.03941847 L30.2318671,7.03941847 C29.7591419,5.49413828 28.2949641,4.46923515 26.6812194,4.55401674 C25.5407067,4.54133389 24.4470406,5.00703241 23.6657805,5.83803342 C22.8845203,6.66903442 22.487126,7.78932829 22.5700912,8.9268901 C22.4871313,10.064447 22.8845287,11.184734 23.6657888,12.0157277 C24.447049,12.8467215 25.540712,13.312413 26.6812194,13.2997252 L26.6812194,13.2997252 Z"/>
<polygon points="36.8477342 15.4674945 34.4371264 15.4674945 34.4371264 2.38628571 36.8477342 2.38628571"/>
<path d="M43.5380316,9.76781183 C43.5380316,9.15114738 43.0522397,8.75870193 42.1178663,8.75870193 C41.2070757,8.82048057 40.3236107,9.0957548 39.5389268,9.5622602 L38.5858286,7.73092465 C39.6930919,7.06514423 40.9567617,6.70409618 42.2486241,6.68441302 C44.1921648,6.68441302 45.9674886,7.58137515 45.9674886,9.84255787 L45.9674886,15.4674945 L43.5380316,15.4674945 L43.5380316,14.6639362 C42.9494098,15.3673061 42.0613957,15.7488608 41.146005,15.6917231 C40.3900371,15.7421039 39.645831,15.484584 39.0826798,14.9777443 C38.5195286,14.4709046 38.1853154,13.7578403 38.1560675,13.0007601 C38.1560675,11.3749188 39.3519468,10.3658089 41.2581433,10.3658089 L42.9400537,10.3658089 C43.3511665,10.3658089 43.5379934,10.1789247 43.5379934,9.86128266 L43.5380316,9.76781183 Z M43.5380316,12.4027631 L43.5380316,11.786089 C43.321275,11.9402969 43.0543042,12.0070182 42.790485,11.9729159 L41.8748173,11.9729159 C41.1086607,11.9729159 40.6602036,12.3092922 40.6602036,12.9072893 C40.6602036,13.486619 41.1272707,13.9164566 41.8748173,13.9164566 C42.303867,13.9699481 42.7348632,13.8332333 43.0546312,13.5422121 C43.3743992,13.2511908 43.5509896,12.8349402 43.5380316,12.4027631 L43.5380316,12.4027631 Z"/>
<path d="M52.6579104,9.3006299 L51.6301236,9.3006299 C50.3966703,9.3006299 49.8361037,9.8799596 49.8361037,11.3749188 L49.8361037,15.4674945 L47.4066179,15.4674945 L47.4066179,6.90863203 L49.7612715,6.90863203 L49.7612715,8.27284306 C50.1001881,7.34759017 51.0007831,6.74968637 51.9850429,6.79648425 C52.2115562,6.79362484 52.4375557,6.81874947 52.6579104,6.87128771 L52.6579104,9.3006299 Z"/>
<path d="M57.4232866,15.4674945 L54.9939445,15.4674945 L54.9939445,8.96425355 L53.7979312,8.96425355 L53.7979312,6.90863203 L57.4232866,6.90863203 L57.4232866,15.4674945 Z M56.0964104,2.38628347 C56.5129556,2.38558064 56.9126431,2.55074046 57.2071855,2.84528284 C57.5017278,3.13982521 57.6668877,3.53951271 57.6661848,3.95605794 C57.6609778,4.814152 56.9638874,5.50702694 56.1057775,5.50702694 C55.2476677,5.50702694 54.5505773,4.814152 54.5453585,3.95605794 C54.5417726,3.09491157 55.2352828,2.39302469 56.0964104,2.38628347 Z"/>
<polygon points="62.8802456 12.8512776 64.8236715 6.90863203 67.3838767 6.90863203 64.33787 15.4674945 61.3292077 15.4674945 58.4139588 6.90863203 61.0488526 6.90863203"/>
<path d="M72.8783522,9.76781183 C72.8783522,9.15114738 72.3924359,8.75870193 71.4580625,8.75870193 C70.5472784,8.82049943 69.6638208,9.09577238 68.8791325,9.5622602 L67.9261491,7.73092465 C69.0333627,7.06513461 70.2969953,6.70408494 71.5888202,6.68441302 C73.5323609,6.68441302 75.3076848,7.58137515 75.3076848,9.84255787 L75.3076848,15.4674945 L72.8783522,15.4674945 L72.8783522,14.6639362 C72.2896971,15.3672586 71.4017035,15.7487939 70.4863256,15.6916944 C69.7303436,15.7420941 68.986117,15.4845835 68.4229464,14.9777426 C67.8597758,14.4709017 67.5255471,13.7578265 67.4962924,13.0007314 C67.4962924,11.3748901 68.6923056,10.3657802 70.5984925,10.3657802 L72.2802785,10.3657802 C72.6913914,10.3657802 72.8783426,10.1788959 72.8783426,9.86125395 L72.8783522,9.76781183 Z M72.8783522,12.4027631 L72.8783522,11.786089 C72.6615874,11.9402794 72.3946236,12.006999 72.1308056,11.9729159 L71.2151378,11.9729159 C70.4488664,11.9729159 70.0004093,12.3092922 70.0004093,12.9072893 C70.0004093,13.486619 70.4676008,13.9164566 71.2151378,13.9164566 C71.6441833,13.9699279 72.0751679,13.8332061 72.394931,13.5421893 C72.7146941,13.2511724 72.8912904,12.8349341 72.8783522,12.4027631 L72.8783522,12.4027631 Z"/>
<path d="M79.9985637,3.65701635 L79.9985637,6.90863203 L81.8485762,6.90863203 L81.8485762,8.96425355 L79.9985637,8.96425355 L79.9985637,12.8325433 C79.9985637,13.3745286 80.4282865,13.4492747 80.8020646,13.4492747 C81.418729,13.4492747 81.9232553,13.3932056 81.9232553,13.3932056 L81.9232553,15.4674945 C81.9232553,15.4674945 80.7459859,15.5796423 80.0357932,15.5796423 C78.8211795,15.5796423 77.5691354,15.3740811 77.5691354,13.6548263 L77.5691354,8.96425355 L76.22363,8.96425355 L76.22363,6.90863203 L77.5691163,6.90863203 L77.5691163,3.65701635 L79.9985637,3.65701635 Z"/>
<path d="M91.5475359,11.8981794 L85.1751771,11.8981794 C85.3031552,12.7204351 85.9194738,13.3815958 86.7307322,13.5669136 C87.5419905,13.7522314 88.3842592,13.4242593 88.856573,12.7391298 L91.3793191,13.0007601 C90.4933306,14.9536735 88.3725856,16.0321989 86.2725384,15.5978628 C84.1724912,15.1635268 82.6535603,13.3322361 82.6149337,11.188092 C82.567807,9.98960603 83.0193435,8.82515843 83.8621298,7.97175307 C84.7049161,7.1183477 85.8636189,6.65226701 87.0626009,6.68438432 C89.4171397,6.68438432 91.5475359,8.21674525 91.5475359,11.8047373 L91.5475359,11.8981794 Z M85.1189837,10.2723955 L88.9499864,10.2723955 C88.8059978,9.34848922 87.9973156,8.67588427 87.0626392,8.70263282 C86.1147409,8.67034807 85.2869107,9.33893202 85.1189837,10.2723955 Z"/>
<path d="M12.6820274,9.85132226 C10.6885049,11.8556057 8.11575776,13.1830474 5.32707189,13.6462054 C5.77780891,14.8758828 6.40559556,16.0331959 7.19058498,17.0815575 C10.3903106,16.2989026 13.3004311,14.619851 15.5794509,12.2414352 C15.0651988,11.0374085 14.3787129,9.91449973 13.5415112,8.90790698 C13.271174,9.23328 12.9846793,9.54772625 12.6820274,9.85124571"/>
<path d="M5.32722498,13.6460332 C4.21304566,10.5852611 4.22627578,7.22758116 5.3645406,4.17568425 C4.07298567,3.95802358 2.75701252,3.92542943 1.45626578,4.07888372 C0.536506305,7.22972054 0.525090565,10.5762272 1.42333236,13.7332656 C2.72217338,13.8896343 4.03666286,13.8602685 5.32722498,13.6460524"/>
<path d="M7.25919787,0.751096346 C6.46424104,1.79423541 5.8259601,2.94792723 5.36457887,4.17561728 C8.13918123,4.64457901 10.6977043,5.96938232 12.6820178,7.96458738 C12.9850078,8.2673988 13.2715025,8.58184824 13.5415017,8.90793568 C14.3788161,7.90142183 15.0653154,6.77849641 15.5794509,5.57440744 C13.3171586,3.21319806 10.4324457,1.54091896 7.25919787,0.751096346"/>
</g>
</g>
</g>
</g>
</svg>
</mat-icon>
</div>
<path d="M5.32722498,13.6460332 C4.21304566,10.5852611 4.22627578,7.22758116 5.3645406,4.17568425 C4.07298567,3.95802358 2.75701252,3.92542943 1.45626578,4.07888372 C0.536506305,7.22972054 0.525090565,10.5762272 1.42333236,13.7332656 C2.72217338,13.8896343 4.03666286,13.8602685 5.32722498,13.6460524"></path>
<path d="M7.25919787,0.751096346 C6.46424104,1.79423541 5.8259601,2.94792723 5.36457887,4.17561728 C8.13918123,4.64457901 10.6977043,5.96938232 12.6820178,7.96458738 C12.9850078,8.2673988 13.2715025,8.58184824 13.5415017,8.90793568 C14.3788161,7.90142183 15.0653154,6.77849641 15.5794509,5.57440744 C13.3171586,3.21319806 10.4324457,1.54091896 7.25919787,0.751096346"></path>
</div>
