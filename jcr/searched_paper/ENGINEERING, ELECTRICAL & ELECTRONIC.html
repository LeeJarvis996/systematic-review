<div xmlns:bean="http://ts.thomson.com/ua/bean" style="background-color: #000000; padding: 10px; color: #FFFFFF; font-family:  arial, sans-serif;">
<div style="height: 25px; width: 100px;">
<mat-icon data-mat-icon-name="clarivate" data-mat-icon-type="svg" aria-hidden="true" class="mat-icon notranslate clarivate-logo mat-icon-no-color" svgicon="clarivate" role="img">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" focusable="false" preserveAspectRatio="xMidYMid meet" version="1.1" viewBox="0 0 92 18" height="100%" width="100%">
<title>Clarivate</title>
<g fill-rule="evenodd" fill="none" stroke-width="1" stroke="none">
<g fill-rule="nonzero" fill="#FFFFFF" transform="translate(-19.000000, -8.000000)">
<g transform="translate(1.000000, 1.000000)">
<g transform="translate(18.000000, 7.000000)">
<path d="M26.6812194,13.2997252 C28.2949641,13.3845068 29.7591419,12.3596036 30.2318671,10.8143235 L33.0910469,10.8143235 C32.3628779,13.742285 29.6973379,15.7705498 26.6812194,15.6916944 C24.8651813,15.7485215 23.1057028,15.0559504 21.8156554,13.7764967 C20.5256081,12.4970431 19.8185526,10.7433351 19.8604035,8.9268901 C19.8185367,7.11043445 20.5255848,5.35671042 21.8156337,4.07724261 C23.1056826,2.7977748 24.8651702,2.10519376 26.6812194,2.16201887 C29.6973451,2.0831702 32.3628861,4.11144761 33.0910469,7.03941847 L30.2318671,7.03941847 C29.7591419,5.49413828 28.2949641,4.46923515 26.6812194,4.55401674 C25.5407067,4.54133389 24.4470406,5.00703241 23.6657805,5.83803342 C22.8845203,6.66903442 22.487126,7.78932829 22.5700912,8.9268901 C22.4871313,10.064447 22.8845287,11.184734 23.6657888,12.0157277 C24.447049,12.8467215 25.540712,13.312413 26.6812194,13.2997252 L26.6812194,13.2997252 Z"/>
<polygon points="36.8477342 15.4674945 34.4371264 15.4674945 34.4371264 2.38628571 36.8477342 2.38628571"/>
<path d="M43.5380316,9.76781183 C43.5380316,9.15114738 43.0522397,8.75870193 42.1178663,8.75870193 C41.2070757,8.82048057 40.3236107,9.0957548 39.5389268,9.5622602 L38.5858286,7.73092465 C39.6930919,7.06514423 40.9567617,6.70409618 42.2486241,6.68441302 C44.1921648,6.68441302 45.9674886,7.58137515 45.9674886,9.84255787 L45.9674886,15.4674945 L43.5380316,15.4674945 L43.5380316,14.6639362 C42.9494098,15.3673061 42.0613957,15.7488608 41.146005,15.6917231 C40.3900371,15.7421039 39.645831,15.484584 39.0826798,14.9777443 C38.5195286,14.4709046 38.1853154,13.7578403 38.1560675,13.0007601 C38.1560675,11.3749188 39.3519468,10.3658089 41.2581433,10.3658089 L42.9400537,10.3658089 C43.3511665,10.3658089 43.5379934,10.1789247 43.5379934,9.86128266 L43.5380316,9.76781183 Z M43.5380316,12.4027631 L43.5380316,11.786089 C43.321275,11.9402969 43.0543042,12.0070182 42.790485,11.9729159 L41.8748173,11.9729159 C41.1086607,11.9729159 40.6602036,12.3092922 40.6602036,12.9072893 C40.6602036,13.486619 41.1272707,13.9164566 41.8748173,13.9164566 C42.303867,13.9699481 42.7348632,13.8332333 43.0546312,13.5422121 C43.3743992,13.2511908 43.5509896,12.8349402 43.5380316,12.4027631 L43.5380316,12.4027631 Z"/>
<path d="M52.6579104,9.3006299 L51.6301236,9.3006299 C50.3966703,9.3006299 49.8361037,9.8799596 49.8361037,11.3749188 L49.8361037,15.4674945 L47.4066179,15.4674945 L47.4066179,6.90863203 L49.7612715,6.90863203 L49.7612715,8.27284306 C50.1001881,7.34759017 51.0007831,6.74968637 51.9850429,6.79648425 C52.2115562,6.79362484 52.4375557,6.81874947 52.6579104,6.87128771 L52.6579104,9.3006299 Z"/>
<path d="M57.4232866,15.4674945 L54.9939445,15.4674945 L54.9939445,8.96425355 L53.7979312,8.96425355 L53.7979312,6.90863203 L57.4232866,6.90863203 L57.4232866,15.4674945 Z M56.0964104,2.38628347 C56.5129556,2.38558064 56.9126431,2.55074046 57.2071855,2.84528284 C57.5017278,3.13982521 57.6668877,3.53951271 57.6661848,3.95605794 C57.6609778,4.814152 56.9638874,5.50702694 56.1057775,5.50702694 C55.2476677,5.50702694 54.5505773,4.814152 54.5453585,3.95605794 C54.5417726,3.09491157 55.2352828,2.39302469 56.0964104,2.38628347 Z"/>
<polygon points="62.8802456 12.8512776 64.8236715 6.90863203 67.3838767 6.90863203 64.33787 15.4674945 61.3292077 15.4674945 58.4139588 6.90863203 61.0488526 6.90863203"/>
<path d="M72.8783522,9.76781183 C72.8783522,9.15114738 72.3924359,8.75870193 71.4580625,8.75870193 C70.5472784,8.82049943 69.6638208,9.09577238 68.8791325,9.5622602 L67.9261491,7.73092465 C69.0333627,7.06513461 70.2969953,6.70408494 71.5888202,6.68441302 C73.5323609,6.68441302 75.3076848,7.58137515 75.3076848,9.84255787 L75.3076848,15.4674945 L72.8783522,15.4674945 L72.8783522,14.6639362 C72.2896971,15.3672586 71.4017035,15.7487939 70.4863256,15.6916944 C69.7303436,15.7420941 68.986117,15.4845835 68.4229464,14.9777426 C67.8597758,14.4709017 67.5255471,13.7578265 67.4962924,13.0007314 C67.4962924,11.3748901 68.6923056,10.3657802 70.5984925,10.3657802 L72.2802785,10.3657802 C72.6913914,10.3657802 72.8783426,10.1788959 72.8783426,9.86125395 L72.8783522,9.76781183 Z M72.8783522,12.4027631 L72.8783522,11.786089 C72.6615874,11.9402794 72.3946236,12.006999 72.1308056,11.9729159 L71.2151378,11.9729159 C70.4488664,11.9729159 70.0004093,12.3092922 70.0004093,12.9072893 C70.0004093,13.486619 70.4676008,13.9164566 71.2151378,13.9164566 C71.6441833,13.9699279 72.0751679,13.8332061 72.394931,13.5421893 C72.7146941,13.2511724 72.8912904,12.8349341 72.8783522,12.4027631 L72.8783522,12.4027631 Z"/>
<path d="M79.9985637,3.65701635 L79.9985637,6.90863203 L81.8485762,6.90863203 L81.8485762,8.96425355 L79.9985637,8.96425355 L79.9985637,12.8325433 C79.9985637,13.3745286 80.4282865,13.4492747 80.8020646,13.4492747 C81.418729,13.4492747 81.9232553,13.3932056 81.9232553,13.3932056 L81.9232553,15.4674945 C81.9232553,15.4674945 80.7459859,15.5796423 80.0357932,15.5796423 C78.8211795,15.5796423 77.5691354,15.3740811 77.5691354,13.6548263 L77.5691354,8.96425355 L76.22363,8.96425355 L76.22363,6.90863203 L77.5691163,6.90863203 L77.5691163,3.65701635 L79.9985637,3.65701635 Z"/>
<path d="M91.5475359,11.8981794 L85.1751771,11.8981794 C85.3031552,12.7204351 85.9194738,13.3815958 86.7307322,13.5669136 C87.5419905,13.7522314 88.3842592,13.4242593 88.856573,12.7391298 L91.3793191,13.0007601 C90.4933306,14.9536735 88.3725856,16.0321989 86.2725384,15.5978628 C84.1724912,15.1635268 82.6535603,13.3322361 82.6149337,11.188092 C82.567807,9.98960603 83.0193435,8.82515843 83.8621298,7.97175307 C84.7049161,7.1183477 85.8636189,6.65226701 87.0626009,6.68438432 C89.4171397,6.68438432 91.5475359,8.21674525 91.5475359,11.8047373 L91.5475359,11.8981794 Z M85.1189837,10.2723955 L88.9499864,10.2723955 C88.8059978,9.34848922 87.9973156,8.67588427 87.0626392,8.70263282 C86.1147409,8.67034807 85.2869107,9.33893202 85.1189837,10.2723955 Z"/>
<path d="M12.6820274,9.85132226 C10.6885049,11.8556057 8.11575776,13.1830474 5.32707189,13.6462054 C5.77780891,14.8758828 6.40559556,16.0331959 7.19058498,17.0815575 C10.3903106,16.2989026 13.3004311,14.619851 15.5794509,12.2414352 C15.0651988,11.0374085 14.3787129,9.91449973 13.5415112,8.90790698 C13.271174,9.23328 12.9846793,9.54772625 12.6820274,9.85124571"/>
<path d="M5.32722498,13.6460332 C4.21304566,10.5852611 4.22627578,7.22758116 5.3645406,4.17568425 C4.07298567,3.95802358 2.75701252,3.92542943 1.45626578,4.07888372 C0.536506305,7.22972054 0.525090565,10.5762272 1.42333236,13.7332656 C2.72217338,13.8896343 4.03666286,13.8602685 5.32722498,13.6460524"/>
<path d="M7.25919787,0.751096346 C6.46424104,1.79423541 5.8259601,2.94792723 5.36457887,4.17561728 C8.13918123,4.64457901 10.6977043,5.96938232 12.6820178,7.96458738 C12.9850078,8.2673988 13.2715025,8.58184824 13.5415017,8.90793568 C14.3788161,7.90142183 15.0653154,6.77849641 15.5794509,5.57440744 C13.3171586,3.21319806 10.4324457,1.54091896 7.25919787,0.751096346"/>
</g>
</g>
</g>
</g>
</svg>
</mat-icon>
</div>
<path d="M5.32722498,13.6460332 C4.21304566,10.5852611 4.22627578,7.22758116 5.3645406,4.17568425 C4.07298567,3.95802358 2.75701252,3.92542943 1.45626578,4.07888372 C0.536506305,7.22972054 0.525090565,10.5762272 1.42333236,13.7332656 C2.72217338,13.8896343 4.03666286,13.8602685 5.32722498,13.6460524"></path>
<path d="M7.25919787,0.751096346 C6.46424104,1.79423541 5.8259601,2.94792723 5.36457887,4.17561728 C8.13918123,4.64457901 10.6977043,5.96938232 12.6820178,7.96458738 C12.9850078,8.2673988 13.2715025,8.58184824 13.5415017,8.90793568 C14.3788161,7.90142183 15.0653154,6.77849641 15.5794509,5.57440744 C13.3171586,3.21319806 10.4324457,1.54091896 7.25919787,0.751096346"></path>
</div><div style="width: 180px; height: 40px; padding: 10px;">
<mat-icon data-mat-icon-name="wos" data-mat-icon-type="svg" aria-hidden="true" style="width: 180px;" class="mat-icon notranslate mat-icon-no-color" svgicon="wos" role="img">
<svg xmlns="http://www.w3.org/2000/svg" focusable="false" preserveAspectRatio="xMidYMid meet" viewBox="0 0 1868 332" height="100%" width="100%">
<title>Web of Science</title>
<path d="M 108.92,75.00            C 108.92,75.00 147.34,75.00 147.34,75.00              147.34,75.00 182.84,208.12 182.84,208.12              182.84,208.12 183.11,208.12 183.11,208.12              183.11,208.12 212.80,75.00 212.80,75.00              212.80,75.00 250.42,75.00 250.42,75.00              250.42,75.00 205.11,261.00 205.11,261.00              205.11,261.00 162.44,261.00 162.44,261.00              162.44,261.00 127.47,127.34 127.47,127.34              127.47,127.34 93.28,261.00 93.28,261.00              93.28,261.00 50.61,261.00 50.61,261.00              50.61,261.00 4.77,75.00 4.77,75.00              4.77,75.00 44.52,75.00 44.52,75.00              44.52,75.00 73.14,208.12 73.14,208.12              73.14,208.12 73.41,208.12 73.41,208.12              73.41,208.12 108.92,75.00 108.92,75.00 Z            M 379.00,210.00            C 379.00,210.00 288.41,210.00 288.41,210.00              289.29,216.78 292.30,222.48 297.44,227.09              302.57,231.70 308.86,234.00 316.30,234.00              327.80,234.00 335.95,230.00 340.73,222.00              340.73,222.00 376.61,225.58 376.61,225.58              371.30,238.39 363.32,248.00 352.69,254.41              342.06,260.80 329.75,264.00 315.77,264.00              297.52,264.00 282.32,257.98 270.19,245.94              258.06,233.90 252.00,218.59 252.00,200.00              252.00,181.42 257.98,166.11 269.94,154.06              281.89,142.02 296.99,136.00 315.23,136.00              333.47,136.00 348.66,142.21 360.80,154.64              372.93,167.06 379.00,185.51 379.00,210.00 Z            M 333.30,171.28            C 328.34,167.09 322.32,165.00 315.23,165.00              308.15,165.00 302.12,167.01 297.16,171.03              292.20,175.04 289.02,180.37 287.61,187.00              287.61,187.00 342.06,187.00 342.06,187.00              341.19,180.71 338.27,175.47 333.30,171.28 Z            M 433.72,245.31            C 433.72,245.31 433.72,261.00 433.72,261.00              433.72,261.00 399.00,261.00 399.00,261.00              399.00,261.00 399.00,75.00 399.00,75.00              399.00,75.00 433.45,75.00 433.45,75.00              433.45,75.00 433.45,134.94 433.45,134.94              433.45,137.95 433.45,141.85 433.45,146.64              433.45,151.42 433.45,154.17 433.45,154.88              436.43,149.39 441.34,144.87 448.17,141.33              455.02,137.78 462.82,136.00 471.59,136.00              488.26,136.00 502.16,142.07 513.30,154.20              524.43,166.33 530.00,181.59 530.00,200.00              530.00,218.41 524.37,233.68 513.11,245.81              501.86,257.94 487.88,264.00 471.17,264.00              462.91,264.00 455.39,262.22 448.62,258.66              441.85,255.09 436.88,250.65 433.72,245.31 Z            M 485.39,176.23            C 479.65,169.98 472.34,166.86 463.45,166.86              454.58,166.86 447.27,169.98 441.53,176.23              435.79,182.48 432.92,190.37 432.92,199.88              432.92,209.20 435.79,217.07 441.53,223.50              447.27,229.93 454.58,233.14 463.45,233.14              472.34,233.14 479.65,229.93 485.39,223.50              491.13,217.07 494.00,209.20 494.00,199.88              494.00,190.37 491.13,182.48 485.39,176.23 Z            M 707.69,245.81            C 695.19,257.94 679.86,264.00 661.72,264.00              643.58,264.00 628.26,257.94 615.75,245.81              603.25,233.68 597.00,218.41 597.00,200.00              597.00,181.59 603.25,166.33 615.75,154.20              628.26,142.07 643.58,136.00 661.72,136.00              679.86,136.00 695.19,142.07 707.69,154.20              720.20,166.33 726.45,181.59 726.45,200.00              726.45,218.41 720.20,233.68 707.69,245.81 Z            M 661.84,166.86            C 652.85,166.86 645.54,170.00 639.91,176.28              634.27,182.55 631.45,190.46 631.45,200.00              631.45,209.54 634.27,217.45 639.91,223.73              645.54,230.01 652.85,233.14 661.84,233.14              670.66,233.14 677.89,230.01 683.53,223.73              689.18,217.45 692.00,209.54 692.00,200.00              692.00,190.46 689.18,182.55 683.53,176.28              677.89,170.00 670.66,166.86 661.84,166.86 Z            M 757.00,139.00            C 757.00,139.00 757.00,104.34 757.00,104.34              757.00,93.15 760.17,84.98 766.52,79.83              772.86,74.67 781.14,72.09 791.36,72.09              791.36,72.09 816.50,73.69 816.50,73.69              816.50,73.69 816.50,105.33 816.50,105.33              809.47,104.45 804.72,104.00 802.27,104.00              798.58,104.00 795.85,104.71 794.09,106.14              792.33,107.57 791.45,110.24 791.45,114.16              791.45,114.16 791.45,139.00 791.45,139.00              791.45,139.00 815.00,139.00 815.00,139.00              815.00,139.00 815.00,168.00 815.00,168.00              815.00,168.00 791.45,168.00 791.45,168.00              791.45,168.00 791.45,260.50 791.45,260.50              791.45,260.50 757.00,260.50 757.00,260.50              757.00,260.50 757.00,168.00 757.00,168.00              757.00,168.00 738.00,168.00 738.00,168.00              738.00,168.00 738.00,139.00 738.00,139.00              738.00,139.00 757.00,139.00 757.00,139.00 Z            M 1004.30,97.27            C 1004.30,97.27 983.11,124.06 983.11,124.06              969.92,111.36 956.73,105.00 943.53,105.00              937.11,105.00 931.59,106.60 926.95,109.80              922.32,112.98 920.00,117.24 920.00,122.56              920.00,131.06 926.74,138.42 940.22,144.62              940.22,144.62 955.66,151.80 955.66,151.80              971.60,159.25 983.48,167.31 991.28,176.00              999.09,184.68 1003.00,195.67 1003.00,208.97              1003.00,223.87 997.13,236.76 985.39,247.66              973.66,258.55 958.09,264.00 938.67,264.00              913.45,264.00 891.31,254.56 872.25,235.67              872.25,235.67 892.52,208.02 892.52,208.02              899.27,214.90 906.74,220.29 914.92,224.17              923.10,228.06 930.83,230.00 938.11,230.00              945.94,230.00 952.21,228.09 956.92,224.28              961.64,220.47 964.00,215.64 964.00,209.80              964.00,203.95 961.65,198.93 956.95,194.77              952.25,190.60 944.85,186.21 934.73,181.61              934.73,181.61 921.70,175.48 921.70,175.48              894.57,162.73 881.00,145.36 881.00,123.38              881.00,107.59 887.05,94.92 899.17,85.36              911.29,75.79 925.91,71.00 943.06,71.00              963.93,71.00 984.34,79.76 1004.30,97.27 Z            M 1082.92,166.86            C 1073.91,166.86 1066.58,170.00 1060.92,176.28              1055.27,182.55 1052.45,190.46 1052.45,200.00              1052.45,209.54 1055.27,217.45 1060.92,223.73              1066.58,230.01 1073.91,233.14 1082.92,233.14              1095.82,233.14 1104.74,226.95 1109.69,214.58              1109.69,214.58 1142.02,224.66 1142.02,224.66              1138.13,236.72 1130.75,246.29 1119.89,253.38              1109.02,260.46 1096.61,264.00 1082.66,264.00              1064.46,264.00 1049.13,257.94 1036.67,245.81              1024.22,233.68 1018.00,218.41 1018.00,200.00              1018.00,181.59 1024.22,166.33 1036.67,154.20              1049.13,142.07 1064.46,136.00 1082.66,136.00              1096.61,136.00 1109.02,139.59 1119.89,146.77              1130.75,153.95 1138.13,163.56 1142.02,175.61              1142.02,175.61 1109.69,185.42 1109.69,185.42              1107.39,179.77 1103.91,175.26 1099.22,171.91              1094.54,168.54 1089.11,166.86 1082.92,166.86 Z            M 1170.31,112.67            C 1166.10,108.45 1164.00,103.27 1164.00,97.12              1164.00,90.98 1166.15,85.76 1170.45,81.45              1174.75,77.15 1179.89,75.00 1185.86,75.00              1192.02,75.00 1197.24,77.15 1201.55,81.45              1205.85,85.76 1208.00,90.98 1208.00,97.12              1208.00,103.27 1205.85,108.45 1201.55,112.67              1197.24,116.89 1192.02,119.00 1185.86,119.00              1179.71,119.00 1174.53,116.89 1170.31,112.67 Z            M 1205.00,139.00            C 1205.00,139.00 1205.00,261.00 1205.00,261.00              1205.00,261.00 1170.55,261.00 1170.55,261.00              1170.55,261.00 1170.55,168.00 1170.55,168.00              1170.55,168.00 1153.50,168.00 1153.50,168.00              1153.50,168.00 1153.50,139.00 1153.50,139.00              1153.50,139.00 1205.00,139.00 1205.00,139.00 Z            M 1353.00,210.00            C 1353.00,210.00 1262.41,210.00 1262.41,210.00              1263.29,216.78 1266.30,222.48 1271.44,227.09              1276.57,231.70 1282.86,234.00 1290.30,234.00              1301.80,234.00 1309.95,230.00 1314.73,222.00              1314.73,222.00 1350.61,225.58 1350.61,225.58              1345.30,238.39 1337.32,248.00 1326.69,254.41              1316.06,260.80 1303.75,264.00 1289.77,264.00              1271.52,264.00 1256.32,257.98 1244.19,245.94              1232.06,233.90 1226.00,218.59 1226.00,200.00              1226.00,181.42 1231.98,166.11 1243.94,154.06              1255.89,142.02 1270.99,136.00 1289.23,136.00              1307.47,136.00 1322.66,142.21 1334.80,154.64              1346.93,167.06 1353.00,185.51 1353.00,210.00 Z            M 1307.30,171.28            C 1302.34,167.09 1296.32,165.00 1289.23,165.00              1282.15,165.00 1276.12,167.01 1271.16,171.03              1266.20,175.04 1263.02,180.37 1261.61,187.00              1261.61,187.00 1316.06,187.00 1316.06,187.00              1315.19,180.71 1312.27,175.47 1307.30,171.28 Z            M 1406.39,153.36            C 1415.92,141.79 1428.27,136.00 1443.45,136.00              1456.87,136.00 1467.72,140.04 1476.02,148.11              1484.30,156.17 1488.45,167.20 1488.45,181.20              1488.45,181.20 1488.45,261.00 1488.45,261.00              1488.45,261.00 1454.00,261.00 1454.00,261.00              1454.00,261.00 1454.00,189.86 1454.00,189.86              1454.00,182.57 1452.00,177.11 1448.00,173.47              1444.01,169.82 1439.09,168.00 1433.25,168.00              1423.50,168.00 1414.90,172.62 1407.45,181.86              1407.45,181.86 1407.45,261.00 1407.45,261.00              1407.45,261.00 1373.00,261.00 1373.00,261.00              1373.00,261.00 1373.00,139.00 1373.00,139.00              1373.00,139.00 1406.39,139.00 1406.39,139.00              1406.39,139.00 1406.39,153.36 1406.39,153.36 Z            M 1573.92,166.86            C 1564.91,166.86 1557.58,170.00 1551.92,176.28              1546.27,182.55 1543.45,190.46 1543.45,200.00              1543.45,209.54 1546.27,217.45 1551.92,223.73              1557.58,230.01 1564.91,233.14 1573.92,233.14              1586.82,233.14 1595.74,226.95 1600.69,214.58              1600.69,214.58 1633.02,224.66 1633.02,224.66              1629.13,236.72 1621.75,246.29 1610.89,253.38              1600.02,260.46 1587.61,264.00 1573.66,264.00              1555.46,264.00 1540.13,257.94 1527.67,245.81              1515.22,233.68 1509.00,218.41 1509.00,200.00              1509.00,181.59 1515.22,166.33 1527.67,154.20              1540.13,142.07 1555.46,136.00 1573.66,136.00              1587.61,136.00 1600.02,139.59 1610.89,146.77              1621.75,153.95 1629.13,163.56 1633.02,175.61              1633.02,175.61 1600.69,185.42 1600.69,185.42              1598.39,179.77 1594.91,175.26 1590.22,171.91              1585.54,168.54 1580.11,166.86 1573.92,166.86 Z            M 1773.00,210.00            C 1773.00,210.00 1682.41,210.00 1682.41,210.00              1683.29,216.78 1686.30,222.48 1691.44,227.09              1696.57,231.70 1702.86,234.00 1710.30,234.00              1721.80,234.00 1729.95,230.00 1734.73,222.00              1734.73,222.00 1770.61,225.58 1770.61,225.58              1765.30,238.39 1757.32,248.00 1746.69,254.41              1736.06,260.80 1723.75,264.00 1709.77,264.00              1691.52,264.00 1676.32,257.98 1664.19,245.94              1652.06,233.90 1646.00,218.59 1646.00,200.00              1646.00,181.42 1651.98,166.11 1663.94,154.06              1675.89,142.02 1690.99,136.00 1709.23,136.00              1727.47,136.00 1742.66,142.21 1754.80,154.64              1766.93,167.06 1773.00,185.51 1773.00,210.00 Z            M 1727.30,171.28            C 1722.34,167.09 1716.32,165.00 1709.23,165.00              1702.15,165.00 1696.12,167.01 1691.16,171.03              1686.20,175.04 1683.02,180.37 1681.61,187.00              1681.61,187.00 1736.06,187.00 1736.06,187.00              1735.19,180.71 1732.27,175.47 1727.30,171.28 Z" stroke-width="1" stroke="black" fill="black"/>
<path d="M 1769.00,76.00            C 1769.00,76.00 1800.00,76.00 1800.00,76.00              1800.00,76.00 1800.00,82.42 1800.00,82.42              1800.00,82.42 1788.00,82.42 1788.00,82.42              1788.00,82.42 1788.00,115.00 1788.00,115.00              1788.00,115.00 1780.84,115.00 1780.84,115.00              1780.84,115.00 1780.84,82.42 1780.84,82.42              1780.84,82.42 1769.00,82.42 1769.00,82.42              1769.00,82.42 1769.00,76.00 1769.00,76.00 Z            M 1827.27,106.64            C 1827.27,106.64 1818.95,106.64 1818.95,106.64              1818.95,106.64 1811.16,87.42 1811.16,87.42              1811.16,87.42 1811.16,115.00 1811.16,115.00              1811.16,115.00 1804.00,115.00 1804.00,115.00              1804.00,115.00 1804.00,76.00 1804.00,76.00              1804.00,76.00 1814.61,76.00 1814.61,76.00              1814.61,76.00 1823.25,98.11 1823.25,98.11              1823.25,98.11 1832.08,76.00 1832.08,76.00              1832.08,76.00 1842.00,76.00 1842.00,76.00              1842.00,76.00 1842.00,115.00 1842.00,115.00              1842.00,115.00 1834.84,115.00 1834.84,115.00              1834.84,115.00 1834.84,87.42 1834.84,87.42              1834.84,87.42 1827.27,106.64 1827.27,106.64 Z" stroke-width="1" stroke="black" fill="black"/>
</svg>
</mat-icon>
</div><table cellspacing="0" cellpadding="2" border="0">
<tr>
<td>63 record(s) printed from Clarivate Web of Science</td>
</tr>
</table><hr>
<table>
<tr>
<td><b>Record 1 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Uncertainty-guided weakly supervised segmentation of cardiac substructures with adapter fine-tuning and Fourier feature extraction</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, SQ (Liu, Siqi); Zhou, SJ (Zhou, Shoujun); Wang, YQ (Wang, Yuanquan); Lu, K (Lu, Ke); Liu, WP (Liu, Weipeng); Wang, ZD (Wang, Zhida)</td>
</tr>

<tr xmlns:bean="http://ts.thomson.com/ua/bean" xmlns:exsl="http://exslt.org/common" xmlns:set="http://exslt.org/sets">
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>283</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>127583</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2025.127583</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>APR 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JUL 15</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
5</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>52</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Accurate delineation of cardiac substructures is crucial for computer-aided diagnosis of heart-related diseases. However, due to the inherent variability and complexity of medical images, achieving accurate segmentation of the complex structures of the whole heart still poses a challenge. Furthermore, labeled medical imaging data with high quality is scarce. To address these challenges, we have developed a novel weakly supervised framework capable of effectively segmenting the whole heart separately in CT and MR images, ensuring outstanding segmentation performance specific to each modality. This framework uses partial pixel-level annotations and bounding box weak labels, employing an uncertainty-guided Mean-Teacher (MT) strategy to reduce reliance on detailed pixel-level annotations. Additionally, to further refine the model's performance, we enhanced it by incorporating the Convolutional Local Spatial Perception Adapter (ConvLSP Adapter) and the Frequency Domain Feature Extraction (FDFE) module. These adaptations specifically boost the model's capability to capture local features, overcoming the limitations of traditional attention layers. To validate the effectiveness of our approach, we conducted experiments using the MICCAI 2017 MM-WHS cardiac dataset. Experimental results show that our method outperforms the boundary-box prompted SAM fully supervised segmentation method, increasing the Dice coefficient by approximately 0.5% for CT and 1.4% for MR. Compared to the MT series segmentation methods, our approach shows improvements of 3.4% for CT and 3% for MR in the Dice coefficient.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001485486900001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Weakly supervised segmentation; SAM; Adapter; Uncertainty estimation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
MEDICAL IMAGE SEGMENTATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Siqi; Wang, Yuanquan; Liu, Weipeng] Hebei Univ Technol HeBUT, Sch Artificial Intelligence, Tianjin 300401, Peoples R China. <br>
[Zhou, Shoujun] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China. <br>
[Lu, Ke] Univ Chinese Acad Sci, Sch Engn Sci, Beijing, Peoples R China. <br>
[Wang, Zhida] Tianjin Med Univ, Chu Hsien I Mem Hosp, NHC Key Lab Hormones &amp; Dev, Tianjin 300134, Peoples R China. <br>
[Wang, Zhida] Tianjin Med Univ, Tianjin Inst Endocrinol, Tianjin Key Lab Metab Dis, Tianjin 300134, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Wang, YQ (corresponding author), Hebei Univ Technol HeBUT, Sch Artificial Intelligence, Tianjin 300401, Peoples R China.<br>Lu, K (corresponding author), Univ Chinese Acad Sci, Sch Engn Sci, Beijing, Peoples R China.<br>Wang, ZD (corresponding author), Tianjin Med Univ, Chu Hsien I Mem Hosp, NHC Key Lab Hormones &amp; Dev, Tianjin 300134, Peoples R China.<br>Wang, ZD (corresponding author), Tianjin Med Univ, Tianjin Inst Endocrinol, Tianjin Key Lab Metab Dis, Tianjin 300134, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
liuweipeng@hebut.edu.cn; sj.zhou@siat.ac.cn; wangyuanquan@scse.hebut.edu.cn; luk@ucas.ac.cn; liuweipeng@hebut.edu.cn; wangyuanquan@scse.hebut.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Tianjin Medical University; Tianjin Medical University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Yuanquan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9232-5392&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>2LM3N</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Science Foundation of China (NSFC)</grant_agency>&nbsp;</td><td>
<div>62472142&nbsp;</div>
<div>61976241&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of Hebei Province</grant_agency>&nbsp;</td><td>
<div>H2024202009&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>International Science and technology cooperation plan project of Zhenjiang</grant_agency>&nbsp;</td><td>
<div>GJ2021008&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Science Foundation of China (NSFC) under Grants 62472142, 61976241, in part by the Jing-Jin-Ji Incorporation Project of the Natural Science Foundation of Hebei Province under Grants H2024202009, and in part by the International Science and technology cooperation plan project of Zhenjiang under grant GJ2021008.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 2 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>DDDG: A dual bi-directional knowledge distillation method with generative self-supervised pre-training and its hardware implementation on SoC for ECG</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhang, HC (Zhang, Huaicheng); Liu, WH (Liu, Wenhan); Guo, QX (Guo, Qianxi); Shi, JG (Shi, Jiguang); Chang, S (Chang, Sheng); Wang, H (Wang, Hao); He, J (He, Jin); Huang, QJ (Huang, Qijun)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>244</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>122969</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2023.122969</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>DEC 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 JUN 15</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>4</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>4</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
20</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>37</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Nowadays, the increase in computing power and data volume boosts the development of deep learning. However, computational resources and the high cost of data labeling are two main obstacles to employing algorithms in various applications. Therefore, a novel method naming Dual Distillation Double Gains (DDDG) is proposed, it is a dual bi-directional knowledge distillation (KD) method with generative self-supervised pre-training. In a self-supervised manner, models are pre-trained with unlabeled data. KD can transfer knowledge from a large model to a lightweight one, which is more suitable for deployments on portable/mobile devices. Based on the teacher-student structure, a reconstructing teacher and a classifying teacher are pre-trained in advance. The reconstructing teacher distills knowledge for the student in pretext tasks by feature-based knowledge. The second distillation occurs in fine-tuning, the classifying teacher mentors the student with response-based knowledge. Both of the distillations are bi-directional, which also reinforce the teacher model in reverse. According to experimental results, F1 score of the student network in two datasets is improved by 8.69% and 9.26% respectively. This value for the teacher is 4.82% and 8.33%. Additionally, DDDG outperforms other state-of-the-art algorithms by 5.25% and 2.06% in F1. For practical applications, DDDG is deployed to a "system-on-a-chip"(SoC) in a heterogeneous manner. Employing ARM and FPGA, the designed system accelerates DDDG by 4.09 times than pure software deployment on the same SoC. The efficient model deployments in heterogeneous systems is promising to be applied to practical applications.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001142871800001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Knowledge distillation (KD); Self-supervised Learning (SSL); Masked time autoencoder (MTAE); Teaching others teaches yourself (TOTY); Cardiovascular diseases (CVD)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CLASSIFICATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhang, Huaicheng; Liu, Wenhan; Guo, Qianxi; Shi, Jiguang; Chang, Sheng; Wang, Hao; He, Jin; Huang, Qijun] Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Huang, QJ (corresponding author), Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
zhuaicheng@whu.edu.cn; WHliu@whu.edu.cn; inge_2017@whu.edu.cn; shijig@whu.edu.cn; changsheng@whu.edu.cn; wanghao@whu.edu.cn; zhuaicheng@whu.edu.cn; huangqj@whu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Wuhan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Hao</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5279-3645&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chang, Sheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4875-5501&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Huaicheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6874-5530&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Shi, Jiguang</display_name>&nbsp;</td><td>LDN-4491-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Han</display_name>&nbsp;</td><td>A-5016-2011&nbsp;</td><td>0000-0001-5448-9903&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Huaicheng</display_name>&nbsp;</td><td>KFA-9029-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>EZ9G0</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>81971702&nbsp;</div>
<div>62074116&nbsp;</div>
<div>61874079&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>&lt;B&gt;Acknowledgments&lt;/B&gt; This work was supported by National Natural Science Foundation of China (81971702, 62074116, and 61874079) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 3 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Knowledge-enhanced meta-transfer learning for few-shot ECG signal classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Fan, LL (Fan, Lulu); Chen, BY (Chen, Bingyang); Zeng, XJ (Zeng, Xingjie); Zhou, JH (Zhou, Jiehan); Zhang, X (Zhang, Xin)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>263</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>125764</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2024.125764</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>NOV 2024</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 MAR 5</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>2</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>3</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
12</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
44</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>48</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Electrocardiogram (ECG) classification aims to identify abnormal cardiac activity that may result in severe damage. The challenge lies in the significant variability among individuals and insufficient data of the target subject. Most methods combine meta-learning and transfer learning to overcome the problem of small samples. However, the model may forget the learned transfer knowledge after several fine-tuning steps, resulting in ineffective transfer. In this paper, we propose a method named KEMT-MCAN, which combines Multilevel Cross-Attention Network (MCAN) and Knowledge-Enhanced Meta-Transfer (KEMT) to improve few-shot ECG classification. First, we develop the MCAN to extract foreground and background features from ECG signals during pre-training, which uses cross-attention to capture signal complexity. Second, we design a KEMT framework to introduce limited target auxiliary knowledge for preventing knowledge forgetting. The KEMT leverages a self-learning weighted fusion (SWF) strategy to extend meta-learning for promoting positive transfer. Results from public datasets show that KEMT-MCAN outperforms the current state-of-the-art works by achieving accuracy up to 91.45% and 80.78% in cross-subject and cross-disease scenarios. We also design noise and class imbalance experiments, totaling 12 cases, to simulate real ECG classification. Our method demonstrates excellent generalization, stability, and efficiency. It shows great potential for application in other time-series classification tasks.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001362031200001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Time series signal classification; Multilevel cross-attention network; Knowledge-enhanced meta transfer; Self-learning weighted fusion; ECG diagnosis</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Fan, Lulu] Zhengzhou Univ Sci &amp; Technol, Zhengzhou 450064, Peoples R China. <br>
[Chen, Bingyang] Henan Univ Technol, Coll Informat Sci &amp; Engn, Zhengzhou 450001, Peoples R China. <br>
[Zeng, Xingjie] Southwest Petr Univ, Sch Comp &amp; Informat Technol, Chengdu 163318, Peoples R China. <br>
[Zhou, Jiehan] Shandong Univ Sci &amp; Technol, Coll Comp Sci &amp; Engn, Qingdao 266590, Peoples R China. <br>
[Zhang, Xin] Hong Kong Univ Sci &amp; Technol, Mech &amp; Aerosp Engn, Hong Kong 999077, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Chen, BY (corresponding author), Henan Univ Technol, Coll Informat Sci &amp; Engn, Zhengzhou 450001, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
lulu_f@zit.edu.cn; bingyangchen@haut.edu.cn; zengxj@swpu.edu.cn; jiehan.zhou@ieee.org; mexzyl@ust.hk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Henan University of Technology; Southwest Petroleum University; Shandong University of Science &amp; Technology; Hong Kong University of Science &amp; Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Bingyang</display_name>&nbsp;</td><td>GXV-3240-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Bingyang</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-2415-8780&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Xin</display_name>&nbsp;</td><td>KIE-1710-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhou, Jiehan</display_name>&nbsp;</td><td>AGW-5302-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Fan, Lulu</display_name>&nbsp;</td><td>P-2168-2016&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Xin</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4236-7436&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>N1L5P</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Founda-tion of China</grant_agency>&nbsp;</td><td>
<div>62072469&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Innovative Funds Plan of Henan University of Technology, China</grant_agency>&nbsp;</td><td>
<div>31401698&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The research is supported by the National Natural Science Founda-tion of China (No. 62072469) , and the Innovative Funds Plan of Henan University of Technology, China (No. 31401698) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 4 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A Multilevel Metric Fusion Framework for Few-Shot Electrocardiogram Classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Gao, TL (Gao, Tianlei); Xie, XY (Xie, Xiaoyun); Liu, H (Liu, Hui); Zhou, SW (Zhou, Shuwang); Shu, ML (Shu, Minglei)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>74</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>4005511</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2025.3553245</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
11</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
11</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>65</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Due to insufficient samples in rare arrhythmia classes, current research in electrocardiogram (ECG) classification has reported poor performance in rare arrhythmia classes and difficulties in promptly generalizing to novel, unseen classes. This article introduces a novel multilevel metric fusion framework specifically designed for few-shot ECG classification. The framework aims to extract multilevel deep local descriptors and learn the intricate relationships between samples across different levels, thereby enhancing the few-shot ECG classification capability. In the proposed method, the episodic training mechanism based on N-way K-shot task is introduced to effectively train deep neural networks with limited samples. Then, a unique multilevel metric fusion framework is developed for similarity learning, which jointly utilizes heartbeat-level and segment-level features for metric learning. Furthermore, the multilevel metric fusion module integrates weighted fusion of heartbeat-level and segment-level scores along the branch dimension, forming a global decision similarity. The proposed method was evaluated on a few-shot ECG database, demonstrating remarkable performance with average accuracies of 72.74%, 69.81%, and 49.84% for five-way ten-shot, five-shot, and one-shot scenarios, respectively. These results significantly surpass existing methods, highlighting the effectiveness of the proposed approach. This study presents a straightforward yet highly effective solution for multilead ECG classification, particularly suitable for few-shot scenarios. Furthermore, the proposed multilevel metric fusion module effectively leverages multilevel features, demonstrating its potential for improved generalization and accuracy in ECG classification tasks. This is the first study to achieve wide-range class classification in few-shot scenarios without relying on auxiliary techniques such as transfer learning or pretraining, and demonstrating important impact to clinical applications.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001459634000029</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram (ECG); episodic training mechanism; few-shot learning (FSL); few-shot learning (FSL); metric fusion; metric fusion; multilevel; multilevel; multilevel</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SCIENTIFIC STATEMENT; ECG; MODEL</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Gao, Tianlei; Zhou, Shuwang] Shandong Univ Sci &amp; Technol, Coll Comp Sci &amp; Engn, Qingdao 266590, Shandong, Peoples R China. <br>
[Gao, Tianlei; Xie, Xiaoyun; Liu, Hui; Zhou, Shuwang; Shu, Minglei] Qilu Univ Technol, Shandong Artificial Intelligence Inst, Shandong Acad Sci, Jinan 250316, Shandong, Peoples R China. <br>
[Gao, Tianlei; Xie, Xiaoyun; Liu, Hui; Zhou, Shuwang; Shu, Minglei] Qilu Univ Technol, Shandong Acad Sci, Sch Math &amp; Stat, Jinan 250316, Shandong, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Xie, XY; Shu, ML (corresponding author), Qilu Univ Technol, Shandong Artificial Intelligence Inst, Shandong Acad Sci, Jinan 250316, Shandong, Peoples R China.<br>Xie, XY; Shu, ML (corresponding author), Qilu Univ Technol, Shandong Acad Sci, Sch Math &amp; Stat, Jinan 250316, Shandong, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
gaotl@sdas.org; xiexy@sdas.org; liuhui@sdas.org; zhousw@sdas.org; shuml@sdas.org</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Shandong University of Science &amp; Technology; Qilu University of Technology; Qilu University of Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xie, Xiaoyun</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3137-5070&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>0ZJ5I</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Taishan Scholars Program: Young Taishan Scholars</grant_agency>&nbsp;</td><td>
<div>tsqn201909137&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by Taishan Scholars Program: Young Taishan Scholars under Grant tsqn201909137.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 5 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Echo-SyncNet: Self-Supervised Cardiac View Synchronization in Echocardiography</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Dezaki, FT (Dezaki, Fatemeh Taheri); Luong, C (Luong, Christina); Ginsberg, T (Ginsberg, Tom); Rohling, R (Rohling, Robert); Gin, K (Gin, Ken); Abolmaesumi, P (Abolmaesumi, Purang); Tsang, T (Tsang, Teresa)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>8</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2092-2104</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3071951</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 AUG</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
16</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>24</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
In echocardiography (echo), an electrocardiogram (ECG) is conventionally used to temporally align different cardiac views for assessing critical measurements. However, in emergencies or point-of-care situations, acquiring an ECG is often not an option, hence motivating the need for alternative temporal synchronization methods. Here, we propose Echo-SyncNet, a self-supervised learning framework to synchronize various cross-sectional 2D echo series without any human supervision or external inputs. The proposed framework takes advantage of two types of supervisory signals derived from the input data: spatiotemporal patterns found between the frames of a single cine (intra-view self-supervision) and interdependencies between multiple cines (inter-view self-supervision). The combined supervisory signals are used to learn a feature-rich and low dimensional embedding space where multiple echo cines can be temporally synchronized. Two intra-view self-supervisions are used, the first is based on the information encoded by the temporal ordering of a cine (temporal intra-view) and the second on the spatial similarities between nearby frames (spatial intra-view). The inter-view self-supervision is used to promote the learning of similar embeddings for frames captured from the same cardiac phase in different echo views. We evaluate the framework with multiple experiments: 1) Using data from 998 patients, Echo-SyncNet shows promising results for synchronizing Apical 2 chamber and Apical 4 chamber cardiac views, which are acquired spatially perpendicular to each other; 2) Using data from 3070 patients, our experiments reveal that the learned representations of Echo-SyncNet outperform a supervised deep learning method that is optimized for automatic detection of fine-grained cardiac cycle phase; 3) We go one step further and show the usefulness of the learned representations in a one-shot learning scenario of cardiac key-frame detection. Without any fine-tuning, key frames in 1188 validation patient studies are identified by synchronizing them with only one labeled reference cine. We do not make any prior assumption about what specific cardiac views are used for training, and hence we show that Echo-SyncNet can accurately generalize to views not present in its training set. Project repository: github.com/fatemehtd/Echo-SyncNet.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000679532100013</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33835916</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Synchronization; Training; Electrocardiography; Task analysis; Annotations; Echocardiography; Two dimensional displays; Echocardiography; fine-grained phase classification; self-supervised learning; synchronization</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Dezaki, Fatemeh Taheri; Abolmaesumi, Purang] Univ British Columbia, Dept Elect &amp; Comp Engn, Vancouver, BC V6T 1Z4, Canada. <br>
[Luong, Christina; Gin, Ken] Univ British Columbia, Vancouver Gen Hosp, Dept Med, Div Cardiol,Echocardiography Lab, Vancouver, BC V5Z 1M9, Canada. <br>
[Ginsberg, Tom] Univ British Columbia, Dept Engn Phys, Vancouver, BC V6T 1Z4, Canada. <br>
[Rohling, Robert] Univ British Columbia, Dept Elect &amp; Comp Engn, Vancouver, BC V6T 1Z4, Canada. <br>
[Rohling, Robert] Univ British Columbia, Dept Mech Engn, Vancouver, BC V6T 1Z4, Canada. <br>
[Tsang, Teresa] Vancouver Gen Hosp, Vancouver, BC V5Z 1M9, Canada. <br>
[Tsang, Teresa] Univ British Columbia, Dept Med, Div Cardiol, Echocardiog Lab, Vancouver, BC V5Z IM9, Canada. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Dezaki, FT (corresponding author), Univ British Columbia, Dept Elect &amp; Comp Engn, Vancouver, BC V6T 1Z4, Canada.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
fatemeht@ece.ubc.ca; christina.luong@ubc.ca; tom.ginsberg@alumni.ubc.ca; rohling@ece.ubc.ca; kenneth.gin@vch.ca; purang@ece.ubc.ca; t.tsang@ubc.ca</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of British Columbia; University of British Columbia; University of British Columbia; University of British Columbia; University of British Columbia; University of British Columbia; University of British Columbia</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gin, Kenneth</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6331-7003&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tsang, Teresa S.M.</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4865-7119&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Abolmaesumi, Purang</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-7259-8609&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Abolmaesumi, Purang</display_name>&nbsp;</td><td>AAE-6670-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ginsberg, Tom</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3458-5188&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Luong, Christina</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-7514-6069&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Dezaki, Fatemeh</display_name>&nbsp;</td><td>AAQ-5296-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tsang, Teresa</display_name>&nbsp;</td><td>AAO-3518-2021&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>TS3CQ</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Sciences and Engineering Research Council of Canada (NSERC)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Canadian Institutes of Health Research (CIHR)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the Natural Sciences and Engineering Research Council of Canada (NSERC) and in part by the Canadian Institutes of Health Research (CIHR). (Fatemeh Taheri Dezaki and Christina Luong contributed equally to this work as first authors.) (Purang Abolmaesumi and Teresa Tsang con-tributed equally to this work as senior authors.)</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted, Bronze</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 6 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Self-Supervised Representation Learning-Based OSA Detection Method Using Single-Channel ECG Signals</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Kumar, CB (Kumar, Chandra Bhushan); Mondal, AK (Mondal, Arnab Kumar); Bhatia, M (Bhatia, Manvir); Panigrahi, BK (Panigrahi, Bijaya Ketan); Gandhi, TK (Gandhi, Tapan Kumar)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>72</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>2511915</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2023.3261931</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>10</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
44</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>64</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Sleep apnea (SA) is a pervasive and highly prevalent sleep disorder identified by recurrent breathing-related problems such as respiratory pauses for almost 10 s (called apnea events) during sleep. It is a strongly underdiagnosed problem because the person suffering from this disease is not aware of this situation. It may cause serious health issues and badly affect the quality of life. Therefore, the diagnosis of sleep is crucial to cure disease. Polysomnography (PSG) is a golden technique for diagnosing sleep disorders. In this technique, multiple sensors are used to collect specific physiological signals such as electroencephalogram (EEG), electromyogram (EMG), electrooculogram (EOG), and many more. In regular clinical practice, medical experts need to manually analyze the signals of sleep hours which is a tedious process. Therefore, the automatic diagnosis tool is needed to simplify this process. Recently, many research groups have proposed deep learning models for the automatic diagnosis of SA using physiological signals with good accuracy. However, all these models require a large amount of annotated data in the supervised training process, which limits the use of those models in real-time scenarios. However, annotating a huge amount of biomedical signals is challenging and requires lots of time and domain expertise. This study proposes a self-supervised representation learning (SSRL) method for detecting hypopnea events from single-channel electrocardiography (ECG) signals. The proposed model is trained in two phases. In the first training phase, an encoder is trained to learn signal representation from the unlabeled data. In the second training phase, the classifier and the encoder are fine-tuned for the classification. Our proposed model performed well on the test dataset with a per-segment classification accuracy of 85%, 89%, and 92% using only 1%, 10%, and 100% of the training data with labels, respectively, for fine-tuning encoder along with the classifier. Also, our proposed model can identify a person suffering from the obstructive SA (OSA) with the accuracy of 100%, even when the encoder and classifier are fine-tuned using only 1% of the training data with the label. The proposed model outperformed the state-of-the-art techniques and can be implemented offline or online for rapid and accurate diagnosis of the problem.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000986586200003</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Sleep apnea; Training; Self-supervised learning; Representation learning; Electrocardiography; Deep learning; Data models; 1-D convolutional neural network (CNN); apnea-hypopnea index (AHI); contrastive learning; obstructive sleep apnea (OSA); self-supervised learning; sleep apnea (SA)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SLEEP-APNEA; NEURAL-NETWORK; CLASSIFICATION; OXIMETRY; EVENTS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Mondal, Arnab Kumar] Indian Inst Technol, Bharti Sch Telecommun &amp; Management, New Delhi 110016, India. <br>
[Mondal, Arnab Kumar] Indian Inst Technol, Sch Informat Technol, New Delhi 110016, India. <br>
[Bhatia, Manvir] Neurol &amp; Sleep Ctr, New Delhi 110016, India. <br>
[Panigrahi, Bijaya Ketan; Gandhi, Tapan Kumar] Indian Inst Technol, Dept Elect Engn, New Delhi 110016, India. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Gandhi, TK (corresponding author), Indian Inst Technol, Dept Elect Engn, New Delhi 110016, India.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
bsz188601@iitd.ac.in; anz208846@iitd.ac.in; bkpanigrahi@ee.iitd.ac.in; tgandhi@iitd.ac.in</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Delhi; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Delhi; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Delhi</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Mondal, Arnab</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7297-374X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gandhi, Tapan Kumar</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3532-9389&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Panigrahi, Bijaya</display_name>&nbsp;</td><td>G-1005-2010&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>G1BE6</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 7 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>MaeFE: Masked Autoencoders Family of Electrocardiogram for Self-Supervised Pretraining and Transfer Learning</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhang, HC (Zhang, Huaicheng); Liu, WH (Liu, Wenhan); Shi, JG (Shi, Jiguang); Chang, S (Chang, Sheng); Wang, H (Wang, Hao); He, J (He, Jin); Huang, QJ (Huang, Qijun)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>72</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2022.3228267</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>15</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>15</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
7</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
73</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>50</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Electrocardiogram (ECG) is a universal diagnostic tool for heart disease, which can provide data for deep learning. The scarcity of labeled data is a major challenge for medical artificial intelligence diagnosis. Acquiring labeled medical data is time-consuming and high-cost because medical specialists are needed. As a kind of generative self-supervised learning method, a masked autoencoder (MAE) is capable to solve these problems. MAE family of ECG (MaeFE) is proposed in this article. Considering the temporal and spatial features of ECG, MaeFE contains three customized masking modes, including masked time autoencoder (MTAE), masked lead autoencoder (MLAE), and masked lead and time autoencoder (MLTAE). MTAE and MLAE pay greater attention to temporal features and spatial features, respectively. MLTAE is a multihead architecture that combines MTAE and MLAE. In the pretraining stage, ECG signals from the pretrain dataset are divided into patches and partially masked. The encoder transfers unmasked patches to tokens and the decoder reconstructs masked ones. In downstream tasks, the pretrained encoder is utilized as a classifier, which is arrhythmia classification performed in the downstream dataset. The process is the so-called transfer learning. MaeFE outperforms the state-of-the-art self-supervised learning methods, SimCLR, MoCo, CLOCS, and MaskUNet in downstream tasks. MTAE has the best comprehensive performance. Compared to contrastive learning models, MTAE achieves at least a 5.18%, 11.80%, and 3.23% increase in accuracy (Acc), Macro-F1, and area under the curve (AUC), respectively, using the linear probe. It also outperforms other models at 8.99% in Acc, 20.18% in Macro-F1, and 7.13% in AUC using fine-tuning. As another downstream task, experiments on the multilabel classification of arrhythmia are also conducted, which reflects the excellent generalization performance of MaeFE. Depending on experimental results, MaeFE turns out to be efficient and robust in downstream tasks. Overcoming the scarcity of labeled data, MaeFE is better than other self-supervised learning methods and achieves satisfying performance. Consequently, the algorithm in this article is on track of playing a major role in practical applications.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000915866600010</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiography (ECG); mask autoencoder (MAE); pretraining; self-supervised learning; transfer learning</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhang, Huaicheng; Liu, Wenhan; Shi, Jiguang; Chang, Sheng; Wang, Hao; He, Jin; Huang, Qijun] Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Hubei, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Huang, QJ (corresponding author), Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Hubei, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
huangqj@whu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Wuhan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Han</display_name>&nbsp;</td><td>A-5016-2011&nbsp;</td><td>0000-0001-5448-9903&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chang, Sheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4875-5501&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Hao</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5279-3645&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Huaicheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6874-5530&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Huaicheng</display_name>&nbsp;</td><td>KFA-9029-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Shi, Jiguang</display_name>&nbsp;</td><td>LDN-4491-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>7Z9JG</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>81971702&nbsp;</div>
<div>62074116&nbsp;</div>
<div>61874079&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the National Natural Science Foundation of China under Grant 81971702, Grant 62074116, and Grant 61874079.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 8 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Self-Supervised Feature Learning for Cardiac Cine MR Image Reconstruction</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Xu, SY (Xu, Siying); Fruh, M (Fruh, Marcel); Hammernik, K (Hammernik, Kerstin); Lingg, A (Lingg, Andreas); Kubler, J (Kubler, Jens); Krumm, P (Krumm, Patrick); Rueckert, D (Rueckert, Daniel); Gatidis, S (Gatidis, Sergios); K&uuml;stner, T (Kustner, Thomas)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>44</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>9</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>3858-3869</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2025.3570226</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 SEP</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
2</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>53</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
We propose a self-supervised feature learning assisted reconstruction (SSFL-Recon) framework for MRI reconstruction to address the limitation of existing supervised learning methods. Although recent deep learning-based methods have shown promising performance in MRI reconstruction, most require fully-sampled images for supervised learning, which is challenging in practice considering long acquisition times under respiratory or organ motion. Moreover, nearly all fully-sampled datasets are obtained from conventional reconstruction of mildly accelerated datasets, thus potentially biasing the achievable performance. The numerous undersampled datasets with different accelerations in clinical practice, hence, remain underutilized. To address these issues, we first train a self-supervised feature extractor on undersampled images to learn sampling-insensitive features. The pre-learned features are subsequently embedded in the self-supervised reconstruction network to assist in removing artifacts. Experiments were conducted retrospectively on an in-house 2D cardiac Cine dataset, including 91 cardiovascular patients and 38 healthy subjects. The results demonstrate that the proposed SSFL-Recon framework outperforms existing self-supervised MRI reconstruction methods and even exhibits comparable or better performance to supervised learning up to 16 x retrospective undersampling. The feature learning strategy can effectively extract global representations, which have proven beneficial in removing artifacts and increasing generalization ability during reconstruction.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001575893400005</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>40408221</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Image reconstruction; Feature extraction; Representation learning; Magnetic resonance imaging; Training; Imaging; Contrastive learning; Sensitivity; Reconstruction algorithms; Data mining; Self-supervised learning; feature learning; contrastive learning; cardiac Cine MRI; MRI reconstruction</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
PARALLEL MRI; SPARSITY; SENSE</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Xu, Siying; Fruh, Marcel; Lingg, Andreas; Kubler, Jens; Krumm, Patrick; Gatidis, Sergios; Kustner, Thomas] Univ Tubingen, Dept Diagnost &amp; Intervent Radiol, Med Image &amp; Data Anal MIDAS Lab, D-72074 Tubingen, Germany. <br>
[Rueckert, Daniel] Tech Univ Munich, Sch Computat Informat &amp; Technol, D-80333 Munich, Germany. <br>
[Rueckert, Daniel] Tech Univ Munich, Klinikum Rechts Isar, D-80333 Munich, Germany. <br>
[Rueckert, Daniel] Imperial Coll London, Dept Comp, London SW7 2AZ, England. <br>
[Gatidis, Sergios] Stanford Univ, Dept Radiol, Stanford, CA 94305 USA. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Xu, SY (corresponding author), Univ Tubingen, Dept Diagnost &amp; Intervent Radiol, Med Image &amp; Data Anal MIDAS Lab, D-72074 Tubingen, Germany.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
siying.xu@med.uni-tuebingen.de; marcel.frueh@med.uni-tuebingen.de; k.hammernik@tum.de; andreas.lingg@med.uni-tuebingen.de; jens.kuebler@med.uni-tuebingen.de; patrick.krumm@med.uni-tuebingen.de; daniel.rueckert@tum.de; sergios.gatidis@med.uni-tuebingen.de; thomas.kuestner@med.uni-tuebingen.de</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Eberhard Karls University of Tubingen; Eberhard Karls University Hospital; Technical University of Munich; Technical University of Munich; Imperial College London; Stanford University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Krumm, Patrick</display_name>&nbsp;</td><td>AAQ-6293-2020&nbsp;</td><td>0000-0003-1705-8439&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Rueckert, Daniel</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5683-5889&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>7OM6C</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>DeutscheForschungsgemeinschaft (DFG, German Research Foundation)</grant_agency>&nbsp;</td><td>
<div>390727645&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the DeutscheForschungsgemeinschaft (DFG, German Research Foundation) through Germany's Excellence Strategy-Clusters of Excellence (EXC) 2064/1 under Project 390727645.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 9 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Few-Shot Learning by a Cascaded Framework With Shape-Constrained Pseudo Label Assessment for Whole Heart Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wang, WJ (Wang, Wenji); Xia, Q (Xia, Qing); Hu, ZQ (Hu, Zhiqiang); Yan, ZN (Yan, Zhennan); Li, ZW (Li, Zhuowei); Wu, Y (Wu, Yang); Huang, N (Huang, Ning); Gao, Y (Gao, Yue); Metaxas, D (Metaxas, Dimitris); Zhang, ST (Zhang, Shaoting)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>10</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2629-2641</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3053008</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>39</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>40</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
34</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>51</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Automatic and accurate 3D cardiac image segmentation plays a crucial role in cardiac disease diagnosis and treatment. Even though CNN based techniques have achieved great success in medical image segmentation, the expensive annotation, large memory consumption, and insufficient generalization ability still pose challenges to their application in clinical practice, especially in the case of 3D segmentation from high-resolution and large-dimension volumetric imaging. In this paper, we propose a few-shot learning framework by combining ideas of semi-supervised learning and self-training for whole heart segmentation and achieve promising accuracy with a Dice score of 0.890 and a Hausdorff distance of 18.539 mm with only four labeled data for training. When more labeled data provided, the model can generalize better across institutions. The key to success lies in the selection and evolution of high-quality pseudo labels in cascaded learning. A shape-constrained network is built to assess the quality of pseudo labels, and the self-training stages with alternative global-local perspectives are employed to improve the pseudo labels. We evaluate our method on the CTA dataset of the MM-WHS 2017 Challenge and a larger multi-center dataset. In the experiments, our method outperforms the state-of-the-art methods significantly and has great generalization ability on the unseen data. We also demonstrate, by a study of two 4D (3D+T) CTA data, the potential of our method to be applied in clinical practice.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000702638800009</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33471751</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Whole heart segmentation; pseudo label; quality assessment; self-training; semi-supervised</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SPARSE REPRESENTATION; MODELS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wang, Wenji; Xia, Qing; Hu, Zhiqiang; Li, Zhuowei; Huang, Ning; Zhang, Shaoting] SenseTime Res, Beijing 100080, Peoples R China. <br>
[Xia, Qing] Tsinghua Univ, Dept Software, Beijing 100084, Peoples R China. <br>
[Yan, Zhennan] SenseBrain Technol Ltd LLC, Princeton, NJ 08540 USA. <br>
[Wu, Yang] Chinese Peoples Liberat Army Gen Hosp, Beijing 100853, Peoples R China. <br>
[Gao, Yue] Tsinghua Univ, Dept Software, Beijing 100084, Peoples R China. <br>
[Metaxas, Dimitris] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA. <br>
[Xia, Qing] Shanghai Jiao Tong Univ, Res Inst, Shanghai 200240, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Xia, Q (corresponding author), SenseTime Res, Beijing 100080, Peoples R China.<br>Xia, Q (corresponding author), Tsinghua Univ, Dept Software, Beijing 100084, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
wangwenji@sensetime.com; xiaqing@sensetime.com; huzhiqiang@sensetime.com; zhennanyan@sensebrain.site; lizhuowei@sensetime.com; 2225012218@qq.com; huangning@sensetime.com; gaoyue@tsinghua.edu.cn; dnm@cs.rutgers.edu; zhangshaoting@sensetime.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Tsinghua University; Chinese People's Liberation Army General Hospital; Tsinghua University; Rutgers University System; Rutgers University New Brunswick; Shanghai Jiao Tong University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gao, Yue</display_name>&nbsp;</td><td>B-3376-2012&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xia, Qing</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0328-7882&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>hu, zhiqiang</display_name>&nbsp;</td><td>HMD-5811-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Shaoting</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-8719-448X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Wenji</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5529-9052&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>WA1FC</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Project of China</grant_agency>&nbsp;</td><td>
<div>Z201100006820064&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>STCSM</grant_agency>&nbsp;</td><td>
<div>2020YFC2004800&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Postdoctoral Research Foundation</grant_agency>&nbsp;</td><td>
<div>19511121400&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the BeijingNova Program under Grant Z201100006820064, in part by the National Key Research and Development Project of China under Grant 2020YFC2004800, in part by the STCSM under Grant 19511121400, and in part by the Beijing Postdoctoral Research Foundation.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 10 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Remote Heart Rate Monitoring in Smart Environments From Videos With Self-Supervised Pretraining</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Gupta, D (Gupta, Divij); Etemad, A (Etemad, Ali)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE INTERNET OF THINGS JOURNAL</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>11</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>6</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>10279-10294</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JIOT.2023.3327623</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 MAR 15</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>2</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
11</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>88</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Recent advances in deep learning have made it increasingly feasible to estimate heart rate (HR) remotely in smart environments by analyzing videos. However, a notable limitation of deep learning methods is their heavy reliance on extensive sets of labeled data for effective training. To address this issue, self-supervised learning has emerged as a promising avenue. Building on this, we introduce a solution that utilizes self-supervised contrastive learning for the estimation of remote photoplethysmography (PPG) and HR monitoring, thereby reducing the dependence on labeled data and enhancing performance. We propose the use of three spatial and three temporal augmentations for training an encoder through a contrastive framework, followed by utilizing the late-intermediate embeddings of the encoder for remote PPG and HR estimation. Our experiments on two publicly available data sets showcase the improvement of our proposed approach over several related works as well as supervised learning baselines, as our results approach the state of the art. We also perform thorough experiments to showcase the effects of using different design choices, such as the video representation learning method, the augmentations used in the pretraining stage, and others. We also demonstrate the robustness of our proposed method over the supervised learning approaches on reduced amounts of labeled data.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001181566200073</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Videos; Estimation; Skin; Heart rate; Training; Deep learning; Convolution; Contrastive learning; photoplethysmography (PPG); remote heart rate (HR); self-supervised learning; smart environments</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
DEEP FACE RECOGNITION; PREDICTION; INTERNET; THINGS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Gupta, Divij; Etemad, Ali] Queens Univ, Dept ECE, Res Inst, Dept Civil Engn, Kingston, ON K7L 3N6, Canada. <br>
[Gupta, Divij; Etemad, Ali] Queens Univ, Ingenu Labs Res Inst, Kingston, ON K7L 3N6, Canada. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Gupta, D (corresponding author), Queens Univ, Dept ECE, Res Inst, Dept Civil Engn, Kingston, ON K7L 3N6, Canada.<br>Gupta, D (corresponding author), Queens Univ, Ingenu Labs Res Inst, Kingston, ON K7L 3N6, Canada.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
gupta.d@queensu.ca; ali.etemad@queensu.ca</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Queens University - Canada; Ingenuity Labs Research Institute; Queens University - Canada</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Etemad, Ali</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7128-0220&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Engineering, Electrical &amp; Electronic; Telecommunications</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Telecommunications</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>KR0C3</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2327-4662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE INTERNET THINGS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Internet Things J.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>16</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>BMO Bank of Montreal</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>No Statement Available</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 11 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Semi-supervised learning for ECG classification without patient-specific labeled data</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhai, XL (Zhai, Xiaolong); Zhou, ZH (Zhou, Zhanhong); Tin, C (Tin, Chung)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>158</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>113411</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2020.113411</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 NOV 15</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>55</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>58</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
99</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>45</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
In this paper, we propose a semi-supervised learning-based ECG classification system for detection of supraventricular ectopic beats (SVEB or S beats) and ventricular ectopic beats (VEB or V beats) which does not require manual labeling of the patient-specific ECG data. Owing to inter-subject variability in ECG signal, patient-specific data is usually required to achieve good performance in ECG classification system. However, manual labeling of patient-specific data requires expert intervention, which is costly and time consuming. Our proposed system is based on a 2D convolutional neural network (CNN) with inputs generated from heartbeat triplets. The system also consists of two auxiliary modules: a normal beat estimation module and an iterative beat label update algorithm. The normal beat estimation selects a small amount of patient-specific normal beats accurately from the testing ECG record in an unsupervised manner. These estimated normal beats are used, together with a common pool dataset, to train a preliminary patient-specific CNN classifier which provides initial labels for the testing data. These labels then undergo a semi-supervised iterative update process for improved performance. Our proposed system was evaluated on the MIT-BIH arrhythmia database. The training of our proposed system is fully automatic, and its performance is comparable with several state-of-art supervised methods which require extra manual labeling of patient-specific ECG data. Our proposed system can be a useful tool for batch processing a large amount of ECG data in clinical applications. (C) 2020 Elsevier Ltd. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000571732700014</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Semi-supervised learning; Arrhythmia; CNN; ECG classification; Time series signal</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
HEARTBEAT CLASSIFICATION; BEAT CLASSIFICATION; ARRHYTHMIA DETECTION; MORPHOLOGY; FEATURES</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhai, Xiaolong; Zhou, Zhanhong; Tin, Chung] City Univ Hong Kong, Dept Biomed Engn, Hong Kong, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Tin, C (corresponding author), City Univ Hong Kong, Dept Biomed Engn, Hong Kong, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
xzhai9-c@my.cityu.edu.hk; zhzhou7-c@my.cityu.edu.hk; chungtin@cityu.edu.hk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
City University of Hong Kong</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>TIN, Chung</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5337-2578&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tin, Chung</display_name>&nbsp;</td><td>A-4457-2010&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhai, Xiaolong</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3126-7325&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>ZHOU, Zhanhong</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9361-9712&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>NR7HV</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Research Grants Council of Hong Kong SAR</grant_agency>&nbsp;</td><td>
<div>CityU 11213717&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by Research Grants Council of Hong Kong SAR (Project CityU 11213717).</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 12 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>AVP-AP: Self-Supervised Automatic View Positioning in 3D Cardiac CT via Atlas Prompting</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Fan, XL (Fan, Xiaolin); Wang, Y (Wang, Yan); Zhang, YY (Zhang, Yingying); Bao, MK (Bao, Mingkun); Jia, BS (Jia, Bosen); Lu, D (Lu, Dong); Gu, YF (Gu, Yifan); Cheng, J (Cheng, Jian); Zhu, HG (Zhu, Haogang)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>44</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>7</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2921-2932</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2025.3554785</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JUL</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
8</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
8</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>53</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Automatic view positioning is crucial for cardiac computed tomography (CT) examinations, including disease diagnosis and surgical planning. However, it is highly challenging due to individual variability and large 3D search space. Existing work needs labor-intensive and time-consuming manual annotations to train view-specific models, which are limited to predicting only a fixed set of planes. However, in real clinical scenarios, the challenge of positioning semantic 2D slices with any orientation into varying coordinate space in arbitrary 3D volume remains unsolved. We thus introduce a novel framework, AVP-AP, the first to use Atlas Prompting for self-supervised Automatic View Positioning in the 3D CT volume. Specifically, this paper first proposes an atlas prompting method, which generates a 3D canonical atlas and trains a network to map slices into their corresponding positions in the atlas space via a self-supervised manner. Then, guided by atlas prompts corresponding to the given query images in a reference CT, we identify the coarse positions of slices in the target CT volume using rigid transformation between the 3D atlas and target CT volume, effectively reducing the search space. Finally, we refine the coarse positions by maximizing the similarity between the predicted slices and the query images in the feature space of a given foundation model. Our framework is flexible and efficient compared to other methods, outperforming other methods by 19.8% average structural similarity (SSIM) in arbitrary view positioning and achieving 9% SSIM in two-chamber view compared to four radiologists. Meanwhile, experiments on a public dataset validate our framework's generalizability.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001523480800028</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>40138235</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Computed tomography; Three-dimensional displays; Planning; Standards; Solid modeling; Image segmentation; Anatomical structure; Predictive models; Foundation models; Computational modeling; Automatic view positioning; atlas prompting; cardiac computed tomography; foundation model; self-supervised learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
TO-VOLUME REGISTRATION; IMAGE REGISTRATION; FRAMEWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Fan, Xiaolin; Wang, Yan; Gu, Yifan] Beihang Univ, Sch Instrumentat &amp; Optoelect Engn, Beijing 100191, Peoples R China. <br>
[Zhang, Yingying; Zhu, Haogang] Beihang Univ, Hangzhou Int Innovat Inst, Data Sci &amp; Intelligent Comp Lab, Hangzhou 311115, Peoples R China. <br>
[Bao, Mingkun; Lu, Dong; Cheng, Jian; Zhu, Haogang] Beihang Univ, Sch Comp Sci &amp; Engn, Beijing 100191, Peoples R China. <br>
[Jia, Bosen] Victoria Univ Wellington, Sch Biol Sci, Wellington 6012, New Zealand. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhang, YY; Zhu, HG (corresponding author), Beihang Univ, Hangzhou Int Innovat Inst, Data Sci &amp; Intelligent Comp Lab, Hangzhou 311115, Peoples R China.<br>Cheng, J; Zhu, HG (corresponding author), Beihang Univ, Sch Comp Sci &amp; Engn, Beijing 100191, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
fanxiaolin.buaa@qq.com; wangyan9509@gmail.com; yingyingzhangbuaa@163.com; bravomikekilo@buaa.edu.cn; jiabose@myvuw.ac.nz; donglusx@gmail.com; guyifan@buaa.edu.cn; jian_cheng@buaa.edu.cn; haogangzhu@buaa.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Beihang University; Beihang University; Beihang University; Victoria University Wellington</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Jia, Bosen</display_name>&nbsp;</td><td>GSD-1813-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>zhang, yingying</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0964-1774&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>4PJ0F</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62406014&nbsp;</div>
<div>U21A20523&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Natural Science Foundation</grant_agency>&nbsp;</td><td>
<div>7244325&nbsp;</div>
<div>L222152&nbsp;</div>
<div>L242038&nbsp;</div>
<div>4252004&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Start-Up Funds of Hangzhou International Innovation Institute of Beihang University</grant_agency>&nbsp;</td><td>
<div>2024KQ045&nbsp;</div>
<div>2024KQ027&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Peking University Third Hospital Fund for Interdisciplinary Research</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under 62406014 and Grant U21A20523; in part by Beijing Natural Science Foundation underGrant 7244325, Grant L222152, Grant L242038, and Grant 4252004; in part by the Start-Up Funds of Hangzhou International Innovation Institute of Beihang University under Grant 2024KQ045 and Grant 2024KQ027; and in part by Peking University Third Hospital Fund for Interdisciplinary Research.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 13 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Semi-Supervised Learning With Kolmogorov-Arnold Network for MRI Cardiac Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Li, CS (Li, Congsheng); Xu, X (Xu, Xu)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>74</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>2515311</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2025.3550246</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
10</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
10</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>58</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
MRI cardiac segmentation plays a vital role for the diagnosis of cardiovascular disease. Recently, many studies have developed semi-supervised learning (SSL) algorithms for this purpose. However, two challenges are still unsolved, i.e., linear pattern modeling and limited perturbation space. To this end, we develop KS-Net, an innovative framework for MRI cardiac segmentation, incorporating the Kolmogorov-Arnold network (KAN) module and an SSL-based perturbation strategy. Specifically, this work designs a U-shaped network with the KAN module to be compatible with nonlinear high-level features. In addition, we introduce a dual-stream perturbation approach to investigate the predefined perturbation space at the image level and leverage SSL for discriminative representations. Our proposed KS-Net is trained and tested on MyoPS 2020 and automated cardiac diagnosis challenge (ACDC) datasets. Experimental results indicated that it effectively outperforms existing state-of-the-art (SOTA) methods in MRI cardiac segmentation.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001453416800036</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Image segmentation; Perturbation methods; Magnetic resonance imaging; Supervised learning; Training; Feature extraction; Deep learning; Convolution; Unsupervised learning; Kolmogorov-Arnold network (KAN); MRI cardiac segmentation; semi-supervised learning (SSL); semi-supervised learning (SSL)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ATLASES</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Li, Congsheng; Xu, Xu] China Acad Informat &amp; Commun Technol, China Telecommun Technol Lab, Beijing 100191, Peoples R China. <br>
[Xu, Xu] Northeastern Univ, Sch Comp Sci &amp; Engn, Shenyang 110004, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Xu, X (corresponding author), China Acad Informat &amp; Commun Technol, China Telecommun Technol Lab, Beijing 100191, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
xuxu@ieee.org</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
China Academy of Information &amp; Communication Technology; Northeastern University - China</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Li, Congsheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-7658-1943&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Li, Congsheng</display_name>&nbsp;</td><td>LSJ-6944-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>0QF5I</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62171458&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Program of China</grant_agency>&nbsp;</td><td>
<div>2022YFC2408000&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Youth Talent Support Program for Doctoral Students of the China Association for Science and Technology</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under Grant 62171458, in part by the National Key Research and Development Program of China under Grant 2022YFC2408000, and in part by the Youth Talent Support Program for Doctoral Students of the China Association for Science and Technology.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 14 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>TCNTransNet: A Semi-Supervised Temporal-Spatial Fusion Framework for Heart Rate Estimation From Camera Video</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Hou, BL (Hou, Bailin); Lv, YM (Lv, Yimou); Qi, L (Qi, Lin); Li, YC (Li, Yongchun)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON CONSUMER ELECTRONICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>71</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>2</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>5837-5846</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TCE.2024.3424338</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 MAY</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
2</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>50</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Remote photoplethysmography (rPPG) offers a remote and non-contact approach to measure physiological signals, such as Heart Rate (HR), from facial videos. With the convenience of capturing video from cameras, rPPG technology can be widely used in daily health monitoring. However, rPPG measurements are susceptible to interference caused by various external factors, such as changes in environmental light and movements from devices and humans. In this paper, we propose a novel rPPG-based HR estimation framework called TCNTransNet. The TCNTransNet is designed with a parallel architecture, which includes Temporal Convolution Network (TCN) and Transformer, can simultaneously capture the local details and global periodicity of rPPG signals. Additionally, we introduce a bidirectional Cross-Attention module to fuse information and mutually complement TCN and Transformer. To leverage the temporal and frequency characteristics of rPPG signals, we adopt a two-stage training strategy in a semi-supervised manner that constrains the signal frequency range learned by the proposed model. We evaluate our method for HR estimation on two challenging public benchmark datasets, COHFACE and VIPL-HR. Extensive experiments demonstrate that our method achieves comparable performance over various complex scenarios.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001554481300031</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Remote photoplethysmography; heart rate estimation; temporal convolutional network; transformer; Remote photoplethysmography; heart rate estimation; temporal convolutional network; transformer</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Hou, Bailin; Lv, Yimou; Qi, Lin] Northeastern Univ, Coll Med &amp; Biol Informat Engn, Shenyang 110004, Peoples R China. <br>
[Qi, Lin] Northeastern Univ, Engn Res Ctr Med Imaging &amp; Intelligent Anal, Shenyang 110169, Peoples R China. <br>
[Qi, Lin] Northeastern Univ, Key Lab Med Image Comp, Minist Educ, Shenyang 110169, Peoples R China. <br>
[Li, Yongchun] Shenyang Contain Elect Technol Co Ltd, Dept Prod Design, Shenyang 110167, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Qi, L (corresponding author), Northeastern Univ, Coll Med &amp; Biol Informat Engn, Shenyang 110004, Peoples R China.<br>Qi, L (corresponding author), Northeastern Univ, Engn Res Ctr Med Imaging &amp; Intelligent Anal, Shenyang 110169, Peoples R China.<br>Qi, L (corresponding author), Northeastern Univ, Key Lab Med Image Comp, Minist Educ, Shenyang 110169, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
hbl87988071@gmail.com; lvyimou233@gmail.com; qilin@bmie.neu.edu.cn; liyongchun@contain.com.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Northeastern University - China; Northeastern University - China; Northeastern University - China</td>
</tr>

<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Telecommunications</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Telecommunications</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>6IY8S</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0098-3063</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-4127</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T CONSUM ELECTR</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Consum. Electron.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Program of China</grant_agency>&nbsp;</td><td>
<div>2020YFC2004400&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of Liaoning Province (General Program)</grant_agency>&nbsp;</td><td>
<div>2021-MS-087&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shenyang Science and Technology Plan Fund</grant_agency>&nbsp;</td><td>
<div>21-104-1-24&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Key Research and Development Program of China under Grant 2020YFC2004400; in part by the Natural Science Foundation of Liaoning Province (General Program) under Grant 2021-MS-087; and in part by the Shenyang Science and Technology Plan Fund under Grant 21-104-1-24.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 15 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>An Atrial Fibrillation Detection Strategy Based on Self-Supervised Pretraining in Wearable ECG Monitoring</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Ma, CY (Ma, Caiyun); Sheng, WJ (Sheng, Weijie); Wang, ZY (Wang, Zhongyu); Zhao, LN (Zhao, Lina); Zhang, YW (Zhang, Yuwei); Cai, ZP (Cai, Zhipeng); Li, JQ (Li, Jianqing); Liu, CY (Liu, Chengyu)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>74</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>4003611</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2025.3546413</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
9</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
11</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>36</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Atrial fibrillation (AF) is an insidious cardiac arrhythmia, with its incidence increasing annually. Timely screening and home-based interventions play a vital role in the effective management of AF. Within the Internet of Medical Things (IoMT) landscape, wearable electrocardiogram (ECG) monitoring devices have been seamlessly integrated to monitor AF. Nonetheless, the substantial influx of ECG signals awaiting annotation and the exorbitant costs associated with employing specialists for manual annotation pose significant hurdles in the development of AF detection systems. Despite the potential utilization of AF detectors trained on open databases, their efficacy in analyzing continuous wearable ECGs remains inadequate. Self-supervised representation learning proficiently characterizes unlabeled data and enhances data utilization without labels. This study proposes an AF detection strategy based on self-supervised pretraining, aiming for optimal AF detection performance with minimal annotation costs. The proposed method employed self-supervised representation learning and pretraining strategy and was validated on four datasets from the fourth China Physiological Signal Challenge 2021 (CPSC2021) database, achieving accuracies of 98.13%, 90.11%, 92.63%, and 91.29%. In addition, validation on 20 wearable ECG recordings yielded mean accuracies of 99.38% and 99.48% for AF and Non-AF on unlabeled data from recordings used for fine-tuning, respectively. We achieved mean accuracies of 97.19% and 94.15% for AF and Non-AF on independent recordings, respectively. The results demonstrate the proposed method's reliability for AF detection in wearable ECG monitoring.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001447532000009</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiography; Biomedical monitoring; Databases; Monitoring; Recording; Rhythm; Data models; Accuracy; Training; Detectors; Atrial fibrillation (AF); electrocardiogram (ECG); residual neural network (ResNet); self-supervised learning (SSL); wearable ECGs</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
DEEP LEARNING APPROACH</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Ma, Caiyun; Wang, Zhongyu; Zhao, Lina; Cai, Zhipeng; Li, Jianqing; Liu, Chengyu] Southeast Univ, Sch Instrument Sci &amp; Engn, State Key Lab Digital Med Engn, Nanjing 210096, Peoples R China. <br>
[Sheng, Weijie] Yangzhou Univ, Sch Informat Engn, Yangzhou 225127, Peoples R China. <br>
[Zhang, Yuwei] Jiangsu Univ Sci &amp; Technol, Sch Comp Sci, Zhenjiang 212003, Jiangsu, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liu, CY (corresponding author), Southeast Univ, Sch Instrument Sci &amp; Engn, State Key Lab Digital Med Engn, Nanjing 210096, Peoples R China.<br>Sheng, WJ (corresponding author), Yangzhou Univ, Sch Informat Engn, Yangzhou 225127, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
101300447@seu.edu.cn; wjsheng@yzu.edu.cn; 230238989@seu.edu.cn; zhaolina0808@126.com; zhangyuwei@seu.edu.cn; zhipeng@seu.edu.cn; ljq@seu.edu.cn; chengyu@seu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Southeast University - China; Yangzhou University; Jiangsu University of Science &amp; Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cai, Zhipeng</display_name>&nbsp;</td><td>AAA-7659-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Chengyu</display_name>&nbsp;</td><td>IWD-6971-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cai, Zhipeng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3653-6838&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>0HO0S</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62171123&nbsp;</div>
<div>62071241&nbsp;</div>
<div>62201144&nbsp;</div>
<div>62211530112&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Program of China</grant_agency>&nbsp;</td><td>
<div>2023YFC3603600&nbsp;</div>
<div>2022YFC2405600&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>China Postdoctoral Science Foundation</grant_agency>&nbsp;</td><td>
<div>2024M760444&nbsp;</div>
<div>2023M730585&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Jiangsu Funding Program for Excellent Postdoctoral Talent</grant_agency>&nbsp;</td><td>
<div>2023ZB812&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under Grant 62171123, Grant 62071241, Grant 62201144, and Grant 62211530112; in part by the National Key Research and Development Program of China under Grant 2023YFC3603600 and Grant 2022YFC2405600; in part by China Postdoctoral Science Foundation under Grant 2024M760444 and Grant 2023M730585; and in part by Jiangsu Funding Program for Excellent Postdoctoral Talent under Grant 2023ZB812.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 16 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Score-Based Diffusion Models With Self-Supervised Learning for Accelerated 3D Multi-Contrast Cardiac MR Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, YY (Liu, Yuanyuan); Cui, ZX (Cui, Zhuo-Xu); Qin, SC (Qin, Shucong); Liu, CC (Liu, Congcong); Zheng, HR (Zheng, Hairong); Wang, HF (Wang, Haifeng); Zhou, YH (Zhou, Yihang); Liang, D (Liang, Dong); Zhu, YJ (Zhu, Yanjie)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>44</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>6</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2436-2448</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2025.3534206</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JUN</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
11</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
12</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>78</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
scan time significantly hinders the widespread applications of three-dimensional multi-contrast cardiac magnetic resonance (3D-MC-CMR) imaging. This study aims to accelerate 3D-MC-CMR acquisition by a novel method based on score-based diffusion models with self-supervised learning. Specifically, we first establish a mapping between the undersampled k-space measurements and the MR images, utilizing a self-supervised Bayesian reconstruction network. Secondly, we develop a joint score-based diffusion model on 3D-MC-CMR images to capture their inherent distribution. Senior Member, The 3D-MC-CMR images are finally reconstructed using the conditioned Langenvin Markov chain Monte Carlo sampling. This approach enables accurate reconstruction without fully sampled training data. Its performance was tested on the dataset acquired by a 3D joint myocardial T1 and T1 rho mapping sequence. The T1 and T1 rho maps were estimated via a dictionary matching method from the reconstructed images. Experimental results show that the proposed method outperforms traditional compressed sensing and existing self-supervised deep learning MRI reconstruction methods. It also achieves high quality T1 and T1 rho parametric maps close to the reference maps, even at a high acceleration rate of 14.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001502493100015</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>40031249</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Image reconstruction; Diffusion models; Magnetic resonance imaging; Training; Self-supervised learning; Three-dimensional displays; Myocardium; Data models; Neural networks; Interpolation; 3D cardiac magnetic resonance imaging; self-supervised; diffusion models; multi-contrast</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
PARALLEL MRI; RESONANCE; COMBINATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Yuanyuan; Qin, Shucong; Zheng, Hairong; Wang, Haifeng; Zhu, Yanjie] Chinese Acad Sci, Shenzhen Inst Adv Technol, Paul C Lauterbur Res Ctr Biomed Imaging, Shenzhen 518055, Guangdong, Peoples R China. <br>
[Liu, Yuanyuan] Natl Innovat Ctr Adv Med Devices, Shenzhen 518045, Guangdong, Peoples R China. <br>
[Cui, Zhuo-Xu; Zhou, Yihang; Liang, Dong] Chinese Acad Sci, Shenzhen Inst Adv Technol, Res Ctr Med AI, Shenzhen 518055, Guangdong, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhu, YJ (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Paul C Lauterbur Res Ctr Biomed Imaging, Shenzhen 518055, Guangdong, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
liuyy@siat.ac.cn; zx.cui@siat.ac.cn; idginshucong@163.com; cc.liu@siat.ac.cn; hr.zheng@siat.ac.cn; hf.wang1@siat.ac.cn; yh.zhou2@siat.ac.cn; dong.liang@siat.ac.cn; yj.zhu@siat.ac.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Yuanyuan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0131-2519&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Haifeng, Wang</display_name>&nbsp;</td><td>HQY-7721-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liang, Dong</display_name>&nbsp;</td><td>A-3335-2011&nbsp;</td><td>0000-0001-6257-0875&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>liu, xiao</display_name>&nbsp;</td><td>HMD-7454-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Congcong</display_name>&nbsp;</td><td>HLG-9805-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>3KL6Y</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Program of China</grant_agency>&nbsp;</td><td>
<div>2021YFF0501402&nbsp;</div>
<div>2023YFA1011403&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62322119&nbsp;</div>
<div>62201561&nbsp;</div>
<div>62206273&nbsp;</div>
<div>62476268&nbsp;</div>
<div>12226008&nbsp;</div>
<div>62125111&nbsp;</div>
<div>62106252&nbsp;</div>
<div>U22A20344&nbsp;</div>
<div>52293425&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guangdong Basic and Applied Basic Research Foundation</grant_agency>&nbsp;</td><td>
<div>2021A1515110540&nbsp;</div>
<div>2023A1515110476&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key Laboratory for Magnetic Resonance and Multimodality Imaging of Guangdong Province</grant_agency>&nbsp;</td><td>
<div>2023B1212060052&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shenzhen Science and Technology Program</grant_agency>&nbsp;</td><td>
<div>RCYX20210609104444089&nbsp;</div>
<div>JCYJ20240813155840052&nbsp;</div>
<div>JCYJ20220818101205012&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Key Research and Development Program of China under Grant 2021YFF0501402 and Grant 2023YFA1011403; in part by the National Natural Science Foundation of China under Grant 62322119, Grant 62201561, Grant 62206273, Grant 62476268, Grant 12226008, Grant 62125111, Grant 62106252, Grant U22A20344, and Grant 52293425; in part by Guangdong Basic and Applied Basic Research Foundation under Grant 2021A1515110540 and Grant 2023A1515110476; in part by Key Laboratory for Magnetic Resonance and Multimodality Imaging of Guangdong Province under Grant 2023B1212060052; and in part by Shenzhen Science and Technology Program under Grant RCYX20210609104444089, Grant JCYJ20240813155840052, and Grant JCYJ20220818101205012.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 17 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>SmartMatch: A semi-supervised framework for obstructive sleep apnea classification using single-lead electrocardiogram signals with limited annotations</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Gayen, S (Gayen, Soumyajit); Rao, NM (Rao, Nalla Maheswara); Sahu, DK (Sahu, Deepak Kumar); Sivaraman, J (Sivaraman, J.); Pal, K (Pal, Kunal); Vasamsetti, S (Vasamsetti, Srikanth); Neelapu, BC (Neelapu, Bala Chakravarthy)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>157</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>111226</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.engappai.2025.111226</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 OCT 1</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
7</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
7</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>50</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Obstructive Sleep Apnea (OSA) is a prevalent respiratory disorder with significant global health implications, affecting individuals of all ages and demographics. This underlines the demand for reliable diagnostic methods and computational models capable of accurately classifying OSA efficiently using single-lead electrocardiogram (ECG) with Limited Annotations. Recent progress in deep learning (DL) techniques, coupled with highperformance computing, has facilitated automatic classification in medical imaging, offering a viable solution for timely diagnosis. However, Traditional supervised learning (SL) requires large, expert-annotated datasets, which are costly and time-intensive to curate, which is a critical bottleneck in resource-constrained settings. To overcome these challenges, we proposed a semi-supervised learning (SSL) framework, SmartMatch. Our SSL framework minimizes reliance on annotated data by effectively leveraging unlabeled ECG signals, reducing annotation burdens while maintaining diagnostic accuracy. The proposed framework is inspired by hierarchical structures observed in real-world scenarios, where leader-follower dynamics play a crucial role in decision-making. Our approach integrates deep metric learning, employing Adaptive batch hard mining to enhance feature representation, alongside an Adaptive pseudo-labeling strategy to refine label quality, and an Adaptive temporal ensembling to stabilize learning while preserving consistency loss constraints. We conducted experiments on the PhysioNet Apnea-ECG repository (PA-ECG) dataset, which comprises 70 overnight recordings. The proposed SmartMatch achieved remarkable performance, yielding high accuracy, precision, recall, and F1-scores of 91.99% (+/- 0.08), 91.98% (+/- 0.10), 91.99% (+/- 0.11), and 91.97% (+/- 0.10) per-segment, respectively. The results highlight SSL's capability to strengthen DL models for OSA detection, particularly in applications involving home sleep apnea testing and wearable IoT devices.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001508289000005</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Adaptive batch hard mining; Adaptive pseudo-labeling; Collaborative knowledge distillation; Deep learning; Obstructive sleep apnea; Semi-supervised learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ALGORITHM</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Gayen, Soumyajit; Rao, Nalla Maheswara; Sahu, Deepak Kumar; Sivaraman, J.; Pal, Kunal; Neelapu, Bala Chakravarthy] Natl Inst Technol Rourkela, Dept Biotechnol &amp; Med Engn, Rourkela 769008, Odisha, India. <br>
[Vasamsetti, Srikanth] CSIR Cent Sci Instruments Org, Chennai 600113, Tamil Nadu, India. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Neelapu, BC (corresponding author), Natl Inst Technol Rourkela, Dept Biotechnol &amp; Med Engn, Biomed Signal &amp; Image Proc Lab, Rourkela 769008, Odisha, India.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
soumyajitgayen98@gmail.com; nallamaheshnitrkl@gmail.com; deepakkusahu13@gmail.com; jsiva@nitrkl.ac.in; palk@nitrkl.ac.in; srikanth.vasamsetti@csio.res.in; neelapubc@nitrkl.ac.in</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
National Institute of Technology (NIT System); National Institute of Technology Rourkela; Council of Scientific &amp; Industrial Research (CSIR) - India; CSIR - Central Scientific Instruments Organisation (CSIO)</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gayen, Soumyajit</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0009-8844-8136&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Sahu, Deepak kumar</display_name>&nbsp;</td><td>GMX-1850-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Automation &amp; Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Automation &amp; Control Systems; Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>3SZ6Q</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0952-1976</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6769</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>ENG APPL ARTIF INTEL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Eng. Appl. Artif. Intell.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>18</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Indian Council of Medical Research (ICMR), Government of India</grant_agency>&nbsp;</td><td>
<div>2021-10018&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work is supported by the Indian Council of Medical Research (ICMR) under the project grant number 2021-10018, Government of India. This research was conducted in the Biomedical Signal and Image Processing Laboratory, Department of Biotechnology and Medical Engineering, National Institute of Technology Rourkela, Odisha, India.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 18 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Cross-database and cross-channel electrocardiogram arrhythmia heartbeat classification based on unsupervised domain adaptation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Imtiaz, MN (Imtiaz, Md. Niaz); Khan, N (Khan, Naimul)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>244</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>122960</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2023.122960</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>DEC 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 JUN 15</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>10</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
33</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>36</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
The classification of electrocardiogram (ECG) plays a crucial role in the development of an automatic cardiovascular diagnostic system. However, the considerable variances in ECG signals between individuals pose a significant challenge. Changes in data distribution limit cross-domain utilization of a model. In this study, we propose a solution to classify ECG in an unlabeled dataset by leveraging knowledge obtained from labeled source domain. We present a domain-adaptive deep network based on cross-domain feature discrepancy optimization. Our method comprises three stages: pre-training, cluster-centroid computing, and adaptation. In pre-training, we employ a Distributionally Robust Optimization (DRO) technique to deal with the vanishing worst-case training loss. To enhance the richness of the features, we concatenate three temporal features with the deep learning features. The cluster computing stage involves computing centroids of distinctly separable clusters for the source using true labels, and for the target using confident predictions. We propose a novel technique for selecting confident predictions in the target domain. In the adaptation stage, we minimize compacting loss within the same cluster, separating loss across different clusters, inter-domain cluster discrepancy loss, and running combined loss to produce a domain-robust model. Experiments conducted in both cross-domain and cross-channel paradigms show the efficacy of the proposed method. Our method achieves superior performance compared to other state-of-the-art approaches in detecting ventricular ectopic beats (V), supraventricular ectopic beats (S), and fusion beats (F). Our method achieves an average improvement of 11.78% in overall accuracy over the non-domain-adaptive baseline method on the three test datasets.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001145786300001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram (ECG); Unsupervised domain adaptation; Arrhythmia heartbeat classification; Deep learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CONVOLUTIONAL NEURAL-NETWORK; RECOGNITION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Imtiaz, Md. Niaz; Khan, Naimul] Toronto Metropolitan Univ, Dept Elect Comp &amp; Biomed Engn, 350 Victoria St, Toronto, ON M5B 2K3, Canada. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Imtiaz, MN (corresponding author), Toronto Metropolitan Univ, Dept Elect Comp &amp; Biomed Engn, 350 Victoria St, Toronto, ON M5B 2K3, Canada.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
niaz.imtiaz@torontomu.ca; n77khan@torontomu.ca</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Toronto Metropolitan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Imtiaz, Md Niaz</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3056-6756&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>FK9B2</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Sciences and Engineering Research Council of Canada (NSERC)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>New Frontiers in Research Fund (NFRF), Canada</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The authors would like to thank the Natural Sciences and Engineering Research Council of Canada (NSERC) and the New Frontiers in Research Fund (NFRF), Canada for providing financial support.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 19 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Inter-Patient ECG Classification with I-Vector Based Unsupervised Patient Adaptation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Xu, SS (Xu, Sean Shensheng); Mak, MW (Mak, Man-Wai); Chang, CQ (Chang, Chunqi)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>210</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>118410</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2022.118410</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>AUG 2022</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2022 DEC 30</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
50</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>41</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This paper proposes an unsupervised patient adaptation approach to creating patient-specific deep neural network (DNN) classifiers for inter-patient ECG classification. The method exploits the information embedded in the patient-specific i-vectors derived from some unlabeled patient-specific ECG. The adaptation process comprises two stages of backpropagation (BP) fine-tuning, using the i-vector of a target patient as an auxiliary input to a middle layer of the DNN. In the first stage, labeled ECG data from a general population are used for creating a patient-adaptive DNN. Then, in the second stage, unlabeled ECG data from the target patient are used for further BP fine-tuning, using the labels hypothesized by the patient-adaptive DNN as the desired outputs. To ensure that only reliable data are used for adaptation, an information-theoretic heartbeat selector is employed to select the patients' ECG with high-confidence hypothesized labels. Evaluations on the MIT-BIH arrhythmia dataset show that the proposed unsupervised adaptation leads to patient-specific ECG classifiers that outperform existing patient-specific models. The classifiers also perform comparably to patient-specific models obtained via supervised adaption. This unsupervised adaptation approach can fully automate patient adaptation, making personalized ECG classification more practical.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000880668000007</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Unsupervised adaptation; Patient-specific i-vectors; Arrhythmia; ECG classification; DNN adaptation</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Xu, Sean Shensheng; Chang, Chunqi] Shenzhen Univ, Hlth Sci Ctr, Sch Biomed Engn, Shenzhen 518060, Peoples R China. <br>
[Xu, Sean Shensheng; Mak, Man-Wai] Hong Kong Polytech Univ, Dept Elect &amp; Informat Engn, Hong Kong, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Chang, CQ (corresponding author), Shenzhen Univ, Hlth Sci Ctr, Sch Biomed Engn, Shenzhen 518060, Peoples R China.<br>Mak, MW (corresponding author), Hong Kong Polytech Univ, Dept Elect &amp; Informat Engn, Hong Kong, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
sean.xu@connect.polyu.hk; enmwmak@polyu.edu.hk; cqchang@szu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Shenzhen University; Hong Kong Polytechnic University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chang, Chunqi</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1172-6491&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Mak, Man-Wai</display_name>&nbsp;</td><td>C-3750-2014&nbsp;</td><td>0000-0001-8854-3760&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Mak, Manwai</display_name>&nbsp;</td><td>C-3750-2014&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chang, CQ</display_name>&nbsp;</td><td>C-1845-2009&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>6A5AJ</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>23</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Na-tional Natural Science Foundation of China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shenzhen-Hong Kong Institute of Brain Science-Shenzhen Fundamental Research Institutions</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>&nbsp;</td><td>
<div>61971371&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>&nbsp;</td><td>
<div>61971289&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>&nbsp;</td><td>
<div>2019SHIBS0003&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was in part supported by National Natural Science Foundation of China under Grant 61971371, Na-tional Natural Science Foundation of China under Grant 61971289, and Shenzhen-Hong Kong Institute of Brain Science-Shenzhen Fundamental Research Institutions under Grant 2019SHIBS0003. Part of the work was done when S.S. Xu was the PostDoc Fellow at The Hong Kong Polytechnic University.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 20 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Unsupervised Domain Adaptation With Variational Approximation for Cardiac Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wu, FP (Wu, Fuping); Zhuang, XH (Zhuang, Xiahai)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>12</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>3555-3567</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3090412</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 DEC</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>60</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>65</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
57</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>50</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Unsupervised domain adaptation is useful in medical image segmentation. Particularly, when ground truths of the target images are not available, domain adaptation can train a target-specific model by utilizing the existing labeled images from other modalities. Most of the reported works mapped images of both the source and target domains into a common latent feature space, and then reduced their discrepancy either implicitly with adversarial training or explicitly by directly minimizing a discrepancy metric. In this work, we propose a new framework, where the latent features of both domains are driven towards a common and parameterized variational form, whose conditional distribution given the image is Gaussian. This is achieved by two networks based on variational auto-encoders (VAEs) and a regularization for this variational approximation. Both of the VAEs, each for one domain, contain a segmentation module, where the source segmentation is trained in a supervised manner, while the target one is trained unsupervisedly. We validated the proposed domain adaptation method using two cardiac segmentation tasks, i.e., the cross-modality (CT and MR) whole heart segmentation and the cross-sequence cardiac MR segmentation. Results show that the proposed method achieved better accuracies compared to two state-of-the-art approaches and demonstrated good potential for cardiac segmentation. Furthermore, the proposed explicit regularization was shown to be effective and efficient in narrowing down the distribution gap between domains, which is useful for unsupervised domain adaptation. The code and data have been released via https://zmiclab.github.io/projects.html.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000724511900027</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34143733</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Image segmentation; Training; Task analysis; Data models; Adaptation models; Measurement; Feature extraction; Domain adaptation; variational approximation; explicit domain discrepancy; cardiac segmentation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
IMAGE; ALIGNMENT; NETWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wu, Fuping] Fudan Univ, Dept Stat Sch Management, Shanghai 200433, Peoples R China. <br>
[Wu, Fuping; Zhuang, Xiahai] Fudan Univ, Sch Data Sci, Shanghai 200433, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhuang, XH (corresponding author), Fudan Univ, Sch Data Sci, Shanghai 200433, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
17110690006@fudan.edu.cn; zxh@fudan.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Fudan University; Fudan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhuang, Xiahai</display_name>&nbsp;</td><td>AAH-6334-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wu, Fuping</display_name>&nbsp;</td><td>ABG-4545-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wu, Fuping</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7179-4766&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>XG1HV</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61971142&nbsp;</div>
<div>11871165&nbsp;</div>
<div>62111530195&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the National Natural Science Foundation of China under Grant 61971142, Grant 11871165, and Grant 62111530195.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 21 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Structure-Driven Unsupervised Domain Adaptation for Cross-Modality Cardiac Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Cui, ZM (Cui, Zhiming); Li, CJ (Li, Changjian); Du, ZX (Du, Zhixu); Chen, NL (Chen, Nenglun); Wei, GD (Wei, Guodong); Chen, RN (Chen, Runnan); Yang, L (Yang, Lei); Shen, DG (Shen, Dinggang); Wang, WP (Wang, Wenping)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>12</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>3604-3616</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3090432</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 DEC</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>29</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>33</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
45</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>52</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Performance degradation due to domain shift remains a major challenge in medical image analysis. Unsupervised domain adaptation that transfers knowledge learned from the source domain with ground truth labels to the target domain without any annotation is the mainstream solution to resolve this issue. In this paper, we present a novel unsupervised domain adaptation framework for cross-modality cardiac segmentation, by explicitly capturing a common cardiac structure embedded across different modalities to guide cardiac segmentation. In particular, we first extract a set of 3D landmarks, in a self-supervised manner, to represent the cardiac structure of different modalities. The high-level structure information is then combined with another complementary feature, the Canny edges, to produce accurate cardiac segmentation results both in the source and target domains. We extensively evaluate our method on the MICCAI 2017 MM-WHS dataset for cardiac segmentation. The evaluation, comparison and comprehensive ablation studies demonstrate that our approach achieves satisfactory segmentation results and outperforms state-of-the-art unsupervised domain adaptation methods by a significant margin.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000724511900031</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34161240</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Image segmentation; Feature extraction; Computed tomography; Magnetic resonance imaging; Three-dimensional displays; Task analysis; Image edge detection; Cross-modality learning; unsupervised domain adaptation; structure distillation; cardiac segmentation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SYNERGISTIC IMAGE; NETWORK; MRI</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Cui, Zhiming; Shen, Dinggang] ShanghaiTech Univ, Sch Biomed Engn, Shanghai 201210, Peoples R China. <br>
[Cui, Zhiming; Du, Zhixu; Chen, Nenglun; Wei, Guodong; Chen, Runnan; Yang, Lei; Wang, Wenping] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China. <br>
[Li, Changjian] UCL, Dept Comp Sci, London WC1E 6EA, England. <br>
[Shen, Dinggang] Shanghai United Imaging Intelligence Co Ltd, Shanghai 200030, Peoples R China. <br>
[Shen, Dinggang] Korea Univ, Dept Artificial Intelligence, Seoul 02841, South Korea. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Shen, DG (corresponding author), ShanghaiTech Univ, Sch Biomed Engn, Shanghai 201210, Peoples R China.<br>Wang, WP (corresponding author), Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.<br>Li, CJ (corresponding author), UCL, Dept Comp Sci, London WC1E 6EA, England.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
zmcui@cs.hku.hk; chjili2011@gmail.com; dzx3501@connect.hku.hk; chennenglun@gmail.com; g.d.wei.china@gmail.com; runnanchen@modontics.com; yanglei.dalian@gmail.com; dinggang.shen@gmail.com; wenping@cs.hku.hk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
ShanghaiTech University; University of Hong Kong; University of London; University College London; Korea University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Shen, Dinggang</display_name>&nbsp;</td><td>ABF-6812-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Du, Zhixu</display_name>&nbsp;</td><td>LQK-5797-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wei, Guodong</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6975-9865&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Li, Changjian</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0448-4957&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>chen, runnan</display_name>&nbsp;</td><td>KFA-0707-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>XG1HV</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 22 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Intelligent Analysis and Heartbeat Saliency Map Representation of Postoperative Atrial Fibrillation Recurrence Based on Mobile Single-Lead Electrocardiogram</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Xie, YS (Xie, Yushan); Zhu, HY (Zhu, Huaiyu); Chen, LT (Chen, Laite); Chen, WS (Chen, Wensheng); Jiang, CY (Jiang, Chenyang); Pan, Y (Pan, Yun)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>73</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>2520610</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2024.3406829</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
5</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>33</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Due to the inconvenience of the current regular in-hospital 12-lead electrocardiogram (ECG) follow-up method for patients undergoing radio frequency catheter ablation (RFCA), poor medical compliance results in the postoperative population experiencing atrial fibrillation (AF) recurrence after RFCA not being diagnosed in time, thus missing the optimal treatment time. This study investigated the feasibility of predicting AF recurrence using follow-up ECG signals within the blanking period. A total of 170 individuals underwent follow-up and mobile single-lead ECG signal collection after receiving RFCA. We developed a deep modified residual network (DMRN) for intrapatient AF recurrence prediction. In addition, we proposed a novel approach to investigate potential indicators of AF recurrence in ECG signals by generating category-level heartbeat saliency maps. Our model achieved an accuracy of 93.18% for intrapatient AF recurrence prediction, and the saliency maps highlighted the importance of ECG waveform features around the S-peak in predicting AF recurrence. This study provides a new perspective on investigating the relationship between AF recurrence and ECG characteristics within the blanking period and initially validates the feasibility of AF recurrence prediction based on mobile single-lead ECG.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001246203300006</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiography; Heart beat; Blanking; Predictive models; Medical diagnostic imaging; Convolution; Visualization; Atrial fibrillation (AF) recurrence; blanking period; deep residual networks; electrocardiogram (ECG); saliency map</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CLASSIFICATION; ABLATION; MANAGEMENT</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Xie, Yushan; Zhu, Huaiyu; Chen, Wensheng; Pan, Yun] Zhejiang Univ, Coll Informat Sci &amp; Elect Engn, Hangzhou 310027, Peoples R China. <br>
[Chen, Laite; Jiang, Chenyang] Zhejiang Univ, Sir Run Run Shaw Hosp, Sch Med, Hangzhou 310000, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Pan, Y (corresponding author), Zhejiang Univ, Coll Informat Sci &amp; Elect Engn, Hangzhou 310027, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
xieys@zju.edu.cn; zhuhuaiyu@zju.edu.cn; laitchen@163.com; chenwensheng@zju.edu.cn; cyjiang@zju.edu.cn; panyun@zju.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Zhejiang University; Zhejiang University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Jia-Yu</display_name>&nbsp;</td><td>J-6798-2013&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhu, Huaiyu</display_name>&nbsp;</td><td>AAC-5437-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>chen, wenshengchen</display_name>&nbsp;</td><td>GYU-1480-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhu, Huaiyu</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6918-4088&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>UD8A2</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Program of China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>No Statement Available</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 23 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Adversarial Spatiotemporal Contrastive Learning for Electrocardiogram Signals</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wang, N (Wang, Ning); Feng, PP (Feng, Panpan); Ge, ZY (Ge, Zhaoyang); Zhou, YJ (Zhou, Yanjie); Zhou, B (Zhou, Bing); Wang, ZM (Wang, Zongmin)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>35</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>10</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>13845-13859</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TNNLS.2023.3272153</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JUL 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>19</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>20</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
6</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
62</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>62</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Extracting invariant representations in unlabeled electrocardiogram (ECG) signals is a challenge for deep neural networks (DNNs). Contrastive learning is a promising method for unsupervised learning. However, it should improve its robustness to noise and learn the spatiotemporal and semantic representations of categories, just like cardiologists. This article proposes a patient-level adversarial spatiotemporal contrastive learning (ASTCL) framework, which includes ECG augmentations, an adversarial module, and a spatiotemporal contrastive module. Based on the ECG noise attributes, two distinct but effective ECG augmentations, ECG noise enhancement, and ECG noise denoising, are introduced. These methods are beneficial for ASTCL to enhance the robustness of the DNN to noise. This article proposes a self-supervised task to increase the antiperturbation ability. This task is represented as a game between the discriminator and encoder in the adversarial module, which pulls the extracted representations into the shared distribution between the positive pairs to discard the perturbation representations and learn the invariant representations. The spatiotemporal contrastive module combines spatiotemporal prediction and patient discrimination to learn the spatiotemporal and semantic representations of categories. To learn category representations effectively, this article only uses patient-level positive pairs and alternately uses the predictor and the stop-gradient to avoid model collapse. To verify the effectiveness of the proposed method, various groups of experiments are conducted on four ECG benchmark datasets and one clinical dataset compared with the state-of-the-art methods. Experimental results showed that the proposed method outperforms the state-of-the-art methods.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001030681200001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37432818</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
~Adversarial learning; contrastive learning; data augmentation; electrocardiogram (ECG)</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wang, Ning; Feng, Panpan; Ge, Zhaoyang; Zhou, Bing; Wang, Zongmin] Zhengzhou Univ, Sch Comp &amp; Artificial Intelligence, Zhengzhou 450000, Peoples R China. <br>
[Zhou, Yanjie] Zhengzhou Univ, Sch Management, Zhengzhou 450000, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhou, YJ (corresponding author), Zhengzhou Univ, Sch Management, Zhengzhou 450000, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
wning@ha.edu.cn; ieyjzhou@zzu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Zhengzhou University; Zhengzhou University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhou, Bing</display_name>&nbsp;</td><td>X-2659-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>ZHOU, BING</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3446-3903&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Hardware &amp; Architecture; Computer Science, Theory &amp; Methods; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>K5W4Q</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2162-237X</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2162-2388</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T NEUR NET LEAR</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Neural Netw. Learn. Syst.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Program of China</grant_agency>&nbsp;</td><td>
<div>2017YFB1401200&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key Research, Development, and Dissemination Program of Henan Province (Science and Technology for the People)</grant_agency>&nbsp;</td><td>
<div>182207310002&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key Science and Technology Project of Xinjiang Production and Construction Corps</grant_agency>&nbsp;</td><td>
<div>2018AB017&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>&amp; nbsp;This work was supported in part by the National Key Research and Development Program of China under Grant 2017YFB1401200, in part by the Key Research, Development, and Dissemination Program of Henan Province (Science and Technology for the People) under Grant 182207310002, and in part by the Key Science and Technology Project of Xinjiang Production and Construction Corps under Grant 2018AB017.&amp; nbsp;</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 24 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Sparse representation of ECG signals for automated recognition of cardiac arrhythmias</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Raj, S (Raj, Sandeep); Ray, KC (Ray, Kailash Chandra)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>105</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>49-64</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2018.03.038</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2018 SEP 1</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>105</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>114</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
103</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>59</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
As per the report of the World Health Organization (WHO), the mortalities due to cardiovascular diseases (CVDs) have increased to 50 million worldwide. Therefore, it is essential to have an efficient diagnosis of CVDs to enhance the healthcare in the clinical cardiovascular domain. The ECG signal analysis of a patient is a very popular tool to perform diagnosis of CVDs. However, due to the non-stationary nature of ECG signal and higher computational burden of the existing signal processing methods, the automated and efficient diagnosis remains a challenge.
<br>This paper presents a new feature extraction method using the sparse representation technique to efficiently represent the different ECG signals for efficient analysis. The sparse method decomposes an ECG signal into elementary waves using an overcomplete gabor dictionary. Four features such as time delay, frequency, width parameter, and square of expansion coefficient are extracted from each of the significant atoms of the dictionary. These features are concatenated and analyzed to determine the optimal length of discriminative feature vector representing each of the ECG signal. These extracted features representing the ECG signals are further classified using machine learning techniques such as least-square twin SVM, k-NN, PNN, and RBFNN. Further, the learning parameters of the classifiers are optimized using ABC and PSO techniques. The experiments are carried out for the proposed methods (i.e. feature extraction along with all classifiers) using benchmark MIT-BIH data and evaluated under category and personalized analysis schemes.
<br>Experimental results show that the proposed ECG signal representation using sparse decomposition technique with PSO optimized least-square twin SVM (best classifier model among k-NN, PNN and RBFNN) reported higher classification accuracy of 99.11% in category and 89.93% in personalized schemes respectively than the existing methods to the state-of-art diagnosis. (C) 2018 Elsevier Ltd. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000432501900005</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram signal; Sparse representation; Overcomplete dictionary; Least-square twin support vector machines; Artificial bee colony; Particle swarm optimization</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NEURAL-NETWORK; HEARTBEAT CLASSIFICATION; BEAT CLASSIFICATION; TIME; DIAGNOSIS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Raj, Sandeep; Ray, Kailash Chandra] Indian Inst Technol Patna, Dept Elect Engn, Bihta 801103, India. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Raj, S (corresponding author), Indian Inst Technol Patna, Dept Elect Engn, Bihta 801103, India.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
srp@iitp.ac.in; kcr@iitp.ac.in</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Indian Institute of Technology (IIT) - Patna</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Raj, Sandeep</display_name>&nbsp;</td><td>G-5779-2018&nbsp;</td><td>0000-0001-6769-5589&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ray, Kc</display_name>&nbsp;</td><td>JLK-9098-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>GG2ED</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>16</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Department of Science and Technology, Government of India under DST-INSPIRE Fellowship Scheme</grant_agency>&nbsp;</td><td>
<div>IF 120841&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The authors acknowledge the Department of Science and Technology, Government of India for sponsoring this research work (IF 120841) under DST-INSPIRE Fellowship Scheme.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 25 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Toward Accurate Cardiac MRI Segmentation With Variational Autoencoder-Based Unsupervised Domain Adaptation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Cui, HF (Cui, Hengfei); Li, Y (Li, Yan); Wang, YF (Wang, Yifan); Xu, D (Xu, Di); Wu, LM (Wu, Lian-Ming); Xia, Y (Xia, Yong)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>43</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>8</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2924-2936</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2024.3382624</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 AUG</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>5</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>7</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
11</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
32</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>36</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Accurate myocardial segmentation is crucial in the diagnosis and treatment of myocardial infarction (MI), especially in Late Gadolinium Enhancement (LGE) cardiac magnetic resonance (CMR) images, where the infarcted myocardium exhibits a greater brightness. However, segmentation annotations for LGE images are usually not available. Although knowledge gained from CMR images of other modalities with ample annotations, such as balanced-Steady State Free Precession (bSSFP), can be transferred to the LGE images, the difference in image distribution between the two modalities (i.e., domain shift) usually results in a significant degradation in model performance. To alleviate this, an end-to-end Variational autoencoder based feature Alignment Module Combining Explicit and Implicit features (VAMCEI) is proposed. We first re-derive the Kullback-Leibler (KL) divergence between the posterior distributions of the two domains as a measure of the global distribution distance. Second, we calculate the prototype contrastive loss between the two domains, bringing closer the prototypes of the same category across domains and pushing away the prototypes of different categories within or across domains. Finally, a domain discriminator is added to the output space, which indirectly aligns the feature distribution and forces the extracted features to be more favorable for segmentation. In addition, by combining CycleGAN and VAMCEI, we propose a more refined multi-stage unsupervised domain adaptation (UDA) framework for myocardial structure segmentation. We conduct extensive experiments on the MSCMRSeg 2019, MyoPS 2020 and MM-WHS 2017 datasets. The experimental results demonstrate that our framework achieves superior performances than state-of-the-art methods.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001285367200007</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>38546999</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Feature extraction; Image segmentation; Myocardium; Semantics; Annotations; Image reconstruction; Training; Cardiac segmentation; domain adaptation; multi-modal MRI; variational autoencoder</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Cui, Hengfei] Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated Aerosp Ground Ocean Big D, Xian 710072, Peoples R China. <br>
[Cui, Hengfei] Northwestern Polytech Univ, Res &amp; Dev Inst, Shenzhen 518057, Peoples R China. <br>
[Cui, Hengfei] Northwestern Polytech Univ, Chongqing Innovat Ctr, Chongqing 401135, Peoples R China. <br>
[Li, Yan; Wang, Yifan; Xia, Yong] Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated Aerosp Ground Ocean Big D, Xian 710072, Peoples R China. <br>
[Xu, Di] Media Innovat Lab, Huawei Cloud, Xian 710075, Peoples R China. <br>
[Wu, Lian-Ming] Shanghai Jiao Tong Univ, Renji Hosp, Sch Med, Dept Radiol, Shanghai 200127, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Xia, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated Aerosp Ground Ocean Big D, Xian 710072, Peoples R China.<br>Wu, LM (corresponding author), Shanghai Jiao Tong Univ, Renji Hosp, Sch Med, Dept Radiol, Shanghai 200127, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
hfcui@nwpu.edu.cn; yanli.master1@gmail.com; yifanwang0229@163.com; xudi21@huawei.com; wlmssmu@126.com; yxia@nwpu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Northwestern Polytechnical University; Northwestern Polytechnical University; Northwestern Polytechnical University; Northwestern Polytechnical University; Huawei Technologies; Shanghai Jiao Tong University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Li, Yan</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0000-1331-9182&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wu, Lian-Ming</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7381-5436&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Yifan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-4519-7535&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cui, Hengfei</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-8625-2521&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Yifan</display_name>&nbsp;</td><td>JDM-1982-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>A8Z6G</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62271405&nbsp;</div>
<div>62171377&nbsp;</div>
<div>82171884&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guangdong Basic and Applied Basic Research Foundation</grant_agency>&nbsp;</td><td>
<div>2023A1515012847&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of Chongqing, China</grant_agency>&nbsp;</td><td>
<div>CSTB2023NSCQ-MSX0286;&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key Research and Development Program of Shaanxi Province, China</grant_agency>&nbsp;</td><td>
<div>2022GY-084&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shenzhen Science and Technology Program</grant_agency>&nbsp;</td><td>
<div>JCYJ20220530161616036&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shanghai Municipal Commission of Science and Technology Medical Innovation Research Special Project</grant_agency>&nbsp;</td><td>
<div>23Y11906900&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shanghai "Yiyuan New Star" Outstanding Youth Talent (Excellent Program)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under Grant 62271405, Grant 62171377, and Grant 82171884; in part by Guangdong Basic and Applied Basic Research Foundation under Grant 2023A1515012847; in part by the Natural Science Foundation of Chongqing, China, under Grant CSTB2023NSCQ-MSX0286; in part by the Key Research and Development Program of Shaanxi Province, China, under Grant 2022GY-084; in part by Shenzhen Science and Technology Program under Grant JCYJ20220530161616036; in part by Shanghai Municipal Commission of Science and Technology Medical Innovation Research Special Project under Grant 23Y11906900; and in part by Shanghai "Yiyuan New Star" Outstanding Youth Talent (Excellent Program).</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 26 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>PRA-Net: Polymorphic Representation-Aware Network for Accurate Cardiac Arrhythmia Detection From Electrocardiogram Signals</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wang, X (Wang, Xu); He, ZS (He, Zhaoshui); Lin, ZJ (Lin, Zhijie); Han, Y (Han, Yang); Su, WQ (Su, Wenqing); Tan, BH (Tan, Beihai); Xie, SL (Xie, Shengli)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>74</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>2511212</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2025.3547091</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
8</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
8</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>56</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Electrocardiogram (ECG) arrhythmia classification is of great significance for cardiologist-level disease diagnosis. However, it is challenging to perform cardiac arrhythmia detection because of these limitations: 1) the abnormal ECG signals vary in different scales; 2) the temporal and spatial dependencies in ECG sequences are always ignored; and 3) the waveform semantic information, for example, wavelet coefficients, higher-order statistics, and slope relationship are often missing. To address these issues, a polymorphic representation-aware network (PRA-Net) is proposed for cardiac arrhythmia detection from ECG signals, where the adaptive wavelet-aware (AWA) module is developed to identify ECG signals at different scales by learning multiscale features, while the adaptive temporal-space-aware (ATA) module is designed to model the temporal and positional dependencies in the sequence, and the collaborative semantic-aware (CSA) module is devised to encode semantic information from waveforms, finally, the adaptive feature attention fusion (AFAF) module is devised to select effective information for cardiac arrhythmia classification. Experiments demonstrate that the proposed PRA-Net outperforms the state-of-the-art methods, achieving average areas under the receiver-operating characteristic curve (AUC) of 99.23% and 98.86% on the CinC17 and MIT-BIH datasets, respectively.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001447532000041</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiography; Arrhythmia; Feature extraction; Semantics; Adaptive systems; Convolution; Collaboration; Data mining; Convolutional neural networks; Adaptation models; Attention mechanism; electrocardiogram (ECG) arrhythmia; polymorphic feature; temporal-space dependency</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ECG SIGNALS; CLASSIFICATION; LOCALIZATION; EXTRACTION; PREDICTION; FEATURES</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wang, Xu] Guangdong Mech &amp; Elect Polytech, Sch Elect &amp; Commun, Guangzhou 510550, Peoples R China. <br>
[He, Zhaoshui] Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Peoples R China. <br>
[He, Zhaoshui; Lin, Zhijie] Guangdong Univ Technol, Key Lab IoT Intelligent Informat Proc &amp; Syst Integ, Minist Educ, Guangzhou 510006, Peoples R China. <br>
[Lin, Zhijie] Guangdong Univ Technol, Guangdong Prov Key Lab Intelligent Syst &amp; Optimiza, Guangzhou 510006, Peoples R China. <br>
[Han, Yang] Sun Yat Sen Univ, Affiliated Hosp 1, Dept Obstet, Guangzhou 510080, Peoples R China. <br>
[Su, Wenqing; Tan, Beihai; Xie, Shengli] Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Peoples R China. <br>
[Su, Wenqing; Tan, Beihai; Xie, Shengli] Guangdong Hong Kong Macao Joint Lab Smart Discrete, Guangzhou 510006, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
He, ZS (corresponding author), Guangdong Univ Technol, Sch Automat, Guangzhou 510006, Peoples R China.<br>He, ZS (corresponding author), Guangdong Univ Technol, Key Lab IoT Intelligent Informat Proc &amp; Syst Integ, Minist Educ, Guangzhou 510006, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
wangxu@gdmec.edu.cn; zhshhe@gdut.edu.cn; zhijiel@mail2.gdut.edu.cn; hanyang@mail2.sysu.edu.cn; 2111904043@mail2.gdut.edu.cn; bhtan@gdut.edu.cn; shlxie@gdut.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Guangdong University of Technology; Guangdong University of Technology; Guangdong University of Technology; Sun Yat Sen University; Guangdong University of Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Su, Wenqing</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0002-7618-1568&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Xu</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-8313-9782&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lin, Zhijie</display_name>&nbsp;</td><td>AAA-3254-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>He, Zhaoshui</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5198-7851&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>0HO0S</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Program of China</grant_agency>&nbsp;</td><td>
<div>2022YFB4703102&nbsp;</div>
<div>2021YFE0108000&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62403145&nbsp;</div>
<div>62273105&nbsp;</div>
<div>U1911401&nbsp;</div>
<div>62203121&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guangdong Province Foundation</grant_agency>&nbsp;</td><td>
<div>2019B1515120036&nbsp;</div>
<div>501200069&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Key Research and Development Program of China under Grant 2022YFB4703102 and Grant 2021YFE0108000; in part by the National Natural Science Foundation of China under Grant 62403145, Grant 62273105, Grant U1911401, and Grant 62203121; and in part by Guangdong Province Foundation under Grant 2019B1515120036 and Grant 501200069. The Associate Editor coordinating the review process was Dr. Mahdi Saleh.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 27 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Adapt Everywhere: Unsupervised Adaptation of Point-Clouds and Entropy Minimization for Multi-Modal Cardiac Image Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Vesal, S (Vesal, Sulaiman); Gu, MX (Gu, Mingxuan); Kosti, R (Kosti, Ronak); Maier, A (Maier, Andreas); Ravikumar, N (Ravikumar, Nishant)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>7</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>1838-1851</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3066683</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 JUL</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>33</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>36</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
37</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>47</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Deep learning models are sensitive to domain shift phenomena. A model trained on images from one domain cannot generalise well when tested on images from a different domain, despite capturing similar anatomical structures. It is mainly because the data distribution between the two domains is different. Moreover, creating annotation for every new modality is a tedious and time-consuming task, which also suffers from high inter- and intra- observer variability. Unsupervised domain adaptation (UDA) methods intend to reduce the gap between source and target domains by leveraging source domain labelled data to generate labels for the target domain. However, current state-of-the-art (SOTA) UDA methods demonstrate degraded performance when there is insufficient data in source and target domains. In this paper, we present a novel UDA method for multi-modal cardiac image segmentation. The proposed method is based on adversarial learning and adapts network features between source and target domain in different spaces. The paper introduces an end-to-end framework that integrates: a) entropy minimization, b) output feature space alignment and c) a novel point-cloud shape adaptation based on the latent features learned by the segmentation model. We validated our method on two cardiac datasets by adapting from the annotated source domain, bSSFP-MRI (balanced Steady-State Free Procession-MRI), to the unannotated target domain, LGE-MRI (Late-gadolinium enhance-MRI), for the multi-sequence dataset; and from MRI (source) to CT (target) for the cross-modality dataset. The results highlighted that by enforcing adversarial learning in different parts of the network, the proposed method delivered promising performance, compared to other SOTA methods.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000668842500009</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33729930</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Image segmentation; Shape; Entropy; Magnetic resonance imaging; Minimization; Adaptation models; Training; Unsupervised domain adaptation; cardiac segmentation; multi-modal segmentation; adversarial learning; point-clouds; entropy minimization</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CARDIOVASCULAR MAGNETIC-RESONANCE; DOMAIN ADAPTATION; SYNERGISTIC IMAGE</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Vesal, Sulaiman; Gu, Mingxuan; Kosti, Ronak; Maier, Andreas] Friedrich Alexander Univ Erlangen Nuremberg, Pattern Recognit Lab, D-91054 Erlangen, Germany. <br>
[Ravikumar, Nishant] Univ Leeds, Ctr Computat Imaging &amp; Simulat Technol Biomed CIS, Sch Comp, Leeds Inst Cardiovasc &amp; Metab Med LICAMM,Sch Med, Leeds LS2 9JT, W Yorkshire, England. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Vesal, S (corresponding author), Friedrich Alexander Univ Erlangen Nuremberg, Pattern Recognit Lab, D-91054 Erlangen, Germany.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
sulaiman.vesal@fau.cie; mingxuan.gu@fau.de; ronak.kosti@fau.de; andreas.maier@fau.de; n.ravikumar@leeds.ac.uk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Erlangen Nuremberg; University of Leeds</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Maier, Andreas</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9550-5284&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>KOSTI, RONAK</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2453-7876&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ravikumar, Nishant</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0134-107X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Vesal, Sulaiman</display_name>&nbsp;</td><td>ABF-2407-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Vesal, Sulaiman</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6156-9338&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Maier, Andreas</display_name>&nbsp;</td><td>AAV-6505-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gu, Mingxuan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5244-4397&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gu, Mingxuan</display_name>&nbsp;</td><td>ACT-7421-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>TC7TP</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>14</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Project EFI-BIG-THERA: Integrative "BigData Modeling"</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>Manuscript received January 27, 2021; revised March 8, 2021; accepted March 14, 2021. Date of publication March 17, 2021; date of current version June 30, 2021. This work was supported by the Project EFI-BIG-THERA: Integrative "BigData Modeling" for the development of novel therapeutic approaches for breast cancer. (Corresponding author: Sulaiman Vesal.)</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 28 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A novel unsupervised domain adaptation framework based on graph convolutional network and multi-level feature alignment for inter-subject ECG classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
He, ZY (He, Ziyang); Chen, YF (Chen, Yufei); Yuan, SY (Yuan, Shuaiying); Zhao, JH (Zhao, Jianhui); Yuan, ZY (Yuan, Zhiyong); Polat, K (Polat, Kemal); Alhudhaif, A (Alhudhaif, Adi); Alenezi, F (Alenezi, Fayadh); Hamid, A (Hamid, Arwa)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>221</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>119711</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2023.119711</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>FEB 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 JUL 1</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>29</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>30</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
72</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>60</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Electrocardiogram (ECG) is an effective non-invasive tool that can detect arrhythmias. Recently, deep learning (DL) has been widely used in ECG classification algorithms. However, differences between subjects lead to data shifts, hindering the further extension of DL algorithms. To solve this problem, we propose a novel multi-level unsupervised domain adaptation framework (MLUDAF) to diagnose arrhythmias. During feature extraction, we use the atrous spatial pyramid pooling residual (ASPP-R) module to extract spatio-temporal features of the samples. Then the graph convolutional network (GCN) module is used to extract the data structure features. During domain adaptation, we design three alignment mechanisms: domain alignment, semantic alignment, and structure alignment. The three alignment strategies are integrated into a unified deep network to guide the feature extractor to extract domain sharing and distinguishable semantic representations, which can reduce the differences between the source and target domains. Experimental results based on the MIT-BIH database show that the proposed method achieves an overall accuracy of 96.8% for arrhythmia detection. Compared to other methods, the proposed method achieves competitive performance. Cross-domain experiments between databases also demonstrate its strong generalizability. Therefore, the proposed method is promising for application in medical diagnosis systems.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000952522700001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
ECG classification; Individual differences; Multi-level unsupervised domain adaptation; Deep learning; Graph convolutional network</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NEURAL-NETWORK; INFORMATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[He, Ziyang; Yuan, Shuaiying; Zhao, Jianhui; Yuan, Zhiyong] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China. <br>
[Chen, Yufei] State Key Lab Math Engn &amp; Adv Comp, Zhengzhou 450001, Peoples R China. <br>
[Polat, Kemal] Bolu Abant Izzet Baysal Univ, Dept Elect &amp; Elect Engn, Bolu, Turkiye. <br>
[Alhudhaif, Adi] Prince Sattam bin Abdulaziz Univ, Coll Comp Engn &amp; Sci Al kharj, Dept Comp Sci, POB 151, Al Kharj 11942, Saudi Arabia. <br>
[Alenezi, Fayadh] Jouf Univ, Coll Engn, Dept Elect Engn, Jouf 72238, Saudi Arabia. <br>
[Hamid, Arwa] Arab Open Univ, Fac Comp Studies, Riyadh 11462, Saudi Arabia. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhao, JH; Yuan, ZY (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.<br>Polat, K (corresponding author), Bolu Abant Izzet Baysal Univ, Dept Elect &amp; Elect Engn, Bolu, Turkiye.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
heziyang@whu.edu.cn; yufeichen2019@outlook.com; yuanshuaiying@whu.edu.cn; jianhuizhao@whu.edu.cn; zhiyongyuan@whu.edu.cn; kpolat@ibu.edu.tr; a.alhudhaif@psau.edu.sa; fshenezi@ju.edu.sa; a.hamid@arabou.edu.sa</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Wuhan University; PLA Information Engineering University; Abant Izzet Baysal University; Prince Sattam Bin Abdulaziz University; Al Jouf University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Alenezi, Fayadh</display_name>&nbsp;</td><td>ABB-4871-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>He, Ziyang</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3286-7138&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>chen, yufei</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4508-9726&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhao, Jianhui</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5803-2564&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>He, Ziyang</display_name>&nbsp;</td><td>LFT-3209-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hamid, Arwa</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2750-536X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Alhudhaif, Adi</display_name>&nbsp;</td><td>AAN-6541-2021&nbsp;</td><td>0000-0002-7201-6963&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Yuan, Zhiyong</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9608-6037&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Polat, Kemal</display_name>&nbsp;</td><td>AGZ-2143-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>A1AI6</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>14</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62073248&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Science and Technology Major Project of Hubei Province, China (Next Generation Al Technologies)</grant_agency>&nbsp;</td><td>
<div>2019AEA170&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Deputyship for Research &amp; Innovation, Ministry of Education in Saudi Arabia</grant_agency>&nbsp;</td><td>
<div>223202&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China (No. 62073248) , in part by the Science and Technology Major Project of Hubei Province, China (Next Generation Al Technologies, No. 2019AEA170) . The authors extend their appreciation to the Deputyship for Research &amp; Innovation, Ministry of Education in Saudi Arabia for funding this research work through project number 223202.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 29 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Learning Representations for Multilead Electrocardiograms From Morphology-Rhythm Contrast</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, WH (Liu, Wenhan); Zhang, HC (Zhang, Huaicheng); Chang, S (Chang, Sheng); Wang, H (Wang, Hao); He, J (He, Jin); Huang, QJ (Huang, Qijun)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>73</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>2509615</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2024.3369152</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>5</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>5</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
21</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>45</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This article proposes a novel contrastive learning framework to learn high-quality representations for multilead electrocardiograms (ECGs). It is termed morphology-rhythm contrast (MRC) since it jointly considers the morphology and rhythm characteristics of multilead ECGs. Unlike existing studies only concentrating on ECG-specific data augmentations, MRC provides a systematic solution for ECG-based contrastive learning. It proposes two new ECG-oriented data augmentation methods termed random beat selection and 0-1 pulse generation for view creation, representing the morphology and rhythm characteristics of an ECG. Then, a triple-branch network maps the three views (raw ECG, morphology, and rhythm view) to a latent space for dual contrastive learning (raw ECG versus morphology view and raw ECG versus rhythm view). This dual contrastive learning can be adjusted to prefer invariance derived from ECG morphology and rhythm, making pretrained encoders suitable for different downstream tasks. Thus, MRC reduces the gap between pretraining and downstream tasks, which is a significant challenge in contrastive learning. More importantly, with only 10% of the training data, MRC-based classification models can yield better performances than the supervised models. Such a finding demonstrates that MRC can reduce the cardiologists' labeling burden in real-world applications. Additionally, MRC achieves high performances in downstream tasks, outperforming existing studies under the same settings. To summarize, MRC is an effective contrastive learning framework for multilead ECGs. It has the potential to alleviate cardiologists' workload by aiding diagnosis and reducing manual labels in real-world applications.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001180920500025</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiography; Self-supervised learning; Task analysis; Rhythm; Morphology; Computer vision; Data augmentation; Contrastive learning; deep learning (DL); electrocardiogram (ECG); self-supervised representation learning (SSRL); signal processing</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CLASSIFICATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Wenhan; Zhang, Huaicheng; Chang, Sheng; Wang, Hao; He, Jin; Huang, Qijun] Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Chin, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Huang, QJ (corresponding author), Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Chin, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
huangqj@whu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Wuhan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Huaicheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6874-5530&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Huaicheng</display_name>&nbsp;</td><td>KFA-9029-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Han</display_name>&nbsp;</td><td>A-5016-2011&nbsp;</td><td>0000-0001-5448-9903&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Hao</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5279-3645&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chang, Sheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4875-5501&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>KO5L6</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>No Statement Available</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 30 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Unsupervised Domain Adaptation From Axial to Short-Axis Multi-Slice Cardiac MR Images by Incorporating Pretrained Task Networks</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Koehler, S (Koehler, Sven); Hussain, T (Hussain, Tarique); Blair, Z (Blair, Zach); Huffaker, T (Huffaker, Tyler); Ritzmann, F (Ritzmann, Florian); Tandon, A (Tandon, Animesh); Pickardt, T (Pickardt, Thomas); Sarikouch, S (Sarikouch, Samir); Latus, H (Latus, Heiner); Greil, G (Greil, Gerald); Wolf, I (Wolf, Ivo); Engelhardt, S (Engelhardt, Sandy)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>10</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2939-2953</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3052972</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>10</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
14</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>44</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Anisotropic multi-slice Cardiac Magnetic Resonance (CMR) Images are conventionally acquired in patient-specific short-axis (SAX) orientation. In specific cardiovascular diseases that affect right ventricular (RV) morphology, acquisitions in standard axial (AX) orientation are preferred by some investigators, due to potential superiority in RV volume measurement for treatment planning. Unfortunately, due to the rare occurrence of these diseases, data in this domain is scarce. Recent research in deep learning-based methods mainly focused on SAX CMR images and they had proven to be very successful. In this work, we show that there is a considerable domain shift between AX and SAX images, and therefore, direct application of existing models yield sub-optimal results on AX samples. We propose a novel unsupervised domain adaptation approach, which uses task-related probabilities in an attention mechanism. Beyond that, cycle consistency is imposed on the learned patient-individual 3D rigid transformation to improve stability when automatically re-sampling the AX images to SAX orientations. The network was trained on 122 registered 3D AX-SAX CMR volume pairs from a multi-centric patient cohort. A mean 3D Dice of 0.86 +/- 0.06 for the left ventricle, 0.65 +/- 0.08 for the myocardium, and 0.77 +/- 0.10 for the right ventricle could be achieved. This is an improvement of 25% in Dice for RV in comparison to direct application on axial slices. To conclude, our pre-trained task module has neither seen CMR images nor labels from the target domain, but is able to segment them after the domain gap is reduced. Code: https://github.com/Cardio-AI/3d-mri-domain-adaptation</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000702638800033</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33471750</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Task analysis; Heart; Image segmentation; Three-dimensional displays; Deep learning; Training; Biomedical imaging; Cardiac magnetic resonance; short axis images; spatial transformer networks; unsupervised domain adaptation; competence network for congenital heart defects</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SEGMENTATION; ORIENTATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Koehler, Sven; Ritzmann, Florian; Engelhardt, Sandy] Univ Heidelberg Hosp, Dept Internal Med 3, Artificial Intelligence Cardiovasc Med Grp, D-69120 Heidelberg, Germany. <br>
[Koehler, Sven; Ritzmann, Florian; Engelhardt, Sandy] German Ctr Cardiovasc Res DZHK, D-68167 Heidelberg, Germany. <br>
[Hussain, Tarique; Tandon, Animesh; Greil, Gerald] Univ Texas Southwestern Med Ctr Dallas, Dept Pediat, Dallas, TX 75390 USA. <br>
[Hussain, Tarique; Tandon, Animesh; Greil, Gerald] Univ Texas Southwestern Med Ctr Dallas, Div Cardiol, Dallas, TX 75390 USA. <br>
[Hussain, Tarique; Tandon, Animesh; Greil, Gerald] Univ Texas Southwestern Med Ctr Dallas, Dept Radiol, Dallas, TX 75390 USA. <br>
[Hussain, Tarique; Tandon, Animesh; Greil, Gerald] Univ Texas Southwestern Med Ctr Dallas, Adv Imaging Res Ctr, Dallas, TX 75390 USA. <br>
[Blair, Zach; Huffaker, Tyler] Univ Texas Southwestern Med Ctr Dallas, Dept Pediat, Dallas, TX 75390 USA. <br>
[Pickardt, Thomas] German Competence Network Congenital Heart, D-13353 Berlin, Germany. <br>
[Pickardt, Thomas] German Ctr Cardiovasc Res DZHK, D-68167 Berlin, Germany. <br>
[Sarikouch, Samir] Hannover Med Sch, Dept Cardiothorac, Transplantat &amp; Vasc Surg, D-30625 Hannover, Germany. <br>
[Sarikouch, Samir] German Competence Network Congenital Heart Defect, D-13353 Berlin, Germany. <br>
[Sarikouch, Samir] German Ctr Cardiovasc Res DZHK, D-68167 Berlin, Germany. <br>
[Latus, Heiner] Tech Univ Munich, Dept Paediat &amp; Congenital Heart Defects, German Heart Ctr Munich, D-80636 Munich, Germany. <br>
[Wolf, Ivo] Mannheim Univ Appl Sci, Dept Comp Sci, D-68163 Mannheim, Germany. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Engelhardt, S (corresponding author), Univ Heidelberg Hosp, Dept Internal Med 3, Artificial Intelligence Cardiovasc Med Grp, D-69120 Heidelberg, Germany.<br>Engelhardt, S (corresponding author), German Ctr Cardiovasc Res DZHK, D-68167 Heidelberg, Germany.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
sven.koehler@med.uni-heidelberg.de; mohammad.hussain@utsouthwestern.edu; zachary.blair@utsouthwestern.edu; tyler.huffaker@utsouthwestern.edu; florian.ritzmann2@hs-mannheim.de; animesh.tandon@utsouthwestern.edu; pickardt@kompetenznetz-ahf.de; sarikouch.samir@mh-hannover.de; latus@dhm.mhn.de; gerald.greil@utsouthwestern.edu; i.wolf@hs-mannheim.de; sandy.engelhardt@med.uni-heidelberg.de</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Ruprecht Karls University Heidelberg; German Centre for Cardiovascular Research; University of Texas System; University of Texas Southwestern Medical Center; University of Texas System; University of Texas Southwestern Medical Center; University of Texas System; University of Texas Southwestern Medical Center; University of Texas System; University of Texas Southwestern Medical Center; University of Texas System; University of Texas Southwestern Medical Center; German Centre for Cardiovascular Research; Hannover Medical School; German Centre for Cardiovascular Research; Technical University of Munich; German Heart Centre Munich</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Koehler, Sven</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4989-8766&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Koehler, Sven</display_name>&nbsp;</td><td>HMP-6265-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Greil, Gerald</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7288-6566&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hussain, Tariq</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1332-2418&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Huffaker, Tyler</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9442-8600&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Pickardt, Thomas</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0019-6325&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tandon, Animesh</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9769-8801&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wolf, Ivo</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6519-6484&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hussain, Tarique</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4091-992X&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>WA1FC</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Informatics for Life Project through the Klaus Tschira Foundation</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Competence Network for Congenital Heart Defects through the Federal Ministry of Education and Research</grant_agency>&nbsp;</td><td>
<div>01GI0601&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>German Centre for Cardiovascular Research (DZHK)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the Informatics for Life Project through the Klaus Tschira Foundation, in part by the Competence Network for Congenital Heart Defects through the Federal Ministry of Education and Research under Grant 01GI0601, and in part by the German Centre for Cardiovascular Research (DZHK).</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted, Green Accepted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 31 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Bimodal Masked Autoencoders with internal representation connections for electrocardiogram classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wei, YF (Wei, Yufeng); Lian, C (Lian, Cheng); Xu, BR (Xu, Bingrong); Zhao, PB (Zhao, Pengbo); Yang, HG (Yang, Honggang); Zeng, ZG (Zeng, Zhigang)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>PATTERN RECOGNITION</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>161</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>111311</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.patcog.2024.111311</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JAN 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 MAY</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
8</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
16</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>35</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Time series self-supervised methods have been widely used, with electrocardiogram (ECG) classification tasks also reaping their benefits. One mainstream paradigm is masked data modeling, which leverages the visible part of data to reconstruct the masked part, aiding in acquiring useful representations for downstream tasks. However, traditional approach predominantly attends to time domain information and places excessive demands on the encoder for reconstruction, thereby hurting model's discriminative ability. In this paper, we present Bimodal Masked autoencoders with Internal Representation Connections (BMIRC) for ECG classification. On the one hand, BMIRC integrates the frequency spectrum of ECG into the masked pre-training process, enhancing the model's comprehensive understanding of the ECG. On the other hand, it establishes internal representation connections (IRC) from the encoder to the decoder, which offers the decoder various levels of information to aid in reconstruction, thereby allowing the encoder to focus on modeling discriminative representations. We conduct comprehensive experiments across three distinct ECG datasets to validate the effectiveness of BMIRC. Experimental results demonstrate that BMIRC surpasses the competitive baselines across the majority of scenarios, encompassing both intra-domain (pre-training and fine-tuning on the same dataset) and cross-domain (pre-training and fine-tuning on different datasets) settings. The code is publicly available at https://github.com/Envy-Clouds/BMIRC.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001392540200001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
ECG; Frequency spectrum; Bimodal; Masked autoencoders; Internal representation connections</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wei, Yufeng; Lian, Cheng; Xu, Bingrong; Zhao, Pengbo; Yang, Honggang] Wuhan Univ Technol, Sch Automat, Wuhan 430074, Peoples R China. <br>
[Zeng, Zhigang] Huazhong Univ Sci &amp; Technol, Sch Artificial Intelligence &amp; Automat, Wuhan 430074, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Lian, C (corresponding author), Wuhan Univ Technol, Sch Automat, Wuhan 430074, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
chenglian@whut.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Wuhan University of Technology; Huazhong University of Science &amp; Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lian, Cheng</display_name>&nbsp;</td><td>KIE-6538-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>wei, yufeng</display_name>&nbsp;</td><td>W-3423-2018&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zeng, Zhigang</display_name>&nbsp;</td><td>A-1794-2013&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER SCI LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>125 London Wall, London, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>R6L5G</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0031-3203</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-5142</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>PATTERN RECOGN</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Pattern Recognit.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Founda-tion of China</grant_agency>&nbsp;</td><td>
<div>62176193&nbsp;</div>
<div>62206204&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the National Natural Science Founda-tion of China under Grants 62176193 and 62206204.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 32 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A Sleep Apnea Detection Method Based on Unsupervised Feature Learning and Single-Lead Electrocardiogram</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Feng, KC (Feng, Kaicheng); Qin, HJ (Qin, Hengji); Wu, S (Wu, Shan); Pan, WF (Pan, Weifeng); Liu, GZ (Liu, Guanzheng)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>70</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>4000912</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2020.3017246</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>95</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>106</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
55</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>58</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Sleep apnea (SA) is a harmful respiratory disorder that has caused widespread concern around the world. Considering that electrocardiogram (ECG)-based SA diagnostic methods were effective and human-friendly, many machine learning or deep learning methods based on ECG have been proposed by prior works. However, these methods are based on feature engineering or supervised and semisupervised learning techniques, and the feature sets are always incomplete, subjective, and highly dependent on labeled data. In addition, some related studies ignored the data imbalance problem which leads to poor performance of classifier on minority classes. In this study, an SA detection model based on frequential stacked sparse auto-encoder (FSSAE) and time-dependent cost-sensitive (TDCS) classification model was proposed. The FSSAE extracts feature set automatically with unsupervised learning technique, and the TDCS classification model is proposed by combining the hidden Markov model (HMM) and the MetaCost algorithm to improve the performance of the classifier by considering temporal dependence and the imbalance problem. In the test set, the result of per-segment classification achieved 85.1%, 86.2%, and 84.4% for accuracy, sensitivity, and specificity, respectively, proving that our method is helpful for SA detection.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000591842200021</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cost sensitive; deep neural network; hidden Markov model (HMM); sleep apnea (SA); stacked sparse autoencoder (SSAE)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
HEART-RATE-VARIABILITY; EXPERT-SYSTEM; QUANTIFICATION; ASSOCIATION; STROKE</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Feng, Kaicheng; Qin, Hengji; Wu, Shan; Pan, Weifeng; Liu, Guanzheng] Sun Yat Sen Univ, Sch Biomed Engn, Guangzhou 510275, Peoples R China. <br>
[Feng, Kaicheng; Qin, Hengji; Wu, Shan; Pan, Weifeng; Liu, Guanzheng] Sun Yat Sen Univ, Sch Biomed Engn, Key Lab Sensing Technol &amp; Biomed Instruments Guan, Guangzhou 510275, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liu, GZ (corresponding author), Sun Yat Sen Univ, Sch Biomed Engn, Guangzhou 510275, Peoples R China.<br>Liu, GZ (corresponding author), Sun Yat Sen Univ, Sch Biomed Engn, Key Lab Sensing Technol &amp; Biomed Instruments Guan, Guangzhou 510275, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
liugzh3@163.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Sun Yat Sen University; Sun Yat Sen University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Qin, Hengji</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5706-7052&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Feng, Kaicheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9972-3361&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Pan, Weifeng</display_name>&nbsp;</td><td>N-9474-2018&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>OU9KO</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61401521&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guangdong Basic and Applied Basic Research Foundation</grant_agency>&nbsp;</td><td>
<div>2020A1515010701&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shenzhen Science and Technology Plan for Fundamental Research</grant_agency>&nbsp;</td><td>
<div>JCY20180307153213863&nbsp;</div>
<div>JCY20190807162003969&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the Natural Science Foundation of China under Grant 61401521; in part by the Guangdong Basic and Applied Basic Research Foundation under Grant 2020A1515010701; and in part by the Shenzhen Science and Technology Plan for Fundamental Research under Grant JCY20180307153213863 and Grant JCY20190807162003969. The Associate Editor coordinating the review process was Lihui Peng.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 33 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Statistical &lt;i&gt;n&lt;/i&gt;-Best AFD-Based Sparse Representation for ECG Biometric Identification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Tan, CY (Tan, Chunyu); Zhang, LM (Zhang, Liming); Qian, T (Qian, Tao); Br&aacute;s, S (Bras, Susana); Pinho, AJ (Pinho, Armando J.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>70</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>2515713</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2021.3119138</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>3</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
18</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>45</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Electrocardiogram (ECG) biometric recognition as a personal identification method is receiving more and more attention because it can support live verification results. Compared with other biometric-based methods, it can provide higher security performance. The difficulty of the problem lies in how to stably extract ECG signal features and achieve real-time verification. In this study, a new type of sparse representation learning framework called statistical n-best adaptive Fourier decomposition (SAFD) originated by Qian is adopted in ECG biometric identification. Adaptive Fourier decomposition (AFD) is a recently developed combination of transform-based signal decomposition and sparse representation method, which can adaptively select the atoms from a redundant dictionary through orthogonal processing. The advantage of the AFD-type methods is that each atom in the dictionary has a precise mathematical formula with good analytic properties. This characteristic is significantly distinguished it from other existing sparse representations, where the atoms learned are usually matrix data and cannot be described mathematically. The proposed SAFD extends the existing n-best AFD from processing single signal to multi-signals and implements the n-best AFD in the stochastic Hardy space. Therefore, the small number of learned atoms by SAFD is sufficient to capture internal structure and robustness of the signal and generate a discriminative representation that reflects the time-frequency characteristics of signals. It is very suitable for non-stationary signals like ECG. The proof of convergence of the algorithm is presented. Extensive experiments are conducted on five public databases collected in different realistic conditions, and an average identification accuracy of 98.0% is achieved. In addition, less than 1 ms for one matching process makes it possible to be implemented in real time. Experimental results demonstrate that the proposed method can achieve superior performance compared to other state-of-the-art ECG biometric identification methods.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000749887400010</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Biometric identification; electrocardiogram (ECG); sparse representation; statistical n-best adaptive Fourier decomposition (SAFD); time-frequency representation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ADAPTIVE FOURIER DECOMPOSITION; CONVOLUTIONAL NEURAL-NETWORK; ALGORITHM</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Tan, Chunyu; Zhang, Liming] Univ Macau, Fac Sci &amp; Technol, Macau, Peoples R China. <br>
[Tan, Chunyu] Anhui Univ, Sch Artificial Intelligence, Hefei 230000, Anhui, Peoples R China. <br>
[Qian, Tao] Macau Univ Sci &amp; Technol, Macao Ctr Math Sci, Macau, Peoples R China. <br>
[Bras, Susana; Pinho, Armando J.] Univ Aveiro, Inst Elect &amp; Informat Engn Aveiro IEETA, P-3810193 Aveiro, Portugal. <br>
[Bras, Susana; Pinho, Armando J.] Univ Aveiro, Dept Elect Telecommun &amp; Informat DETI, P-3810193 Aveiro, Portugal. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhang, LM (corresponding author), Univ Macau, Fac Sci &amp; Technol, Macau, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
yb57416@connect.um.edu.mo; lmzhang@um.edu.mo; tqian@must.edu.mo; susana.bras@ua.pt; ap@ua.pt</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Macau; Anhui University; Macau University of Science &amp; Technology; Universidade de Aveiro; Universidade de Aveiro</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bras, Susana</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-8650-9219&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Liming</display_name>&nbsp;</td><td>G-5518-2013&nbsp;</td><td>0000-0002-2664-8193&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Br&aacute;s, Susana</display_name>&nbsp;</td><td>AAV-2421-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Pinho, Armando</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9164-0016&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Pinho, Armando</display_name>&nbsp;</td><td>A-2309-2012&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Liming</display_name>&nbsp;</td><td>ABG-5996-2020&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>YR3IE</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Science and Technology Development Fund of Macao Special Administrative Region (SAR) Fundo para o Desenvolvimento das Ciencias e da Tecnologia (FDCT)</grant_agency>&nbsp;</td><td>
<div>0123/2018/A3&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Multi-Year Research Grant</grant_agency>&nbsp;</td><td>
<div>201800111-FST&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>European Regional Development Fund</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Fundo Social Europeu (FSE) through COMPETE2020, through Fundacao para a Ciencia e Tecnologia (FCT)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Scope of the Projects [Instituto de Engenharia Eletronica e Informatica de Aveiro/Universidade de Aveiro (IEETA/UA)]</grant_agency>&nbsp;</td><td>
<div>UIDB/00127/2020&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the Science and Technology Development Fund of Macao Special Administrative Region (SAR) Fundo para o Desenvolvimento das Ciencias e da Tecnologia (FDCT) under Grant 0123/2018/A3; in part by Multi-Year Research Grant 201800111-FST; in part by European Regional Development Fund, Fundo Social Europeu (FSE) through COMPETE2020, through Fundacao para a Ciencia e Tecnologia (FCT), in the scope of the Framework Contract Foreseen in the numbers 4-6 of the article 23, of the Decree-Law 57/2016, of August 29, changed by Law 57/2017, of July 19; and in part by the Scope of the Projects [Instituto de Engenharia Eletronica e Informatica de Aveiro/Universidade de Aveiro (IEETA/UA)] under Grant UIDB/00127/2020.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 34 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Direct Lead Assignment: A Simple and Scalable Contrastive Learning Method for ECG and Its IoMT Applications</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, WH (Liu, Wenhan); Pan, SR (Pan, Shurong); Chang, S (Chang, Sheng); Huang, QJ (Huang, Qijun); Jiang, N (Jiang, Nan)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE INTERNET OF THINGS JOURNAL</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>12</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>5</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>5672-5686</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JIOT.2024.3487977</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 MAR 1</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>2</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>2</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
3</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>46</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Nowadays applying deep learning (DL) to electrocardiogram (ECG) analysis has become a significant topic in intelligent healthcare. DL models heavily rely on large-scale labeled ECGs in supervised learning, while labeling ECGs is a costly and time-consuming process. This article proposes a simple self-supervised learning (SSL) method to pretrain models using unlabeled ECGs, improving model performances in a low- data regime. It is termed direct lead assignment (DLA). In pretraining, DLA employs multilead and single-lead encoders to interact between global and lead-specific representations. The pretrained encoders can constitute scalable models, which can be deployed on Internet of Medical Things (IoMT) devices for ECG monitoring with different leads. According to the experiments, DLA outperforms existing SSL methods for ECGs and reduces the reliance on labels by 4x-8x. In other words, DLA can make the model obtain better results when labeled data are scarce than the one trained from scratch, as the pretraining helps the model recognize critical ECG patterns in a low-data regime. For IoMT applications, the models are deployed on a Raspberry Pi 2 W with an ARM Cortex-A53 processor. It can run the models in real time. The maximum running time is about 388 ms/10-s record. Thus, DLA shows excellent potential for automatic ECG analysis based on IoMT, aiding cardiologists in diagnosing cardiovascular diseases.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001433294700034</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Deep learning (DL); electrocardiogram (ECG); Internet of Medical Things (IoMT); Internet of Medical Things (IoMT); self-supervised learning (SSL); self-supervised learning (SSL); self-supervised learning (SSL)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
INTERNET; SYSTEM</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Wenhan; Jiang, Nan] East China Jiaotong Univ, Sch Informat &amp; Software Engn, Nanchang 330013, Peoples R China. <br>
[Pan, Shurong; Chang, Sheng; Huang, Qijun] Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liu, WH (corresponding author), East China Jiaotong Univ, Sch Informat &amp; Software Engn, Nanchang 330013, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
WHliu@ecjtu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
East China Jiaotong University; Wuhan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>jiang, nan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1712-1872&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chang, Sheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4875-5501&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Engineering, Electrical &amp; Electronic; Telecommunications</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Telecommunications</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>Y6O6I</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2327-4662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE INTERNET THINGS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Internet Things J.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62062034&nbsp;</div>
<div>62172160&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Program of China</grant_agency>&nbsp;</td><td>
<div>2022YFB2602200&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Double Thousand Plan of Jiangxi Province</grant_agency>&nbsp;</td><td>
<div>JXSQ2023201010&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Jiangxi Province Key Laboratory of Advanced Network Computing</grant_agency>&nbsp;</td><td>
<div>2024SSY03071&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under Grant 62062034 and Grant 62172160; in part by the National Key Research and Development Program of China under Grant 2022YFB2602200; in part by the Double Thousand Plan of Jiangxi Province under Grant JXSQ2023201010; and in part by the Jiangxi Province Key Laboratory of Advanced Network Computing under Grant 2024SSY03071.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 35 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Unsupervised Multimanifold Cross-Guided Diffusion Deformable Registration for Cardiac MRI</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhao, QF (Zhao, Qifeng); Wang, XC (Wang, Xuchu)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TNNLS.2025.3577483</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JUN 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JUN 18</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
5</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>54</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Diffusion networks demonstrate remarkable robustness in extracting complex structural features across various domains of medical image processing. In the task of cardiac image registration, diffusion networks excel at reconstructing intricate structural details, thereby enabling effective representation of cardiac anatomical motion. In this article, we propose an unsupervised diffusion registration framework named MCG-Reg for 3-D cardiac magnetic resonance (MR) image registration, employing a multimanifold cross-fusion strategy. MCG-Reg comprises two components: the multimanifold cross-fusion (MCF) module and the weighted fusion codec (WFC) module. MCF module decouples the cardiac image, leveraging multifrequency and multiscale features for cross-attention (CA) calculation, and fuses with the edge image to enable adaptive focus gathering and edge perception capabilities in the model, thereby enhancing the effective aggregation of local and global features. WFC module further processes cardiac features by utilizing offset attention to capture large displacement information, while employing feature energy maps for residual connections to enhance the model's attention perception ability, thus facilitating better topology maintenance and boundary constraint realization. The registration accuracy and model generalization of the proposed MCG-Reg are validated in publicly available ACDC, M&amp;Ms, and CAP datasets. The experimental results verify that it achieves state-of-the-art performance in comparison to related methods, highlighting the significant potential of the proposed framework in cardiac image analysis applications.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001512675400001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>40526546</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article; Early Access</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Deformation; Image registration; Feature extraction; Accuracy; Deep learning; Anatomical structure; Biomedical imaging; Image edge detection; Diffusion models; Correlation; Deformable image registration; diffusion model; multimanifold cross fusion (MCF); unsupervised learning; weighted fusion codec (WFC)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SEGMENTATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhao, Qifeng; Wang, Xuchu] Chongqing Univ, Coll Optoelect Engn, Chongqing 401331, Peoples R China. <br>
[Wang, Xuchu] Chongqing Univ, Key Lab Optoelect Technol &amp; Syst, Minist Educ, Chongqing 401331, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Wang, XC (corresponding author), Chongqing Univ, Coll Optoelect Engn, Chongqing 401331, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
xcwang@cqu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Chongqing University; Chongqing University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhao, Qifeng</display_name>&nbsp;</td><td>LNP-4731-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Hardware &amp; Architecture; Computer Science, Theory &amp; Methods; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>3ZL2S</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2162-237X</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2162-2388</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T NEUR NET LEAR</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Neural Netw. Learn. Syst.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61971076&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of Chongqing Municipality</grant_agency>&nbsp;</td><td>
<div>CSTB2024NSCQ-MSX0369&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under Grant 61971076 and in part by the Natural Science Foundation of Chongqing Municipality under Grant CSTB2024NSCQ-MSX0369</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 36 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Deep Neural Network Denoising Model Based on Sparse Representation Algorithm for ECG Signal</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Hou, YR (Hou, Yanrong); Liu, RX (Liu, Ruixia); Shu, ML (Shu, Minglei); Xie, XY (Xie, Xiaoyun); Chen, CF (Chen, Changfang)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>72</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>2507711</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2023.3251408</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>22</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>24</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
55</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>62</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Electrocardiogram (ECG) denoising is very important for heart disease diagnosis. The traditional ECG denoising models have problems such as single noise type and poor interpretability of deep neural networks. The innovation of the proposed method is to incorporate the precious achievements of traditional methods into the design of neural networks and to build a bridge between them. Therefore, a novel interpretable deep denoising framework based on sparse representation is proposed in this study, and the half quadratic splitting (HQS) algorithm is applied to decompose the denoising method into sparse representations as an iterative solution process. In addition, a new weight distribution (WD) module is designed to extract adaptive hyperparameters based on ECG correlation instead of empirical values and greatly improves the efficiency of hyperparameter selection. To demonstrate the fairness and effectiveness of the proposed method, four different denoising models with different data preprocessing techniques are used for comparison. The extensive experimental validation and simulation studies demonstrated that the proposed framework has an excellent performance in quantitative and visual evaluation.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000955734200028</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
electrocardiogram (ECG); half quadratic splitting (HQS); neural network; sparse representation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
REGULARIZATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Hou, Yanrong] Qilu Univ Technol, Sch Math &amp; Stat, Shandong Acad Sci, Jinan 250353, Peoples R China. <br>
[Liu, Ruixia; Shu, Minglei; Xie, Xiaoyun; Chen, Changfang] Qilu Univ Technol, Shandong Artificial Intelligence Inst, Shandong Acad Sci, Jinan 250014, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liu, RX (corresponding author), Qilu Univ Technol, Shandong Artificial Intelligence Inst, Shandong Acad Sci, Jinan 250014, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
liurx@sdas.org</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Qilu University of Technology; Qilu University of Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xie, Xiaoyun</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3137-5070&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>liu, ruixia</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-4044-5384&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hou, yanrong</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-4675-5885&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>A5TD5</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62172243&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of Shandong Province</grant_agency>&nbsp;</td><td>
<div>ZR2021MF084&nbsp;</div>
<div>ZR2020QF020&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under Grant 62172243 and in part by the Natural Science Foundation of Shandong Province under Grant ZR2021MF084 and Grant ZR2020QF020.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 37 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>High-Accuracy, Unsupervised Annotation of Seismocardiogram Traces for Heart Rate Monitoring</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Cocconcelli, F (Cocconcelli, Federico); Mora, N (Mora, Niccolo); Matrella, G (Matrella, Guido); Ciampolini, P (Ciampolini, Paolo)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>69</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>9</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>6372-6380</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2020.2967135</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 SEPT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
8</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>34</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This article presents an unsupervised, automated procedure for the analysis of Seismocardiogram (SCG) signals. SCG is a measure of chest vibrations, induced by the mechanical activity of the heart, which allows extracting relevant parameters, including heart rate (HR) and HR variability (HRV). An initial self-calibration is performed, solely based on the SCG traces, yielding a suitable heartbeat template (personalized for each subject). Then, beat detection and timing annotation are performed in two steps: at first, candidate beats are identified and validated, by means of suitably defined detection signals; then, precise timing annotation is achieved by best aligning such candidate beats to the previously extracted template. The algorithm has been validated on two separate data sets, featuring different acquisition setups: the first one is the publicly available Combined measurement of ECG, Breathing and Seismocardiogram (CEBS) database, reporting SCG signals from the subjects lying in supine position, whereas the second one was acquired using a custom setup, involving the sitting subjects. Results show good sensitivity and precision scores (98.5% and 98.6% for the CEBS database, and 99.1% and 97.9% for the Custom one, respectively). In addition, comparison with electrocardiogram (ECG) gold-standard is given, showing good agreement between the beat-to-beat intervals computed from SCG and the ECG gold-standard: on average, R-2 scores of 99.3% and 98.4% are achieved on the CEBS and Custom data sets, respectively. Furthermore, a low rms error is achieved on the CEBS and Custom data sets, amounting to 4.6 and 6.2 ms, respectively (i.e., 2.3 T-s and 3.1 T-s, where T-s is the sampling period): such results are well compared with related literature. Validation on two different data sets indicates the robustness of the proposed methodology.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000559518800042</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Accelerometer; active assisted living (AAL); heart rate (HR); microelectromechanical system (MEMS); Seismocardiogram (SCG); vital sign monitoring</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NONCONTACT</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Cocconcelli, Federico; Mora, Niccolo; Matrella, Guido; Ciampolini, Paolo] Univ Parma, Dipartimento Ingn &amp; Architettura, I-43121 Parma, Italy. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Cocconcelli, F (corresponding author), Univ Parma, Dipartimento Ingn &amp; Architettura, I-43121 Parma, Italy.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
federico.cocconcelli@unipr.it; niccolo.mora@unipr.it; guido.matrella@unipr.it; paolo.ciampolini@unipr.it</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Parma</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>CIAMPOLINI, Paolo</display_name>&nbsp;</td><td>A-9279-2018&nbsp;</td><td>0000-0001-8944-2152&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Mora, Niccol&ograve;</display_name>&nbsp;</td><td>Z-1823-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Mora, Niccolo</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0093-0024&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Matrella, Guido</display_name>&nbsp;</td><td>Q-3272-2016&nbsp;</td><td>0000-0002-0705-527X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cocconcelli, Federico</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-8104-8836&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>NA0OF</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>9</value>
</td>
</tr>

<tr>
<td>
<b>Open Access:</b>

<value>hybrid</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 38 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Class-specific weighted broad learning system-based domain adaptation for patient-specific ECG classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Fan, W (Fan, Wei); Si, YJ (Si, Yujuan); Sun, MQ (Sun, Meiqi); Zhou, L (Zhou, Lin); Yang, WY (Yang, Weiyi); Alhudhaif, A (Alhudhaif, Adi); Alenezi, F (Alenezi, Fayadh)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>273</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>126824</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2025.126824</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>FEB 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 MAY 10</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
16</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
23</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>47</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
With the growing prevalence of wearable devices, fast and accurate classification of patient-specific electrocardiogram (ECG) is crucial for daily heart monitoring. Despite the surge in generic arrhythmia detection methods, automated systems with real-time capabilities and satisfactory performance for patient-specific ECG classification remain rare. Particularly, the morphological differences in ECG waveforms among individuals and the imbalances between beat classes pose major challenges to any model. In this paper, we propose two novel domain adaptation algorithms by improving the previously established class-specific weighted broad learning system (CSWBLS) with high resistance to imbalance data, named one-step CSWBLS-based domain adaptation (OCSWBLS-DA) and two-step CSWBLS-based domain adaptation (TCSWBLS-DA). OCSWBLS-DA achieves individual adaptation by simultaneously learning knowledge from a large number of common heartbeats without distinguishing patients and a small number of patient-specific heartbeats in one step. TCSWBLS-DA is first pre- trained on common heartbeats and then fine-tuned on patient-specific heartbeats to adapt to the corresponding individual. Both algorithms not only inherit high learning efficiency and the ability to address imbalance problems from CSWBLS but also have better generalization. Experimental results on the MIT-BIH arrhythmia database following the recommendations of Association for the Advancement of Medical Instrumentation (AAMI) EC57: 2012 standard show that both methods outperformed state-of-the-art techniques in detecting ventricular and supraventricular ectopic beats, with TCSWBLS-DA achieving the highest F1-scores of 96.1% and 80.6%, respectively. Moreover, TCSWBLS-DA takes only 0.07 seconds to adapt to a new individual and 0.034 milliseconds to identify a single beat due to its simple structure, demonstrating significant potential for practical application.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001429962300001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Patient-specific ECG classification; Arrhythmia; Domain drift; Class imbalance; Class-specific weighted broad learning system; (CSWBLS); Domain adaptation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
MORPHOLOGY</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Fan, Wei] Fudan Univ, Sch Informat Sci &amp; Technol, Shanghai 200438, Peoples R China. <br>
[Si, Yujuan] Zhuhai Coll Sci &amp; Technol, Sch Elect &amp; Informat Engn, Zhuhai 519041, Peoples R China. <br>
[Si, Yujuan; Sun, Meiqi; Zhou, Lin] Jilin Univ, Coll Commun Engn, Changchun 130012, Peoples R China. <br>
[Yang, Weiyi] Nanjing Univ Informat Sci &amp; Technol, Sch Artificial Intelligence, Nanjing 210044, Peoples R China. <br>
[Alhudhaif, Adi] Prince Sattam bin Abdulaziz Univ, Coll Comp Engn &amp; Sci Al kharj, Dept Comp Sci, Al Kharj 11942, Saudi Arabia. <br>
[Alenezi, Fayadh] Jouf Univ, Coll Engn, Dept Elect Engn, Sakaka 72238, Saudi Arabia. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Si, YJ (corresponding author), Zhuhai Coll Sci &amp; Technol, Sch Elect &amp; Informat Engn, Zhuhai 519041, Peoples R China.<br>Si, YJ (corresponding author), Jilin Univ, Coll Commun Engn, Changchun 130012, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
siyj@jlu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Fudan University; Jilin University; Nanjing University of Information Science &amp; Technology; Prince Sattam Bin Abdulaziz University; Al Jouf University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Alenezi, Fayadh</display_name>&nbsp;</td><td>ABB-4871-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Alhudhaif, Adi</display_name>&nbsp;</td><td>AAN-6541-2021&nbsp;</td><td>0000-0002-7201-6963&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Sun, Meiqi</display_name>&nbsp;</td><td>ADI-7658-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>Y1Q6N</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>17</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of Guangdong Province</grant_agency>&nbsp;</td><td>
<div>2023A1515011302&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guang-dong Key Disciplines Project</grant_agency>&nbsp;</td><td>
<div>2022ZDJS140&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Featured Innovation Projects of the Guangdong Universities</grant_agency>&nbsp;</td><td>
<div>2022KTSCX189&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Startup Foundation for Introducing Talent of NUIST</grant_agency>&nbsp;</td><td>
<div>2023r058&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the Natural Science Foundation of Guangdong Province (grant number 2023A1515011302) , the Guang-dong Key Disciplines Project (grant number 2022ZDJS140) , the Featured Innovation Projects of the Guangdong Universities (grant number 2022KTSCX189) , and the Startup Foundation for Introducing Talent of NUIST (grant number 2023r058) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 39 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Learning Deep Off-the-Person Heart Biometrics Representations</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Luz, EJD (da Silva Luz, Eduardo Jose); Moreira, GJP (Moreira, Gladston J. P.); Oliveira, LS (Oliveira, Luiz S.); Schwartz, WR (Schwartz, William Robson); Menotti, D (Menotti, David)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>13</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>5</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>1258-1270</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIFS.2017.2784362</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2018 MAY</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>81</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>91</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
65</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>37</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Since the beginning of the new millennium, the electrocardiogram (ECG) has been studied as a biometric trait for security systems and other applications. Recently, with devices such as smartphones and tablets, the acquisition of ECG signal in the off-the-person category has made this biometric signal suitable for real scenarios. In this paper, we introduce the usage of deep learning techniques, specifically convolutional networks, for extracting useful representation for heart biometrics recognition. Particularly, we investigate the learning of feature representations for heart biometrics through two sources: on the raw heartbeat signal and on the heartbeat spectrogram. We also introduce heartbeat data augmentation techniques, which are very important to generalization in the context of deep learning approaches. Using the same experimental setup for six methods in the literature, we show that our proposal achieves state-of-the-art results in the two off-the-person publicly available databases.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000424043800013</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram; biometric systems; deep learning; off-the-person category</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ECG; IDENTIFICATION; SYSTEMS; SIGNAL</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[da Silva Luz, Eduardo Jose; Moreira, Gladston J. P.] Univ Fed Ouro Preto, Comp Dept, BR-35400000 Ouro Preto, Brazil. <br>
[Oliveira, Luiz S.; Menotti, David] Univ Fed Parana, Dept Informat, BR-81531980 Curitiba, Parana, Brazil. <br>
[Schwartz, William Robson] Univ Fed Minas Gerais, Dept Comp Sci, BR-31270010 Belo Horizonte, MG, Brazil. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Menotti, D (corresponding author), Univ Fed Parana, Dept Informat, BR-81531980 Curitiba, Parana, Brazil.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
eduluz@iceb.ufop.br; gladston@iceb.ufop.br; lesoliveira@inf.ufpr.br; william@dcc.ufmg.br; menotti@inf.ufpr.br</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Universidade Federal de Ouro Preto; Universidade Federal do Parana; Universidade Federal de Minas Gerais</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Menotti, David</display_name>&nbsp;</td><td>M-6205-2014&nbsp;</td><td>0000-0003-2430-2030&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Schwartz, William</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1449-8834&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Luz, Eduardo J. da S.</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5249-1559&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Schwartz, William</display_name>&nbsp;</td><td>E-6612-2011&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Moreira, Gladston</display_name>&nbsp;</td><td>H-9396-2012&nbsp;</td><td>0000-0001-7747-5926&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Luz, Eduardo</display_name>&nbsp;</td><td>AAZ-1274-2020&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Theory &amp; Methods; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>FU7PE</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1556-6013</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1556-6021</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INF FOREN SEC</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Inf. Forensic Secur.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>UFOP</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>UFPR</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>UFMG</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>FAPEMIG</grant_agency>&nbsp;</td><td>
<div>APQ-02825-14&nbsp;</div>
<div>PPM-00540-17&nbsp;</div>
<div>APQ-00567-14&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>CAPES</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>CNPq</grant_agency>&nbsp;</td><td>
<div>307010/2014-7&nbsp;</div>
<div>311053/2016-5&nbsp;</div>
<div>428333/2016-8&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>IBM Ph.D. fellowship</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by UFOP, UFPR, UFMG, FAPEMIG (APQ-02825-14, PPM-00540-17, APQ-00567-14), in part by CAPES, and in part by CNPq under Grant 307010/2014-7, Grant 311053/2016-5, and Grant 428333/2016-8. The work of E. J. da Silva Luz was supported by an IBM Ph.D. fellowship.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 40 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Lead Separation and Combination: A Novel Unsupervised 12-Lead ECG Feature Learning Framework for Internet of Medical Things</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, WH (Liu, Wenhan); Guo, QX (Guo, Qianxi); Gao, XW (Gao, Xinwei); Chang, S (Chang, Sheng); Wang, H (Wang, Hao); He, J (He, Jin); Huang, Q (Huang, Qijun)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE INTERNET OF THINGS JOURNAL</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>9</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>23</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>23897-23914</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JIOT.2022.3188771</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2022 DEC 1</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>6</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>6</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
36</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>65</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
The development of healthcare industry, especially Internet of Medical Things (IoMT), has generated considerable unlabeled electrocardiogram (ECG) signals. This article proposes a new unsupervised feature learning method for these unlabeled 12-lead ECGs, a type of 12-channel 1-D time series. Based on contrastive predictive coding (CPC), it considers the characteristics of 12-lead ECGs and develops novel lead-separation CPC (LSCPC) and lead-combination CPC (LCCPC). Specifically, LSCPC captures intralead features for each lead, while LCCPC combines all the leads and explores interlead relationships. Furthermore, a fusion model of LSCPC and LCCPC generates final representations. The Physikalisch-Technische Bundesanstalt (PTB)-XL database that contains 21 837 12-lead records is used for unsupervised feature learning. Using learned features, linear classifiers are trained to accomplish the downstream tasks. 448 ECG records from 148 myocardial infarction (MI) and 52 healthy control subjects of the PTB database are used for MI detection. 6877 records from the CPSC-2018 database are used for atrial fibrillation (AF) detection, including 918 normal records, 1098 AF records, and 4861 other records. Using fivefold cross-validation, our model achieves 90.38% and 73.27% accuracy in MI and AF detection, respectively. Compared with existing models, it improves the performances by at least 2.32% for MI detection and 3.99% for AF detection. The model has been deployed on a lightweight embedded system (800-MHz ARM processor, 1-GB RAM). The maximum latency is only 465.34 ms, which can satisfy the real-time constraints. Overall, all the results have demonstrated the potential of our method for real-world healthcare, and lightweight IoMT applications.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000904931000042</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Deep learning (DL); electrocardiogram (ECG) classification; Internet of Medical Things (IoMT) applications; unsupervised learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CONVOLUTIONAL NEURAL-NETWORK; MYOCARDIAL-INFARCTION; HEARTBEAT CLASSIFICATION; ARRHYTHMIA DETECTION; SIGNALS; ELECTROCARDIOGRAM</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Wenhan; Guo, Qianxi; Gao, Xinwei; Chang, Sheng; Wang, Hao; He, Jin; Huang, Qijun] Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Huang, QJ (corresponding author), Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
huangqj@whu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Wuhan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Han</display_name>&nbsp;</td><td>A-5016-2011&nbsp;</td><td>0000-0001-5448-9903&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Hao</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5279-3645&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chang, Sheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4875-5501&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Engineering, Electrical &amp; Electronic; Telecommunications</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Telecommunications</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>7J9UN</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2327-4662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE INTERNET THINGS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Internet Things J.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>18</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>81971702&nbsp;</div>
<div>62074116&nbsp;</div>
<div>61874079&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the National Natural Science Foundation of China under Grant 81971702, Grant 62074116, and Grant 61874079.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 41 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Detection of Myocardial Infarction From 12-Lead ECG Trace Images Using Eigendomain Deep Representation Learning</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Bhaskarpandit, S (Bhaskarpandit, Sathvik); Gade, A (Gade, Anurag); Dash, S (Dash, Shaswati); Dash, DK (Dash, Dinesh Kumar); Tripathy, RK (Tripathy, Rajesh Kumar); Pachori, RB (Pachori, Ram Bilas)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>72</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>4001812</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2023.3241986</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>12</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
45</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>42</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Myocardial infarction (MI) is a life-debilitating emergency in which there is a lack of blood flow in the heart muscle, resulting in permanent damage to the myocardium and sudden cardiac death. The 12-lead electrocardiogram (ECG) is a standardized diagnostic test conducted in hospitals to detect and localize MI-based heart disease. To diagnose MI, the cardiologist visualizes the alternations in the patterns of the 12-lead-based ECG trace image. The automated detection of MI from the 12-lead-based ECG trace image using artificial intelligence (AI)-based approaches is important in the clinical study for the accurate diagnosis of MI disease. This article proposes a novel eigendomain-based deep representation learning (DRL) approach to automatically detect MI using 12-lead ECG trace images. The singular value decomposition (SVD) and eigendomain grouping are used to evaluate five modes or components from the 12-lead ECG trace image. The EfficientNetV2B2-based transfer learning model extracts feature maps from the 12-lead ECG trace image and all five modes. The global average pooling (GAP), batch normalization (BN), dropout, and soft-max layers are used for each feature map to obtain the probability scores. The concatenated probability scores of all the feature maps, followed by the dense layer and output layer, are used to detect MI. A public database containing the 12-lead ECG trace images is used to evaluate the performance of the proposed approach. The results show that for the MI class, the proposed approach has achieved the accuracy value of 100%. Similarly, for normal versus MI versus other cardiac-arrhythmia-based disease classification schemes, the proposed approach has obtained the overall accuracy, F1-score, specificity, and sensitivity values of 99.03%, 99.01%, 99.49%, and 98.96%, respectively using fivefold cross-validation (CV). The suggested approach has demonstrated higher overall accuracy than 24 existing transfer-learning-based models to detect MI using the 12-lead ECG trace images.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000935352600012</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiography; Lead; Diseases; Recording; Feature extraction; Representation learning; Transfer learning; 12-Lead electrocardiogram (ECG) trace image; deep learning (DL); eigendomain analysis; myocardial infarction (MI); performance evaluation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ELECTROCARDIOGRAMS; CLASSIFICATION; LOCALIZATION; NETWORK; SIGNALS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Bhaskarpandit, Sathvik; Gade, Anurag; Dash, Shaswati; Tripathy, Rajesh Kumar] BITS Pilani, Dept EEE, Hyderabad Campus, Hyderabad 500078, India. <br>
[Dash, Dinesh Kumar] Parala Maharaja Engn Coll, Dept Elect &amp; Telecommun Engn, Berhampur 761003, India. <br>
[Pachori, Ram Bilas] Indian Inst Technol Indore, Dept Elect Engn, Indore 453552, India. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Tripathy, RK (corresponding author), BITS Pilani, Dept EEE, Hyderabad Campus, Hyderabad 500078, India.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
dinesh.etc@pmec.ac.in; rajeshiitg13@gmail.com; pachori@iiti.ac.in</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Birla Institute of Technology &amp; Science Pilani (BITS Pilani); Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Indore</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>dash, dinesh</display_name>&nbsp;</td><td>AAQ-8692-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>DASH, SHASWATI</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-8395-1749&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tripathy, Rajesh</display_name>&nbsp;</td><td>U-4578-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Pachori, Ram Bilas</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6061-4309&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>DASH, SHASWATI</display_name>&nbsp;</td><td>AFJ-6757-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gade, Anurag</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3266-9086&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Pachori, Ram</display_name>&nbsp;</td><td>AAO-5839-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tripathy, RK</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2517-3103&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>9C3WU</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 42 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>SequenceMorph: A Unified Unsupervised Learning Framework for Motion Tracking on Cardiac Image Sequences</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Ye, M (Ye, Meng); Yang, D (Yang, Dong); Huang, QY (Huang, Qiaoying); Kanski, M (Kanski, Mikael); Axel, L (Axel, Leon); Metaxas, DN (Metaxas, Dimitris N.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>45</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>8</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>10409-10426</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TPAMI.2023.3243040</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 AUG</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>12</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>12</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
39</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>76</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Modern medical imaging techniques, such as ultrasound (US) and cardiac magnetic resonance (MR) imaging, have enabled the evaluation of myocardial deformation directly from an image sequence. While many traditional cardiac motion tracking methods have been developed for the automated estimation of the myocardial wall deformation, they are not widely used in clinical diagnosis, due to their lack of accuracy and efficiency. In this paper, we propose a novel deep learning-based fully unsupervised method, SequenceMorph, for in vivo motion tracking in cardiac image sequences. In our method, we introduce the concept of motion decomposition and recomposition. We first estimate the inter-frame (INF) motion field between any two consecutive frames, by a bi-directional generative diffeomorphic registration neural network. Using this result, we then estimate the Lagrangian motion field between the reference frame and any other frame, through a differentiable composition layer. Our framework can be extended to incorporate another registration network, to further reduce the accumulated errors introduced in the INF motion tracking step, and to refine the Lagrangian motion estimation. By utilizing temporal information to perform reasonable estimations of spatio-temporal motion fields, this novel method provides a useful solution for image sequence motion tracking. Our method has been applied to US (echocardiographic) and cardiac MR (untagged and tagged cine) image sequences; the results show that SequenceMorph is significantly superior to conventional motion tracking methods, in terms of the cardiac motion tracking accuracy and inference efficiency.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001022958600074</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37022840</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac; diffeomorphic; motion tracking; unsupervised</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
OPTICAL-FLOW; REGISTRATION; DISPLACEMENT; ROBUST; MODEL</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Ye, Meng; Metaxas, Dimitris N.] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA. <br>
[Yang, Dong] NVIDIA Corp, Bethesda, MD 95051 USA. <br>
[Huang, Qiaoying] Meta, Seattle, WA 98109 USA. <br>
[Kanski, Mikael; Axel, Leon] New York Univ, Grossman Sch Med, New York, NY 10016 USA. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Metaxas, DN (corresponding author), Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
my389@cs.rutgers.edu; don.yang.mech@gmail.com; charwinghuang@gmail.com; mikael.kanski@nyulangone.org; leon.axel@nyulangone.org; dnm@cs.rutgers.edu</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Rutgers University System; Rutgers University New Brunswick; Nvidia Corporation; New York University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Huang, Qiaoying</display_name>&nbsp;</td><td>AAU-7744-2021&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE COMPUTER SOC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>L4KG5</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0162-8828</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1939-3539</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T PATTERN ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Pattern Anal. Mach. Intell.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>18</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 43 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Graph-Enhanced Low-Resource ECG Representation Learning for Emotion Recognition Based on Wearable Internet of Things</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Chen, J (Chen, Jian); Hu, YZ (Hu, Yuzhu); Garg, L (Garg, Lalit); Gadekallu, TR (Gadekallu, Thippa Reddy); Srivastava, G (Srivastava, Gautam); Wang, W (Wang, Wei)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE INTERNET OF THINGS JOURNAL</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>11</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>24</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>39056-39068</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JIOT.2024.3430297</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 DEC 15</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>6</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>6</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
12</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>58</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Internet of Things (IoT) devices like wearable devices have enabled quick monitoring of electrocardiogram (ECG) signals with lower resources than multielectrode ECG devices, opening up development opportunities for sustainable ECG-based emotion recognition. However, existing methods that rely on predesigned features extracted from single-lead ECG signals cannot automatically extract effective features from the original ECG signal collected by IoT devices. To address this limitation, we propose a novel approach leveraging signal transformation and graph representation learning for ECG-based emotion recognition. The signal graph learning process can be divided into local subgraph learning for ECG representation learning and signal enhancement graph to derive the graph-enhanced representation. We employ a designed loss function by calculating cosine similarity to extract an effective representation of the original signal from the transformed signal in the local subgraph learning. Additionally, we utilize a graph convolution model based on the signal enhancement graph to obtain a graph-enhanced representation of the ECG signal. The method incorporates six signal transformations and constructs a self-signal transformation graph. For emotion recognition, we design a classification network comprising convolutional neural networks (CNNs) and long short-term memory (LSTM) networks. Experiments on public data sets show the superiority of our method among other baselines. Ablation studies are conducted to verify the performance.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001375815300020</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiography; Emotion recognition; Feature extraction; Long short term memory; Representation learning; Internet of Things; Wearable devices; Affective computing; AIoT; electrocardiogram (ECG) signal; emotion recognition; wearable devices</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
STRESS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Chen, Jian; Hu, Yuzhu] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen 518000, Peoples R China. <br>
[Chen, Jian; Hu, Yuzhu; Wang, Wei] Shenzhen MSU BIT Univ, Artificial Intelligence Res Inst, Guangdong Hong Kong Macao Joint Lab Emot Intellige, Shenzhen 518172, Peoples R China. <br>
[Garg, Lalit] Univ Malta, Fac Informat &amp; Commun Technol, MSD-2080 Msida, Malta. <br>
[Gadekallu, Thippa Reddy] Lovely Profess Univ, Div Res &amp; Dev, Phagwara 144411, India. <br>
[Gadekallu, Thippa Reddy] Chitkara Univ, Ctr Res Impact &amp; Outcome, Rajpura 140401, India. <br>
[Srivastava, Gautam] Brandon Univ, Dept Math &amp; Comp Sci, Brandon, BC R7A 6A9, Canada. <br>
[Srivastava, Gautam] China Med Univ, Res Ctr Interneural Comp, Taichung 40402, Taiwan. <br>
[Srivastava, Gautam] Lebanese Amer Univ, Dept Comp Sci &amp; Math, Beirut 1102, Lebanon. <br>
[Srivastava, Gautam] Chitkara Univ, Inst Engn &amp; Technol, Ctr Res Impact &amp; Outcome, Rajpura 140401, India. <br>
[Wang, Wei] Beijing Inst Technol, Sch Med Technol, Beijing 100081, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Wang, W (corresponding author), Shenzhen MSU BIT Univ, Artificial Intelligence Res Inst, Guangdong Hong Kong Macao Joint Lab Emot Intellige, Shenzhen 518172, Peoples R China.<br>Srivastava, G (corresponding author), Brandon Univ, Dept Math &amp; Comp Sci, Brandon, BC R7A 6A9, Canada.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
chenj589@mail2.sysu.edu.cn; huyzh27@mail2.sysu.edu.cn; Lalit.garg@um.edu.mt; thippareddy@ieee.org; srivastavag@brandonu.ca; ehomewang@ieee.org</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Sun Yat Sen University; Shenzhen MSU-BIT University; University of Malta; Lovely Professional University; Chitkara University, Punjab; Brandon University; China Medical University Taiwan; Lebanese American University; Chitkara University, Punjab; Beijing Institute of Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Jian</display_name>&nbsp;</td><td>JYP-8467-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hu, Yuzhu</display_name>&nbsp;</td><td>KAN-9077-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Garg, Lalit</display_name>&nbsp;</td><td>M-2560-2013&nbsp;</td><td>0000-0002-3868-0481&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Srivastava, Gautam</display_name>&nbsp;</td><td>N-5668-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Wei</display_name>&nbsp;</td><td>GYU-4649-2022&nbsp;</td><td>0000-0002-1717-5785&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wei, Wang</display_name>&nbsp;</td><td>GYU-4649-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Srivastava, Gautam</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9851-4103&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Garg, Lalit</display_name>&nbsp;</td><td>AAE-6453-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>hu, yu zhu</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0448-739X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gadekallu, Thippa Reddy</display_name>&nbsp;</td><td>T-4254-2019&nbsp;</td><td>0000-0003-0097-801X&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Engineering, Electrical &amp; Electronic; Telecommunications</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Telecommunications</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>P1T3F</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2327-4662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE INTERNET THINGS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Internet Things J.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shenzhen Scienceand Technology Innovation Commission</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Technology Planning Project of Guangdong Province</grant_agency>&nbsp;</td><td>
<div>2023B1212060029&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the Shenzhen Scienceand Technology Innovation Commission and the Science and Technology Planning Project of Guangdong Province under Grant 2023B1212060029.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 44 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Learning Joint and Specific Patterns: A Unified Sparse Representation for Off-the-Person ECG Biometric Recognition</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Huang, YW (Huang, Yuwen); Yang, GP (Yang, Gongping); Wang, KK (Wang, Kuikui); Liu, HY (Liu, Haiying); Yin, YL (Yin, Yilong)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>16</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>147-160</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIFS.2020.3006384</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>29</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>32</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
86</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>52</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Devices such as smartphones and tablets have spurred interest in off-the-person electrocardiogram (ECG) biometric recognition. While the advantage of using multi-feature information for establishing identities has been widely recognized, computational sparse representation models for multi-feature biometric recognition have only recently received more attention. We propose a unified sparse representation framework which collaboratively exploits joint and specific patterns for ECG biometric recognition. In particular, unlike joint sparse representation, which only considers the consistency among sparsity patterns of multiple features, we combine the consistent and pairwise constraints, which not only learn latent discriminant representations for all features but capture the interactions between them. In addition, our framework is universal and easily adapts to other multi-feature sparse representation models by just tuning the regularization parameters. The optimization problem is solved by an efficient alternating direction method of multipliers (ADMM). Extensive experiments on two publicly available off-the-person datasets demonstrate that our method can achieve competitive or even superior performance compared to state-of-the-art ECG biometric recognition methods.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000554454600011</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Off-the-person ECG biometric recognition; joint and specific pattern; unified sparse representation; pairwise constraints</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
FACE RECOGNITION; LOW-RANK; EXTRACTION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Huang, Yuwen; Yang, Gongping; Wang, Kuikui; Yin, Yilong] Shandong Univ, Sch Software, Jinan 250100, Peoples R China. <br>
[Huang, Yuwen; Yang, Gongping] Heze Univ, Sch Comp, Heze 274015, Peoples R China. <br>
[Liu, Haiying] Changji Univ, Dept Comp Engn, Changji 831100, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Yang, GP (corresponding author), Shandong Univ, Sch Software, Jinan 250100, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
ywhuang@mail.sdu.edu.cn; gpyang@sdu.edu.cn; sarahkuikui@163.com; 1466432554@qq.com; ylyin@sdu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Shandong University; Heze University; Changji University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Yang, Gongping</display_name>&nbsp;</td><td>B-9923-2012&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Yang, Gongping</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7637-2749&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Theory &amp; Methods; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>MS7KP</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1556-6013</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1556-6021</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INF FOREN SEC</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Inf. Forensic Secur.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>14</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China (NSFC)-Xinjiang Joint Fund</grant_agency>&nbsp;</td><td>
<div>U1903127&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key Research and Development Project of Shandong Province</grant_agency>&nbsp;</td><td>
<div>2018GGX101032&nbsp;</div>
<div>2019GGX101056&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China (NSFC)-Xinjiang Joint Fund under Grant U1903127 and in part by the Key Research and Development Project of Shandong Province under Grant 2018GGX101032 and Grant 2019GGX101056.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 45 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Learning-Based Regularization for Cardiac Strain Analysis via Domain Adaptation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Lu, AE (Lu, Allen); Ahn, SS (Ahn, Shawn S.); Ta, K (Ta, Kevinminh); Parajuli, N (Parajuli, Nripesh); Stendahl, JC (Stendahl, John C.); Liu, Z (Liu, Zhao); Boutagy, NE (Boutagy, Nabil E.); Jeng, GS (Jeng, Geng-Shi); Staib, LH (Staib, Lawrence H.); O'Donnell, M (O'Donnell, Matthew); Sinusas, AJ (Sinusas, Albert J.); Duncan, JS (Duncan, James S.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>9</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2233-2245</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3074033</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 SEP</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>14</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>15</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
15</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>48</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Reliable motion estimation and strain analysis using 3D+ time echocardiography (4DE) for localization and characterization of myocardial injury is valuable for early detection and targeted interventions. However, motion estimation is difficult due to the low-SNR that stems from the inherent image properties of 4DE, and intelligent regularization is critical for producing reliable motion estimates. In this work, we incorporated the notion of domain adaptation into a supervised neural network regularization framework. We first propose a semi-supervised Multi-Layered Perceptron (MLP) network with biomechanical constraints for learning a latent representation that is shown to have more physiologically plausible displacements. We extended this framework to include a supervised loss term on synthetic data and showed the effects of biomechanical constraints on the network's ability for domain adaptation. We validated the semi-supervised regularization method on in vivo data with implanted sonomicrometers. Finally, we showed the ability of our semi-supervised learning regularization approach to identify infarct regions using estimated regional strain maps with good agreement to manually traced infarct regions from postmortem excised hearts.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000692208500005</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33872145</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Strain; Adaptation models; Myocardium; Finite element analysis; Feature extraction; Estimation; Data models; Cardiac function; echocardiography; motion analysis; machine learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SPECKLE TRACKING; NONRIGID REGISTRATION; DEFORMATION; IMAGES; MOTION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Lu, Allen; Ahn, Shawn S.; Ta, Kevinminh; Staib, Lawrence H.; Duncan, James S.] Yale Univ, Dept Biomed Engn, New Haven, CT 06511 USA. <br>
[Parajuli, Nripesh] Capt Hlth, San Francisco, CA 94132 USA. <br>
[Stendahl, John C.; Boutagy, Nabil E.; Sinusas, Albert J.] Yale Univ, Sect Cardiovasc Med, Dept Internal Med, New Haven, CT 06511 USA. <br>
[Liu, Zhao; Staib, Lawrence H.; Sinusas, Albert J.; Duncan, James S.] Yale Univ, Dept Radiol &amp; Biomed Imaging, New Haven, CT 06511 USA. <br>
[Jeng, Geng-Shi] Natl Yang Ming Chiao Tung Univ, Inst Elect, Hsinchu 30010, Taiwan. <br>
[Staib, Lawrence H.; Duncan, James S.] Yale Univ, Dept Elect Engn, New Haven, CT 06511 USA. <br>
[O'Donnell, Matthew] Univ Washington, Dept Bioengn, Seattle, WA 98015 USA. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Ahn, SS (corresponding author), Yale Univ, Dept Biomed Engn, New Haven, CT 06511 USA.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
haiyinglu.allen@gmail.com; shawn.ahn@yale.edu; kevinminh.ta@yale.edu; nripesh.parajuli.21@gmail.com; john.stendahl@yale.edu; zhao.liu@yale.edu; nabil.boutagy@yale.edu; jeng@nctu.edu.tw; lawrence.staib@yale.edu; odonnel@uw.edu; albert.sinusas@yale.edu; james.duncan@yale.edu</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Yale University; Yale University; Yale University; National Yang Ming Chiao Tung University; Yale University; University of Washington; University of Washington Seattle</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ahn, Shawn</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5961-3376&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Staib, Lawrence</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9516-5136&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Sinusas, Albert</display_name>&nbsp;</td><td>A-7235-2009&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>, Geng-Shi</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4105-573X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Stendahl, John</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1568-9280&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>UK8IN</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Institute of Health</grant_agency>&nbsp;</td><td>
<div>R01HL121226&nbsp;</div>
<div>T32HL098069&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Institute of Health Medical Scientist Training Program</grant_agency>&nbsp;</td><td>
<div>T32GM007205&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Heart Lung and Blood Institute</grant_agency>&nbsp;</td><td>
<div>R01HL121226&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Institute of General Medical Sciences</grant_agency>&nbsp;</td><td>
<div>T32GM136651&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Institute of Health under Grant R01HL121226 and Grant T32HL098069 and in part by the National Institute of Health Medical Scientist Training Program under Grant T32GM007205.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>hybrid, Green Accepted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 46 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Fitbeat: COVID-19 estimation based on wristband heart rate using a contrastive convolutional auto-encoder</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, S (Liu, Shuo); Han, J (Han, Jing); Puyal, EL (Puyal, Estela Laporta); Kontaxis, S (Kontaxis, Spyridon); Sun, SX (Sun, Shaoxiong); Locatelli, P (Locatelli, Patrick); Dineley, J (Dineley, Judith); Pokorny, FB (Pokorny, Florian B.); Dalla Costa, G (Dalla Costa, Gloria); Leocani, L (Leocani, Letizia); Guerrero, AI (Guerrero, Ana Isabel); Nos, C (Nos, Carlos); Zabalza, A (Zabalza, Ana); Sorensen, PS (Sorensen, Per Soelberg); Buron, M (Buron, Mathias); Magyari, M (Magyari, Melinda); Ranjan, Y (Ranjan, Yatharth); Rashid, Z (Rashid, Zulqarnain); Conde, P (Conde, Pauline); Stewart, C (Stewart, Callum); Folarin, AA (Folarin, Amos A.); Dobson, RJB (Dobson, Richard J. B.); Bail&oacute;n, R (Bailon, Raquel); Vairavan, S (Vairavan, Srinivasan); Cummins, N (Cummins, Nicholas); Narayan, VA (Narayan, Vaibhav A.); Hotopf, M (Hotopf, Matthew); Comi, G (Comi, Giancarlo); Schuller, B (Schuller, Bjoern)</td>
</tr>

<tr>
<td>
<b>Group Author(s):</b>
RADAR-CNS Consortium</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>PATTERN RECOGNITION</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>123</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>108403</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.patcog.2021.108403</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>NOV 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2022 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>23</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>25</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
19</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>30</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This study proposes a contrastive convolutional auto-encoder (contrastive CAE), a combined architecture of an auto-encoder and contrastive loss, to identify individuals with suspected COVID-19 infection using heart-rate data from participants with multiple sclerosis (MS) in the ongoing RADAR-CNS mHealth research project. Heart-rate data was remotely collected using a Fitbit wristband. COVID-19 infection was either confirmed through a positive swab test, or inferred through a self-reported set of recognised symptoms of the virus. The contrastive CAE outperforms a conventional convolutional neural network (CNN), a long short-term memory (LSTM) model, and a convolutional auto-encoder without contrastive loss (CAE). On a test set of 19 participants with MS with reported symptoms of COVID-19, each one paired with a participant with MS with no COVID-19 symptoms, the contrastive CAE achieves an unweighted average recall of 95 . 3% , a sensitivity of 100% and a specificity of 90 . 6% , an area under the receiver operating characteristic curve (AUC-ROC) of 0.944, indicating a maximum successful detection of symptoms in the given heart rate measurement period, whilst at the same time keeping a low false alarm rate. (c) 2021 Elsevier Ltd. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000717961100004</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34720200</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
COVID-19; Respiratory tract infection; Anomaly detection; Contrastive learning; Convolutional auto-encoder</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Shuo; Han, Jing; Dineley, Judith; Pokorny, Florian B.; Cummins, Nicholas; Schuller, Bjoern] Univ Augsburg, EIHW Chair Embedded Intelligence Hlth Care &amp; Well, Augsburg, Germany. <br>
[Han, Jing] Univ Cambridge, Dept Comp Sci &amp; Technol, Cambridge, England. <br>
[Puyal, Estela Laporta; Kontaxis, Spyridon; Bailon, Raquel] Univ Zaragoza, Aragon Inst Engn Res I3A, IIS Aragon, BSICoS Grp, Zaragoza, Spain. <br>
[Puyal, Estela Laporta; Kontaxis, Spyridon; Bailon, Raquel] Biomat &amp; Nanomed CIBER BNN, CIBER Bioengn, Madrid, Spain. <br>
[Sun, Shaoxiong; Ranjan, Yatharth; Rashid, Zulqarnain; Conde, Pauline; Stewart, Callum; Folarin, Amos A.; Dobson, Richard J. B.; Cummins, Nicholas] Kings Coll London, Inst Psychiat Psychol &amp; Neurosci, Dept Biostat &amp; Hlth Informat, London, England. <br>
[Locatelli, Patrick] Univ Bergamo, Dept Engn &amp; Appl Sci, Bergamo, Italy. <br>
[Pokorny, Florian B.] Med Univ Graz, Div Phoniatr, Graz, Austria. <br>
[Dalla Costa, Gloria; Leocani, Letizia] Sci Inst Hosp San Raffaele, Univ Vita Salute San Raffaele &amp; Expt Neurophysiol, Inst Expt Neurol, Milan, Italy. <br>
[Guerrero, Ana Isabel; Nos, Carlos; Zabalza, Ana] Univ Autonoma Barcelona, Hosp Univ Vall dHebron, Multiple Sclerosis Ctr Catalonia Cemcat, Dept Neurol Neuroimmunol, Barcelona, Spain. <br>
[Sorensen, Per Soelberg; Buron, Mathias; Magyari, Melinda] Copenhagen Univ Hosp Rigshosp, Danish Multiple Sclerosis Ctr, Dept Neurol, Copenhagen, Denmark. <br>
[Folarin, Amos A.; Dobson, Richard J. B.] UCL, Inst Hlth Informat, London, England. <br>
[Vairavan, Srinivasan; Narayan, Vaibhav A.] Janssen Res &amp; Dev LLC, Titusville, NJ USA. <br>
[Hotopf, Matthew] Kings Coll London, Inst Psychiat Psychol &amp; Neurosci, Dept Psychol Med, London, England. <br>
[Hotopf, Matthew] South London &amp; Maudsley Natl Hlth Serv Fdn Trust, London, England. <br>
[Comi, Giancarlo] Univ Vita Salute San Raffaele, Casa Cura Privata Policlin, Milan, Italy. <br>
[Schuller, Bjoern] Imperial Coll London, GLAM Grp Language Audio &amp; Mus, London, England. <br>
[RADAR-CNS Consortium] RADAR CNS Consortium, London, England. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liu, S (corresponding author), Univ Augsburg, EIHW Chair Embedded Intelligence Hlth Care &amp; Well, Augsburg, Germany.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
shuo.liu@informatik.uni-augsburg.de</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Augsburg; University of Cambridge; University of Zaragoza; CIBER - Centro de Investigacion Biomedica en Red; CIBERBBN; University of London; King's College London; University of Bergamo; Medical University of Graz; Vita-Salute San Raffaele University; IRCCS Ospedale San Raffaele; Autonomous University of Barcelona; Hospital Universitari Vall d'Hebron; University of Copenhagen; Copenhagen University Hospital; Rigshospitalet; University of London; University College London; Johnson &amp; Johnson; Johnson &amp; Johnson USA; Janssen Biotech Inc; University of London; King's College London; South London &amp; Maudsley NHS Trust; Vita-Salute San Raffaele University; Imperial College London</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Stewart, Callum</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9947-8677&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Dineley, Judith</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5541-6853&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Vairavan, Srinivasan</display_name>&nbsp;</td><td>OHU-2732-2025&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zabalza, Ana</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3860-5251&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Leocani, Letizia</display_name>&nbsp;</td><td>ABH-4703-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Comi, Giancarlo</display_name>&nbsp;</td><td>AAN-1941-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bail&oacute;n, Raquel</display_name>&nbsp;</td><td>L-7781-2014&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Dobson, Richard</display_name>&nbsp;</td><td>C-9269-2011&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Schuller, Bjorn</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6478-8699&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zabalza, Ana</display_name>&nbsp;</td><td>AAX-5767-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Folarin, Amos</display_name>&nbsp;</td><td>IWE-0229-2023&nbsp;</td><td>0000-0002-0333-1927&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Pokorny, Florian</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9203-2904&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Sun, Shaoxiong</display_name>&nbsp;</td><td>GOK-0990-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Magyari, Melinda</display_name>&nbsp;</td><td>AAV-9058-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Costa, Gloria</display_name>&nbsp;</td><td>F-6440-2017&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bailon, Raquel</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1272-0550&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cummins, Nicholas</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1178-917X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Schuller, Bj&ouml;rn</display_name>&nbsp;</td><td>D-3241-2011&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>dobson, richard</display_name>&nbsp;</td><td>C-9269-2011&nbsp;</td><td>0000-0003-4224-9245&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Buron, Mathias</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1260-1156&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Magyari, Melinda</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0972-5222&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>, Ana Isabel</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5891-2123&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Han, Jing</display_name>&nbsp;</td><td>AAB-3944-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cummins, Nicholas</display_name>&nbsp;</td><td>AAC-6431-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Leocani, Letizia</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9326-6753&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hotopf, Matthew</display_name>&nbsp;</td><td>E-4971-2010&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER SCI LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>125 London Wall, London, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>WW5MS</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0031-3203</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-5142</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>PATTERN RECOGN</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Pattern Recognit.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Innovative Medicines Initiative6 2 Joint Undertaking</grant_agency>&nbsp;</td><td>
<div>115902&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>European Union's Horizon 2020 research and innovation programme</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EFPIA</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Medical Research Council</grant_agency>&nbsp;</td><td>
<div>HDR-9002&nbsp;</div>
<div>HDR-9003&nbsp;</div>
<div>HDR-9004&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Institute for Health Research</grant_agency>&nbsp;</td><td>
<div>NF-SI-0515-10102&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This project has received funding from the Innovative Medicines Initiative6 2 Joint Undertaking under grant agreement No 115902. This Joint Undertaking receives support from the European Union's Horizon 2020 research and innovation programme and EFPIA. This communication reflects the views of the RADAR-CNS consortium and neither IMI nor the European Union and EFPIA are liable for any use that may be made of the information contained herein.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 47 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Time-synchrosqueezing generalized W transform for high-resolution time-frequency representation and application in dual-domain ECG classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Li, R (Li, Rui); Chen, H (Chen, Hui); Chen, XP (Chen, Xuping); Liu, YQ (Liu, Yunqi); Xu, JF (Xu, Jinfeng); Lu, Y (Lu, Yao)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>280</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>127459</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2025.127459</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>APR 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JUN 25</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
18</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
18</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>48</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Time-frequency (TF) analysis has received considerable attention in electrocardiogram (ECG) classification, due to its superiority revealing subtle features between various frequencies and time of non-stationary signals. Most existing ECG classification methods employ traditional signal classification or feature extraction with traditional TF analysis methods for classification. However, current TF analysis methods either have low resolution for weak frequency modulation ECG signals, or cannot accurately characterize multi-component low-frequency features relevant to clinical ECG classification. Therefore, to overcome the above limitations, this paper proposed a new TF feature-based deep learning classification method. First, we proposed a timesynchrosqueezing generalized W transform to characterize clinically-relevant low-frequency features of ECG signals with high resolution in both time and frequency domains. Then, based on the generated multi-scale, sparse TF features, we selected a suitable image-based neural network and proposed a new ECG classification framework, which transforms the traditional ECG signal classification into a dual-domain (TF domain) image classification for arrhythmia, normal sinus rhythm, and congestive heart failure, thereby improving ECG classification performance. Furthermore, a three-class classification experiment on public ECG datasets of arrhythmia, normal sinus rhythm, and congestive heart failure illustrated the superior performance of the proposed framework over different state-of-the-art ECG classification methods, achieving an area under the curve (AUC) of 0.996, with accuracy, sensitivity, specificity, and F1 score of 0.987, 0.963, 0.984, and 0.972, respectively.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001470608000001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram (ECG); Generalized W transform; Time-synchrosqueezing; Dual-domain classification</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Li, Rui; Lu, Yao] Sun Yat Sen Univ, Sch Comp Sci &amp; Engn, Guangzhou 510275, Peoples R China. <br>
[Chen, Hui; Chen, Xuping] Chengdu Univ Technol, Sch Math Sci, Chengdu 610059, Peoples R China. <br>
[Liu, Yunqi] Guangzhou Med Univ, Affiliated Hosp 1, Dept Cardiac Surg, Guangzhou 510060, Peoples R China. <br>
[Xu, Jinfeng] City Univ Hong Kong, Dept Biostat, Hong Kong 999077, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Lu, Y (corresponding author), Sun Yat Sen Univ, Sch Comp Sci &amp; Engn, Guangzhou 510275, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
lirui256@mail2.sysu.edu.cn; huichencdut@cdut.edu.cn; xupingchen@stu.cdut.edu.cn; lyunq@mail.sysu.edu.cn; jinfenxu@cityu.edu.hk; luyao23@mail.sysu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Sun Yat Sen University; Chengdu University of Technology; Guangzhou Medical University; City University of Hong Kong</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Xuping</display_name>&nbsp;</td><td>T-5322-2017&nbsp;</td><td>0000-0003-0787-378X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>XU, Jinfeng</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0006-9397-2125&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>1PO1K</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>14</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>China Department of Science and Technology</grant_agency>&nbsp;</td><td>
<div>2023YFE0204300&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>R &amp;D project of Pazhou Lab (HuangPu) , China</grant_agency>&nbsp;</td><td>
<div>2023K0606&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NSFC, China</grant_agency>&nbsp;</td><td>
<div>82441027&nbsp;</div>
<div>62371476&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guangzhou Science and Technology bureau, China</grant_agency>&nbsp;</td><td>
<div>2023B03J1237&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Health Research Major Projects of Hunan Health Commission, China</grant_agency>&nbsp;</td><td>
<div>W20241010&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guangdong Province Key Laboratory of Computational Science at the Sun Yat-sen University, China</grant_agency>&nbsp;</td><td>
<div>2020B1212060032&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the China Department of Science and Technology under Key Grant 2023YFE0204300, in part by the R &amp;D project of Pazhou Lab (HuangPu) , China under Grant 2023K0606, in part by the NSFC, China under Grant 82441027, Grant 62371476, in part by the Guangzhou Science and Technology bureau, China under Grant 2023B03J1237, in part by the Health Research Major Projects of Hunan Health Commission, China under grant W20241010, in part by the Guangdong Province Key Laboratory of Computational Science at the Sun Yat-sen University, China under grant 2020B1212060032.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 48 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Morphology-Aware ECG Diagnostic Framework With Cross-Task Attention Transfer for Improved Myocardial Infarction Diagnosis</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Choudhary, PS (Choudhary, Pharvesh Salman); Dandapat, S (Dandapat, Samarendra)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>73</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>4007811</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2024.3403205</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>2</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>2</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
15</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>57</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
In recent years, deep learning has been widely used in automated interpretation of electrocardiogram (ECG) signals, and several high-performing models have been developed. However, a majority of the existing deep learning models adopt a data-driven approach agnostic of any clinical priors. In this work, we present a novel morphology-aware diagnostic model for the detection of myocardial infarction (MI) from ECG signals. Clinically, MI is associated with specific morphological alterations in the ECG waveform. Integration of such clinical context into the learning process can aid in diagnosis. To facilitate this, we first design an attention-based ECG delineation network, focusing on learning morphology-specific attention. Then, we introduce a cross-task attention transfer (CTAT) framework to transfer the morphology-specific information of the delineation task to the MI detection network, thereby incorporating morphological context into the MI detection task. We evaluate our method on three public 12-lead ECG datasets. Experimental evaluation shows that our proposed framework achieves promising performance for MI detection from 12-lead ECG signals. Results also demonstrate superior performance compared with other state-of-the-art methods. Moreover, analysis of the post hoc interpretation in the form of Grad-CAM attributions verifies the model's performance and provides clinically meaningful inferences to its predictions.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001248198900021</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Attention transfer; cross-task attention; electrocardiogram (ECG); myocardial infarction (MI)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
4TH UNIVERSAL DEFINITION; DATABASE; CLASSIFICATION; ALGORITHMS; NETWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Choudhary, Pharvesh Salman; Dandapat, Samarendra] Indian Inst Technol Guwahati, Dept Elect &amp; Elect Engn, Gauhati 781039, Assam, India. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Choudhary, PS (corresponding author), Indian Inst Technol Guwahati, Dept Elect &amp; Elect Engn, Gauhati 781039, Assam, India.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
pharvesh@iitg.ac.in</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Guwahati</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Choudhary, Pharvesh Salman</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-7929-0017&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>UL4K1</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 49 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Non-Rigid Respiratory Motion Estimation of Whole-Heart Coronary MR Images Using Unsupervised Deep Learning</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Qi, HK (Qi, Haikun); Fuin, N (Fuin, Niccolo); Cruz, G (Cruz, Gastao); Pan, JZ (Pan, Jiazhen); Kuestner, T (Kuestner, Thomas); Bustin, A (Bustin, Aurelien); Botnar, RM (Botnar, Rene M.); Prieto, C (Prieto, Claudia)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>1</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>444-454</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2020.3029205</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 JAN</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>36</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>38</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
31</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>52</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Non-rigid motion-corrected reconstruction has been proposed to account for the complex motion of the heart in free-breathing 3D coronary magnetic resonance angiography (CMRA). This reconstruction framework requires efficient and accurate estimation of non-rigid motion fields from undersampled images at different respiratory positions (or bins). However, state-of-the-art registration methods can be time-consuming. This article presents a novel unsupervised deep learning-based strategy for fast estimation of inter-bin 3D non-rigid respiratory motion fields for motion-corrected free-breathing CMRA. The proposed 3D respiratory motion estimation network (RespME-net) is trained as a deep encoder-decoder network, taking pairs of 3D image patches extracted from CMRA volumes as input and outputting the motion field between image patches. Using image warping by the estimated motion field, a loss function that imposes image similarity and motion smoothness is adopted to enable training without ground truth motion field. RespME-net is trained patch-wise to circumvent the challenges of training a 3D network volume-wise which requires large amounts of GPU memory and 3D datasets. We perform 5-fold cross-validation with 45 CMRA datasets and demonstrate that RespME-net can predict 3D non-rigid motion fields with subpixel accuracy (0.44 +/- 0.38 mm) within similar to 10 seconds, being similar to 20 times faster than a GPU-implemented state-of-the-art non-rigid registration method. Moreover, we perform non-rigid motion-compensated CMRA reconstruction for 9 additional patients. The proposed RespME-net has achieved similar motion-corrected CMRA image quality to the conventional registration method regarding coronary artery length and sharpness.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000604883800038</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33021937</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Three-dimensional displays; Motion estimation; Image reconstruction; Two dimensional displays; Biomedical imaging; Image registration; Optimization; Motion estimation; deep learning; motion-compensated reconstruction; coronary magnetic resonance angiography</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
MAGNETIC-RESONANCE; OPTICAL-FLOW; QUANTITATIVE-ANALYSIS; REGISTRATION; DEFORMATION; ANGIOGRAPHY; ALIGNMENT; MODELS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Qi, Haikun; Fuin, Niccolo; Cruz, Gastao; Pan, Jiazhen; Kuestner, Thomas; Bustin, Aurelien; Botnar, Rene M.; Prieto, Claudia] Kings Coll London, Sch Biomed Engn &amp; Imaging Sci, London SE1 7EH, England. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Qi, HK (corresponding author), Kings Coll London, Sch Biomed Engn &amp; Imaging Sci, London SE1 7EH, England.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
haikun.qi@kcl.ac.uk; niccolo.fuin@kcl.ac.uk; gastao.cruz@kcl.ac.uk; jiazhen.pan@gmx.de; thomas.kuestner@kcl.ac.uk; aurelien.bustin@kcl.ac.uk; rene.botnar@kcl.ac.uk; claudia.prieto@kcl.ac.uk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of London; King's College London</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Qi, Haikun</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4709-5185&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bustin, Aurelien</display_name>&nbsp;</td><td>AAC-9237-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Kuestner, Thomas</display_name>&nbsp;</td><td>ABE-7866-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Botnar, Rene</display_name>&nbsp;</td><td>AAZ-2112-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cruz, Gastao</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-7397-9104&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Prieto, Claudia</display_name>&nbsp;</td><td>F-8308-2013&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Botnar, Rene</display_name>&nbsp;</td><td>E-6875-2012&nbsp;</td><td>0000-0003-2811-2509&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cruz, Gastao</display_name>&nbsp;</td><td>KSM-1438-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>PO0TG</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Engineering and Physical Sciences Research Council (EPSRC)</grant_agency>&nbsp;</td><td>
<div>EP/P032311/1&nbsp;</div>
<div>EP/P001009/1&nbsp;</div>
<div>EP/P007619/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>British Heart Foundation (BHF)</grant_agency>&nbsp;</td><td>
<div>PG/18/59/33955&nbsp;</div>
<div>RG/20/1/34802&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>King's BHF Centre of Research Excellence</grant_agency>&nbsp;</td><td>
<div>RE/18/2/34213&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Wellcome EPSRC Centre for Medical Engineering</grant_agency>&nbsp;</td><td>
<div>NS/A000049/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Department of Health via the National Institute for Health Research (NIHR) Cardiovascular Health Technology Cooperative (HTC) and Comprehensive Biomedical Research Centre</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>King's College London</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>King's College Hospital NHS Foundation Trust</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Engineering and Physical Sciences Research Council</grant_agency>&nbsp;</td><td>
<div>EP/P001009/1&nbsp;</div>
<div>EP/P007619/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EPSRC</grant_agency>&nbsp;</td><td>
<div>EP/P032311/1&nbsp;</div>
<div>EP/P001009/1&nbsp;</div>
<div>EP/P007619/1&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>Thiswork was supported in part by the Engineering and Physical Sciences Research Council (EPSRC) under Grant EP/P032311/1, Grant EP/P001009/1, and Grant EP/P007619/1; in part by the British Heart Foundation (BHF) under Grant PG/18/59/33955 and Grant RG/20/1/34802; in part by the King's BHF Centre of Research Excellence under Grant RE/18/2/34213; in part by theWellcome EPSRC Centre for Medical Engineering under Grant NS/A000049/1; and in part by the Department of Health via the National Institute for Health Research (NIHR) Cardiovascular Health Technology Cooperative (HTC) and Comprehensive Biomedical Research Centre awarded to the Guy's and St Thomas' NHS Foundation Trust in partnership with the King's College London and the King's College Hospital NHS Foundation Trust.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 50 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Robust Optical Flow Estimation in Cardiac Ultrasound Images Using a Sparse Representation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Ouzir, N (Ouzir, Nora); Basarab, A (Basarab, Adrian); Lairez, O (Lairez, Olivier); Tourneret, JY (Tourneret, Jean-Yves)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>38</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>3</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>741-752</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2018.2870947</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2019 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>25</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>26</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
24</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>45</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This paper introduces a robust 2-D cardiac motion estimation method. The problem is formulated as an energy minimization with an optical flow-based data fidelity term and two regularization terms imposing spatial smoothness and the sparsity of the motion field in an appropriate cardiac motion dictionary. Robustness to outliers, such as imaging artefacts and anatomical motion boundaries, is introduced using robust weighting functions for the data fidelity term as well as for the spatial and sparse regularizations. The motion fields and the weights are computed jointly using an iteratively re-weighted minimization strategy. The proposed robust approach is evaluated on synthetic data and realistic simulation sequences with available ground-truth by comparing the performance with state-of-the-art algorithms. Finally, the proposed method is validated using two sequences of in vivo images. The obtained results show the interest of the proposed approach for 2-D cardiac ultrasound imaging.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000460662400009</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>30235121</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac ultrasound; robust motion estimation; optical flow; sparse regularization; dictionary learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
MOTION ESTIMATION; B-MODE; TISSUE DOPPLER; NONRIGID REGISTRATION; STRAIN ESTIMATION; ECHOCARDIOGRAPHY; OPTIMIZATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Ouzir, Nora; Tourneret, Jean-Yves] Univ Toulouse, Signal &amp; Image Dept, IRIT INP ENSEEIHT Tesa, F-31071 Toulouse, France. <br>
[Basarab, Adrian] Univ Toulouse, CNRS, Signal &amp; Image Dept, IRIT,UMR 5505, F-31062 Toulouse, France. <br>
[Lairez, Olivier] Univ Paul Sabatier, CHU Toulouse, INSERM, UMR 1048,Inst Malad Metab &amp; Cardiovasc, Toulouse, France. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Ouzir, N (corresponding author), Univ Toulouse, Signal &amp; Image Dept, IRIT INP ENSEEIHT Tesa, F-31071 Toulouse, France.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
nora.ouzir@enseeiht.fr; adrian.basarab@irit.fr; jean-yves.tourneret@enseeiht.fr</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Universite Federale Toulouse Midi-Pyrenees (ComUE); Universite de Toulouse; Institut National Polytechnique de Toulouse; Universite Toulouse III - Paul Sabatier; Universite de Toulouse; Universite Federale Toulouse Midi-Pyrenees (ComUE); Universite Toulouse III - Paul Sabatier; Institut National Polytechnique de Toulouse; Universite Toulouse 1 Capitole; Universite de Toulouse - Jean Jaures; Centre National de la Recherche Scientifique (CNRS); CNRS - Institute for Information Sciences &amp; Technologies (INS2I); Universite de Toulouse; Universite Toulouse III - Paul Sabatier; CHU de Toulouse; Institut National de la Sante et de la Recherche Medicale (Inserm)</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Basarab, Adrian</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5642-7244&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>O, Lairez</display_name>&nbsp;</td><td>B-7152-2016&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ouzir, Nora</display_name>&nbsp;</td><td>ACS-1544-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>HO1JV</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>thematic trimester on image processing of the CIMI Labex, Toulouse, France</grant_agency>&nbsp;</td><td>
<div>ANR-11-LABX-0040-CIMI&nbsp;</div>
<div>ANR-11-IDEX-0002-02&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the thematic trimester on image processing of the CIMI Labex, Toulouse, France, underGrant ANR-11-LABX-0040-CIMI within the Program ANR-11-IDEX-0002-02.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 51 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A Subject-Driven Unsupervised Hidden Semi-Markov Model and Gaussian Mixture Model for Heart Sound Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Oliveira, J (Oliveira, Jorge); Renna, F (Renna, Francesco); Coimbra, M (Coimbra, Miguel)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>13</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>2</value>&nbsp;&nbsp;<b>Special Issue:</b> 
<value>SI</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>323-331</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JSTSP.2019.2908723</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2019 MAY</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>8</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
21</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>30</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
The analysis of heart sounds is a challenging task, due to the quick temporal onset between successive events and the fact that an important fraction of the information carried by phonocardiogram (PCG) signals lies in the inaudible part of the human spectrum. For these reasons, computer-aided analysis of the PCG can dramatically improve the quantity of information recovered from such signals. In this paper, a hidden semi-Markov model (HSMM) is used to automatically segment PCG signals. In the proposed models, the emission probability distributions are approximated via Gaussian mixture model (GMM) priors. The choice of GMM emission probability distributions allow to apply re-estimation routines to automatically adjust the HSMM emission probability distributions to each subject. Building on the proposed method for fine tuning emission distributions, a novel subject-driven unsupervised heart sound segmentation algorithm is proposed and validated over the publicly available PhysioNet dataset. Perhaps surprisingly, the proposed unsupervised method achieved results in line with state-of-the-art supervised approaches, when applied to long heart sounds.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000468435500012</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Signal processing; Markov models; Gaussian mixture models; phonocardiogram; emission modeling and optimization</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CLASSIFICATION; 1ST</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Oliveira, Jorge; Renna, Francesco; Coimbra, Miguel] Univ Porto, Inst Telecomunicacoes, Fac Ciencias, P-4169007 Porto, Portugal. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Oliveira, J (corresponding author), Univ Porto, Inst Telecomunicacoes, Fac Ciencias, P-4169007 Porto, Portugal.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
oliveira_jorge@dcc.fc.up.pt; frarennna@dcc.fc.up.pt; mcoimbra@dcc.fc.up.pt</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Instituto de Telecomunicacoes; Universidade do Porto</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>, Jorge</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3190-8367&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Renna, Francesco</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-8243-8350&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Renna, Francesco</display_name>&nbsp;</td><td>AAE-4116-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Coimbra, Miguel</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7501-6523&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Oliveira, Jorge</display_name>&nbsp;</td><td>HSH-4076-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>HY9BZ</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1932-4553</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1941-0484</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J-STSP</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Sel. Top. Signal Process.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>9</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Norte Portugal Regional Operational Programme (NORTE 2020), under the PORTUGAL 2020 Partnership Agreement, through the European Regional Development Fund (ERDF) - Project NanoSTIMA</grant_agency>&nbsp;</td><td>
<div>NORTE-01-0145-FEDER-000016&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>FCT</grant_agency>&nbsp;</td><td>
<div>SFRH/BPD/118714/2016&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>internal project SmartHeart</grant_agency>&nbsp;</td><td>
<div>UID/EEA/50008/2013&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Funda&ccedil;&atilde;o para a Ci&ecirc;ncia e a Tecnologia</grant_agency>&nbsp;</td><td>
<div>SFRH/BPD/118714/2016&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by Norte Portugal Regional Operational Programme (NORTE 2020), under the PORTUGAL 2020 Partnership Agreement, through the European Regional Development Fund (ERDF), funded by the Project NanoSTIMA (NORTE-01-0145-FEDER-000016); in part by internal project SmartHeart in scope of Project UID/EEA/50008/2013; and in part by the FCT Grant SFRH/BPD/118714/2016. The guest editor coordinating the review of this paper and approving it for publication was Dr. Bob Lee Sturm. (Corresponding author: Jorge Oliveira.)</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 52 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Personalized Transfer Learning for Single-Lead ECG-Based Sleep Apnea Detection: Exploring the Label Mapping Length and Transfer Strategy Using Hybrid Transformer Model</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Hu, SC (Hu, Shuaicong); Wang, YN (Wang, Ya'nan); Liu, J (Liu, Jian); Yang, CW (Yang, Cuiwei)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>72</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>2526515</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2023.3312698</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>17</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>18</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
25</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>49</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Objective: Automatic sleep apnea (SA) detection based on deep learning (DL) and single-lead electrocardiogram (ECG) has been extensively studied. We aim to explore the impact of different DL model structures and label mapping length (LML) on personalized transfer learning (TL), providing personalized TL applicability conditions based on the proposed hybrid transformer model (HTM). Methods: Two DL models, a pure convolutional neural network (CNN)-based model (PCM) and a proposed HTM, are included in the study. Eight different LMLs are considered. Furthermore, various personalized TL strategies are introduced to thoroughly explore the impact. Finally, two-sided t-tests are utilized to evaluate the significance. Results: In the same database, the average accuracy and AUC for the personalized PCM are 0.8412 and 0.9002, respectively, with p &lt; 0.001, while the hybrid transformer-based personalized model achieves an average accuracy of 0.8537 and an average AUC of 0.9147 with p &lt; 0.001. Across databases, the accuracy and AUC of personalized HTM reach 0.8271 and 0.8724, respectively, and p &lt; 0.001. Conclusion: The increase in LML has a beneficial impact on the general model (GM) and personalized model for different model structures. The HTM exhibits better performance in both GM and personalized TL compared to the PCM. Additionally, personalized TL achieves significant improvement when utilizing only positive samples within the same database. However, it is more advantageous to utilize only negative samples when performing cross-database personalized TL. Significance: This article provides guidance for personalized TL in SA detection and provides an HTM-based personalized TL method.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001071771900003</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram (ECG); hybrid transformer; sleep apnea (SA); transfer learning (TL)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
EXTRACTION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Hu, Shuaicong; Wang, Ya'nan; Liu, Jian; Yang, Cuiwei] Fudan Univ, Ctr Biomed Engn, Sch Informat Sci &amp; Technol, Shanghai 200433, Peoples R China. <br>
[Yang, Cuiwei] Key Lab Med Imaging Comp &amp; Comp Assisted Intervent, Shanghai 200093, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Yang, CW (corresponding author), Fudan Univ, Ctr Biomed Engn, Sch Informat Sci &amp; Technol, Shanghai 200433, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
22110720104@m.fudan.edu.cn; wangyn20@fudan.edu.cn; liuj22@m.fudan.edu.cn; yangcw@fudan.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Fudan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hu, Shuaicong</display_name>&nbsp;</td><td>NIU-9967-2025&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Yang, Cuiwei</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3338-5835&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hu, shuaicong</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5458-0416&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Ya'nan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5599-3423&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Jian</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5791-7221&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>S5SV9</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shanghai Science and Technology Support Project</grant_agency>&nbsp;</td><td>
<div>18441900900&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Medical Scientific Research Key Project of Jiangsu Commission of Health</grant_agency>&nbsp;</td><td>
<div>ZDB2020025&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the Shanghai Science and Technology Support Project under Grant 18441900900 and in part by the Medical Scientific Research Key Project of Jiangsu Commission of Health under Grant ZDB2020025.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 53 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Bipolar Spiral Midfield Wireless Power Transfer for Cardiac Implants Application</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Le-Huu, H (Le-Huu, Hoang); Seo, C (Seo, Chulhun)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE ANTENNAS AND WIRELESS PROPAGATION LETTERS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>20</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>9</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>1631-1635</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/LAWP.2021.3092011</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 SEP</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>31</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>33</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
14</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>16</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This letter proposes a midfield wireless power transfer system using a bipolar spiral-shape transmitter (BPSP-Tx) for cardiac implants application. Optimal current distribution is built on BPSP-Tx surface following spiral structure to generate a focused field inside human tissue and adapt the implantable receiver (Rx) misalignments. Source performance has been verified by implantable hooked-shape Rx (HKSD-Rx) that separated at a distance of 45 mm from Tx. Measurements are conducted in minced pork for validation. Experimental results show that the transmission coefficient can achieve -20.48 dB at a distance of 45 mm and -22.15 at 60 mm. Furthermore, the Rx misalignment is verified by output power level, which shows that the proposed system can maintain high performance on a rotation range of Rx from - 90 degrees to 90 degrees. Finally, the human safety regulations are verified to present a low specific absorption rate, which demonstrates the potential for cardiac implants.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000692232300009</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Biomedical implants; bipolar spiral transmitter; hooked-shape dipole; midfield wireless power transfer (WPT)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SYSTEMS; DESIGN</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Le-Huu, Hoang; Seo, Chulhun] Soongsil Univ, Dept Informat &amp; Commun Convergence, Seoul 06978, South Korea. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Le-Huu, H (corresponding author), Soongsil Univ, Dept Informat &amp; Commun Convergence, Seoul 06978, South Korea.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
hoangle.set58@gmail.com; chulhun@ssu.ac.kr</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Soongsil University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Seo, Chulhun</display_name>&nbsp;</td><td>AAS-2675-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Le Huu, Hoang</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-2460-6491&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>LE-HUU, HOANG</display_name>&nbsp;</td><td>AAU-6618-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Seo, Chulhun</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6765-8734&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Telecommunications</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Telecommunications</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>UK8RF</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1536-1225</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1548-5757</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE ANTENN WIREL PR</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Antennas Wirel. Propag. Lett.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>5</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Science and ICT</grant_agency>&nbsp;</td><td>
<div>NRF-2017R1A5A1015596&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>Manuscript received June 7, 2021; accepted June 20, 2021. Date of publication June 24, 2021; date of current version September 3, 2021. This work was supported by theBasic Science Research Program through theNationalResearch Foundation of Korea (NRF) funded by the Ministry of Science and ICT under Grant NRF-2017R1A5A1015596.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 54 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>RhythmNet: End-to-End Heart Rate Estimation From Face via Spatial-Temporal Representation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Niu, XS (Niu, Xuesong); Shan, SG (Shan, Shiguang); Han, H (Han, Hu); Chen, XL (Chen, Xilin)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON IMAGE PROCESSING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>29</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2409-2423</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIP.2019.2947204</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 </value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>263</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>303</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
104</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>43</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Heart rate (HR) is an important physiological signal that reflects the physical and emotional status of a person. Traditional HR measurements usually rely on contact monitors, which may cause inconvenience and discomfort. Recently, some methods have been proposed for remote HR estimation from face videos; however, most of them focus on well-controlled scenarios, their generalization ability into less-constrained scenarios (e.g., with head movement, and bad illumination) are not known. At the same time, lacking large-scale HR databases has limited the use of deep models for remote HR estimation. In this paper, we propose an end-to-end RhythmNet for remote HR estimation from the face. In RyhthmNet, we use a spatial-temporal representation encoding the HR signals from multiple ROI volumes as its input. Then the spatial-temporal representations are fed into a convolutional network for HR estimation. We also take into account the relationship of adjacent HR measurements from a video sequence via Gated Recurrent Unit (GRU) and achieves efficient HR measurement. In addition, we build a large-scale multi-modal HR database (named as VIPL-HR (1) ), which contains 2,378 visible light videos (VIS) and 752 near-infrared (NIR) videos of 107 subjects. Our VIPL-HR database contains various variations such as head movements, illumination variations, and acquisition device changes, replicating a less-constrained scenario for HR estimation. The proposed approach outperforms the state-of-the-art methods on both the public-domain and our VIPL-HR databases. (1) VIPL-HR is available at: http://vipl.ict.ac.cn/view_database.php?id=15</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000507869900016</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>31647433</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Heart rate; Estimation; Webcams; Databases; Skin; Image color analysis; Head; Remote heart rate estimation; rPPG; spatial-temporal representation; end-to-end learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
REMOTE-PPG; NONCONTACT</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Niu, Xuesong; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China. <br>
[Niu, Xuesong; Shan, Shiguang; Chen, Xilin] Univ Chinese Acad Sci, Sch Comp Sci &amp; Technol, Beijing 100049, Peoples R China. <br>
[Shan, Shiguang; Han, Hu] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China. <br>
[Shan, Shiguang] CAS Ctr Excellence Brain Sci &amp; Intelligence Techn, Shanghai 200031, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Shan, SG (corresponding author), Univ Chinese Acad Sci, Sch Comp Sci &amp; Technol, Beijing 100049, Peoples R China.<br>Shan, SG (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
xuesong.niu@vipl.ict.ac.cn; sgshan@ict.ac.cn; hanhu@ict.ac.cn; xlchen@ict.ac.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; Center for Excellence in Brain Science and Intelligence Technology, CAS</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Shan, Shiguang</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-8348-392X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Xilin</display_name>&nbsp;</td><td>I-4153-2014&nbsp;</td><td>0000-0003-3024-4404&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Han, Hu</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6010-1792&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Xilin</display_name>&nbsp;</td><td>A-1409-2012&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Han, Hu</display_name>&nbsp;</td><td>KKE-6424-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Niu, Xuesong</display_name>&nbsp;</td><td>MEO-3849-2025&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>KD4XT</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1057-7149</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1941-0042</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T IMAGE PROCESS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Image Process.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key R&amp;D Program of China</grant_agency>&nbsp;</td><td>
<div>2017YFA0700800&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61672496&nbsp;</div>
<div>61702486&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>External Cooperation Program of Chinese Academy of Sciences (CAS)</grant_agency>&nbsp;</td><td>
<div>GJHZ1843&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Key R&amp;D Program of China under Grant 2017YFA0700800, in part by the Natural Science Foundation of China under Grant 61672496 and Grant 61702486, and in part by the External Cooperation Program of Chinese Academy of Sciences (CAS) under Grant GJHZ1843.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>ESI Highly Cited Paper:</b>

<value>Y</value>
</td>
</tr>

<tr>
<td>
<b>ESI Hot Paper:</b>

<value>N</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 55 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Heart Rate Estimation From Facial Videos Using a Spatiotemporal Representation With Convolutional Neural Networks</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Song, RC (Song, Rencheng); Zhang, SL (Zhang, Senle); Li, C (Li, Chang); Zhang, YF (Zhang, Yunfei); Cheng, J (Cheng, Juan); Chen, X (Chen, Xun)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>69</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>10</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>7411-7421</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIM.2020.2984168</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>89</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>94</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
92</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>30</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Remote photoplethysmography (rPPG) is a kind of noncontact technique to measure heart rate (HR) from facial videos. As the demand for long-term health monitoring grows, rPPG attracts much attention from researchers. However, the performance of conventional rPPG methods is easily degenerated due to noise interference. Recently, some deep learning-based rPPG methods have been introduced and they revealed good performance against noise. In this article, we propose a new rPPG method with convolutional neural networks (CNNs) to build a mapping between a spatiotemporal HR feature image to its corresponding HR value. The feature map is constructed in a time-delayed way with noise-contaminated pulse signals extracted from existing rPPG methods. The CNN model is trained using transfer learning where images built from synthetic rPPG signals are taken to train the model first in order to generate initials for the practical one. The synthetic rPPG signals are interpolated from blood volume pulses or electrocardiograms through a modified Akima cubic Hermite interpolation. The proposed method is tested in both within-database and cross-database configurations on public databases. The results demonstrate that our method achieves overall the best performance compared to some other typical rPPG methods. The mean absolute error reaches 5.98 beats per minute and the mean error rate percentage is 7.97% in the cross-database testing on MAHNOB-HCI data set. Besides, some key factors that affect the performance of our method are also discussed which indicates potential ways for further improvements.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000571849100009</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Heart rate; Feature extraction; Spatiotemporal phenomena; Convolutional neural networks; Image color analysis; Deep learning; Skin; Convolutional neural network; heart rate estimation; remote photoplethysmography; spatiotemporal representation; transfer learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NONCONTACT</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Song, Rencheng; Zhang, Senle; Li, Chang; Cheng, Juan] Hefei Univ Technol, Dept Biomed Engn, Hefei 230009, Peoples R China. <br>
[Zhang, Yunfei] Senturing Technol Ltd, Vancouver, BC V6T 1Z1, Canada. <br>
[Zhang, Yunfei] Shenzhen ViWiStar Technol Ltd, Shenzhen 518133, Peoples R China. <br>
[Chen, Xun] Univ Sci &amp; Technol China, Dept Elect Engn &amp; Informat Sci, Hefei 230026, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Cheng, J (corresponding author), Hefei Univ Technol, Dept Biomed Engn, Hefei 230009, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
rcsong@hfut.edu.cn; zhangsenle@mail.hfut.edu.cn; changli@hfut.edu.cn; yunfeizhang0616@gmail.com; chengjuan@hfut.edu.cn; xunchen@ustc.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Hefei University of Technology; Chinese Academy of Sciences; University of Science &amp; Technology of China, CAS</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Song, Rencheng</display_name>&nbsp;</td><td>JRW-5597-2023&nbsp;</td><td>0000-0001-7760-7562&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Xun</display_name>&nbsp;</td><td>AFG-0453-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cheng, Juan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1206-1698&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>NR8YL</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0018-9456</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9662</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T INSTRUM MEAS</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Instrum. Meas.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61922075&nbsp;</div>
<div>81571760&nbsp;</div>
<div>41901350&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Fundamental Research Funds for the Central Universities</grant_agency>&nbsp;</td><td>
<div>JZ2019HGTA0049&nbsp;</div>
<div>JZ2019HGBZ0151&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under Grant 61922075, Grant 81571760, and Grant 41901350 and in part by the Fundamental Research Funds for the Central Universities under Grant JZ2019HGTA0049 and Grant JZ2019HGBZ0151.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 56 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Heart failure disease stratification with temporal electronic health records: Patient representation and sub identification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liang, Y (Liang, Ye); Guo, CH (Guo, Chonghui); Li, HL (Li, Hailin)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>158</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>111429</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.engappai.2025.111429</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>OCT 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 OCT 22</value>&nbsp;&nbsp;<b>Part:</b> 
<value>B</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
6</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
6</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>76</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Heart failure disease stratification provides health status information for distinct patient subgroups, facilitating timely interventions. However, traditional techniques struggle with the complexity and longitudinality of electronic health records and require a predetermined number of groups, limiting their applicability. To address these challenges, we introduce a novel patient representation model using a temporal dual bidirectional neural network with an attention mechanism to effectively model electronic health records. We also propose a density peak-based clustering method that identifies distinct clinical heart failure sub-phenotypes with minimal manual intervention. Our deep learning model effectively processes electronic health records to generate patient representations. Our clustering method uses an adaptive cut-off distance to reduce manual input and employs affinity propagation's responsibility matrix to determine each patient's local density, automatically identifying sub-phenotype centroids. Evaluation using a real-world clinical dataset and various indicators shows our methods outperform existing approaches. Importantly, they can identify clinically meaningful heart failure sub-phenotypes, with statistical test results holding practical value for clinical decision-making.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001523163000003</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Heart failure; Electronic health records; Patient representation; Disease stratification; Density peak clustering</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
PREDICTION; PNEUMONIA</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liang, Ye; Guo, Chonghui] Dalian Univ Technol, Inst Syst Engn, Dalian, Peoples R China. <br>
[Li, Hailin] Huaqiao Univ, Coll Business Adm, Quanzhou, Peoples R China. <br>
[Li, Hailin] Huaqiao Univ, Res Ctr Appl Stat &amp; Big Data, Xiamen, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Guo, CH (corresponding author), Dalian Univ Technol, Inst Syst Engn, Dalian, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
liangye210@163.com; dlutguo@dlut.edu.cn; liangye210@163.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Dalian University of Technology; Huaqiao University; Huaqiao University</td>
</tr>

<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Automation &amp; Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Automation &amp; Control Systems; Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>4OW9C</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0952-1976</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6769</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>ENG APPL ARTIF INTEL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Eng. Appl. Artif. Intell.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>19</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>71771034&nbsp;</div>
<div>72371049&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Liaoning Province Applied Basic Research Program Project</grant_agency>&nbsp;</td><td>
<div>2023JH2/101300208&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Dalian High Level Talents Innovation Support Plan</grant_agency>&nbsp;</td><td>
<div>2021RD01&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This research is supported by the National Natural Science Foundation of China (Grant No. 71771034 and Grant No. 72371049) , the Liaoning Province Applied Basic Research Program Project (Grant No. 2023JH2/101300208) , and the Dalian High Level Talents Innovation Support Plan (Grant No. 2021RD01) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 57 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>An Effective Sandwiched Wireless Power Transfer System for Charging Implantable Cardiac Pacemaker</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, CH (Liu, Chunhua); Jiang, CQ (Jiang, Chaoqiang); Song, J (Song, Jingjing); Chau, KT (Chau, K. T.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>66</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>5</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>4108-4117</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TIE.2018.2840522</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2019 MAY</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>129</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>135</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
107</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>34</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This paper presents a new effective sandwiched wireless power transfer (WPT) system, which is adopted to recharge the battery of a micro medical robotics for a cardiac pacemaker. The key of the design is to use the distinct sandwiched topology in both the transmitter and receiver coils, whose operating frequency of 160 kHz is significantly lower than the reported WPT system up to megahertz. Furthermore, the implantable receiver adopts the bilateral coil design, which can harness more power within a limited size. Meanwhile, with the sandwiched transmitting coils, the proposed design achieves the high feasibility and flexibility of the controllable distance for different kinds of micro medical robotics in patients. As a result, the proposed system can provide the power as high as 5 W and the transmission efficiency up to 88%. Finally, the corresponding theoretical analysis, simulation, and experimentation are carried out to prove the validity of the proposed sandwiched medical WPT system for the implantable device in the patient body.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000455188700079</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac pacemaker; micro medical robotics; wireless charging; wireless power transfer (WPT)</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Chunhua; Song, Jingjing] City Univ Hong Kong, Sch Energy &amp; Environm, Hong Kong, Peoples R China. <br>
[Jiang, Chaoqiang; Chau, K. T.] Univ Hong Kong, Dept Elect &amp; Elect Engn, Hong Kong, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liu, CH (corresponding author), City Univ Hong Kong, Sch Energy &amp; Environm, Hong Kong, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
chualiu@eee.hku.hk; cqjiang@eee.hku.hk; songjingjingnb@yeah.net; ktchau@eee.hku.hk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
City University of Hong Kong; University of Hong Kong</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Jiang, C. Q.</display_name>&nbsp;</td><td>V-2772-2019&nbsp;</td><td>0000-0001-5374-364X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Chunhua</display_name>&nbsp;</td><td>K-2234-2013&nbsp;</td><td>0000-0002-3105-5448&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Jiang, Chaoqiang</display_name>&nbsp;</td><td>V-2772-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chau, Kwok</display_name>&nbsp;</td><td>C-1583-2009&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chau, Kwok Tong</display_name>&nbsp;</td><td>C-1583-2009&nbsp;</td><td>0000-0003-1620-9688&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Automation &amp; Control Systems; Engineering, Electrical &amp; Electronic; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Automation &amp; Control Systems; Engineering; Instruments &amp; Instrumentation</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>HG7QO</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0046</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1557-9948</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T IND ELECTRON</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Ind. Electron.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>ITF Tier3 of Innovation and Technology Commission of HKSAR, China</grant_agency>&nbsp;</td><td>
<div>ITS/353/16&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Energy and Conservation Fund of Hong Kong Special Administrative Region, China (ECF Project)</grant_agency>&nbsp;</td><td>
<div>92/2016&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by a grant from ITF Tier3 of Innovation and Technology Commission of HKSAR, China (Project ITS/353/16), and in part by a grant from Energy and Conservation Fund of Hong Kong Special Administrative Region, China (ECF Project 92/2016).</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 58 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A cascaded framework with cross-modality transfer learning for whole heart segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Ding, Y (Ding, Yi); Mu, D (Mu, Dan); Zhang, JQ (Zhang, Jiaqi); Qin, Z (Qin, Zhen); You, L (You, Li); Qin, ZG (Qin, Zhiguang); Guo, YK (Guo, Yingkun)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>PATTERN RECOGNITION</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>147</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>110088</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.patcog.2023.110088</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>NOV 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>16</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
8</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
35</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>39</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Automatic and accurate segmentation of the whole heart structure from 3D cardiac images plays an important role in helping physicians diagnose and treat cardiovascular disease. However, the time-consuming and laborious manual labeling of the heart images results in the inefficiency of utilizing the existing CT or MRI for training the deep learning network, which decrease the accuracy of whole heart segmentation. However, multi-modality data contains multi-level information of cardiac images due to different imaging mechanisms, which is beneficial to improve the segmentation accuracy. Therefore, this paper proposes a cascaded framework with cross-modality transfer learning for whole heart segmentation (CM-TranCaF), which consists of three key modules: modality transfer network (MTN), U-shaped multi-attention network (MAUNet) and spatial configuration network (SCN). In MTN, MRI images are transferred from MRI domain to CT domain, to increase the data volume by adopting the idea of adversarial training. The MAUNet is designed based on UNet, while the attention gates (AGs) are integrated into the skip connection to reduce the weight of background pixels. Moreover, to solve the problem of boundary blur, the position attention block (PAB) is also integrated into the bottom layer to aggregate similar features. Finally, the SCN is used to finetune the segmentation results by utilizing the anatomical information between different cardiac substructures. By evaluating the proposed method on the dataset of the MM-WHS challenge, CM-TranCaF achieves a Dice score of 91.1% on the testing dataset. The extensive experimental results prove the effectiveness of the proposed method compared to other state-of-the-art methods.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001111542700001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Whole heart segmentation; Modality transfer; Generative adversarial training; Unify data distribution; Attention mechanism</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Ding, Yi; Mu, Dan; Zhang, Jiaqi; Qin, Zhen; Qin, Zhiguang] Univ Elect Sci &amp; Technol China, Network &amp; Data Secur Key Lab Sichuan Prov, Sch Informat &amp; Software Engn, Chengdu 610054, Peoples R China. <br>
[You, Li] Erasmus MC, Dept Mol Genet, Rotterdam, Netherlands. <br>
[Guo, Yingkun] Sichuan Univ, West China Univ Hosp 2, Dept Radiol,Minist Educ, Key Lab Obstet &amp; Gynecol &amp; Pediat Dis &amp; Birth Defe, Chengdu 610041, Peoples R China. <br>
[Ding, Yi; Qin, Zhen] YIBIN GREAT Technol Co Ltd, Yibin 644000, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Qin, Z (corresponding author), Univ Elect Sci &amp; Technol China, Network &amp; Data Secur Key Lab Sichuan Prov, Sch Informat &amp; Software Engn, Chengdu 610054, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
yi.ding@uestc.edu.cn; heymudan@163.com; 916822436@qq.com; zhenqin@uestc.edu.cn; l.you@erasmusmc.nl; qinzg@uestc.edu.cn; gykpanda@163.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Electronic Science &amp; Technology of China; Erasmus University Rotterdam; Erasmus MC; Sichuan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>zhang, jiaqi</display_name>&nbsp;</td><td>JNR-7443-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Qin, Zhiguang</display_name>&nbsp;</td><td>MSX-2237-2025&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ding, Yi</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3406-9770&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER SCI LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>125 London Wall, London, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>Z4BJ0</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0031-3203</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-5142</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>PATTERN RECOGN</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Pattern Recognit.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62076054&nbsp;</div>
<div>62072074&nbsp;</div>
<div>62027827&nbsp;</div>
<div>62002047&nbsp;</div>
<div>62372083&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Sichuan Science and Technology Innovation Platform and Talent Plan</grant_agency>&nbsp;</td><td>
<div>2022JDJQ0039&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Sichuan Science and Technology Support Plan</grant_agency>&nbsp;</td><td>
<div>2022YFQ0045&nbsp;</div>
<div>2022YFS0220&nbsp;</div>
<div>2021YFG0131&nbsp;</div>
<div>2023YFS0020&nbsp;</div>
<div>2023YFS 0197&nbsp;</div>
<div>2023YFG0148&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Medico-Engineering Cooperation Funds from University of Electronic Science and Technology of China</grant_agency>&nbsp;</td><td>
<div>ZYGX2021YGLH212&nbsp;</div>
<div>ZYGX2022YGRH012&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>YIBIN Science and Technology Support Plan</grant_agency>&nbsp;</td><td>
<div>2021CG003&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>CCF-Baidu Open Fund</grant_agency>&nbsp;</td><td>
<div>202312&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China (No. 62076054, No. 62072074, No. 62027827, No. 62002047, No. 62372083) , the Sichuan Science and Technology Innovation Platform and Talent Plan (No. 2022JDJQ0039) , the Sichuan Science and Technology Support Plan (No. 2022YFQ0045, No. 2022YFS0220, No. 2021YFG0131, No. 2023YFS0020, No. 2023YFS 0197, No. 2023YFG0148) , the Medico-Engineering Cooperation Funds from University of Electronic Science and Technology of China (No. ZYGX2021YGLH212, No. ZYGX2022YGRH012) , the YIBIN Science and Technology Support Plan (No. 2021CG003) , the CCF-Baidu Open Fund (No. 202312) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 59 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A High-Performance Wireless Power Transfer System for Cardiac Pacemaker Based on Multi-MNG</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Chen, WH (Chen, Weihua); Wang, C (Wang, Chao); Yan, XH (Yan, Xiaoheng); Zhu, FY (Zhu, Feiyu)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF EMERGING AND SELECTED TOPICS IN POWER ELECTRONICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>13</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>3</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>3976-3987</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JESTPE.2025.3562660</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JUN</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
6</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
6</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>33</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
In response to the issues of low transmission efficiency, poor offset tolerance, and severe magnetic leakage in wireless energy transmission systems for cardiac pacemakers, this article presents a novel wireless power transfer system for cardiac pacemakers based on multimagnetic negative materials (Multi-MNG). Based on the theory of equivalent medium for magnetic negative materials (MNGs) and the distribution of magnetic fields, three different metamaterial units with varying magnetic permeabilities are designed and arranged in a mixed manner to ensure effective convergence of the system's magnetic field, shield magnetic field leakage, and reduce specific absorption rate (SAR). The accuracy, high efficiency, robustness, and safety of the Multi-MNG system's transmission are validated through simulations at 8.94 MHz, and it mitigates the impact of magnetic leakage on the human body without a significant decrease in transmission performance. The maximum SAR value of the system is 0.0000504. The transmission performance of the Multi-MNG system is compared with that of ferrite, an unshielded MNG array 1 system, and a traditional system. The experiment unequivocally verifies the high performance of the Multi-MNG system, with a demonstrated maximum system output power of 1.323 W and a transmission efficiency peaking at 72.1%, The temperature rise is $2.9 degrees C, which meets human safety standards.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001521565000003</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Magnetic materials; Metamaterials; Magnetic fields; Magnetic resonance; Magnetic shielding; Magnetic noise; Coils; Pacemakers; Wireless power transfer; Magnetic losses; Cardiac pacemaker; Multi-MNG; transmission performance; wireless power transfer (WPT)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
LOW ELECTROMAGNETIC-FIELD; METAMATERIAL SLAB; EFFICIENCY; DESIGN</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Chen, Weihua; Wang, Chao; Yan, Xiaoheng; Zhu, Feiyu] Liaoning Tech Univ, Fac Elect &amp; Control Engn, Huludao 125130, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Yan, XH (corresponding author), Liaoning Tech Univ, Fac Elect &amp; Control Engn, Huludao 125130, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
fxlgd@163.com; 472220435@stu.lntu.edu.cn; xiaohengyan@163.com; zfylgd@163.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Liaoning Technical University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Weihua</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-7481-1610&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Engineering, Electrical &amp; Electronic</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Engineering</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>4MN6L</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-6777</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-6785</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J EM SEL TOP P</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Emerg. Sel. Top. Power Electron.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>The 2023 Liaoning Provincial Department of Education Basic Research Project</grant_agency>&nbsp;</td><td>
<div>JYTMS20230815&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the 2023 Liaoning Provincial Department of Education Basic Research Project (General Project) under Grant JYTMS20230815.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 60 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>CF Distance: A New Domain Discrepancy Metric and Application to Explicit Domain Adaptation for Cross-Modality Cardiac Image Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wu, FP (Wu, Fuping); Zhuang, XH (Zhuang, Xiahai)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>39</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>12</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>4274-4285</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2020.3016144</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 DEC</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>64</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>69</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
44</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>42</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Domain adaptation has great values in unpaired cross-modality image segmentation, where the training images with gold standard segmentation are not available from the target image domain. The aim is to reduce the distribution discrepancy between the source and target domains. Hence, an effective measurement for this discrepancy is critical. In this work, we propose a new metric based on characteristic functions of distributions. This metric, referred to as CF distance, enables explicit domain adaptation, in contrast to the implicit manners minimizing domain discrepancy via adversarial training. Based on this CF distance, we propose an unsupervised domain adaptation framework for cross-modality cardiac segmentation, which consists of image reconstruction and prior distribution matching. We validated the method on two tasks, i.e., the CT-MR cross-modality segmentation and the multi-sequence cardiac MR segmentation. Results showed that the proposed explicit metric was effective in domain adaptation, and the segmentation method delivered promising and superior performance, compared to other state-of-the-art techniques. The data and source code of this work has been released via https://zmiclab.github.io/projects.html.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000595547500045</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>32784131</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Measurement; Training; Image segmentation; Neural networks; Task analysis; Image reconstruction; Optimization; Cardiacsegmentation; omain adaptation; domain discrepancy; characteristic function</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NETWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wu, Fuping] Fudan Univ, Dept Stat, Sch Management, Shanghai 200433, Peoples R China. <br>
[Wu, Fuping; Zhuang, Xiahai] Fudan Univ, Sch Data Sci, Shanghai 200433, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhuang, XH (corresponding author), Fudan Univ, Sch Data Sci, Shanghai 200433, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
17110690006@fudan.edu.cn; zxh@fudan.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Fudan University; Fudan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhuang, Xiahai</display_name>&nbsp;</td><td>AAH-6334-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wu, Fuping</display_name>&nbsp;</td><td>ABG-4545-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wu, Fuping</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7179-4766&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>PA3OL</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61971142&nbsp;</div>
<div>11871165&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the National Natural Science Foundation of China under Grant 61971142 and Grant 11871165.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 61 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>DiT-SFDA: A source-free domain adaptation method for intelligent diagnosis of cardiovascular diseases with limited heart sound samples</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wang, SY (Wang, Suiyan); Liu, Y (Liu, Yang); Liu, ZX (Liu, Zhixiang); Yuan, XM (Yuan, Xiaoming); Ji, Y (Ji, Yun); Liang, PF (Liang, Pengfei)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>EXPERT SYSTEMS WITH APPLICATIONS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>285</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>128118</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.eswa.2025.128118</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>MAY 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 AUG 1</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
16</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
16</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>44</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
In recent years, the application of deep learning in intelligent diagnosis (ID) of cardiovascular diseases (CVDs) has significantly improved diagnostic efficiency and accuracy. However, in practice, owing to data privacy constraints, high labeling cost and specialized medical knowledge, collecting adequate labeled samples continues to present substantial technical difficulties, which makes ID of CVDs under limited samples a challenging issue. In this paper, a novel source-free domain adaptation (SFDA) approach for ID of CVDs, named DiT-SFDA, is proposed by integrating an improved diffusion model based on transformer (DiT) and a semi-supervised domain adaptation network (SDAN). Specifically, the method first converts heart sound (HS) signals into Mel spectrograms that can represent their time-frequency characteristics. Then, more realistic labeled samples are generated through DiT using limited real labeled data, effectively solving training data insufficiency. Subsequently, the generated labeled samples serve as the source domain, while the real samples serve as the limited labeled data in the target domain, and the SDAN based on minimax entropy is employed to further improve the performance of the model. Finally, experimental validation demonstrates that the DiT-SFDA method achieves significantly better diagnostic performance than other methods on two datasets. This innovative approach not only effectively addresses the critical challenge of data scarcity, but also provides an efficient and robust solution for the early screening and precise diagnosis of CVDs.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001492281000001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Diffusion model; Domain adaptation; Cardiovascular disease; Intelligent diagnosis</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wang, Suiyan; Liu, Yang; Liu, Zhixiang; Yuan, Xiaoming; Ji, Yun; Liang, Pengfei] Yanshan Univ, Sch Mech Engn, Qinhuangdao 066004, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liang, PF (corresponding author), Yanshan Univ, Sch Mech Engn, Qinhuangdao 066004, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
wangsy@stumail.ysu.edu.cn; lyang0216@stumail.ysu.edu.cn; zhixiang@stumail.ysu.edu.cn; yuanxiaoming@ysu.edu.cn; jiyun@ysu.edu.cn; liangpf@ysu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Yanshan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liang, Pengfei</display_name>&nbsp;</td><td>KEJ-1689-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liang, Pengfei</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1938-895X&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Engineering, Electrical &amp; Electronic; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Operations Research &amp; Management Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>2VL9J</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0957-4174</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1873-6793</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>EXPERT SYST APPL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Expert Syst. Appl.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>52405076&nbsp;</div>
<div>52375134&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The work was supported by the National Natural Science Foundation of China No.52405076 and 52375134.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 62 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Dual-Teacher plus plus : Exploiting Intra-Domain and Inter-Domain Knowledge With Reliable Transfer for Cardiac Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Li, K (Li, Kang); Wang, SJ (Wang, Shujun); Yu, LQ (Yu, Lequan); Heng, PA (Heng, Pheng Ann)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>10</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2771-2782</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2020.3038828</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>24</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>27</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
37</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>61</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Annotation scarcity is a long-standing problem in medical image analysis area. To efficiently leverage limited annotations, abundant unlabeled data are additionally exploited in semi-supervised learning, while well-established cross-modality data are investigated in domain adaptation. In this paper, we aim to explore the feasibility of concurrently leveraging both unlabeled data and cross-modality data for annotation-efficient cardiac segmentation. To this end, we propose a cutting-edge semi-supervised domain adaptation framework, namely Dual-Teacher++. Besides directly learning from limited labeled target domain data (e.g., CT) via a student model adopted by previous literature, we design novel dual teacher models, including an inter-domain teacher model to explore cross-modality priors from source domain (e.g., MR) and an intra-domain teacher model to investigate the knowledge beneath unlabeled target domain. In this way, the dual teacher models would transfer acquired inter- and intra-domain knowledge to the student model for further integration and exploitation. Moreover, to encourag reliable dual-domain knowledge transfer, we enhance the inter-domain knowledge transfer on the samples with higher similarity to target domain after appearance alignment, and also strengthen intra-domain knowledge transfer of unlabeled target data with higher prediction confidence. In this way, the student model can obtain reliable dual-domain knowledge and yield improved performance on target domain data. We extensively evaluated the feasibility of our method on the MM-WHS 2017 challenge dataset. The experiments have demonstrated the superiority of our framework over other semi-supervised learning and domain adaptation methods. Moreover, our performance gains could be yielded in bidirections, i.e., adapting from MR to CT, and from CT to MR. Our code will be available at https://github.com/kli-lalala/Dual-Teacher-.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000702638800020</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33201808</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Adaptation models; Data models; Reliability; Predictive models; Computed tomography; Annotations; Semisupervised learning; Semi-supervised domain adaptation; cross-modality; cardiac segmentation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ADAPTATION; IMAGE</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Li, Kang; Wang, Shujun; Heng, Pheng Ann] Chinese Univ Hong Kong, Dept Comp Sci Engn, Hong Kong, Peoples R China. <br>
[Yu, Lequan] Stanford Univ, Dept Radiat Oncol, Palo Alto, CA 94306 USA. <br>
[Heng, Pheng Ann] Chinese Acad Sci, Shenzhen Inst Adv Technol, Guangdong Prov Key Lab Comp Vis &amp; Virtual Real, Shenzhen 518055, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Yu, LQ (corresponding author), Stanford Univ, Dept Radiat Oncol, Palo Alto, CA 94306 USA.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
kli@cse.cuhk.edu.hk; sjwang@cse.cuhk.edu.hk; lequany@stanford.edu; pheng@cse.cuhk.edu.hk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Chinese University of Hong Kong; Stanford University; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Yu, Lequan</display_name>&nbsp;</td><td>U-5377-2019&nbsp;</td><td>0000-0002-9315-6527&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>WANG, Shujun</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1495-3278&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Li, Kang</display_name>&nbsp;</td><td>LMN-3556-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Shujun</display_name>&nbsp;</td><td>AAD-7001-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>LI, Kang</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0149-6912&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Heng, Pheng</display_name>&nbsp;</td><td>KJL-6056-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Heng, Pheng Ann</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3055-5034&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>WA1FC</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key-Area Research and Development Program of GuangdongProvince, China</grant_agency>&nbsp;</td><td>
<div>2020B010165004&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Hong Kong Innovation and Technology Fund</grant_agency>&nbsp;</td><td>
<div>ITS/311/18FP&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>U1813204&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the Key-Area Research and Development Program of GuangdongProvince, China, under Project 2020B010165004, in part by the Hong Kong Innovation and Technology Fund under Project ITS/311/18FP, and in part by the National Natural Science Foundation of China under Project U1813204.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 63 of 63</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Fetal Congenital Heart Disease Echocardiogram Screening Based on DGACNN: Adversarial One-Class Classification Combined with Video Transfer Learning</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Gong, YX (Gong, Yuxin); Zhang, YY (Zhang, Yingying); Zhu, HG (Zhu, Haogang); Lv, J (Lv, Jing); Cheng, Q (Cheng, Qian); Zhang, HJ (Zhang, Hongjia); He, YH (He, Yihua); Wang, SL (Wang, Shuliang)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>39</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>4</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>1206-1222</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2019.2946059</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 APR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>67</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>78</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
55</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>39</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Fetal congenital heart disease (FHD) is a common and serious congenital malformation in children. In Asia, FHD birth defect rates have reached as high as 9.3 0025. For the early detection of birth defects and mortality, echocardiography remains the most effective method for screening fetal heart malformations. However, standard echocardiograms of the fetal heart, especially four-chamber view images, are difficult to obtain. In addition, the pathophysiological changes in fetal hearts during different pregnancy periods lead to ever-changing two-dimensional fetal heart structures and hemodynamics, and it requires extensive professional knowledge to recognize and judge disease development. Thus, research on the automatic screening for FHD is necessary. In this paper, we proposed a new model named DGACNN that shows the best performance in recognizing FHD, achieving a rate of 85. The motivation for this network is to deal with the problem that there are insufficient training datasets to train a robust model. There are many unlabeled video slices, but they are tough and time-consuming to annotate. Thus, how to use these un-annotated video slices to improve the DGACNN capability for recognizing FHD, in terms of both recognition accuracy and robustness, is very meaningful for FHD screening. The architecture of DGACNN comprises two parts, that is, DANomaly and GACNN (Wgan-GP and CNN). DANomaly, similar to the ALOCC network, but incorporates cycle adversarial learning to train an end-to-end one-class classification (OCC) network that is more robust and has a higher accuracy than ALOCC in screening video slices. For the GACNN architecture, we use FCH (four chamber heart) video slices at around the end-systole, as screened by DANomaly, to train a WGAN-GP for the purpose of obtaining ideal low-level features that can robustly improve the FHD recognition accuracy. A few annotated video slices, as screened by DANomaly, can also be used for data augmentation so as to improve the FHD recognition further. The experiments show that the DGACNN outperforms other state-of-the-art networks by 10025; in recognizing FHD. A comparison experiment shows that the proposed network already outperforms the performance of expert cardiologists in recognizing FHD, reaching 84 025; in a test. Thus, the proposed architecture has high potential for helping cardiologists complete early FHD screenings.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000525265800036</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>31603775</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Fetal congenital heart disease; one-class classification; generative adversarial network; transfer learning; echocardiography; four-chamber heart</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CONVOLUTIONAL NEURAL-NETWORKS; UNITED-STATES</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Gong, Yuxin; Zhang, Yingying; Zhu, Haogang; Cheng, Qian] Beihang Univ, Sch Comp Sci &amp; Engn, State Key Lab Software Dev Environm, Beijing 100083, Peoples R China. <br>
[Gong, Yuxin; Zhang, Yingying] Beihang Univ, Sch Biol Sci &amp; Med Engn, Beijing 100083, Peoples R China. <br>
[Zhu, Haogang] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Beijing 100083, Peoples R China. <br>
[Zhu, Haogang] Beihang Univiers, Hefei Innovat Res Inst, Beijing 100083, Peoples R China. <br>
[Lv, Jing; Zhang, Hongjia; He, Yihua] Capital Med Univ, Beijing Anzhen Hosp, Dept Ultrasound, Beijing 100069, Peoples R China. <br>
[Wang, Shuliang] Beijing Inst Technol, Sch Comp Sci &amp; Technol, Beijing 100811, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhu, HG (corresponding author), Beihang Univ, Sch Comp Sci &amp; Engn, State Key Lab Software Dev Environm, Beijing 100083, Peoples R China.<br>He, YH (corresponding author), Capital Med Univ, Beijing Anzhen Hosp, Dept Ultrasound, Beijing 100069, Peoples R China.<br>Wang, SL (corresponding author), Beijing Inst Technol, Sch Comp Sci &amp; Technol, Beijing 100811, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
gongyuxinbuaa@163.com; haogangzhu@buaa.edu.cn; heyihuaecho@hotmail.com; slwang2011@bit.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Beihang University; Beihang University; Beihang University; Capital Medical University; Beijing Institute of Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>lv, jing</display_name>&nbsp;</td><td>JXM-6679-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cheng, Qian</display_name>&nbsp;</td><td>M-6702-2017&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>gong, yuxin</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4692-8931&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>zhang, yingying</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0964-1774&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>WANG, Shuliang</display_name>&nbsp;</td><td>A-2626-2012&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>LC4AC</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>17</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>State Key Laboratory of Software Development Environment, Beihang University, Beijing, China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Hefei Innovation Research Institute, Beihang University, China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation</grant_agency>&nbsp;</td><td>
<div>61702027&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Science and Technology Plan Project</grant_agency>&nbsp;</td><td>
<div>Z171100000117022&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Municipal Science &amp; Technology Commission</grant_agency>&nbsp;</td><td>
<div>Z181100001918008&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Lab for Cardiovascular Precision Medicine</grant_agency>&nbsp;</td><td>
<div>PXM2018014226000013&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the State Key Laboratory of Software Development Environment, Beihang University, Beijing, China, in part by the Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, China, in part by the Hefei Innovation Research Institute, Beihang University, China, in part by the National Natural Science Foundation under Grant 61702027, in part by the Beijing Science and Technology Plan Project under Grant Z171100000117022, in part by the Beijing Municipal Science &amp; Technology Commission under Grant Z181100001918008, and in part by the Beijing Lab for Cardiovascular Precision Medicine under Grant PXM2018014226000013.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr>
<table xmlns:bean="http://ts.thomson.com/ua/bean">
<tr>
<td>End of File</td>
</tr>
</table><div style="background-color: #000000; padding: 10px; color: #FFFFFF; font-family: arial, sans-serif;">
<div style="height: 25px; width: 100px;">
<mat-icon data-mat-icon-name="clarivate" data-mat-icon-type="svg" aria-hidden="true" class="mat-icon notranslate clarivate-logo mat-icon-no-color" svgicon="clarivate" role="img">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" focusable="false" preserveAspectRatio="xMidYMid meet" version="1.1" viewBox="0 0 92 18" height="100%" width="100%">
<title>Clarivate</title>
<g fill-rule="evenodd" fill="none" stroke-width="1" stroke="none">
<g fill-rule="nonzero" fill="#FFFFFF" transform="translate(-19.000000, -8.000000)">
<g transform="translate(1.000000, 1.000000)">
<g transform="translate(18.000000, 7.000000)">
<path d="M26.6812194,13.2997252 C28.2949641,13.3845068 29.7591419,12.3596036 30.2318671,10.8143235 L33.0910469,10.8143235 C32.3628779,13.742285 29.6973379,15.7705498 26.6812194,15.6916944 C24.8651813,15.7485215 23.1057028,15.0559504 21.8156554,13.7764967 C20.5256081,12.4970431 19.8185526,10.7433351 19.8604035,8.9268901 C19.8185367,7.11043445 20.5255848,5.35671042 21.8156337,4.07724261 C23.1056826,2.7977748 24.8651702,2.10519376 26.6812194,2.16201887 C29.6973451,2.0831702 32.3628861,4.11144761 33.0910469,7.03941847 L30.2318671,7.03941847 C29.7591419,5.49413828 28.2949641,4.46923515 26.6812194,4.55401674 C25.5407067,4.54133389 24.4470406,5.00703241 23.6657805,5.83803342 C22.8845203,6.66903442 22.487126,7.78932829 22.5700912,8.9268901 C22.4871313,10.064447 22.8845287,11.184734 23.6657888,12.0157277 C24.447049,12.8467215 25.540712,13.312413 26.6812194,13.2997252 L26.6812194,13.2997252 Z"/>
<polygon points="36.8477342 15.4674945 34.4371264 15.4674945 34.4371264 2.38628571 36.8477342 2.38628571"/>
<path d="M43.5380316,9.76781183 C43.5380316,9.15114738 43.0522397,8.75870193 42.1178663,8.75870193 C41.2070757,8.82048057 40.3236107,9.0957548 39.5389268,9.5622602 L38.5858286,7.73092465 C39.6930919,7.06514423 40.9567617,6.70409618 42.2486241,6.68441302 C44.1921648,6.68441302 45.9674886,7.58137515 45.9674886,9.84255787 L45.9674886,15.4674945 L43.5380316,15.4674945 L43.5380316,14.6639362 C42.9494098,15.3673061 42.0613957,15.7488608 41.146005,15.6917231 C40.3900371,15.7421039 39.645831,15.484584 39.0826798,14.9777443 C38.5195286,14.4709046 38.1853154,13.7578403 38.1560675,13.0007601 C38.1560675,11.3749188 39.3519468,10.3658089 41.2581433,10.3658089 L42.9400537,10.3658089 C43.3511665,10.3658089 43.5379934,10.1789247 43.5379934,9.86128266 L43.5380316,9.76781183 Z M43.5380316,12.4027631 L43.5380316,11.786089 C43.321275,11.9402969 43.0543042,12.0070182 42.790485,11.9729159 L41.8748173,11.9729159 C41.1086607,11.9729159 40.6602036,12.3092922 40.6602036,12.9072893 C40.6602036,13.486619 41.1272707,13.9164566 41.8748173,13.9164566 C42.303867,13.9699481 42.7348632,13.8332333 43.0546312,13.5422121 C43.3743992,13.2511908 43.5509896,12.8349402 43.5380316,12.4027631 L43.5380316,12.4027631 Z"/>
<path d="M52.6579104,9.3006299 L51.6301236,9.3006299 C50.3966703,9.3006299 49.8361037,9.8799596 49.8361037,11.3749188 L49.8361037,15.4674945 L47.4066179,15.4674945 L47.4066179,6.90863203 L49.7612715,6.90863203 L49.7612715,8.27284306 C50.1001881,7.34759017 51.0007831,6.74968637 51.9850429,6.79648425 C52.2115562,6.79362484 52.4375557,6.81874947 52.6579104,6.87128771 L52.6579104,9.3006299 Z"/>
<path d="M57.4232866,15.4674945 L54.9939445,15.4674945 L54.9939445,8.96425355 L53.7979312,8.96425355 L53.7979312,6.90863203 L57.4232866,6.90863203 L57.4232866,15.4674945 Z M56.0964104,2.38628347 C56.5129556,2.38558064 56.9126431,2.55074046 57.2071855,2.84528284 C57.5017278,3.13982521 57.6668877,3.53951271 57.6661848,3.95605794 C57.6609778,4.814152 56.9638874,5.50702694 56.1057775,5.50702694 C55.2476677,5.50702694 54.5505773,4.814152 54.5453585,3.95605794 C54.5417726,3.09491157 55.2352828,2.39302469 56.0964104,2.38628347 Z"/>
<polygon points="62.8802456 12.8512776 64.8236715 6.90863203 67.3838767 6.90863203 64.33787 15.4674945 61.3292077 15.4674945 58.4139588 6.90863203 61.0488526 6.90863203"/>
<path d="M72.8783522,9.76781183 C72.8783522,9.15114738 72.3924359,8.75870193 71.4580625,8.75870193 C70.5472784,8.82049943 69.6638208,9.09577238 68.8791325,9.5622602 L67.9261491,7.73092465 C69.0333627,7.06513461 70.2969953,6.70408494 71.5888202,6.68441302 C73.5323609,6.68441302 75.3076848,7.58137515 75.3076848,9.84255787 L75.3076848,15.4674945 L72.8783522,15.4674945 L72.8783522,14.6639362 C72.2896971,15.3672586 71.4017035,15.7487939 70.4863256,15.6916944 C69.7303436,15.7420941 68.986117,15.4845835 68.4229464,14.9777426 C67.8597758,14.4709017 67.5255471,13.7578265 67.4962924,13.0007314 C67.4962924,11.3748901 68.6923056,10.3657802 70.5984925,10.3657802 L72.2802785,10.3657802 C72.6913914,10.3657802 72.8783426,10.1788959 72.8783426,9.86125395 L72.8783522,9.76781183 Z M72.8783522,12.4027631 L72.8783522,11.786089 C72.6615874,11.9402794 72.3946236,12.006999 72.1308056,11.9729159 L71.2151378,11.9729159 C70.4488664,11.9729159 70.0004093,12.3092922 70.0004093,12.9072893 C70.0004093,13.486619 70.4676008,13.9164566 71.2151378,13.9164566 C71.6441833,13.9699279 72.0751679,13.8332061 72.394931,13.5421893 C72.7146941,13.2511724 72.8912904,12.8349341 72.8783522,12.4027631 L72.8783522,12.4027631 Z"/>
<path d="M79.9985637,3.65701635 L79.9985637,6.90863203 L81.8485762,6.90863203 L81.8485762,8.96425355 L79.9985637,8.96425355 L79.9985637,12.8325433 C79.9985637,13.3745286 80.4282865,13.4492747 80.8020646,13.4492747 C81.418729,13.4492747 81.9232553,13.3932056 81.9232553,13.3932056 L81.9232553,15.4674945 C81.9232553,15.4674945 80.7459859,15.5796423 80.0357932,15.5796423 C78.8211795,15.5796423 77.5691354,15.3740811 77.5691354,13.6548263 L77.5691354,8.96425355 L76.22363,8.96425355 L76.22363,6.90863203 L77.5691163,6.90863203 L77.5691163,3.65701635 L79.9985637,3.65701635 Z"/>
<path d="M91.5475359,11.8981794 L85.1751771,11.8981794 C85.3031552,12.7204351 85.9194738,13.3815958 86.7307322,13.5669136 C87.5419905,13.7522314 88.3842592,13.4242593 88.856573,12.7391298 L91.3793191,13.0007601 C90.4933306,14.9536735 88.3725856,16.0321989 86.2725384,15.5978628 C84.1724912,15.1635268 82.6535603,13.3322361 82.6149337,11.188092 C82.567807,9.98960603 83.0193435,8.82515843 83.8621298,7.97175307 C84.7049161,7.1183477 85.8636189,6.65226701 87.0626009,6.68438432 C89.4171397,6.68438432 91.5475359,8.21674525 91.5475359,11.8047373 L91.5475359,11.8981794 Z M85.1189837,10.2723955 L88.9499864,10.2723955 C88.8059978,9.34848922 87.9973156,8.67588427 87.0626392,8.70263282 C86.1147409,8.67034807 85.2869107,9.33893202 85.1189837,10.2723955 Z"/>
<path d="M12.6820274,9.85132226 C10.6885049,11.8556057 8.11575776,13.1830474 5.32707189,13.6462054 C5.77780891,14.8758828 6.40559556,16.0331959 7.19058498,17.0815575 C10.3903106,16.2989026 13.3004311,14.619851 15.5794509,12.2414352 C15.0651988,11.0374085 14.3787129,9.91449973 13.5415112,8.90790698 C13.271174,9.23328 12.9846793,9.54772625 12.6820274,9.85124571"/>
<path d="M5.32722498,13.6460332 C4.21304566,10.5852611 4.22627578,7.22758116 5.3645406,4.17568425 C4.07298567,3.95802358 2.75701252,3.92542943 1.45626578,4.07888372 C0.536506305,7.22972054 0.525090565,10.5762272 1.42333236,13.7332656 C2.72217338,13.8896343 4.03666286,13.8602685 5.32722498,13.6460524"/>
<path d="M7.25919787,0.751096346 C6.46424104,1.79423541 5.8259601,2.94792723 5.36457887,4.17561728 C8.13918123,4.64457901 10.6977043,5.96938232 12.6820178,7.96458738 C12.9850078,8.2673988 13.2715025,8.58184824 13.5415017,8.90793568 C14.3788161,7.90142183 15.0653154,6.77849641 15.5794509,5.57440744 C13.3171586,3.21319806 10.4324457,1.54091896 7.25919787,0.751096346"/>
</g>
</g>
</g>
</g>
</svg>
</mat-icon>
</div>
<path d="M5.32722498,13.6460332 C4.21304566,10.5852611 4.22627578,7.22758116 5.3645406,4.17568425 C4.07298567,3.95802358 2.75701252,3.92542943 1.45626578,4.07888372 C0.536506305,7.22972054 0.525090565,10.5762272 1.42333236,13.7332656 C2.72217338,13.8896343 4.03666286,13.8602685 5.32722498,13.6460524"></path>
<path d="M7.25919787,0.751096346 C6.46424104,1.79423541 5.8259601,2.94792723 5.36457887,4.17561728 C8.13918123,4.64457901 10.6977043,5.96938232 12.6820178,7.96458738 C12.9850078,8.2673988 13.2715025,8.58184824 13.5415017,8.90793568 C14.3788161,7.90142183 15.0653154,6.77849641 15.5794509,5.57440744 C13.3171586,3.21319806 10.4324457,1.54091896 7.25919787,0.751096346"></path>
</div>
