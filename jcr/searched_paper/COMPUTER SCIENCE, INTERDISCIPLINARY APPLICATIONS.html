<div xmlns:bean="http://ts.thomson.com/ua/bean" style="background-color: #000000; padding: 10px; color: #FFFFFF; font-family:  arial, sans-serif;">
<div style="height: 25px; width: 100px;">
<mat-icon data-mat-icon-name="clarivate" data-mat-icon-type="svg" aria-hidden="true" class="mat-icon notranslate clarivate-logo mat-icon-no-color" svgicon="clarivate" role="img">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" focusable="false" preserveAspectRatio="xMidYMid meet" version="1.1" viewBox="0 0 92 18" height="100%" width="100%">
<title>Clarivate</title>
<g fill-rule="evenodd" fill="none" stroke-width="1" stroke="none">
<g fill-rule="nonzero" fill="#FFFFFF" transform="translate(-19.000000, -8.000000)">
<g transform="translate(1.000000, 1.000000)">
<g transform="translate(18.000000, 7.000000)">
<path d="M26.6812194,13.2997252 C28.2949641,13.3845068 29.7591419,12.3596036 30.2318671,10.8143235 L33.0910469,10.8143235 C32.3628779,13.742285 29.6973379,15.7705498 26.6812194,15.6916944 C24.8651813,15.7485215 23.1057028,15.0559504 21.8156554,13.7764967 C20.5256081,12.4970431 19.8185526,10.7433351 19.8604035,8.9268901 C19.8185367,7.11043445 20.5255848,5.35671042 21.8156337,4.07724261 C23.1056826,2.7977748 24.8651702,2.10519376 26.6812194,2.16201887 C29.6973451,2.0831702 32.3628861,4.11144761 33.0910469,7.03941847 L30.2318671,7.03941847 C29.7591419,5.49413828 28.2949641,4.46923515 26.6812194,4.55401674 C25.5407067,4.54133389 24.4470406,5.00703241 23.6657805,5.83803342 C22.8845203,6.66903442 22.487126,7.78932829 22.5700912,8.9268901 C22.4871313,10.064447 22.8845287,11.184734 23.6657888,12.0157277 C24.447049,12.8467215 25.540712,13.312413 26.6812194,13.2997252 L26.6812194,13.2997252 Z"/>
<polygon points="36.8477342 15.4674945 34.4371264 15.4674945 34.4371264 2.38628571 36.8477342 2.38628571"/>
<path d="M43.5380316,9.76781183 C43.5380316,9.15114738 43.0522397,8.75870193 42.1178663,8.75870193 C41.2070757,8.82048057 40.3236107,9.0957548 39.5389268,9.5622602 L38.5858286,7.73092465 C39.6930919,7.06514423 40.9567617,6.70409618 42.2486241,6.68441302 C44.1921648,6.68441302 45.9674886,7.58137515 45.9674886,9.84255787 L45.9674886,15.4674945 L43.5380316,15.4674945 L43.5380316,14.6639362 C42.9494098,15.3673061 42.0613957,15.7488608 41.146005,15.6917231 C40.3900371,15.7421039 39.645831,15.484584 39.0826798,14.9777443 C38.5195286,14.4709046 38.1853154,13.7578403 38.1560675,13.0007601 C38.1560675,11.3749188 39.3519468,10.3658089 41.2581433,10.3658089 L42.9400537,10.3658089 C43.3511665,10.3658089 43.5379934,10.1789247 43.5379934,9.86128266 L43.5380316,9.76781183 Z M43.5380316,12.4027631 L43.5380316,11.786089 C43.321275,11.9402969 43.0543042,12.0070182 42.790485,11.9729159 L41.8748173,11.9729159 C41.1086607,11.9729159 40.6602036,12.3092922 40.6602036,12.9072893 C40.6602036,13.486619 41.1272707,13.9164566 41.8748173,13.9164566 C42.303867,13.9699481 42.7348632,13.8332333 43.0546312,13.5422121 C43.3743992,13.2511908 43.5509896,12.8349402 43.5380316,12.4027631 L43.5380316,12.4027631 Z"/>
<path d="M52.6579104,9.3006299 L51.6301236,9.3006299 C50.3966703,9.3006299 49.8361037,9.8799596 49.8361037,11.3749188 L49.8361037,15.4674945 L47.4066179,15.4674945 L47.4066179,6.90863203 L49.7612715,6.90863203 L49.7612715,8.27284306 C50.1001881,7.34759017 51.0007831,6.74968637 51.9850429,6.79648425 C52.2115562,6.79362484 52.4375557,6.81874947 52.6579104,6.87128771 L52.6579104,9.3006299 Z"/>
<path d="M57.4232866,15.4674945 L54.9939445,15.4674945 L54.9939445,8.96425355 L53.7979312,8.96425355 L53.7979312,6.90863203 L57.4232866,6.90863203 L57.4232866,15.4674945 Z M56.0964104,2.38628347 C56.5129556,2.38558064 56.9126431,2.55074046 57.2071855,2.84528284 C57.5017278,3.13982521 57.6668877,3.53951271 57.6661848,3.95605794 C57.6609778,4.814152 56.9638874,5.50702694 56.1057775,5.50702694 C55.2476677,5.50702694 54.5505773,4.814152 54.5453585,3.95605794 C54.5417726,3.09491157 55.2352828,2.39302469 56.0964104,2.38628347 Z"/>
<polygon points="62.8802456 12.8512776 64.8236715 6.90863203 67.3838767 6.90863203 64.33787 15.4674945 61.3292077 15.4674945 58.4139588 6.90863203 61.0488526 6.90863203"/>
<path d="M72.8783522,9.76781183 C72.8783522,9.15114738 72.3924359,8.75870193 71.4580625,8.75870193 C70.5472784,8.82049943 69.6638208,9.09577238 68.8791325,9.5622602 L67.9261491,7.73092465 C69.0333627,7.06513461 70.2969953,6.70408494 71.5888202,6.68441302 C73.5323609,6.68441302 75.3076848,7.58137515 75.3076848,9.84255787 L75.3076848,15.4674945 L72.8783522,15.4674945 L72.8783522,14.6639362 C72.2896971,15.3672586 71.4017035,15.7487939 70.4863256,15.6916944 C69.7303436,15.7420941 68.986117,15.4845835 68.4229464,14.9777426 C67.8597758,14.4709017 67.5255471,13.7578265 67.4962924,13.0007314 C67.4962924,11.3748901 68.6923056,10.3657802 70.5984925,10.3657802 L72.2802785,10.3657802 C72.6913914,10.3657802 72.8783426,10.1788959 72.8783426,9.86125395 L72.8783522,9.76781183 Z M72.8783522,12.4027631 L72.8783522,11.786089 C72.6615874,11.9402794 72.3946236,12.006999 72.1308056,11.9729159 L71.2151378,11.9729159 C70.4488664,11.9729159 70.0004093,12.3092922 70.0004093,12.9072893 C70.0004093,13.486619 70.4676008,13.9164566 71.2151378,13.9164566 C71.6441833,13.9699279 72.0751679,13.8332061 72.394931,13.5421893 C72.7146941,13.2511724 72.8912904,12.8349341 72.8783522,12.4027631 L72.8783522,12.4027631 Z"/>
<path d="M79.9985637,3.65701635 L79.9985637,6.90863203 L81.8485762,6.90863203 L81.8485762,8.96425355 L79.9985637,8.96425355 L79.9985637,12.8325433 C79.9985637,13.3745286 80.4282865,13.4492747 80.8020646,13.4492747 C81.418729,13.4492747 81.9232553,13.3932056 81.9232553,13.3932056 L81.9232553,15.4674945 C81.9232553,15.4674945 80.7459859,15.5796423 80.0357932,15.5796423 C78.8211795,15.5796423 77.5691354,15.3740811 77.5691354,13.6548263 L77.5691354,8.96425355 L76.22363,8.96425355 L76.22363,6.90863203 L77.5691163,6.90863203 L77.5691163,3.65701635 L79.9985637,3.65701635 Z"/>
<path d="M91.5475359,11.8981794 L85.1751771,11.8981794 C85.3031552,12.7204351 85.9194738,13.3815958 86.7307322,13.5669136 C87.5419905,13.7522314 88.3842592,13.4242593 88.856573,12.7391298 L91.3793191,13.0007601 C90.4933306,14.9536735 88.3725856,16.0321989 86.2725384,15.5978628 C84.1724912,15.1635268 82.6535603,13.3322361 82.6149337,11.188092 C82.567807,9.98960603 83.0193435,8.82515843 83.8621298,7.97175307 C84.7049161,7.1183477 85.8636189,6.65226701 87.0626009,6.68438432 C89.4171397,6.68438432 91.5475359,8.21674525 91.5475359,11.8047373 L91.5475359,11.8981794 Z M85.1189837,10.2723955 L88.9499864,10.2723955 C88.8059978,9.34848922 87.9973156,8.67588427 87.0626392,8.70263282 C86.1147409,8.67034807 85.2869107,9.33893202 85.1189837,10.2723955 Z"/>
<path d="M12.6820274,9.85132226 C10.6885049,11.8556057 8.11575776,13.1830474 5.32707189,13.6462054 C5.77780891,14.8758828 6.40559556,16.0331959 7.19058498,17.0815575 C10.3903106,16.2989026 13.3004311,14.619851 15.5794509,12.2414352 C15.0651988,11.0374085 14.3787129,9.91449973 13.5415112,8.90790698 C13.271174,9.23328 12.9846793,9.54772625 12.6820274,9.85124571"/>
<path d="M5.32722498,13.6460332 C4.21304566,10.5852611 4.22627578,7.22758116 5.3645406,4.17568425 C4.07298567,3.95802358 2.75701252,3.92542943 1.45626578,4.07888372 C0.536506305,7.22972054 0.525090565,10.5762272 1.42333236,13.7332656 C2.72217338,13.8896343 4.03666286,13.8602685 5.32722498,13.6460524"/>
<path d="M7.25919787,0.751096346 C6.46424104,1.79423541 5.8259601,2.94792723 5.36457887,4.17561728 C8.13918123,4.64457901 10.6977043,5.96938232 12.6820178,7.96458738 C12.9850078,8.2673988 13.2715025,8.58184824 13.5415017,8.90793568 C14.3788161,7.90142183 15.0653154,6.77849641 15.5794509,5.57440744 C13.3171586,3.21319806 10.4324457,1.54091896 7.25919787,0.751096346"/>
</g>
</g>
</g>
</g>
</svg>
</mat-icon>
</div>
<path d="M5.32722498,13.6460332 C4.21304566,10.5852611 4.22627578,7.22758116 5.3645406,4.17568425 C4.07298567,3.95802358 2.75701252,3.92542943 1.45626578,4.07888372 C0.536506305,7.22972054 0.525090565,10.5762272 1.42333236,13.7332656 C2.72217338,13.8896343 4.03666286,13.8602685 5.32722498,13.6460524"></path>
<path d="M7.25919787,0.751096346 C6.46424104,1.79423541 5.8259601,2.94792723 5.36457887,4.17561728 C8.13918123,4.64457901 10.6977043,5.96938232 12.6820178,7.96458738 C12.9850078,8.2673988 13.2715025,8.58184824 13.5415017,8.90793568 C14.3788161,7.90142183 15.0653154,6.77849641 15.5794509,5.57440744 C13.3171586,3.21319806 10.4324457,1.54091896 7.25919787,0.751096346"></path>
</div><div style="width: 180px; height: 40px; padding: 10px;">
<mat-icon data-mat-icon-name="wos" data-mat-icon-type="svg" aria-hidden="true" style="width: 180px;" class="mat-icon notranslate mat-icon-no-color" svgicon="wos" role="img">
<svg xmlns="http://www.w3.org/2000/svg" focusable="false" preserveAspectRatio="xMidYMid meet" viewBox="0 0 1868 332" height="100%" width="100%">
<title>Web of Science</title>
<path d="M 108.92,75.00            C 108.92,75.00 147.34,75.00 147.34,75.00              147.34,75.00 182.84,208.12 182.84,208.12              182.84,208.12 183.11,208.12 183.11,208.12              183.11,208.12 212.80,75.00 212.80,75.00              212.80,75.00 250.42,75.00 250.42,75.00              250.42,75.00 205.11,261.00 205.11,261.00              205.11,261.00 162.44,261.00 162.44,261.00              162.44,261.00 127.47,127.34 127.47,127.34              127.47,127.34 93.28,261.00 93.28,261.00              93.28,261.00 50.61,261.00 50.61,261.00              50.61,261.00 4.77,75.00 4.77,75.00              4.77,75.00 44.52,75.00 44.52,75.00              44.52,75.00 73.14,208.12 73.14,208.12              73.14,208.12 73.41,208.12 73.41,208.12              73.41,208.12 108.92,75.00 108.92,75.00 Z            M 379.00,210.00            C 379.00,210.00 288.41,210.00 288.41,210.00              289.29,216.78 292.30,222.48 297.44,227.09              302.57,231.70 308.86,234.00 316.30,234.00              327.80,234.00 335.95,230.00 340.73,222.00              340.73,222.00 376.61,225.58 376.61,225.58              371.30,238.39 363.32,248.00 352.69,254.41              342.06,260.80 329.75,264.00 315.77,264.00              297.52,264.00 282.32,257.98 270.19,245.94              258.06,233.90 252.00,218.59 252.00,200.00              252.00,181.42 257.98,166.11 269.94,154.06              281.89,142.02 296.99,136.00 315.23,136.00              333.47,136.00 348.66,142.21 360.80,154.64              372.93,167.06 379.00,185.51 379.00,210.00 Z            M 333.30,171.28            C 328.34,167.09 322.32,165.00 315.23,165.00              308.15,165.00 302.12,167.01 297.16,171.03              292.20,175.04 289.02,180.37 287.61,187.00              287.61,187.00 342.06,187.00 342.06,187.00              341.19,180.71 338.27,175.47 333.30,171.28 Z            M 433.72,245.31            C 433.72,245.31 433.72,261.00 433.72,261.00              433.72,261.00 399.00,261.00 399.00,261.00              399.00,261.00 399.00,75.00 399.00,75.00              399.00,75.00 433.45,75.00 433.45,75.00              433.45,75.00 433.45,134.94 433.45,134.94              433.45,137.95 433.45,141.85 433.45,146.64              433.45,151.42 433.45,154.17 433.45,154.88              436.43,149.39 441.34,144.87 448.17,141.33              455.02,137.78 462.82,136.00 471.59,136.00              488.26,136.00 502.16,142.07 513.30,154.20              524.43,166.33 530.00,181.59 530.00,200.00              530.00,218.41 524.37,233.68 513.11,245.81              501.86,257.94 487.88,264.00 471.17,264.00              462.91,264.00 455.39,262.22 448.62,258.66              441.85,255.09 436.88,250.65 433.72,245.31 Z            M 485.39,176.23            C 479.65,169.98 472.34,166.86 463.45,166.86              454.58,166.86 447.27,169.98 441.53,176.23              435.79,182.48 432.92,190.37 432.92,199.88              432.92,209.20 435.79,217.07 441.53,223.50              447.27,229.93 454.58,233.14 463.45,233.14              472.34,233.14 479.65,229.93 485.39,223.50              491.13,217.07 494.00,209.20 494.00,199.88              494.00,190.37 491.13,182.48 485.39,176.23 Z            M 707.69,245.81            C 695.19,257.94 679.86,264.00 661.72,264.00              643.58,264.00 628.26,257.94 615.75,245.81              603.25,233.68 597.00,218.41 597.00,200.00              597.00,181.59 603.25,166.33 615.75,154.20              628.26,142.07 643.58,136.00 661.72,136.00              679.86,136.00 695.19,142.07 707.69,154.20              720.20,166.33 726.45,181.59 726.45,200.00              726.45,218.41 720.20,233.68 707.69,245.81 Z            M 661.84,166.86            C 652.85,166.86 645.54,170.00 639.91,176.28              634.27,182.55 631.45,190.46 631.45,200.00              631.45,209.54 634.27,217.45 639.91,223.73              645.54,230.01 652.85,233.14 661.84,233.14              670.66,233.14 677.89,230.01 683.53,223.73              689.18,217.45 692.00,209.54 692.00,200.00              692.00,190.46 689.18,182.55 683.53,176.28              677.89,170.00 670.66,166.86 661.84,166.86 Z            M 757.00,139.00            C 757.00,139.00 757.00,104.34 757.00,104.34              757.00,93.15 760.17,84.98 766.52,79.83              772.86,74.67 781.14,72.09 791.36,72.09              791.36,72.09 816.50,73.69 816.50,73.69              816.50,73.69 816.50,105.33 816.50,105.33              809.47,104.45 804.72,104.00 802.27,104.00              798.58,104.00 795.85,104.71 794.09,106.14              792.33,107.57 791.45,110.24 791.45,114.16              791.45,114.16 791.45,139.00 791.45,139.00              791.45,139.00 815.00,139.00 815.00,139.00              815.00,139.00 815.00,168.00 815.00,168.00              815.00,168.00 791.45,168.00 791.45,168.00              791.45,168.00 791.45,260.50 791.45,260.50              791.45,260.50 757.00,260.50 757.00,260.50              757.00,260.50 757.00,168.00 757.00,168.00              757.00,168.00 738.00,168.00 738.00,168.00              738.00,168.00 738.00,139.00 738.00,139.00              738.00,139.00 757.00,139.00 757.00,139.00 Z            M 1004.30,97.27            C 1004.30,97.27 983.11,124.06 983.11,124.06              969.92,111.36 956.73,105.00 943.53,105.00              937.11,105.00 931.59,106.60 926.95,109.80              922.32,112.98 920.00,117.24 920.00,122.56              920.00,131.06 926.74,138.42 940.22,144.62              940.22,144.62 955.66,151.80 955.66,151.80              971.60,159.25 983.48,167.31 991.28,176.00              999.09,184.68 1003.00,195.67 1003.00,208.97              1003.00,223.87 997.13,236.76 985.39,247.66              973.66,258.55 958.09,264.00 938.67,264.00              913.45,264.00 891.31,254.56 872.25,235.67              872.25,235.67 892.52,208.02 892.52,208.02              899.27,214.90 906.74,220.29 914.92,224.17              923.10,228.06 930.83,230.00 938.11,230.00              945.94,230.00 952.21,228.09 956.92,224.28              961.64,220.47 964.00,215.64 964.00,209.80              964.00,203.95 961.65,198.93 956.95,194.77              952.25,190.60 944.85,186.21 934.73,181.61              934.73,181.61 921.70,175.48 921.70,175.48              894.57,162.73 881.00,145.36 881.00,123.38              881.00,107.59 887.05,94.92 899.17,85.36              911.29,75.79 925.91,71.00 943.06,71.00              963.93,71.00 984.34,79.76 1004.30,97.27 Z            M 1082.92,166.86            C 1073.91,166.86 1066.58,170.00 1060.92,176.28              1055.27,182.55 1052.45,190.46 1052.45,200.00              1052.45,209.54 1055.27,217.45 1060.92,223.73              1066.58,230.01 1073.91,233.14 1082.92,233.14              1095.82,233.14 1104.74,226.95 1109.69,214.58              1109.69,214.58 1142.02,224.66 1142.02,224.66              1138.13,236.72 1130.75,246.29 1119.89,253.38              1109.02,260.46 1096.61,264.00 1082.66,264.00              1064.46,264.00 1049.13,257.94 1036.67,245.81              1024.22,233.68 1018.00,218.41 1018.00,200.00              1018.00,181.59 1024.22,166.33 1036.67,154.20              1049.13,142.07 1064.46,136.00 1082.66,136.00              1096.61,136.00 1109.02,139.59 1119.89,146.77              1130.75,153.95 1138.13,163.56 1142.02,175.61              1142.02,175.61 1109.69,185.42 1109.69,185.42              1107.39,179.77 1103.91,175.26 1099.22,171.91              1094.54,168.54 1089.11,166.86 1082.92,166.86 Z            M 1170.31,112.67            C 1166.10,108.45 1164.00,103.27 1164.00,97.12              1164.00,90.98 1166.15,85.76 1170.45,81.45              1174.75,77.15 1179.89,75.00 1185.86,75.00              1192.02,75.00 1197.24,77.15 1201.55,81.45              1205.85,85.76 1208.00,90.98 1208.00,97.12              1208.00,103.27 1205.85,108.45 1201.55,112.67              1197.24,116.89 1192.02,119.00 1185.86,119.00              1179.71,119.00 1174.53,116.89 1170.31,112.67 Z            M 1205.00,139.00            C 1205.00,139.00 1205.00,261.00 1205.00,261.00              1205.00,261.00 1170.55,261.00 1170.55,261.00              1170.55,261.00 1170.55,168.00 1170.55,168.00              1170.55,168.00 1153.50,168.00 1153.50,168.00              1153.50,168.00 1153.50,139.00 1153.50,139.00              1153.50,139.00 1205.00,139.00 1205.00,139.00 Z            M 1353.00,210.00            C 1353.00,210.00 1262.41,210.00 1262.41,210.00              1263.29,216.78 1266.30,222.48 1271.44,227.09              1276.57,231.70 1282.86,234.00 1290.30,234.00              1301.80,234.00 1309.95,230.00 1314.73,222.00              1314.73,222.00 1350.61,225.58 1350.61,225.58              1345.30,238.39 1337.32,248.00 1326.69,254.41              1316.06,260.80 1303.75,264.00 1289.77,264.00              1271.52,264.00 1256.32,257.98 1244.19,245.94              1232.06,233.90 1226.00,218.59 1226.00,200.00              1226.00,181.42 1231.98,166.11 1243.94,154.06              1255.89,142.02 1270.99,136.00 1289.23,136.00              1307.47,136.00 1322.66,142.21 1334.80,154.64              1346.93,167.06 1353.00,185.51 1353.00,210.00 Z            M 1307.30,171.28            C 1302.34,167.09 1296.32,165.00 1289.23,165.00              1282.15,165.00 1276.12,167.01 1271.16,171.03              1266.20,175.04 1263.02,180.37 1261.61,187.00              1261.61,187.00 1316.06,187.00 1316.06,187.00              1315.19,180.71 1312.27,175.47 1307.30,171.28 Z            M 1406.39,153.36            C 1415.92,141.79 1428.27,136.00 1443.45,136.00              1456.87,136.00 1467.72,140.04 1476.02,148.11              1484.30,156.17 1488.45,167.20 1488.45,181.20              1488.45,181.20 1488.45,261.00 1488.45,261.00              1488.45,261.00 1454.00,261.00 1454.00,261.00              1454.00,261.00 1454.00,189.86 1454.00,189.86              1454.00,182.57 1452.00,177.11 1448.00,173.47              1444.01,169.82 1439.09,168.00 1433.25,168.00              1423.50,168.00 1414.90,172.62 1407.45,181.86              1407.45,181.86 1407.45,261.00 1407.45,261.00              1407.45,261.00 1373.00,261.00 1373.00,261.00              1373.00,261.00 1373.00,139.00 1373.00,139.00              1373.00,139.00 1406.39,139.00 1406.39,139.00              1406.39,139.00 1406.39,153.36 1406.39,153.36 Z            M 1573.92,166.86            C 1564.91,166.86 1557.58,170.00 1551.92,176.28              1546.27,182.55 1543.45,190.46 1543.45,200.00              1543.45,209.54 1546.27,217.45 1551.92,223.73              1557.58,230.01 1564.91,233.14 1573.92,233.14              1586.82,233.14 1595.74,226.95 1600.69,214.58              1600.69,214.58 1633.02,224.66 1633.02,224.66              1629.13,236.72 1621.75,246.29 1610.89,253.38              1600.02,260.46 1587.61,264.00 1573.66,264.00              1555.46,264.00 1540.13,257.94 1527.67,245.81              1515.22,233.68 1509.00,218.41 1509.00,200.00              1509.00,181.59 1515.22,166.33 1527.67,154.20              1540.13,142.07 1555.46,136.00 1573.66,136.00              1587.61,136.00 1600.02,139.59 1610.89,146.77              1621.75,153.95 1629.13,163.56 1633.02,175.61              1633.02,175.61 1600.69,185.42 1600.69,185.42              1598.39,179.77 1594.91,175.26 1590.22,171.91              1585.54,168.54 1580.11,166.86 1573.92,166.86 Z            M 1773.00,210.00            C 1773.00,210.00 1682.41,210.00 1682.41,210.00              1683.29,216.78 1686.30,222.48 1691.44,227.09              1696.57,231.70 1702.86,234.00 1710.30,234.00              1721.80,234.00 1729.95,230.00 1734.73,222.00              1734.73,222.00 1770.61,225.58 1770.61,225.58              1765.30,238.39 1757.32,248.00 1746.69,254.41              1736.06,260.80 1723.75,264.00 1709.77,264.00              1691.52,264.00 1676.32,257.98 1664.19,245.94              1652.06,233.90 1646.00,218.59 1646.00,200.00              1646.00,181.42 1651.98,166.11 1663.94,154.06              1675.89,142.02 1690.99,136.00 1709.23,136.00              1727.47,136.00 1742.66,142.21 1754.80,154.64              1766.93,167.06 1773.00,185.51 1773.00,210.00 Z            M 1727.30,171.28            C 1722.34,167.09 1716.32,165.00 1709.23,165.00              1702.15,165.00 1696.12,167.01 1691.16,171.03              1686.20,175.04 1683.02,180.37 1681.61,187.00              1681.61,187.00 1736.06,187.00 1736.06,187.00              1735.19,180.71 1732.27,175.47 1727.30,171.28 Z" stroke-width="1" stroke="black" fill="black"/>
<path d="M 1769.00,76.00            C 1769.00,76.00 1800.00,76.00 1800.00,76.00              1800.00,76.00 1800.00,82.42 1800.00,82.42              1800.00,82.42 1788.00,82.42 1788.00,82.42              1788.00,82.42 1788.00,115.00 1788.00,115.00              1788.00,115.00 1780.84,115.00 1780.84,115.00              1780.84,115.00 1780.84,82.42 1780.84,82.42              1780.84,82.42 1769.00,82.42 1769.00,82.42              1769.00,82.42 1769.00,76.00 1769.00,76.00 Z            M 1827.27,106.64            C 1827.27,106.64 1818.95,106.64 1818.95,106.64              1818.95,106.64 1811.16,87.42 1811.16,87.42              1811.16,87.42 1811.16,115.00 1811.16,115.00              1811.16,115.00 1804.00,115.00 1804.00,115.00              1804.00,115.00 1804.00,76.00 1804.00,76.00              1804.00,76.00 1814.61,76.00 1814.61,76.00              1814.61,76.00 1823.25,98.11 1823.25,98.11              1823.25,98.11 1832.08,76.00 1832.08,76.00              1832.08,76.00 1842.00,76.00 1842.00,76.00              1842.00,76.00 1842.00,115.00 1842.00,115.00              1842.00,115.00 1834.84,115.00 1834.84,115.00              1834.84,115.00 1834.84,87.42 1834.84,87.42              1834.84,87.42 1827.27,106.64 1827.27,106.64 Z" stroke-width="1" stroke="black" fill="black"/>
</svg>
</mat-icon>
</div><table cellspacing="0" cellpadding="2" border="0">
<tr>
<td>61 record(s) printed from Clarivate Web of Science</td>
</tr>
</table><hr>
<table>
<tr>
<td><b>Record 1 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Automated detection of diabetic subject using pre-trained 2D-CNN models with frequency spectrum images extracted from heart rate signals</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Yildirim, O (Yildirim, Ozal); Talo, M (Talo, Muhammed); Ay, B (Ay, Betul); Baloglu, UB (Baloglu, Ulas Baran); Aydin, G (Aydin, Galip); Acharya, UR (Acharya, U. Rajendra)</td>
</tr>

<tr xmlns:bean="http://ts.thomson.com/ua/bean" xmlns:exsl="http://exslt.org/common" xmlns:set="http://exslt.org/sets">
<td><b>Source:</b> 
<value>COMPUTERS IN BIOLOGY AND MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>113</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>103387</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.compbiomed.2019.103387</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2019 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>102</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>115</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
51</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>52</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
In this study, a deep-transfer learning approach is proposed for the automated diagnosis of diabetes mellitus (DM), using heart rate (HR) signals obtained from electrocardiogram (ECG) data. Recent progress in deep learning has contributed significantly to improvement in the quality of healthcare. In order for deep learning models to perform well, large datasets are required for training. However, a difficulty in the biomedical field is the lack of clinical data with expert annotation. A recent, commonly implemented technique to train deep learning models using small datasets is to transfer the weighting, developed from a large dataset, to the current model. This deep learning transfer strategy is generally employed for two-dimensional signals. Herein, the weighting of models pre-trained using two-dimensional large image data was applied to one-dimensional HR signals. The one-dimensional HR signals were then converted into frequency spectrum images, which were utilized for application to well-known pre-trained models, specifically: AlexNet, VggNet, ResNet, and DenseNet. The DenseNet pre-trained model yielded the highest classification average accuracy of 97.62%, and sensitivity of 100%, to detect DM subjects via HR signal recordings. In the future, we intend to further test this developed model by utilizing additional data along with cloud-based storage to diagnose DM via heart signal analysis.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000496898100001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>31421276</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Diabetes mellitus; Heart rate signals; Deep learning; Transfer learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
DISCRETE WAVELET TRANSFORM; COMPUTER-AIDED DIAGNOSIS; CLASSIFICATION; MELLITUS; RETINOPATHY; FEATURES; INDEX</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Yildirim, Ozal; Talo, Muhammed] Munzur Univ, Dept Comp Engn, Tunceli, Turkey. <br>
[Ay, Betul; Aydin, Galip] Firat Univ, Dept Comp Engn, Elazig, Turkey. <br>
[Baloglu, Ulas Baran] Univ Bristol, Dept Comp Sci, Bristol, Avon, England. <br>
[Acharya, U. Rajendra] Ngee Ann Polytech, Dept Elect &amp; Comp Engn, Singapore, Singapore. <br>
[Acharya, U. Rajendra] Singapore Sch Social Sci, Sch Sci &amp; Technol, Dept Biomed Engn, Singapore, Singapore. <br>
[Acharya, U. Rajendra] Taylors Univ, Fac Hlth &amp; Med Sci, Sch Med, Subang Jaya 47500, Malaysia. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Yildirim, O (corresponding author), Munzur Univ, Dept Comp Engn, Tunceli, Turkey.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
oyildirim@munzur.edu.tr</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Munzur University; Firat University; University of Bristol; Taylor's University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Baloglu, Ulas Baran</display_name>&nbsp;</td><td>P-7444-2015&nbsp;</td><td>0000-0002-2045-9922&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Acharya, U Rajendra</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2689-8552&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Aydin, Galip</display_name>&nbsp;</td><td>W-1473-2018&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>YILDIRIM, &Ouml;zal</display_name>&nbsp;</td><td>AAV-5584-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Acharya, Rajendra</display_name>&nbsp;</td><td>E-3791-2010&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>BALOGLU, Ulas</display_name>&nbsp;</td><td>P-7444-2015&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Talo, Muhammed</display_name>&nbsp;</td><td>Y-6047-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>AY, BET&Uuml;L</display_name>&nbsp;</td><td>JAN-6412-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Life Sciences &amp; Biomedicine - Other Topics; Computer Science; Engineering; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>JN4VW</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0010-4825</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-0534</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>COMPUT BIOL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Comput. Biol. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 2 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Multi-level semantic adaptation for few-shot segmentation on cardiac image sequences</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Guo, SD (Guo, Saidi); Xu, L (Xu, Lin); Feng, C (Feng, Cheng); Xiong, HH (Xiong, Huahua); Gao, ZF (Gao, Zhifan); Zhang, HY (Zhang, Heye)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>73</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>102170</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2021.102170</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>AUG 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>42</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>44</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
46</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>109</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Obtaining manual labels is time-consuming and labor-intensive on cardiac image sequences. Few-shot segmentation can utilize limited labels to learn new tasks. However, it suffers from two challenges: spatial-temporal distribution bias and long-term information bias. These challenges derive from the impact of the time dimension on cardiac image sequences, resulting in serious over-adaptation. In this paper, we propose the multi-level semantic adaptation (MSA) for few-shot segmentation on cardiac image sequences. The MSA addresses the two biases by exploring the domain adaptation and the weight adaptation on the semantic features in multiple levels, including sequence-level, frame-level, and pixel-level. First, the MSA proposes the dual-level feature adjustment for domain adaptation in spatial and temporal directions. This adjustment explicitly aligns the frame-level feature and the sequence-level feature to improve the model adaptation on diverse modalities. Second, the MSA explores the hierarchical attention metric for weight adaptation in the frame-level feature and the pixel-level feature. This metric focuses on the similar frame and the target region to promote the model discrimination on the border features. The extensive experiments demonstrate that our MSA is effective in f ew-shot segmentation on cardiac image sequences with three modalities, i.e. MR, CT, and Echo (e.g. the average Dice is 0.9243), as well as superior to the ten state-of-the-art methods. (c) 2021 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000697062100005</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34380105</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac image sequences; Few-shot segmentation; Domain adaptation; Attention mechanism</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CAROTID-ARTERY WALL; LEFT-VENTRICLE; MODALITY ADAPTATION; DOMAIN ADAPTATION; ATTENTION; NETWORK; MR; QUANTIFICATION; REGRESSION; DIAGNOSIS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Guo, Saidi; Gao, Zhifan; Zhang, Heye] Sun Yat Sen Univ, Sch Biomed Engn, Guangzhou, Peoples R China. <br>
[Xu, Lin] Gen Hosp Southern Theatre Command, PLA, Guangzhou, Guangdong, Peoples R China. <br>
[Xu, Lin] Southern Med Univ, Sch Clin Med 1, Guangzhou, Guangdong, Peoples R China. <br>
[Feng, Cheng] Third Peoples Hosp Shenzhen, Dept Ultrasound, Shenzhen, Guangdong, Peoples R China. <br>
[Xiong, Huahua] Shenzhen Univ, Shenzhen Peoples Hosp 2, Dept Ultrasound, Affiliated Hosp 1, Shenzhen, Guangdong, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Gao, ZF; Zhang, HY (corresponding author), Sun Yat Sen Univ, Sch Biomed Engn, Guangzhou, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
gaozhifan@mail.sysu.edu.cn; zhangheye@mail.sysu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Sun Yat Sen University; Southern Medical University - China; The Third People's Hospital of Shenzhen; Shenzhen University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Heye</display_name>&nbsp;</td><td>JPK-4651-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gao, Zhifan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1576-4439&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>XIONG, HUAHUA</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7468-7130&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xu, Lin</display_name>&nbsp;</td><td>JOK-8307-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>guo, saidi</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2945-2599&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gao, Zhifan</display_name>&nbsp;</td><td>O-9082-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xu, Lin</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7750-8011&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xiong, Huhahua</display_name>&nbsp;</td><td>HGV-0570-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>UR9LU</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>19</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key-Area Research and Development Program of Guangdong Province</grant_agency>&nbsp;</td><td>
<div>2019B010110001&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key Program for International Cooperation Projects of Guangdong Province</grant_agency>&nbsp;</td><td>
<div>2018A050506031&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of Guangdong Province</grant_agency>&nbsp;</td><td>
<div>2020B1515120061&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>U1801265&nbsp;</div>
<div>U1908211&nbsp;</div>
<div>61976222&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guang-dong Natural Science Funds for Distinguished Young Scholar</grant_agency>&nbsp;</td><td>
<div>2019B151502031&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This study was supported in part by the Key-Area Research and Development Program of Guangdong Province (2019B010110 0 01) , in part by the Key Program for International Cooperation Projects of Guangdong Province (2018A050506031) , in part by the Natural Science Foundation of Guangdong Province (2020B1515120061) , in part by the National Natural Science Foundation of China (U1801265 , U1908211 , 61976222) , and in part by the Guang-dong Natural Science Funds for Distinguished Young Scholar (2019B151502031) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 3 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Echo-SyncNet: Self-Supervised Cardiac View Synchronization in Echocardiography</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Dezaki, FT (Dezaki, Fatemeh Taheri); Luong, C (Luong, Christina); Ginsberg, T (Ginsberg, Tom); Rohling, R (Rohling, Robert); Gin, K (Gin, Ken); Abolmaesumi, P (Abolmaesumi, Purang); Tsang, T (Tsang, Teresa)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>8</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2092-2104</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3071951</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 AUG</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
16</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>24</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
In echocardiography (echo), an electrocardiogram (ECG) is conventionally used to temporally align different cardiac views for assessing critical measurements. However, in emergencies or point-of-care situations, acquiring an ECG is often not an option, hence motivating the need for alternative temporal synchronization methods. Here, we propose Echo-SyncNet, a self-supervised learning framework to synchronize various cross-sectional 2D echo series without any human supervision or external inputs. The proposed framework takes advantage of two types of supervisory signals derived from the input data: spatiotemporal patterns found between the frames of a single cine (intra-view self-supervision) and interdependencies between multiple cines (inter-view self-supervision). The combined supervisory signals are used to learn a feature-rich and low dimensional embedding space where multiple echo cines can be temporally synchronized. Two intra-view self-supervisions are used, the first is based on the information encoded by the temporal ordering of a cine (temporal intra-view) and the second on the spatial similarities between nearby frames (spatial intra-view). The inter-view self-supervision is used to promote the learning of similar embeddings for frames captured from the same cardiac phase in different echo views. We evaluate the framework with multiple experiments: 1) Using data from 998 patients, Echo-SyncNet shows promising results for synchronizing Apical 2 chamber and Apical 4 chamber cardiac views, which are acquired spatially perpendicular to each other; 2) Using data from 3070 patients, our experiments reveal that the learned representations of Echo-SyncNet outperform a supervised deep learning method that is optimized for automatic detection of fine-grained cardiac cycle phase; 3) We go one step further and show the usefulness of the learned representations in a one-shot learning scenario of cardiac key-frame detection. Without any fine-tuning, key frames in 1188 validation patient studies are identified by synchronizing them with only one labeled reference cine. We do not make any prior assumption about what specific cardiac views are used for training, and hence we show that Echo-SyncNet can accurately generalize to views not present in its training set. Project repository: github.com/fatemehtd/Echo-SyncNet.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000679532100013</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33835916</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Synchronization; Training; Electrocardiography; Task analysis; Annotations; Echocardiography; Two dimensional displays; Echocardiography; fine-grained phase classification; self-supervised learning; synchronization</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Dezaki, Fatemeh Taheri; Abolmaesumi, Purang] Univ British Columbia, Dept Elect &amp; Comp Engn, Vancouver, BC V6T 1Z4, Canada. <br>
[Luong, Christina; Gin, Ken] Univ British Columbia, Vancouver Gen Hosp, Dept Med, Div Cardiol,Echocardiography Lab, Vancouver, BC V5Z 1M9, Canada. <br>
[Ginsberg, Tom] Univ British Columbia, Dept Engn Phys, Vancouver, BC V6T 1Z4, Canada. <br>
[Rohling, Robert] Univ British Columbia, Dept Elect &amp; Comp Engn, Vancouver, BC V6T 1Z4, Canada. <br>
[Rohling, Robert] Univ British Columbia, Dept Mech Engn, Vancouver, BC V6T 1Z4, Canada. <br>
[Tsang, Teresa] Vancouver Gen Hosp, Vancouver, BC V5Z 1M9, Canada. <br>
[Tsang, Teresa] Univ British Columbia, Dept Med, Div Cardiol, Echocardiog Lab, Vancouver, BC V5Z IM9, Canada. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Dezaki, FT (corresponding author), Univ British Columbia, Dept Elect &amp; Comp Engn, Vancouver, BC V6T 1Z4, Canada.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
fatemeht@ece.ubc.ca; christina.luong@ubc.ca; tom.ginsberg@alumni.ubc.ca; rohling@ece.ubc.ca; kenneth.gin@vch.ca; purang@ece.ubc.ca; t.tsang@ubc.ca</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of British Columbia; University of British Columbia; University of British Columbia; University of British Columbia; University of British Columbia; University of British Columbia; University of British Columbia</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gin, Kenneth</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6331-7003&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tsang, Teresa S.M.</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4865-7119&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Abolmaesumi, Purang</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-7259-8609&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Abolmaesumi, Purang</display_name>&nbsp;</td><td>AAE-6670-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ginsberg, Tom</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3458-5188&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Luong, Christina</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-7514-6069&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Dezaki, Fatemeh</display_name>&nbsp;</td><td>AAQ-5296-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tsang, Teresa</display_name>&nbsp;</td><td>AAO-3518-2021&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>TS3CQ</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Sciences and Engineering Research Council of Canada (NSERC)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Canadian Institutes of Health Research (CIHR)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the Natural Sciences and Engineering Research Council of Canada (NSERC) and in part by the Canadian Institutes of Health Research (CIHR). (Fatemeh Taheri Dezaki and Christina Luong contributed equally to this work as first authors.) (Purang Abolmaesumi and Teresa Tsang con-tributed equally to this work as senior authors.)</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted, Bronze</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 4 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Self-Supervised Feature Learning for Cardiac Cine MR Image Reconstruction</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Xu, SY (Xu, Siying); Fruh, M (Fruh, Marcel); Hammernik, K (Hammernik, Kerstin); Lingg, A (Lingg, Andreas); Kubler, J (Kubler, Jens); Krumm, P (Krumm, Patrick); Rueckert, D (Rueckert, Daniel); Gatidis, S (Gatidis, Sergios); K&uuml;stner, T (Kustner, Thomas)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>44</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>9</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>3858-3869</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2025.3570226</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 SEP</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
2</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>53</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
We propose a self-supervised feature learning assisted reconstruction (SSFL-Recon) framework for MRI reconstruction to address the limitation of existing supervised learning methods. Although recent deep learning-based methods have shown promising performance in MRI reconstruction, most require fully-sampled images for supervised learning, which is challenging in practice considering long acquisition times under respiratory or organ motion. Moreover, nearly all fully-sampled datasets are obtained from conventional reconstruction of mildly accelerated datasets, thus potentially biasing the achievable performance. The numerous undersampled datasets with different accelerations in clinical practice, hence, remain underutilized. To address these issues, we first train a self-supervised feature extractor on undersampled images to learn sampling-insensitive features. The pre-learned features are subsequently embedded in the self-supervised reconstruction network to assist in removing artifacts. Experiments were conducted retrospectively on an in-house 2D cardiac Cine dataset, including 91 cardiovascular patients and 38 healthy subjects. The results demonstrate that the proposed SSFL-Recon framework outperforms existing self-supervised MRI reconstruction methods and even exhibits comparable or better performance to supervised learning up to 16 x retrospective undersampling. The feature learning strategy can effectively extract global representations, which have proven beneficial in removing artifacts and increasing generalization ability during reconstruction.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001575893400005</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>40408221</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Image reconstruction; Feature extraction; Representation learning; Magnetic resonance imaging; Training; Imaging; Contrastive learning; Sensitivity; Reconstruction algorithms; Data mining; Self-supervised learning; feature learning; contrastive learning; cardiac Cine MRI; MRI reconstruction</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
PARALLEL MRI; SPARSITY; SENSE</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Xu, Siying; Fruh, Marcel; Lingg, Andreas; Kubler, Jens; Krumm, Patrick; Gatidis, Sergios; Kustner, Thomas] Univ Tubingen, Dept Diagnost &amp; Intervent Radiol, Med Image &amp; Data Anal MIDAS Lab, D-72074 Tubingen, Germany. <br>
[Rueckert, Daniel] Tech Univ Munich, Sch Computat Informat &amp; Technol, D-80333 Munich, Germany. <br>
[Rueckert, Daniel] Tech Univ Munich, Klinikum Rechts Isar, D-80333 Munich, Germany. <br>
[Rueckert, Daniel] Imperial Coll London, Dept Comp, London SW7 2AZ, England. <br>
[Gatidis, Sergios] Stanford Univ, Dept Radiol, Stanford, CA 94305 USA. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Xu, SY (corresponding author), Univ Tubingen, Dept Diagnost &amp; Intervent Radiol, Med Image &amp; Data Anal MIDAS Lab, D-72074 Tubingen, Germany.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
siying.xu@med.uni-tuebingen.de; marcel.frueh@med.uni-tuebingen.de; k.hammernik@tum.de; andreas.lingg@med.uni-tuebingen.de; jens.kuebler@med.uni-tuebingen.de; patrick.krumm@med.uni-tuebingen.de; daniel.rueckert@tum.de; sergios.gatidis@med.uni-tuebingen.de; thomas.kuestner@med.uni-tuebingen.de</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Eberhard Karls University of Tubingen; Eberhard Karls University Hospital; Technical University of Munich; Technical University of Munich; Imperial College London; Stanford University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Krumm, Patrick</display_name>&nbsp;</td><td>AAQ-6293-2020&nbsp;</td><td>0000-0003-1705-8439&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Rueckert, Daniel</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5683-5889&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>7OM6C</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>DeutscheForschungsgemeinschaft (DFG, German Research Foundation)</grant_agency>&nbsp;</td><td>
<div>390727645&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the DeutscheForschungsgemeinschaft (DFG, German Research Foundation) through Germany's Excellence Strategy-Clusters of Excellence (EXC) 2064/1 under Project 390727645.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 5 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A Generalisable Heartbeat Classifier Leveraging Self-Supervised Learning for ECG Analysis During Magnetic Resonance Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Aublin, PG (Aublin, Pierre Gabriel); Felblinger, J (Felblinger, Jacques); Oster, J (Oster, Julien)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>28</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>9</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>5147-5155</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2024.3411792</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 SEP</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
24</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>44</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Electrocardiogram (ECG) is acquired during Magnetic Resonance Imaging (MRI) to monitor patients and synchronize image acquisition with the heart motion. ECG signals are highly distorted during MRI due to the complex electromagnetic environment. Automated ECG analysis is therefore complicated in this context and there is no reference technique in MRI to classify pathological heartbeats. Imaging arrhythmic patients is hence difficult in MRI. Deep Learning based heartbeat classifier have been suggested but require large databases whereas existing annotated sets of ECG in MRI are very small. We proposed a Siamese network to leverage a large database of unannotated ECGs outside MRI. This was used to develop an efficient representation of ECG signals, further used to develop a heartbeat classifier. We extensively tested several data augmentations and self-supervised learning (SSL) techniques and assessed the generalization of the obtained classifier to ECG signals acquired in MRI. These augmentations included random noises and a model simulating MRI specific artefacts. SSL pretraining improved the generalizability of heartbeat classifiers in MRI (F1=0.75) compared to Deep Learning not relying on SSL (F1=0.46) and another classical machine learning approach (F1=0.40). These promising results seem to indicate that the use of SSL techniques can learn efficient ECG signal representation, and are useful for the development of Deep Learning models even when only scarce annotated medical data are available.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001309075700034</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>38857140</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram; magnethohydrodynamic effect; deep learning; representation learning; Siamese network; Electrocardiogram; magnethohydrodynamic effect; deep learning; representation learning; Siamese network</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ELECTROCARDIOGRAM; SIGNALS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Aublin, Pierre Gabriel; Felblinger, Jacques; Oster, Julien] Univ Lorraine, IADI, U1254, Inserm, F-54000 Nancy, France. <br>
[Aublin, Pierre Gabriel] Univ Augsburg, Chair Diagnost Sensing, D-86159 Augsburg, Germany. <br>
[Felblinger, Jacques; Oster, Julien] Univ Lorraine, CHRU Nancy, Inserm, CIC IT1433, F-54035 Nancy, France. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Oster, J (corresponding author), Univ Lorraine, IADI, U1254, Inserm, F-54000 Nancy, France.<br>Oster, J (corresponding author), Univ Lorraine, CHRU Nancy, Inserm, CIC IT1433, F-54035 Nancy, France.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
julien.oster@inserm.fr</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Universite de Lorraine; Institut National de la Sante et de la Recherche Medicale (Inserm); University of Augsburg; CHU de Nancy; Universite de Lorraine; Institut National de la Sante et de la Recherche Medicale (Inserm)</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Felblinger, Jacques</display_name>&nbsp;</td><td>ABG-2033-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Felblinger, jacques</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9245-6595&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>oster, Julien</display_name>&nbsp;</td><td>F-3597-2017&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Aublin, Pierre G.</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-8082-7811&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>F3T3E</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>9</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>ERA-CVD Joint Transnational Call 2019, MEIDIC-VTACH</grant_agency>&nbsp;</td><td>
<div>ANR-19-ECVD-0004&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Agence Nationale de la Recherche (ANR)</grant_agency>&nbsp;</td><td>
<div>ANR-19-ECVD-0004&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by ERA-CVD Joint Transnational Call 2019, MEIDIC-VTACH under Grant ANR-19-ECVD-0004.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 6 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Few-Shot Learning by a Cascaded Framework With Shape-Constrained Pseudo Label Assessment for Whole Heart Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wang, WJ (Wang, Wenji); Xia, Q (Xia, Qing); Hu, ZQ (Hu, Zhiqiang); Yan, ZN (Yan, Zhennan); Li, ZW (Li, Zhuowei); Wu, Y (Wu, Yang); Huang, N (Huang, Ning); Gao, Y (Gao, Yue); Metaxas, D (Metaxas, Dimitris); Zhang, ST (Zhang, Shaoting)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>10</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2629-2641</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3053008</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>39</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>40</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
34</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>51</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Automatic and accurate 3D cardiac image segmentation plays a crucial role in cardiac disease diagnosis and treatment. Even though CNN based techniques have achieved great success in medical image segmentation, the expensive annotation, large memory consumption, and insufficient generalization ability still pose challenges to their application in clinical practice, especially in the case of 3D segmentation from high-resolution and large-dimension volumetric imaging. In this paper, we propose a few-shot learning framework by combining ideas of semi-supervised learning and self-training for whole heart segmentation and achieve promising accuracy with a Dice score of 0.890 and a Hausdorff distance of 18.539 mm with only four labeled data for training. When more labeled data provided, the model can generalize better across institutions. The key to success lies in the selection and evolution of high-quality pseudo labels in cascaded learning. A shape-constrained network is built to assess the quality of pseudo labels, and the self-training stages with alternative global-local perspectives are employed to improve the pseudo labels. We evaluate our method on the CTA dataset of the MM-WHS 2017 Challenge and a larger multi-center dataset. In the experiments, our method outperforms the state-of-the-art methods significantly and has great generalization ability on the unseen data. We also demonstrate, by a study of two 4D (3D+T) CTA data, the potential of our method to be applied in clinical practice.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000702638800009</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33471751</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Whole heart segmentation; pseudo label; quality assessment; self-training; semi-supervised</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SPARSE REPRESENTATION; MODELS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wang, Wenji; Xia, Qing; Hu, Zhiqiang; Li, Zhuowei; Huang, Ning; Zhang, Shaoting] SenseTime Res, Beijing 100080, Peoples R China. <br>
[Xia, Qing] Tsinghua Univ, Dept Software, Beijing 100084, Peoples R China. <br>
[Yan, Zhennan] SenseBrain Technol Ltd LLC, Princeton, NJ 08540 USA. <br>
[Wu, Yang] Chinese Peoples Liberat Army Gen Hosp, Beijing 100853, Peoples R China. <br>
[Gao, Yue] Tsinghua Univ, Dept Software, Beijing 100084, Peoples R China. <br>
[Metaxas, Dimitris] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA. <br>
[Xia, Qing] Shanghai Jiao Tong Univ, Res Inst, Shanghai 200240, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Xia, Q (corresponding author), SenseTime Res, Beijing 100080, Peoples R China.<br>Xia, Q (corresponding author), Tsinghua Univ, Dept Software, Beijing 100084, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
wangwenji@sensetime.com; xiaqing@sensetime.com; huzhiqiang@sensetime.com; zhennanyan@sensebrain.site; lizhuowei@sensetime.com; 2225012218@qq.com; huangning@sensetime.com; gaoyue@tsinghua.edu.cn; dnm@cs.rutgers.edu; zhangshaoting@sensetime.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Tsinghua University; Chinese People's Liberation Army General Hospital; Tsinghua University; Rutgers University System; Rutgers University New Brunswick; Shanghai Jiao Tong University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gao, Yue</display_name>&nbsp;</td><td>B-3376-2012&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Xia, Qing</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0328-7882&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>hu, zhiqiang</display_name>&nbsp;</td><td>HMD-5811-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Shaoting</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-8719-448X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Wenji</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5529-9052&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>WA1FC</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Project of China</grant_agency>&nbsp;</td><td>
<div>Z201100006820064&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>STCSM</grant_agency>&nbsp;</td><td>
<div>2020YFC2004800&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Postdoctoral Research Foundation</grant_agency>&nbsp;</td><td>
<div>19511121400&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the BeijingNova Program under Grant Z201100006820064, in part by the National Key Research and Development Project of China under Grant 2020YFC2004800, in part by the STCSM under Grant 19511121400, and in part by the Beijing Postdoctoral Research Foundation.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 7 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>ECG Biometric Authentication Using Self-Supervised Learning for IoT Edge Sensors</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wang, GX (Wang, Guoxin); Shanker, S (Shanker, Shreejith); Nag, A (Nag, Avishek); Lian, Y (Lian, Yong); John, D (John, Deepu)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>28</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>11</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>6606-6618</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2024.3455803</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 NOV</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>10</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
6</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
31</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>43</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Wearable Internet of Things (IoT) devices are gaining ground for continuous physiological data acquisition and health monitoring. These physiological signals can be used for security applications to achieve continuous authentication and user convenience due to passive data acquisition. This paper investigates an electrocardiogram (ECG) based biometric user authentication system using features derived from the Convolutional Neural Network (CNN) and self-supervised contrastive learning. Contrastive learning enables us to use large unlabeled datasets to train the model and establish its generalizability. We propose approaches enabling the CNN encoder to extract appropriate features that distinguish the user from other subjects. When evaluated using the PTB ECG database with 290 subjects, the proposed technique achieved an authentication accuracy of 99.15%. To test its generalizability, we applied the model to two new datasets, the MIT-BIH Arrhythmia Database and the ECG-ID Database, achieving over 98.5% accuracy without any modifications. Furthermore, we show that repeating the authentication step three times can increase accuracy to nearly 100% for both PTBDB and ECGIDDB. This paper also presents model optimizations for embedded device deployment, which makes the system more relevant to real-world scenarios. To deploy our model in IoT edge sensors, we optimized the model complexity by applying quantization and pruning. The optimized model achieves 98.67% accuracy on PTBDB, with 0.48% accuracy loss and 62.6% CPU cycles compared to the unoptimized model. An accuracy-vs-time-complexity tradeoff analysis is performed, and results are presented for different optimization levels.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001359232100010</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>39250357</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Feature extraction; Electrocardiography; Authentication; Accuracy; Training; Contrastive learning; Biological system modeling; electrocardiogram authentication; IoT devices</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
FRAMEWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wang, Guoxin; John, Deepu] Univ Coll Dublin, Sch Elect &amp; Elect Engn, Dublin, Ireland. <br>
[Shanker, Shreejith] Trinity Coll Dublin, Dept Elect &amp; Elect Engn, Dublin, Ireland. <br>
[Nag, Avishek] Univ Coll Dublin, Sch Comp Sci, Dublin, Ireland. <br>
[Lian, Yong] York Univ, Dept Elect Engn &amp; Comp Sci, Toronto, ON M3J 1P3, Canada. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
John, D (corresponding author), Univ Coll Dublin, Sch Elect &amp; Elect Engn, Dublin, Ireland.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
guoxin.wang@ucdconnect.ie; shankers@tcd.ie; avishek.nag@ucd.ie; plian@yorku.ca; deepu.john@ucd.ie</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University College Dublin; Trinity College Dublin; University College Dublin; York University - Canada</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Guoxin</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3619-3399&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lian, Yong</display_name>&nbsp;</td><td>MSY-3562-2025&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Shanker, Shreejith</display_name>&nbsp;</td><td>HGT-9976-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Nag, Avishek</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1702-1492&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lian, Yong</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5289-5219&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>John, Deepu</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6139-1100&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>John, Deepu</display_name>&nbsp;</td><td>AAL-7045-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Nag, Avishek</display_name>&nbsp;</td><td>T-9268-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Guoxin</display_name>&nbsp;</td><td>LKM-8856-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>M7I4Z</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>China Scholarship Council</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>JEDAI Project through the Horizon 2020 FET Chist-Era Program</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Microelectronic Circuit Centre Ireland</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the China Scholarship Council, in part by the JEDAI Project through the Horizon 2020 FET Chist-Era Program and, in part by Microelectronic Circuit Centre Ireland.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 8 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>In-Distribution and Out-of-Distribution Self-Supervised ECG Representation Learning for Arrhythmia Detection</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Soltanieh, S (Soltanieh, Sahar); Hashemi, J (Hashemi, Javad); Etemad, A (Etemad, Ali)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>28</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>2</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>789-800</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2023.3331626</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 FEB</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>4</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>5</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
7</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
41</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>44</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This paper presents a systematic investigation into the effectiveness of Self-Supervised Learning (SSL) methods for Electrocardiogram (ECG) arrhythmia detection. We begin by conducting a novel analysis of the data distributions on three popular ECG-based arrhythmia datasets: PTB-XL, Chapman, and Ribeiro. To the best of our knowledge, our study is the first to quantitatively explore and characterize these distributions in the area. We then perform a comprehensive set of experiments using different augmentations and parameters to evaluate the effectiveness of various SSL methods, namely SimCRL, BYOL, and SwAV, for ECG representation learning, where we observe the best performance achieved by SwAV. Furthermore, our analysis shows that SSL methods achieve highly competitive results to those achieved by supervised state-of-the-art methods. To further assess the performance of these methods on both In-Distribution (ID) and Out-of-Distribution (OOD) ECG data, we conduct cross-dataset training and testing experiments. Our comprehensive experiments show almost identical results when comparing ID and OOD schemes, indicating that SSL techniques can learn highly effective representations that generalize well across different OOD datasets. This finding can have major implications for ECG-based arrhythmia detection. Lastly, to further analyze our results, we perform detailed per-disease studies on the performance of the SSL methods on the three datasets.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001203362500009</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37948139</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Arrhythmia detection; contrastive learning; electrocardiogram; self-supervised learning; in-distribution; out-of-distribution</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Soltanieh, Sahar; Etemad, Ali] Queens Univ, Dept Elect &amp; Comp Engn, Kingston, ON K7L 3N6, Canada. <br>
[Hashemi, Javad] Queens Univ, Sch Comp, Kingston, ON K7L 3N6, Canada. <br>
[Etemad, Ali] Queens Univ, Ingenu Labs Res Inst, Kingston, ON K7L 3N6, Canada. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Soltanieh, S (corresponding author), Queens Univ, Dept Elect &amp; Comp Engn, Kingston, ON K7L 3N6, Canada.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
sahar.soltanieh@queensu.ca; javad.hashemi@queensu.ca; ali.etemad@queensu.ca</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Queens University - Canada; Queens University - Canada; Ingenuity Labs Research Institute; Queens University - Canada</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hashemi, Javad</display_name>&nbsp;</td><td>D-5827-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Soltanieh, Sahar</display_name>&nbsp;</td><td>LCE-1157-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Soltanieh, Sahar</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0004-0724-1816&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Etemad, Ali</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7128-0220&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>NW0A0</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Sciences and Engineering Research Council of Canada</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>No Statement Available</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 9 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Self-Supervised, Non-Contact Heartbeat Detection Based on Ballistocardiograms Utilizing Physiological Information Guidance</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Jiao, CZ (Jiao, Changzhe); Yang, AY (Yang, Aoyu); Zhao, HT (Zhao, Hantao); Yi, RH (Yi, Ruhan); Gou, SP (Gou, Shuiping); Sha, Y (Sha, Yu); Wen, WS (Wen, Wanshun); Jiao, LC (Jiao, Licheng); Skubic, M (Skubic, Marjorie)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>29</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>4</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2589-2602</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2024.3509875</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 APR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
5</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>33</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Ballistocardiograms (BCG) is a passive, non-contact heart rate detection technology that requires no action on the part of the individual. However, during the BCG signal acquisition process, the surface pressure generated by cardiac contraction is easily disturbed by external factors, and as people's health deteriorates, the j-peak (the main peak of the BCG signal) is no longer prominent. Our aim is to establish a non-contact, self-supervised heart rate detection method based on physiological information, to improve the accuracy and robustness of BCG heart rate detection under wider and more adverse conditions. The algorithm is guided by the heart rate estimation based on BCG itself, thereby reconstructing a signal with physiological significance. We also propose a heartbeat mapping algorithm based on Bidirectional Long Short-Term Memory Network (BiLSTM) for extracting global deep features, achieving real-time heartbeat prediction, and eliminating local deviations brought about by reconstruction. To verify the effectiveness of the proposed method, this paper evaluated 40 young subjects and 4 elderly subjects. Compared with the existing state-of-the-art methods, beat-to-beat heart rate estimation and heartbeat detection both performed excellently, surpassing most methods using precise labels. The experimental results show that the proposed method achieves effective heartbeat detection, demonstrating robustness and effectiveness in the face of unavoidable noise and variations.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001459663700041</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>40030671</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Ballistocardiograms; heartbeat detection; non-contact; non-contact; physiological significance; physiological significance; self-supervised; self-supervised; self-supervised</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
BIDIRECTIONAL LSTM; SYSTEM</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Jiao, Changzhe; Yang, Aoyu; Zhao, Hantao; Gou, Shuiping; Sha, Yu; Jiao, Licheng] Xidian Univ, Sch Artificial Intelligence, Key Lab Intelligent Percept &amp; Image Understanding, Educ Minist China, Xian 710071, Peoples R China. <br>
[Yi, Ruhan; Skubic, Marjorie] Univ Missouri, Dept Elect Engn &amp; Comp Sci, Columbia, MO 65211 USA. <br>
[Wen, Wanshun] Zhejiang Prov Peoples Hosp, Dept Rehabil Med, Hangzhou 310024, Peoples R China. <br>
[Wen, Wanshun] Hangzhou Med Coll, Affiliated Peoples Hosp, Hangzhou 310053, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Gou, SP (corresponding author), Xidian Univ, Sch Artificial Intelligence, Key Lab Intelligent Percept &amp; Image Understanding, Educ Minist China, Xian 710071, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
shpgou@mail.xidian.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Xidian University; University of Missouri System; University of Missouri Columbia; Hangzhou Medical College; Zhejiang Provincial People's Hospital; Hangzhou Medical College</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Jiao, Changzhe</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1392-8348&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>0ZK6T</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>14</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62372358&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Inter-discipline Guidance Project of Xidian University</grant_agency>&nbsp;</td><td>
<div>21103240003&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of Zhejiang Province</grant_agency>&nbsp;</td><td>
<div>LGF20H020010&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under Grant 62372358 in part by the Inter-discipline Guidance Project of Xidian University under Grant 21103240003, and in part by the Natural Science Foundation of Zhejiang Province under Grant LGF20H020010.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 10 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Self-supervised representation learning from 12-lead ECG data</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Mehari, T (Mehari, Temesgen); Strodthoff, N (Strodthoff, Nils)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>COMPUTERS IN BIOLOGY AND MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>141</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>105114</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.compbiomed.2021.105114</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>DEC 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2022 FEB</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>95</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>106</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
95</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>39</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Clinical 12-lead electrocardiography (ECG) is one of the most widely encountered kinds of biosignals. Despite the increased availability of public ECG datasets, label scarcity remains a central challenge in the field. Self-supervised learning represents a promising way to alleviate this issue. This would allow to train more powerful models given the same amount of labeled data and to incorporate or improve predictions about rare diseases, for which training datasets are inherently limited. In this work, we put forward the first comprehensive assessment of self-supervised representation learning from clinical 12-lead ECG data. To this end, we adapt state-of-the-art self-supervised methods based on instance discrimination and latent forecasting to the ECG domain. In a first step, we learn contrastive representations and evaluate their quality based on linear evaluation performance on a recently established, comprehensive, clinical ECG classification task. In a second step, we analyze the impact of self-supervised pretraining on finetuned ECG classifiers as compared to purely supervised performance. For the best-performing method, an adaptation of contrastive predictive coding, we find a linear evaluation performance only 0.5% below supervised performance. For the finetuned models, we find improvements in downstream performance of roughly 1% compared to supervised performance, label efficiency, as well as robustness against physiological noise. This work clearly establishes the feasibility of extracting discriminative representations from ECG data via self-supervised learning and the numerous advantages when finetuning such representations on downstream tasks as compared to purely supervised training. As first comprehensive assessment of its kind in the ECG domain carried out exclusively on publicly available datasets, we hope to establish a first step towards reproducible progress in the rapidly evolving field of representation learning for biosignals.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000747358300005</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34973584</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Deep neural networks; Electrocardiography; Time series analysis; Unsupervised learning; Self-supervised learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ELECTROCARDIOGRAMS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Mehari, Temesgen] Phys Tech Bundesanstalt, Berlin, Germany. <br>
[Mehari, Temesgen; Strodthoff, Nils] Fraunhofer Heinrich Hertz Inst, Berlin, Germany. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Strodthoff, N (corresponding author), Carl von Ossietzky Univ Oldenburg, Oldenburg, Germany.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
temesgen.mehari@ptb.de; nils.strodthoff@uol.de</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Physikalisch-Technische Bundesanstalt (PTB); Fraunhofer Gesellschaft</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Mehari, Temesgen</display_name>&nbsp;</td><td>KCX-8728-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Strodthoff, Nils</display_name>&nbsp;</td><td>AAK-8661-2021&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Life Sciences &amp; Biomedicine - Other Topics; Computer Science; Engineering; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>YN6HS</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0010-4825</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-0534</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>COMPUT BIOL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Comput. Biol. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>8</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Bundesministerium fur Bildung und Forschung through the BIFOLD - Berlin Institute for the Foundations of Learning and Data</grant_agency>&nbsp;</td><td>
<div>01IS18025A&nbsp;</div>
<div>01IS18037A&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>MedalCare</grant_agency>&nbsp;</td><td>
<div>18HLT07&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EMPIR programme</grant_agency>&nbsp;</td><td>
<div>18HLT07&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>European Union's Horizon 2020 research and innovation programme</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the Bundesministerium fur Bildung und Forschung through the BIFOLD -Berlin Institute for the Foundations of Learning and Data (ref. 01IS18025A and ref. 01IS18037A) and 18HLT07 MedalCare. The project 18HLT07 MedalCare has received funding from the EMPIR programme co-financed by the participating states and from the European Union's Horizon 2020 research and innovation programme.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>hybrid, Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 11 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>AVP-AP: Self-Supervised Automatic View Positioning in 3D Cardiac CT via Atlas Prompting</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Fan, XL (Fan, Xiaolin); Wang, Y (Wang, Yan); Zhang, YY (Zhang, Yingying); Bao, MK (Bao, Mingkun); Jia, BS (Jia, Bosen); Lu, D (Lu, Dong); Gu, YF (Gu, Yifan); Cheng, J (Cheng, Jian); Zhu, HG (Zhu, Haogang)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>44</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>7</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2921-2932</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2025.3554785</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JUL</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
8</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
8</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>53</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Automatic view positioning is crucial for cardiac computed tomography (CT) examinations, including disease diagnosis and surgical planning. However, it is highly challenging due to individual variability and large 3D search space. Existing work needs labor-intensive and time-consuming manual annotations to train view-specific models, which are limited to predicting only a fixed set of planes. However, in real clinical scenarios, the challenge of positioning semantic 2D slices with any orientation into varying coordinate space in arbitrary 3D volume remains unsolved. We thus introduce a novel framework, AVP-AP, the first to use Atlas Prompting for self-supervised Automatic View Positioning in the 3D CT volume. Specifically, this paper first proposes an atlas prompting method, which generates a 3D canonical atlas and trains a network to map slices into their corresponding positions in the atlas space via a self-supervised manner. Then, guided by atlas prompts corresponding to the given query images in a reference CT, we identify the coarse positions of slices in the target CT volume using rigid transformation between the 3D atlas and target CT volume, effectively reducing the search space. Finally, we refine the coarse positions by maximizing the similarity between the predicted slices and the query images in the feature space of a given foundation model. Our framework is flexible and efficient compared to other methods, outperforming other methods by 19.8% average structural similarity (SSIM) in arbitrary view positioning and achieving 9% SSIM in two-chamber view compared to four radiologists. Meanwhile, experiments on a public dataset validate our framework's generalizability.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001523480800028</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>40138235</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Computed tomography; Three-dimensional displays; Planning; Standards; Solid modeling; Image segmentation; Anatomical structure; Predictive models; Foundation models; Computational modeling; Automatic view positioning; atlas prompting; cardiac computed tomography; foundation model; self-supervised learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
TO-VOLUME REGISTRATION; IMAGE REGISTRATION; FRAMEWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Fan, Xiaolin; Wang, Yan; Gu, Yifan] Beihang Univ, Sch Instrumentat &amp; Optoelect Engn, Beijing 100191, Peoples R China. <br>
[Zhang, Yingying; Zhu, Haogang] Beihang Univ, Hangzhou Int Innovat Inst, Data Sci &amp; Intelligent Comp Lab, Hangzhou 311115, Peoples R China. <br>
[Bao, Mingkun; Lu, Dong; Cheng, Jian; Zhu, Haogang] Beihang Univ, Sch Comp Sci &amp; Engn, Beijing 100191, Peoples R China. <br>
[Jia, Bosen] Victoria Univ Wellington, Sch Biol Sci, Wellington 6012, New Zealand. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhang, YY; Zhu, HG (corresponding author), Beihang Univ, Hangzhou Int Innovat Inst, Data Sci &amp; Intelligent Comp Lab, Hangzhou 311115, Peoples R China.<br>Cheng, J; Zhu, HG (corresponding author), Beihang Univ, Sch Comp Sci &amp; Engn, Beijing 100191, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
fanxiaolin.buaa@qq.com; wangyan9509@gmail.com; yingyingzhangbuaa@163.com; bravomikekilo@buaa.edu.cn; jiabose@myvuw.ac.nz; donglusx@gmail.com; guyifan@buaa.edu.cn; jian_cheng@buaa.edu.cn; haogangzhu@buaa.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Beihang University; Beihang University; Beihang University; Victoria University Wellington</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Jia, Bosen</display_name>&nbsp;</td><td>GSD-1813-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>zhang, yingying</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0964-1774&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>4PJ0F</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62406014&nbsp;</div>
<div>U21A20523&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Natural Science Foundation</grant_agency>&nbsp;</td><td>
<div>7244325&nbsp;</div>
<div>L222152&nbsp;</div>
<div>L242038&nbsp;</div>
<div>4252004&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Start-Up Funds of Hangzhou International Innovation Institute of Beihang University</grant_agency>&nbsp;</td><td>
<div>2024KQ045&nbsp;</div>
<div>2024KQ027&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Peking University Third Hospital Fund for Interdisciplinary Research</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under 62406014 and Grant U21A20523; in part by Beijing Natural Science Foundation underGrant 7244325, Grant L222152, Grant L242038, and Grant 4252004; in part by the Start-Up Funds of Hangzhou International Innovation Institute of Beihang University under Grant 2024KQ045 and Grant 2024KQ027; and in part by Peking University Third Hospital Fund for Interdisciplinary Research.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 12 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>MBSS-T1: Model-based subject-specific self-supervised motion correction for robust cardiac T1 mapping</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Hanania, E (Hanania, Eyal); Zehavi-Lenz, A (Zehavi-Lenz, Adi); Volovik, I (Volovik, Ilya); Link-Sourani, D (Link-Sourani, Daphna); Cohen, I (Cohen, Israel); Freiman, M (Freiman, Moti)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>102</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>103495</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2025.103495</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>FEB 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 MAY</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>1</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
3</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>41</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Cardiac T1 mapping is a valuable quantitative MRI technique for diagnosing diffuse myocardial diseases. Traditional methods, relying on breath-hold sequences and cardiac triggering based on an ECG signal, face challenges with patient compliance, limiting their effectiveness. Image registration can enable motion-robust cardiac T1 mapping, but inherent intensity differences between time points pose a challenge. We present MBSST1, a subject-specific self-supervised model for motion correction in cardiac T1 mapping. Physical constraints, implemented through a loss function comparing synthesized and motion-corrected images, enforce signal decay behavior, while anatomical constraints, applied via a Dice loss, ensure realistic deformations. The unique combination of these constraints results in motion-robust cardiac T1 mapping along the longitudinal relaxation axis. Ina 5-fold experiment on a public dataset of 210 patients (STONE sequence) and an internal dataset of 19 patients (MOLLI sequence), MBSS-T1 outperformed baseline deep-learning registration methods. It achieved superior model fitting quality (R2: 0.975 vs. 0.941, 0.946 for STONE; 0.987 vs. 0.982, 0.965 for MOLLI free- breathing; 0.994 vs. 0.993, 0.991 for MOLLI breath-hold), anatomical alignment (Dice: 0.89 vs. 0.84, 0.88 for STONE; 0.963 vs. 0.919, 0.851 for MOLLI free-breathing; 0.954 vs. 0.924, 0.871 for MOLLI breath-hold), and visual quality (4.33 vs. 3.38, 3.66 for STONE; 4.1 vs. 3.5, 3.28 for MOLLI free-breathing; 3.79 vs. 3.15, 2.84 for MOLLI breath-hold). MBSS-T1 enables motion-robust T1 mapping for broader patient populations, overcoming challenges such as suboptimal compliance, and facilitates free-breathing cardiac T1 mapping without requiring large annotated datasets. Our code is available at https://github.com/TechnionComputationalMRILab/MBSST1.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001432441300001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>39987819</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
T1 mapping; Motion correction; Myocardial imaging; Deep learning; Model-based deep learning; Free-breathing MRI</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
IMAGE REGISTRATION; MYOCARDIAL T-1; VOLUME; FRAMEWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Hanania, Eyal; Cohen, Israel] Technion IIT, Fac Elect &amp; Comp Engn, Haifa, Israel. <br>
[Zehavi-Lenz, Adi; Link-Sourani, Daphna; Freiman, Moti] Technion IIT, Fac Biomed Engn, Haifa, Israel. <br>
[Zehavi-Lenz, Adi; Link-Sourani, Daphna; Freiman, Moti] Technion IIT, Fac Biomed Engn, May Blum Dahl MRI Res Ctr, Haifa, Israel. <br>
[Volovik, Ilya] Bnai Zion Med Ctr, Haifa, Israel. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Hanania, E (corresponding author), Technion IIT, Fac Elect &amp; Comp Engn, Haifa, Israel.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
EyalHan@campus.technion.ac.il</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Technion Israel Institute of Technology; Technion Israel Institute of Technology; Technion Israel Institute of Technology; Bnai Zion Medical Center</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cohen, Israel</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-2556-3972&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Freiman, Moti</display_name>&nbsp;</td><td>B-2016-2013&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hanania, Eyal</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5268-8674&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>Y5H8V</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Israel-US Binational Science Foundation</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Israeli Ministry of Science and Technology</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Israel Innovation Authority</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Joint Microsoft Education</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Israel Inter-university Computation Center (IUCC) program</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by research grants from the Israel-US Binational Science Foundation, the Israeli Ministry of Science and Technology, the Israel Innovation Authority, and the joint Microsoft Education and the Israel Inter-university Computation Center (IUCC) program.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 13 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Self-supervised learning for Electrocardiogram classification using Lead Correlation and Decorrelation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, WH (Liu, Wenhan); Pan, SR (Pan, Shurong); Chang, S (Chang, Sheng); Huang, QJ (Huang, Qijun); Jiang, N (Jiang, Nan)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>APPLIED SOFT COMPUTING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>172</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>112871</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.asoc.2025.112871</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>FEB 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
8</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
11</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>41</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
In recent years, the development of deep learning has shown potential in the automatic analysis of electrocardiogram (ECG), aiding cardiologists in detecting cardiovascular diseases (CVDs). Generally, deep learning models depend on numerous labeled ECGs to train, but manual labeling of ECGs is costly as it requires considerable time and expertise. Self-supervised learning (SSL) can solve this problem by pretraining deep learning models with unlabeled ECGs, mitigating their reliance on labeled ECGs. This work proposes lead correlation and decorrelation (LCD) for effective and efficient SSL of ECGs. Concretely, LCD combines intra-lead correlation, inter-lead correlation, intra-lead and inter-lead decorrelation in pretraining. These mechanisms utilize multilead ECG characteristics: intra-lead invariance, inter-lead invariance, inter-lead variance, and intra-lead redundancy. After pretraining, LCD can provide a generic encoder for feature extraction of any ECG lead in a classification task. Benefitting from the effective pretraining mechanism, models with the encoders pretrained by LCD outperform most of the baselines. Compared with the best baseline, they achieve better/comparable classification performances in the same tasks with less pretraining time. Furthermore, LCD helps the models focus on critical features when training with insufficient labeled ECGs, reducing the reliance on labeled ECGs by 4 similar to 6x. All the results demonstrate that LCD is an effective and efficient method, boosting a broader application of deep learning to automatic ECG analysis. The code is available at https://github.com/Aiwiscal/ECG_SSL_LCD.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001429865400001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Self-supervised learning; Deep learning; Electrocardiogram; Representation learning</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Wenhan; Jiang, Nan] East China Jiaotong Univ, Sch Informat &amp; Software Engn, Nanchang 330013, Peoples R China. <br>
[Pan, Shurong; Chang, Sheng; Huang, Qijun] Wuhan Univ, Sch Phys &amp; Technol, Wuhan 430072, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liu, WH (corresponding author), East China Jiaotong Univ, Sch Informat &amp; Software Engn, Nanchang 330013, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
WHliu@ecjtu.edu.cn; panshurong@whu.edu.cn; changsheng@whu.edu.cn; huangqj@whu.edu.cn; jiangnan@ecjtu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
East China Jiaotong University; Wuhan University</td>
</tr>

<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>Y1M9G</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1568-4946</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-9681</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>APPL SOFT COMPUT</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Appl. Soft. Comput.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Early Career Young Scientific and Tech-nological Talent Training Program of Jiangxi Province</grant_agency>&nbsp;</td><td>
<div>20244BCE52162&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62062034&nbsp;</div>
<div>62172160&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Devel-opment Program of China</grant_agency>&nbsp;</td><td>
<div>2022YFB2602200&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Double Thousand Plan of Jiangxi Province</grant_agency>&nbsp;</td><td>
<div>JXSQ2023201010&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Jiangxi Province Key Laboratory of Advanced Network Computing</grant_agency>&nbsp;</td><td>
<div>2024SSY03071&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by Early Career Young Scientific and Tech-nological Talent Training Program of Jiangxi Province under Grant No. 20244BCE52162, National Natural Science Foundation of China under Grant No. 62062034 and 62172160, National Key Research and Devel-opment Program of China under Grant No. 2022YFB2602200, Double Thousand Plan of Jiangxi Province under Grant No. JXSQ2023201010 and Jiangxi Province Key Laboratory of Advanced Network Computing under Grant No. 2024SSY03071.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 14 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Explainable cardiac pathology classification on cine MRI with motion characterization by semi-supervised learning of apparent flow</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zheng, Q (Zheng, Qiao); Delingette, H (Delingette, Herve); Ayache, N (Ayache, Nicholas)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>56</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>80-95</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2019.06.001</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2019 AUG</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>67</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>77</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
24</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>45</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
We propose a method to classify cardiac pathology based on a novel approach to extract image derived features to characterize the shape and motion of the heart. An original semi-supervised learning procedure, which makes efficient use of a large amount of non-segmented images and a small amount of images segmented manually by experts, is developed to generate pixel-wise apparent flow between two time points of a 2D+t cine MRI image sequence. Combining the apparent flow maps and cardiac segmentation masks, we obtain a local apparent flow corresponding to the 2D motion of myocardium and ventricular cavities. This leads to the generation of time series of the radius and thickness of myocardial segments to represent cardiac motion. These time series of motion features are reliable and explainable characteristics of pathological cardiac motion. Furthermore, they are combined with shape-related features to classify cardiac pathologies. Using only nine feature values as input, we propose an explainable, simple and flexible model for pathology classification. On ACDC training set and testing set, the model achieves 95% and 94% respectively as classification accuracy. Its performance is hence comparable to that of the state-of-the-art. Comparison with various other models is performed to outline some advantages of our model. (C) 2019 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000480375900007</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>31200290</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac pathology; Classification; Cine MRI; Motion; Deep learning; Semi-supervised learning; Neural network; Apparent flow</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
REGISTRATION; DEMONS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zheng, Qiao; Delingette, Herve; Ayache, Nicholas] Univ Cote dAzur, INRIA, 2004 Route Lucioles, F-06902 Sophia Antipolis, France. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zheng, Q (corresponding author), Univ Cote dAzur, INRIA, 2004 Route Lucioles, F-06902 Sophia Antipolis, France.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
qiao.zheng@inria.fr</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Inria; Universite Cote d'Azur</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Delingette, Herve</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6050-5949&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Delingette, Herve</display_name>&nbsp;</td><td>NOF-5139-2025&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>IP9NC</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>16</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>European Research Council (MedYMA)</grant_agency>&nbsp;</td><td>
<div>ERC-AdG-2011-291080&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The authors acknowledge the partial support from the European Research Council (MedYMA ERC-AdG-2011-291080).</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 15 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>CalibrationPhys: Self-Supervised Video-Based Heart and Respiratory Rate Measurements by Calibrating Between Multiple Cameras</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Akamatsu, Y (Akamatsu, Yusuke); Umematsu, T (Umematsu, Terumi); Imaoka, H (Imaoka, Hitoshi)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>28</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>3</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>1460-1471</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2023.3345486</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>5</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>6</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
8</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>45</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Video-based heart and respiratory rate measurements using facial videos are more useful and user-friendly than traditional contact-based sensors. However, most of the current deep learning approaches require ground-truth pulse and respiratory waves for model training, which are expensive to collect. In this paper, we propose CalibrationPhys, a self-supervised video-based heart and respiratory rate measurement method that calibrates between multiple cameras. CalibrationPhys trains deep learning models without supervised labels by using facial videos captured simultaneously by multiple cameras. Contrastive learning is performed so that the pulse and respiratory waves predicted from the synchronized videos using multiple cameras are positive and those from different videos are negative. CalibrationPhys also improves the robustness of the models by means of a data augmentation technique and successfully leverages a pre-trained model for a particular camera. Experimental results utilizing two datasets demonstrate that CalibrationPhys outperforms state-of-the-art heart and respiratory rate measurement methods. Since we optimize camera-specific models using only videos from multiple cameras, our approach makes it easy to use arbitrary cameras for heart and respiratory rate measurements.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001180907300045</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>38127597</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Remote photoplethysmography; heart rate; respiratory rate; facial video; convolutional neural network; contrastive learning; pre-training</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NONCONTACT</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Akamatsu, Yusuke; Umematsu, Terumi; Imaoka, Hitoshi] NEC Corp Ltd, Biometr Res Labs, Kawasaki 2118666, Japan. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Akamatsu, Y (corresponding author), NEC Corp Ltd, Biometr Res Labs, Kawasaki 2118666, Japan.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
yusuke-akamatsu@nec.com; terumi@nec.com; h-imaoka_cb@nec.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
NEC Corporation</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Akamatsu, Yusuke</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9123-3955&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Akamatsu, Yusuke</display_name>&nbsp;</td><td>HNO-9146-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Umematsu, Terumi</display_name>&nbsp;</td><td>AAY-6635-2021&nbsp;</td><td>0000-0002-6328-0674&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>KO4Y9</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 16 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Score-Based Diffusion Models With Self-Supervised Learning for Accelerated 3D Multi-Contrast Cardiac MR Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, YY (Liu, Yuanyuan); Cui, ZX (Cui, Zhuo-Xu); Qin, SC (Qin, Shucong); Liu, CC (Liu, Congcong); Zheng, HR (Zheng, Hairong); Wang, HF (Wang, Haifeng); Zhou, YH (Zhou, Yihang); Liang, D (Liang, Dong); Zhu, YJ (Zhu, Yanjie)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>44</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>6</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2436-2448</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2025.3534206</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JUN</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
11</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
12</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>78</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
scan time significantly hinders the widespread applications of three-dimensional multi-contrast cardiac magnetic resonance (3D-MC-CMR) imaging. This study aims to accelerate 3D-MC-CMR acquisition by a novel method based on score-based diffusion models with self-supervised learning. Specifically, we first establish a mapping between the undersampled k-space measurements and the MR images, utilizing a self-supervised Bayesian reconstruction network. Secondly, we develop a joint score-based diffusion model on 3D-MC-CMR images to capture their inherent distribution. Senior Member, The 3D-MC-CMR images are finally reconstructed using the conditioned Langenvin Markov chain Monte Carlo sampling. This approach enables accurate reconstruction without fully sampled training data. Its performance was tested on the dataset acquired by a 3D joint myocardial T1 and T1 rho mapping sequence. The T1 and T1 rho maps were estimated via a dictionary matching method from the reconstructed images. Experimental results show that the proposed method outperforms traditional compressed sensing and existing self-supervised deep learning MRI reconstruction methods. It also achieves high quality T1 and T1 rho parametric maps close to the reference maps, even at a high acceleration rate of 14.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001502493100015</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>40031249</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Image reconstruction; Diffusion models; Magnetic resonance imaging; Training; Self-supervised learning; Three-dimensional displays; Myocardium; Data models; Neural networks; Interpolation; 3D cardiac magnetic resonance imaging; self-supervised; diffusion models; multi-contrast</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
PARALLEL MRI; RESONANCE; COMBINATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Yuanyuan; Qin, Shucong; Zheng, Hairong; Wang, Haifeng; Zhu, Yanjie] Chinese Acad Sci, Shenzhen Inst Adv Technol, Paul C Lauterbur Res Ctr Biomed Imaging, Shenzhen 518055, Guangdong, Peoples R China. <br>
[Liu, Yuanyuan] Natl Innovat Ctr Adv Med Devices, Shenzhen 518045, Guangdong, Peoples R China. <br>
[Cui, Zhuo-Xu; Zhou, Yihang; Liang, Dong] Chinese Acad Sci, Shenzhen Inst Adv Technol, Res Ctr Med AI, Shenzhen 518055, Guangdong, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhu, YJ (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Paul C Lauterbur Res Ctr Biomed Imaging, Shenzhen 518055, Guangdong, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
liuyy@siat.ac.cn; zx.cui@siat.ac.cn; idginshucong@163.com; cc.liu@siat.ac.cn; hr.zheng@siat.ac.cn; hf.wang1@siat.ac.cn; yh.zhou2@siat.ac.cn; dong.liang@siat.ac.cn; yj.zhu@siat.ac.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Yuanyuan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0131-2519&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Haifeng, Wang</display_name>&nbsp;</td><td>HQY-7721-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liang, Dong</display_name>&nbsp;</td><td>A-3335-2011&nbsp;</td><td>0000-0001-6257-0875&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>liu, xiao</display_name>&nbsp;</td><td>HMD-7454-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Congcong</display_name>&nbsp;</td><td>HLG-9805-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>3KL6Y</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Program of China</grant_agency>&nbsp;</td><td>
<div>2021YFF0501402&nbsp;</div>
<div>2023YFA1011403&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62322119&nbsp;</div>
<div>62201561&nbsp;</div>
<div>62206273&nbsp;</div>
<div>62476268&nbsp;</div>
<div>12226008&nbsp;</div>
<div>62125111&nbsp;</div>
<div>62106252&nbsp;</div>
<div>U22A20344&nbsp;</div>
<div>52293425&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guangdong Basic and Applied Basic Research Foundation</grant_agency>&nbsp;</td><td>
<div>2021A1515110540&nbsp;</div>
<div>2023A1515110476&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key Laboratory for Magnetic Resonance and Multimodality Imaging of Guangdong Province</grant_agency>&nbsp;</td><td>
<div>2023B1212060052&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shenzhen Science and Technology Program</grant_agency>&nbsp;</td><td>
<div>RCYX20210609104444089&nbsp;</div>
<div>JCYJ20240813155840052&nbsp;</div>
<div>JCYJ20220818101205012&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Key Research and Development Program of China under Grant 2021YFF0501402 and Grant 2023YFA1011403; in part by the National Natural Science Foundation of China under Grant 62322119, Grant 62201561, Grant 62206273, Grant 62476268, Grant 12226008, Grant 62125111, Grant 62106252, Grant U22A20344, and Grant 52293425; in part by Guangdong Basic and Applied Basic Research Foundation under Grant 2021A1515110540 and Grant 2023A1515110476; in part by Key Laboratory for Magnetic Resonance and Multimodality Imaging of Guangdong Province under Grant 2023B1212060052; and in part by Shenzhen Science and Technology Program under Grant RCYX20210609104444089, Grant JCYJ20240813155840052, and Grant JCYJ20220818101205012.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 17 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>An Efficient and Private ECG Classification System Using Split and Semi-Supervised Learning</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Ayad, A (Ayad, Ahmad); Barhoush, M (Barhoush, Mahdi); Frei, M (Frei, Marian); Volker, B (Volker, Benedikt); Schmeink, A (Schmeink, Anke)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>27</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>9</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>4261-4272</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2023.3281977</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 SEP</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>6</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>6</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
17</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>68</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Electrocardiography (ECG) is a standard diagnostic tool for evaluating the overall heart's electrical activity and is vital for detecting many cardiovascular diseases. Classifying ECG recordings using deep neural networks has been investigated in literature and has shown very good performance. However, this performance assumes that the training data is centralized, which is often not the case in real-life scenarios, where data resides in multiple places and only a small portion of it is labeled. Therefore, in this work, we propose an ECG classification system that focuses on preserving data privacy and enhancing overall system efficiency. We analyzed the complexity of previously proposed deep learning-based models and showed that the temporal convolutional network-based models (TCN) were the most efficient. Then, we built on the TCN models a modified split-learning (SL) system that achieves the same classification performance as the basic SL but reduces the communication overhead between the server and the client by 71.7% as well as reducing the computations at the client by 46.5% compared to the original SL system based on the TCN network. Finally, we implement semi-supervised learning in our system to enhance its classification performance by 9.1%-15.7%, when the training data consists only of 10% labeled data. We have tested our proposed system on a test IoT setup and it achieved satisfactory classification accuracy while being private and energy efficient for green-AI applications.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001064467900006</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37262112</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
ECG; privacy-aware machine learning; distributed machine learning; edge computing; energy-efficient machine learning; split-learning; autoencoder; semi-supervised learning; mean teacher; FixMatch</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Ayad, Ahmad; Barhoush, Mahdi; Frei, Marian; Volker, Benedikt; Schmeink, Anke] RWTH Univ, Chair Informat Theory &amp; Data Analyt INDA, D-52074 Aachen, Germany. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Ayad, A (corresponding author), RWTH Univ, Chair Informat Theory &amp; Data Analyt INDA, D-52074 Aachen, Germany.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
ahmad.ayad@inda.rwth-aachen.de; mahdi.barhoush@inda.rwth-aachen.de; marian.frei@rwth-aachen.de; benedikt.voelker@rwth-aachen.de; anke.schmeink@inda.rwth-aachen.de</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
RWTH Aachen University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ayad, Ahmad</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9081-1274&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Schmeink, Anke</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9929-2925&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Frei, Marian</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0002-6899-3013&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Barhoush, Mahdi</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3787-0662&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Volker, Benedikt</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0009-7266-7676&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>R5AE7</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Federal Ministry of Education and Research (BMBF, Germany) through NeuroSys: Impulse durch Anwendungen (Projekt D)</grant_agency>&nbsp;</td><td>
<div>03ZU1106DA&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the Federal Ministry of Education and Research (BMBF, Germany) through NeuroSys: Impulse durch Anwendungen (Projekt D) under Grant 03ZU1106DA.&amp; nbsp;</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 18 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Semi-Supervised Learning for Low-Cost Personalized Obstructive Sleep Apnea Detection Using Unsupervised Deep Learning and Single-Lead Electrocardiogram</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Hu, SC (Hu, Shuaicong); Wang, YN (Wang, Ya'nan); Liu, J (Liu, Jian); Yang, CW (Yang, Cuiwei); Wang, AG (Wang, Aiguo); Li, KZ (Li, Kuanzheng); Liu, WX (Liu, Wenxin)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>27</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>11</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>5281-5292</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2023.3304299</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 NOV</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>25</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>27</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
32</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>38</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Objective: Obstructive sleep apnea (OSA) is a common sleep-related breathing disorder that can lead to a wide range of health issues if left untreated. This study aims to address the lack of research on personalized models for single-lead electrocardiogram (ECG)-based OSA detection, by proposing an automatic semi-supervised algorithm for automated low-cost personalization fine-tuning. Methods: We utilize a convolutional neural network (CNN)-based auto-encoder (AE) with a modified training objective to detect anomalous region of OSA. An indicator based on model outputs is utilized as a benchmark measure to assign pseudo-labels with confidence to each sample. Finally, we perform validation of the semi-supervised algorithm on the same database and cross-database scenarios. Results: By introducing semi-supervised personalization, the accuracy, AUC, and mean absolute error (MAE) of the general model (GM) of 35 subjects from the same database are improved from 86.3%, 0.915, and 5.178 to 90.3%, 0.948, and 2.593. Simultaneously, in the validation of 25 subjects from a cross-database, the accuracy, AUC, and MAE of the GM are enhanced from 75.6%, 0.800, and 9.149 to 84.3%, 0.881, and 3.509. Conclusion: The improved version of AE demonstrates excellent adaptability in identifying abnormal features in OSA, employing a data-driven approach to assign pseudo-labels for unknown data automatically. Additionally, leveraging the pseudo-labels through a semi-supervised fine-tuning strategy provides a solution to overcome the limitation of clinical annotations, facilitating low-cost implementation of personalized models. Significance: The semisupervised approach proposed in this article provides a high-performance and annotation-free solution for personalized adjustment of automatic OSA detection.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001129955100008</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37566509</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Obstructive sleep apnea (OSA); electrocardiogram (ECG); auto-encoder (AE); semi-supervised</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SYSTEM</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Hu, Shuaicong; Wang, Ya'nan; Liu, Jian] Fudan Univ, Sch Informat Sci &amp; Technol, Ctr Biomed Engn, Shanghai 200433, Peoples R China. <br>
[Yang, Cuiwei] Fudan Univ, Sch Informat Sci &amp; Technol, Ctr Biomed Engn, Shanghai 200433, Peoples R China. <br>
[Yang, Cuiwei] Key Lab Med Imaging Comp &amp; Comp Assisted Interven, Shanghai 200093, Peoples R China. <br>
[Wang, Aiguo; Li, Kuanzheng; Liu, Wenxin] Xinghua City Peoples Hosp, Taizhou 225700, Jiangsu, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Yang, CW (corresponding author), Fudan Univ, Sch Informat Sci &amp; Technol, Ctr Biomed Engn, Shanghai 200433, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
22110720104@m.fudan.edu.cn; wangyn20@fudan.edu.cn; 22110720117@m.fudan.edu.cn; yangcw@fudan.edu.cn; xhwag@163.com; stronger1831@126.com; 450930173@qq.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Fudan University; Fudan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Wenxin</display_name>&nbsp;</td><td>LXW-5765-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Yang, Cuiwei</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3338-5835&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hu, shuaicong</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5458-0416&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Ya'nan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5599-3423&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Aiguo</display_name>&nbsp;</td><td>HNP-7198-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hu, Shuaicong</display_name>&nbsp;</td><td>NIU-9967-2025&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Jian</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5791-7221&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>DC9R2</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shanghai Science and Technology Support Project</grant_agency>&nbsp;</td><td>
<div>18441900900&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Medical Scientific Research Key Project of Jiangsu Commission of Health</grant_agency>&nbsp;</td><td>
<div>ZDB2020025&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by Shanghai Science and Technology Support Project under Grant 18441900900 and in part by the Medical Scientific Research Key Project of Jiangsu Commission of Health under Grant ZDB2020025.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 19 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Unsupervised Domain Adaptation With Variational Approximation for Cardiac Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wu, FP (Wu, Fuping); Zhuang, XH (Zhuang, Xiahai)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>12</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>3555-3567</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3090412</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 DEC</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>60</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>65</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
57</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>50</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Unsupervised domain adaptation is useful in medical image segmentation. Particularly, when ground truths of the target images are not available, domain adaptation can train a target-specific model by utilizing the existing labeled images from other modalities. Most of the reported works mapped images of both the source and target domains into a common latent feature space, and then reduced their discrepancy either implicitly with adversarial training or explicitly by directly minimizing a discrepancy metric. In this work, we propose a new framework, where the latent features of both domains are driven towards a common and parameterized variational form, whose conditional distribution given the image is Gaussian. This is achieved by two networks based on variational auto-encoders (VAEs) and a regularization for this variational approximation. Both of the VAEs, each for one domain, contain a segmentation module, where the source segmentation is trained in a supervised manner, while the target one is trained unsupervisedly. We validated the proposed domain adaptation method using two cardiac segmentation tasks, i.e., the cross-modality (CT and MR) whole heart segmentation and the cross-sequence cardiac MR segmentation. Results show that the proposed method achieved better accuracies compared to two state-of-the-art approaches and demonstrated good potential for cardiac segmentation. Furthermore, the proposed explicit regularization was shown to be effective and efficient in narrowing down the distribution gap between domains, which is useful for unsupervised domain adaptation. The code and data have been released via https://zmiclab.github.io/projects.html.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000724511900027</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34143733</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Image segmentation; Training; Task analysis; Data models; Adaptation models; Measurement; Feature extraction; Domain adaptation; variational approximation; explicit domain discrepancy; cardiac segmentation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
IMAGE; ALIGNMENT; NETWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wu, Fuping] Fudan Univ, Dept Stat Sch Management, Shanghai 200433, Peoples R China. <br>
[Wu, Fuping; Zhuang, Xiahai] Fudan Univ, Sch Data Sci, Shanghai 200433, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhuang, XH (corresponding author), Fudan Univ, Sch Data Sci, Shanghai 200433, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
17110690006@fudan.edu.cn; zxh@fudan.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Fudan University; Fudan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhuang, Xiahai</display_name>&nbsp;</td><td>AAH-6334-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wu, Fuping</display_name>&nbsp;</td><td>ABG-4545-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wu, Fuping</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7179-4766&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>XG1HV</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61971142&nbsp;</div>
<div>11871165&nbsp;</div>
<div>62111530195&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the National Natural Science Foundation of China under Grant 61971142, Grant 11871165, and Grant 62111530195.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 20 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Structure-Driven Unsupervised Domain Adaptation for Cross-Modality Cardiac Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Cui, ZM (Cui, Zhiming); Li, CJ (Li, Changjian); Du, ZX (Du, Zhixu); Chen, NL (Chen, Nenglun); Wei, GD (Wei, Guodong); Chen, RN (Chen, Runnan); Yang, L (Yang, Lei); Shen, DG (Shen, Dinggang); Wang, WP (Wang, Wenping)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>12</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>3604-3616</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3090432</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 DEC</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>29</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>33</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
45</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>52</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Performance degradation due to domain shift remains a major challenge in medical image analysis. Unsupervised domain adaptation that transfers knowledge learned from the source domain with ground truth labels to the target domain without any annotation is the mainstream solution to resolve this issue. In this paper, we present a novel unsupervised domain adaptation framework for cross-modality cardiac segmentation, by explicitly capturing a common cardiac structure embedded across different modalities to guide cardiac segmentation. In particular, we first extract a set of 3D landmarks, in a self-supervised manner, to represent the cardiac structure of different modalities. The high-level structure information is then combined with another complementary feature, the Canny edges, to produce accurate cardiac segmentation results both in the source and target domains. We extensively evaluate our method on the MICCAI 2017 MM-WHS dataset for cardiac segmentation. The evaluation, comparison and comprehensive ablation studies demonstrate that our approach achieves satisfactory segmentation results and outperforms state-of-the-art unsupervised domain adaptation methods by a significant margin.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000724511900031</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34161240</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Image segmentation; Feature extraction; Computed tomography; Magnetic resonance imaging; Three-dimensional displays; Task analysis; Image edge detection; Cross-modality learning; unsupervised domain adaptation; structure distillation; cardiac segmentation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SYNERGISTIC IMAGE; NETWORK; MRI</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Cui, Zhiming; Shen, Dinggang] ShanghaiTech Univ, Sch Biomed Engn, Shanghai 201210, Peoples R China. <br>
[Cui, Zhiming; Du, Zhixu; Chen, Nenglun; Wei, Guodong; Chen, Runnan; Yang, Lei; Wang, Wenping] Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China. <br>
[Li, Changjian] UCL, Dept Comp Sci, London WC1E 6EA, England. <br>
[Shen, Dinggang] Shanghai United Imaging Intelligence Co Ltd, Shanghai 200030, Peoples R China. <br>
[Shen, Dinggang] Korea Univ, Dept Artificial Intelligence, Seoul 02841, South Korea. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Shen, DG (corresponding author), ShanghaiTech Univ, Sch Biomed Engn, Shanghai 201210, Peoples R China.<br>Wang, WP (corresponding author), Univ Hong Kong, Dept Comp Sci, Hong Kong, Peoples R China.<br>Li, CJ (corresponding author), UCL, Dept Comp Sci, London WC1E 6EA, England.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
zmcui@cs.hku.hk; chjili2011@gmail.com; dzx3501@connect.hku.hk; chennenglun@gmail.com; g.d.wei.china@gmail.com; runnanchen@modontics.com; yanglei.dalian@gmail.com; dinggang.shen@gmail.com; wenping@cs.hku.hk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
ShanghaiTech University; University of Hong Kong; University of London; University College London; Korea University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Shen, Dinggang</display_name>&nbsp;</td><td>ABF-6812-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Du, Zhixu</display_name>&nbsp;</td><td>LQK-5797-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wei, Guodong</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6975-9865&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Li, Changjian</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0448-4957&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>chen, runnan</display_name>&nbsp;</td><td>KFA-0707-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>XG1HV</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 21 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A multi-module algorithm for heartbeat classification based on unsupervised learning and adaptive feature transfer</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wang, YN (Wang, Yanan); Hu, SC (Hu, Shuaicong); Liu, J (Liu, Jian); Zhong, GY (Zhong, Gaoyan); Yang, CW (Yang, Cuiwei)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>COMPUTERS IN BIOLOGY AND MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>170</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>108072</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.compbiomed.2024.108072</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JAN 2024</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>3</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>3</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
26</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>54</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
The scarcity of annotated data is a common issue in the realm of heartbeat classification based on deep learning. Transfer learning (TL) has emerged as an effective strategy for addressing this issue. However, current TL techniques in this realm overlook the probability distribution differences between the source domain (SD) and target domain (TD) databases. The motivation of this paper is to address the challenge of labeled data scarcity at the model level while exploring an effective method to eliminate domain discrepancy between SD and TD databases, especially when SD and TD are derived from inconsistent tasks. This study proposes a multi-module heartbeat classification algorithm. Initially, unsupervised feature extractors are designed to extract rich features from unlabeled SD and TD data. Subsequently, a novel adaptive transfer method is proposed to effectively eliminate domain discrepancy between features of SD for pre-training (PTF-SD) and features of TD for fine-tuning (FTF-TD). Finally, the adapted PTF-SD is employed to pre-train a designed classifier, and FTF-TD is used for classifier fine-tuning, with the objective of evaluating the algorithm's performance on the TD task. In our experiments, MNIST-DB serves as the SD database for handwritten digit image classification task, MIT-DB as the TD database for heartbeat classification task. The overall accuracy of classifying heartbeats into normal heartbeats, supraventricular ectopic beats (SVEBs), and ventricular ectopic beats (VEBs) reaches 96.7 %. Specifically, the sensitivity (Sen), positive predictive value (PPV), and F1 score for SVEBs are 0.802, 0.701, and 0.748, respectively. For VEBs, Sen, PPV, and F1 score are 0.976, 0.840, and 0.903, respectively. The results indicate that the proposed multi-module algorithm effectively addresses the challenge labeled data scarcity in heartbeat classification through unsupervised learning and adaptive feature transfer methods.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001171387100001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>38301518</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Annotated data scarcity; Heartbeat classification; Adaptive feature transfer; Unsupervised learning; Domain discrepancy</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CONVOLUTIONAL NEURAL-NETWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wang, Yanan; Hu, Shuaicong; Liu, Jian; Zhong, Gaoyan; Yang, Cuiwei] Fudan Univ, Ctr Biomed Engn, Sch Informat Sci &amp; Technol, Shanghai 200433, Peoples R China. <br>
[Yang, Cuiwei] Key Lab Med Imaging Comp &amp; Comp Assisted Intervent, Shanghai 200093, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Yang, CW (corresponding author), Fudan Univ, Ctr Biomed Engn, Sch Informat Sci &amp; Technol, Shanghai 200433, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
wangyn20@fudan.edu.cn; schu22@m.fudan.edu.cn; liuj22@m.fudan.edu.cn; zhonggaoyan@126.com; yangcw@fudan.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Fudan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hu, Shuaicong</display_name>&nbsp;</td><td>NIU-9967-2025&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Yang, Cuiwei</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3338-5835&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Life Sciences &amp; Biomedicine - Other Topics; Computer Science; Engineering; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>JE1D8</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0010-4825</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-0534</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>COMPUT BIOL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Comput. Biol. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shanghai Science and Technology Support Project</grant_agency>&nbsp;</td><td>
<div>18441900900&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by Shanghai Science and Technology Support Project under Grant 18441900900.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 22 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Constraint-Based Unsupervised Domain Adaptation Network for Multi-Modality Cardiac Image Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Du, XQ (Du, Xiuquan); Liu, YG (Liu, Yueguo)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>26</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>1</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>67-78</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2021.3126874</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2022 JAN</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>14</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>17</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
34</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>44</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
The cardiac CT and MRI images depict the various structures of the heart, which are very valuable for analyzing heart function. However, due to the difference in the shape of the cardiac images and imaging techniques, automatic segmentation is challenging. To solve this challenge, in this paper, we propose a new constraint-based unsupervised domain adaptation network. This network first performs mutual translation of images between different domains, it can provide training data for the segmentation model, and ensure domain invariance at the image level. Then, we input the target domain into the source domain segmentation model to obtain pseudo-labels and introduce cross-domain self-supervised learning between the two segmentation models. Here, a new loss function is designed to ensure the accuracy of the pseudo-labels. In addition, a cross-domain consistency loss is also introduced. Finally, we construct a multi-level aggregation segmentation network to obtain more refined target domain information. We validate our method on the public whole heart image segmentation challenge dataset and obtain experimental results of 82.9% and 5.5 on dice and average symmetric surface distance (ASSD), respectively. These experimental results prove that our method can provide important assistance in the clinical evaluation of unannotated cardiac datasets.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000745829300012</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34757915</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Image segmentation; Computed tomography; Heart; Training; Biomedical imaging; Magnetic resonance imaging; Adversarial machine learning; Unsupervised domain adaptation; multi-modality cardiac image; self-supervised learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SYNERGISTIC IMAGE</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Du, Xiuquan] Anhui Univ, Key Lab Intelligent Comp &amp; Signal Proc, Minist Educ, Hefei 240601, Peoples R China. <br>
[Du, Xiuquan; Liu, Yueguo] Anhui Univ, Sch Comp Sci &amp; Technol, Hefei 240601, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Du, XQ (corresponding author), Anhui Univ, Key Lab Intelligent Comp &amp; Signal Proc, Minist Educ, Hefei 240601, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
dxqllp@163.com; 2567470422@qq.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Anhui University; Anhui University</td>
</tr>

<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>YL3YF</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Research project of Anhui province</grant_agency>&nbsp;</td><td>
<div>KJ2020A0035&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by Natural Science Research project of Anhui province under Grant KJ2020A0035.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 23 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Toward Accurate Cardiac MRI Segmentation With Variational Autoencoder-Based Unsupervised Domain Adaptation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Cui, HF (Cui, Hengfei); Li, Y (Li, Yan); Wang, YF (Wang, Yifan); Xu, D (Xu, Di); Wu, LM (Wu, Lian-Ming); Xia, Y (Xia, Yong)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>43</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>8</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2924-2936</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2024.3382624</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 AUG</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>5</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>7</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
11</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
32</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>36</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Accurate myocardial segmentation is crucial in the diagnosis and treatment of myocardial infarction (MI), especially in Late Gadolinium Enhancement (LGE) cardiac magnetic resonance (CMR) images, where the infarcted myocardium exhibits a greater brightness. However, segmentation annotations for LGE images are usually not available. Although knowledge gained from CMR images of other modalities with ample annotations, such as balanced-Steady State Free Precession (bSSFP), can be transferred to the LGE images, the difference in image distribution between the two modalities (i.e., domain shift) usually results in a significant degradation in model performance. To alleviate this, an end-to-end Variational autoencoder based feature Alignment Module Combining Explicit and Implicit features (VAMCEI) is proposed. We first re-derive the Kullback-Leibler (KL) divergence between the posterior distributions of the two domains as a measure of the global distribution distance. Second, we calculate the prototype contrastive loss between the two domains, bringing closer the prototypes of the same category across domains and pushing away the prototypes of different categories within or across domains. Finally, a domain discriminator is added to the output space, which indirectly aligns the feature distribution and forces the extracted features to be more favorable for segmentation. In addition, by combining CycleGAN and VAMCEI, we propose a more refined multi-stage unsupervised domain adaptation (UDA) framework for myocardial structure segmentation. We conduct extensive experiments on the MSCMRSeg 2019, MyoPS 2020 and MM-WHS 2017 datasets. The experimental results demonstrate that our framework achieves superior performances than state-of-the-art methods.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001285367200007</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>38546999</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Feature extraction; Image segmentation; Myocardium; Semantics; Annotations; Image reconstruction; Training; Cardiac segmentation; domain adaptation; multi-modal MRI; variational autoencoder</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Cui, Hengfei] Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated Aerosp Ground Ocean Big D, Xian 710072, Peoples R China. <br>
[Cui, Hengfei] Northwestern Polytech Univ, Res &amp; Dev Inst, Shenzhen 518057, Peoples R China. <br>
[Cui, Hengfei] Northwestern Polytech Univ, Chongqing Innovat Ctr, Chongqing 401135, Peoples R China. <br>
[Li, Yan; Wang, Yifan; Xia, Yong] Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated Aerosp Ground Ocean Big D, Xian 710072, Peoples R China. <br>
[Xu, Di] Media Innovat Lab, Huawei Cloud, Xian 710075, Peoples R China. <br>
[Wu, Lian-Ming] Shanghai Jiao Tong Univ, Renji Hosp, Sch Med, Dept Radiol, Shanghai 200127, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Xia, Y (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated Aerosp Ground Ocean Big D, Xian 710072, Peoples R China.<br>Wu, LM (corresponding author), Shanghai Jiao Tong Univ, Renji Hosp, Sch Med, Dept Radiol, Shanghai 200127, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
hfcui@nwpu.edu.cn; yanli.master1@gmail.com; yifanwang0229@163.com; xudi21@huawei.com; wlmssmu@126.com; yxia@nwpu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Northwestern Polytechnical University; Northwestern Polytechnical University; Northwestern Polytechnical University; Northwestern Polytechnical University; Huawei Technologies; Shanghai Jiao Tong University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Li, Yan</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0000-1331-9182&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wu, Lian-Ming</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7381-5436&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Yifan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-4519-7535&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cui, Hengfei</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-8625-2521&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Yifan</display_name>&nbsp;</td><td>JDM-1982-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>A8Z6G</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62271405&nbsp;</div>
<div>62171377&nbsp;</div>
<div>82171884&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guangdong Basic and Applied Basic Research Foundation</grant_agency>&nbsp;</td><td>
<div>2023A1515012847&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of Chongqing, China</grant_agency>&nbsp;</td><td>
<div>CSTB2023NSCQ-MSX0286;&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key Research and Development Program of Shaanxi Province, China</grant_agency>&nbsp;</td><td>
<div>2022GY-084&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shenzhen Science and Technology Program</grant_agency>&nbsp;</td><td>
<div>JCYJ20220530161616036&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shanghai Municipal Commission of Science and Technology Medical Innovation Research Special Project</grant_agency>&nbsp;</td><td>
<div>23Y11906900&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Shanghai "Yiyuan New Star" Outstanding Youth Talent (Excellent Program)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under Grant 62271405, Grant 62171377, and Grant 82171884; in part by Guangdong Basic and Applied Basic Research Foundation under Grant 2023A1515012847; in part by the Natural Science Foundation of Chongqing, China, under Grant CSTB2023NSCQ-MSX0286; in part by the Key Research and Development Program of Shaanxi Province, China, under Grant 2022GY-084; in part by Shenzhen Science and Technology Program under Grant JCYJ20220530161616036; in part by Shanghai Municipal Commission of Science and Technology Medical Innovation Research Special Project under Grant 23Y11906900; and in part by Shanghai "Yiyuan New Star" Outstanding Youth Talent (Excellent Program).</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 24 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Bidirectional cross-modality unsupervised domain adaptation using generative adversarial networks for cardiac image segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Cui, HF (Cui, Hengfei); Chang, YW (Chang Yuwen); Lei, J (Lei Jiang); Yong, X (Yong Xia); Zhang, YN (Zhang, Yanning)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>COMPUTERS IN BIOLOGY AND MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>136</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>104726</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.compbiomed.2021.104726</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>AUG 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 SEP</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>27</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>30</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
53</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>50</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Background: A novel Generative Adversarial Networks (GAN) based bidirectional cross-modality unsupervised domain adaptation (GBCUDA) framework is developed for cardiac image segmentation, which can effectively tackle the problem of network's segmentation performance degradation when adapting to the target domain without ground truth labels. Method: GBCUDA uses GAN for image alignment, applies adversarial learning to extract image features, and gradually enhances the domain invariance of extracted features. The shared encoder performs an end-to-end learning task in which features that differ between the two domains complement each other. The selfattention mechanism is incorporated to the GAN network, which can generate details based on the prompts of all feature positions. Furthermore, spectrum normalization is implemented to stabilize the training of GAN, and knowledge distillation loss is introduced to process high-level feature-maps in order to better complete the crossmode segmentation task. Results: The effectiveness of our proposed unsupervised domain adaptation framework is tested over the MultiModality Whole Heart Segmentation (MM-WHS) Challenge 2017 dataset. The proposed method is able to improve the average Dice from 74.1% to 81.5% for the four cardiac substructures, and reduce the average symmetric surface distance (ASD) from 7.0 to 5.8 over CT images. For MRI images, our proposed framework trained on CT images gives the average Dice of 59.2% and reduces the average ASD from 5.7 to 4.9. Conclusions: The evaluation results demonstrate our method's effectiveness on domain adaptation and the superiority to the current state-of-the-art domain adaptation methods.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000707411400002</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34371318</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Generative adversarial networks; Unsupervised domain adaptation; Cardiac segmentation; Self-attention mechanism; Knowledge distillation loss</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SYNERGISTIC IMAGE; HEART</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Cui, Hengfei; Chang Yuwen; Lei Jiang; Yong Xia; Zhang, Yanning] Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated Aerosp Ground Ocean Big, Xian 710072, Peoples R China. <br>
[Cui, Hengfei; Chang Yuwen; Lei Jiang; Yong Xia] Northwestern Polytech Univ, Sch Comp Sci &amp; Engn, Ctr Multidisciplinary Convergence Comp CMCC, Xian 710072, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Cui, HF (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Natl Engn Lab Integrated Aerosp Ground Ocean Big, Xian 710072, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
hfcui@nwpu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Northwestern Polytechnical University; Northwestern Polytechnical University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>lei, jiang</display_name>&nbsp;</td><td>GQA-9644-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Zhi-jun</display_name>&nbsp;</td><td>HGE-3958-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cui, Hengfei</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-8625-2521&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Life Sciences &amp; Biomedicine - Other Topics; Computer Science; Engineering; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>WH0XE</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0010-4825</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-0534</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>COMPUT BIOL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Comput. Biol. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61801393&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Fundamental Research Funds for the Central Universities</grant_agency>&nbsp;</td><td>
<div>3102020QD1001&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The study was supported in part by the National Natural Science Foundation of China under Grant 61801393, and in part by the Fundamental Research Funds for the Central Universities under Grant 3102020QD1001.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 25 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Unlocking the diagnostic potential of electrocardiograms through information transfer from cardiac magnetic resonance imaging</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Turgut,&Ouml; (Turgut, Ozgun); M&uuml;ller, P (Mueller, Philip); Hager, P (Hager, Paul); Shit, S (Shit, Suprosanna); Starck, S (Starck, Sophie); Menten, MJ (Menten, Martin J.); Martens, E (Martens, Eimo); Rueckert, D (Rueckert, Daniel)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>101</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>103451</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2024.103451</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JAN 2025</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 APR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
8</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>73</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Cardiovascular diseases (CVD) can be diagnosed using various diagnostic modalities. The electrocardiogram (ECG) is a cost-effective and widely available diagnostic aid that provides functional information of the heart. However, its ability to classify and spatially localise CVD is limited. In contrast, cardiac magnetic resonance (CMR) imaging provides detailed structural information of the heart and thus enables evidence- based diagnosis of CVD, but long scan times and high costs limit its use in clinical routine. In this work, we present a deep learning strategy for cost-effective and comprehensive cardiac screening solely from ECG. Our approach combines multimodal contrastive learning with masked data modelling to transfer domain-specific information from CMR imaging to ECG representations. In extensive experiments using data from 40,044 UK Biobank subjects, we demonstrate the utility and generalisability of our method for subject-specific risk prediction of CVD and the prediction of cardiac phenotypes using only ECG data. Specifically, our novel multimodal pre-training paradigm improves performance by up to 12.19% for risk prediction and 27.59% for phenotype prediction. Ina qualitative analysis, we demonstrate that our learned ECG representations incorporate information from CMR image regions of interest. Our entire pipeline is publicly available at https://github.com/oetu/MMCL-ECG-CMR.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001409219400001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>39793216</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram; Cardiac magnetic resonance imaging; Multimodal contrastive learning; Masked data modelling; Self-supervised learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
DIABETES-MELLITUS; HEART-FAILURE; SEGMENTATION; DYSFUNCTION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Turgut, Ozgun; Mueller, Philip; Hager, Paul; Starck, Sophie; Menten, Martin J.; Rueckert, Daniel] Tech Univ Munich, Sch Computat Informat &amp; Technol, Munich, Germany. <br>
[Turgut, Ozgun; Mueller, Philip; Hager, Paul; Starck, Sophie; Martens, Eimo; Rueckert, Daniel] Tech Univ Munich, Sch Med, Klinikum Rechts Isar, Munich, Germany. <br>
[Shit, Suprosanna] Univ Zurich, Dept Quant Biomed, Zurich, Switzerland. <br>
[Menten, Martin J.; Rueckert, Daniel] Munich Ctr Machine Learning, Munich, Germany. <br>
[Menten, Martin J.; Rueckert, Daniel] Imperial Coll London, Dept Comp, London, England. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Turgut,&Ouml; (corresponding author), Tech Univ Munich, Sch Computat Informat &amp; Technol, Munich, Germany.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
oezguen.turgut@tum.de</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Technical University of Munich; Technical University of Munich; University of Zurich; Imperial College London</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>M&uuml;ller, Philip</display_name>&nbsp;</td><td>HOH-3993-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hager, Paul</display_name>&nbsp;</td><td>KVZ-2285-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Shit, Suprosanna</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4435-7207&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Rueckert, Daniel</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5683-5889&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Menten, Martin</display_name>&nbsp;</td><td>JAO-3681-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Shit, Suprosanna</display_name>&nbsp;</td><td>AET-7423-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Martens, Eimo</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5801-0901&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hager, Paul</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2166-0262&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Martens, Eimo</display_name>&nbsp;</td><td>AAX-3975-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Turgut, Ozgun</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0002-8704-0277&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Muller, Philip</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-8186-6479&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>U1B0L</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>UK Biobank Resource</grant_agency>&nbsp;</td><td>
<div>87802&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This research has been conducted using the UK Biobank Resource under Application Number 87802.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>hybrid</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 26 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Adapt Everywhere: Unsupervised Adaptation of Point-Clouds and Entropy Minimization for Multi-Modal Cardiac Image Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Vesal, S (Vesal, Sulaiman); Gu, MX (Gu, Mingxuan); Kosti, R (Kosti, Ronak); Maier, A (Maier, Andreas); Ravikumar, N (Ravikumar, Nishant)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>7</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>1838-1851</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3066683</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 JUL</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>33</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>36</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
37</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>47</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Deep learning models are sensitive to domain shift phenomena. A model trained on images from one domain cannot generalise well when tested on images from a different domain, despite capturing similar anatomical structures. It is mainly because the data distribution between the two domains is different. Moreover, creating annotation for every new modality is a tedious and time-consuming task, which also suffers from high inter- and intra- observer variability. Unsupervised domain adaptation (UDA) methods intend to reduce the gap between source and target domains by leveraging source domain labelled data to generate labels for the target domain. However, current state-of-the-art (SOTA) UDA methods demonstrate degraded performance when there is insufficient data in source and target domains. In this paper, we present a novel UDA method for multi-modal cardiac image segmentation. The proposed method is based on adversarial learning and adapts network features between source and target domain in different spaces. The paper introduces an end-to-end framework that integrates: a) entropy minimization, b) output feature space alignment and c) a novel point-cloud shape adaptation based on the latent features learned by the segmentation model. We validated our method on two cardiac datasets by adapting from the annotated source domain, bSSFP-MRI (balanced Steady-State Free Procession-MRI), to the unannotated target domain, LGE-MRI (Late-gadolinium enhance-MRI), for the multi-sequence dataset; and from MRI (source) to CT (target) for the cross-modality dataset. The results highlighted that by enforcing adversarial learning in different parts of the network, the proposed method delivered promising performance, compared to other SOTA methods.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000668842500009</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33729930</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Image segmentation; Shape; Entropy; Magnetic resonance imaging; Minimization; Adaptation models; Training; Unsupervised domain adaptation; cardiac segmentation; multi-modal segmentation; adversarial learning; point-clouds; entropy minimization</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CARDIOVASCULAR MAGNETIC-RESONANCE; DOMAIN ADAPTATION; SYNERGISTIC IMAGE</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Vesal, Sulaiman; Gu, Mingxuan; Kosti, Ronak; Maier, Andreas] Friedrich Alexander Univ Erlangen Nuremberg, Pattern Recognit Lab, D-91054 Erlangen, Germany. <br>
[Ravikumar, Nishant] Univ Leeds, Ctr Computat Imaging &amp; Simulat Technol Biomed CIS, Sch Comp, Leeds Inst Cardiovasc &amp; Metab Med LICAMM,Sch Med, Leeds LS2 9JT, W Yorkshire, England. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Vesal, S (corresponding author), Friedrich Alexander Univ Erlangen Nuremberg, Pattern Recognit Lab, D-91054 Erlangen, Germany.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
sulaiman.vesal@fau.cie; mingxuan.gu@fau.de; ronak.kosti@fau.de; andreas.maier@fau.de; n.ravikumar@leeds.ac.uk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Erlangen Nuremberg; University of Leeds</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Maier, Andreas</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9550-5284&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>KOSTI, RONAK</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2453-7876&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ravikumar, Nishant</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0134-107X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Vesal, Sulaiman</display_name>&nbsp;</td><td>ABF-2407-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Vesal, Sulaiman</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6156-9338&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Maier, Andreas</display_name>&nbsp;</td><td>AAV-6505-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gu, Mingxuan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5244-4397&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gu, Mingxuan</display_name>&nbsp;</td><td>ACT-7421-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>TC7TP</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>14</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Project EFI-BIG-THERA: Integrative "BigData Modeling"</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>Manuscript received January 27, 2021; revised March 8, 2021; accepted March 14, 2021. Date of publication March 17, 2021; date of current version June 30, 2021. This work was supported by the Project EFI-BIG-THERA: Integrative "BigData Modeling" for the development of novel therapeutic approaches for breast cancer. (Corresponding author: Sulaiman Vesal.)</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 27 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Super-Resolution of Cardiac MR Cine Imaging using Conditional GANs and Unsupervised Transfer Learning</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Xia, Y (Xia, Yan); Ravikumar, N (Ravikumar, Nishant); Greenwood, JP (Greenwood, John P.); Neubauer, S (Neubauer, Stefan); Petersen, SE (Petersen, Steffen E.); Frangi, AF (Frangi, Alejandro F.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>71</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>102037</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2021.102037</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>APR 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 JUL</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>46</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>50</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
39</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>60</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
High-resolution (HR), isotropic cardiac Magnetic Resonance (MR) cine imaging is challenging since it requires long acquisition and patient breath-hold times. Instead, 2D balanced steady-state free precession (SSFP) sequence is widely used in clinical routine. However, it produces highly-anisotropic image stacks, with large through-plane spacing that can hinder subsequent image analysis. To resolve this, we propose a novel, robust adversarial learning super-resolution (SR) algorithm based on conditional generative adversarial nets (GANs), that incorporates a state-of-the-art optical flow component to generate an auxiliary image to guide image synthesis. The approach is designed for real-world clinical scenarios and requires neither multiple low-resolution (LR) scans with multiple views, nor the corresponding HR scans, and is trained in an end-to-end unsupervised transfer learning fashion. The designed framework effectively incorporates visual properties and relevant structures of input images and can synthesise 3D isotropic, anatomically plausible cardiac MR images, consistent with the acquired slices. Experimental results show that the proposed SR method outperforms several state-of-the-art methods both qualitatively and quantitatively. We show that subsequent image analyses including ventricle segmentation, cardiac quantification, and non-rigid registration can benefit from the super-resolved, isotropic cardiac MR images, to produce more accurate quantitative results, without increasing the acquisition time. The average Dice similarity coefficient (DSC) for the left ventricular (LV) cavity and myocardium are 0.95 and 0.81, respectively, between real and synthesised slice segmentation. For non-rigid registration and motion tracking through the cardiac cycle, the proposed method improves the average DSC from 0.75 to 0.86, compared to the original resolution images.
<br>(c) 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ )</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000663615600008</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33910110</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac MRI; Deep learning; Super-resolution; Conditional generative adversarial net; Optical flow; Conditional batch normalisation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CARDIOVASCULAR MAGNETIC-RESONANCE; UK BIOBANK; RESOLUTION; RATIONALE; DESIGN</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Xia, Yan; Ravikumar, Nishant; Frangi, Alejandro F.] Univ Leeds, Sch Comp, Ctr Computat Imaging &amp; Simulat Technol Biomed CIS, Leeds, W Yorkshire, England. <br>
[Xia, Yan; Ravikumar, Nishant; Greenwood, John P.; Frangi, Alejandro F.] Univ Leeds, Sch Med, Leeds Inst Cardiovasc &amp; Metab Med LICAMM, Leeds, W Yorkshire, England. <br>
[Neubauer, Stefan] Univ Oxford, John Radcliffe Hosp, Div Cardiovasc Med, Oxford Ctr Clin Magnet Resonance Res, Oxford, England. <br>
[Petersen, Steffen E.] Queen Mary Univ London, NIHR Barts Biomed Res Ctr, William Harvey Res Inst, London, England. <br>
[Petersen, Steffen E.] Barts Hlth NHS Trust, St Bartholomews Hosp, Barts Heart Ctr, London, England. <br>
[Frangi, Alejandro F.] Katholieke Univ Leuven, Cardiovasc Sci Dept, Med Imaging Res Ctr MIRC, Leuven, Belgium. <br>
[Frangi, Alejandro F.] Katholieke Univ Leuven, Dept Elect Engn, Med Imaging Res Ctr MIRC, Leuven, Belgium. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Xia, Y (corresponding author), Univ Leeds, Sch Comp, Ctr Computat Imaging &amp; Simulat Technol Biomed CIS, Leeds, W Yorkshire, England.<br>Xia, Y (corresponding author), Univ Leeds, Sch Med, Leeds Inst Cardiovasc &amp; Metab Med LICAMM, Leeds, W Yorkshire, England.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
y.xia@leeds.ac.uk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Leeds; University of Leeds; University of Oxford; University of London; Queen Mary University London; Barts Health NHS Trust; University of London; Queen Mary University London; KU Leuven; KU Leuven</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Neubauer, Stefan</display_name>&nbsp;</td><td>B-8448-2011&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Neubauer, Stefan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9017-5645&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Frangi, Alejandro</display_name>&nbsp;</td><td>C-6500-2008&nbsp;</td><td>0000-0002-2675-528X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Greenwood, John</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-2861-0914&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ravikumar, Nishant</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0134-107X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Petersen, Steffen</display_name>&nbsp;</td><td>A-8389-2011&nbsp;</td><td>0000-0003-4622-5160&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>SV1WP</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>17</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Royal Academy of Engineering Chair in Emerging Technologies Scheme</grant_agency>&nbsp;</td><td>
<div>CiET1819/19&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EPSRC</grant_agency>&nbsp;</td><td>
<div>POC041&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>MedIAN Network</grant_agency>&nbsp;</td><td>
<div>EP/N026993/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Engineering and Physical Sciences Research Council (EPSRC)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EPSRC through TUSCA</grant_agency>&nbsp;</td><td>
<div>EP/V04799X/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>SmartHeart EPSRC programme</grant_agency>&nbsp;</td><td>
<div>EP/P001009/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>British Heart Foundation</grant_agency>&nbsp;</td><td>
<div>PG/14/89/31194&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Institute for Health Research (NIHR) Barts Biomedical Research Centre</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>European Union' s Horizon 2020 research and innovation programme</grant_agency>&nbsp;</td><td>
<div>825903&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>British Heart Foundation</grant_agency>&nbsp;</td><td>
<div>PG/14/89/31194&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Engineering and Physical Sciences Research Council</grant_agency>&nbsp;</td><td>
<div>EP/N026993/1&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This research has been conducted using the UK Biobank Resource under Application 11350. The cardiac MR images presented in Figs. 1, 2, 6, 7, 8, 9, 10, 11, 16 and 18 in the manuscript were reproduced with the permission of UK Biobank (c). The authors are grateful to all UK Biobank participants and staff. AFF acknowledges support from the Royal Academy of Engineering Chair in Emerging Technologies Scheme (CiET1819/19) , EPSRC-funded Grow MedTech CardioX (POC041) , and the MedIAN Network (EP/N026993/1) funded by the Engineering and Physical Sciences Research Council (EPSRC) . The work of AFF is also partially funded by EPSRC through TUSCA (EP/V04799X/1) . SN acknowledges the National Institute for Health Research (NIHR) Oxford Biomedical Research Centre based at The Oxford University Hospitals Trust at the University of Oxford, and the British Heart Foundation Centre of Research Excellence. SEP acknowledges support from the SmartHeart EPSRC programme grant ( www.nihr.ac.uk; EP/P001009/1) , the British Heart Foundation for funding the manual analysis to create a cardiovascular magnetic resonance imaging reference standard for the UK Biobank imaging resource in 5,0 0 0 CMR scans ( www.bhf.org.uk; PG/14/89/31194) , and the National Institute for Health Research (NIHR) Barts Biomedical Research Centre. SEP has received funding from the European Union' s Horizon 2020 research and innovation programme under grant agreement No 825903 (euCanSHare project) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Accepted, hybrid</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 28 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Diagnostic quality assessment for low-dimensional ECG representations</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Kov&aacute;cs, P (Kovacs, Peter); B&ouml;ck, C (Boeck, Carl); Tschoellitsch, T (Tschoellitsch, Thomas); Huemer, M (Huemer, Mario); Meier, J (Meier, Jens)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>COMPUTERS IN BIOLOGY AND MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>150</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>106086</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.compbiomed.2022.106086</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>SEP 2022</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2022 NOV</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>3</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>3</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
6</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>30</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
There have been several attempts to quantify the diagnostic distortion caused by algorithms that perform low -dimensional electrocardiogram (ECG) representation. However, there is no universally accepted quantitative measure that allows the diagnostic distortion arising from denoising, compression, and ECG beat representation algorithms to be determined. Hence, the main objective of this work was to develop a framework to enable biomedical engineers to efficiently and reliably assess diagnostic distortion resulting from ECG processing algorithms. We propose a semiautomatic framework for quantifying the diagnostic resemblance between original and denoised/reconstructed ECGs. Evaluation of the ECG must be done manually, but is kept simple and does not require medical training. In a case study, we quantified the agreement between raw and reconstructed (denoised) ECG recordings by means of kappa-based statistical tests. The proposed methodology takes into account that the observers may agree by chance alone. Consequently, for the case study, our statistical analysis reports the "true", beyond-chance agreement in contrast to other, less robust measures, such as simple percent agreement calculations. Our framework allows efficient assessment of clinically important diagnostic distortion, a potential side effect of ECG (pre-)processing algorithms. Accurate quantification of a possible diagnostic loss is critical to any subsequent ECG signal analysis, for instance, the detection of ischemic ST episodes in long-term ECG recordings.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000878510400004</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>36191392</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Baseline removal; Clinical evaluation; Diagnostic distortion measures; ECG denoising; Kappa statistics</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
HIGH AGREEMENT; LOW KAPPA</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Kovacs, Peter] Eotvos Lorand Univ, Dept Numer Anal, Pazmany Peter Setany 1, H-1117 Budapest, Hungary. <br>
[Boeck, Carl] Johannes Kepler Univ Linz, Inst Signal Proc, JKU LIT SAL eSPML Lab, Altenberger Str 69, A-4040 Linz, Austria. <br>
[Tschoellitsch, Thomas; Meier, Jens] Johannes Kepler Univ Linz, Clin Anesthesiol &amp; Intens Care Med, Krankenhausstr 9, A-4020 Linz, Austria. <br>
[Huemer, Mario] Johannes Kepler Univ Linz, Inst Signal Proc, Altenberger Str 69, A-4040 Linz, Austria. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Kov&aacute;cs, P (corresponding author), Eotvos Lorand Univ, Dept Numer Anal, Pazmany Peter Setany 1, H-1117 Budapest, Hungary.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
kovika@inf.elte.hu; carl.boeck@jku.at; Thomas.Tschoellitsch@kepleruniklinkum.at; mario.huemer@jku.at; Jens.Meier@kepleruniklinkum.at</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Eotvos Lorand University; Johannes Kepler University Linz; Johannes Kepler University Linz; Johannes Kepler University Linz</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bock, Carl</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2207-2411&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tschoellitsch, Thomas</display_name>&nbsp;</td><td>HJP-9501-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Kov&aacute;cs, P&eacute;ter</display_name>&nbsp;</td><td>H-7307-2017&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Life Sciences &amp; Biomedicine - Other Topics; Computer Science; Engineering; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>5X3NV</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0010-4825</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-0534</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>COMPUT BIOL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Comput. Biol. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>9</value>
</td>
</tr>

<tr>
<td>
<b>Open Access:</b>

<value>Green Published, hybrid, Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 29 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Automated ECG Noise Detection and Classification System for Unsupervised Healthcare Monitoring</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Satija, U (Satija, Udit); Ramkumar, B (Ramkumar, Barathram); Manikandan, MS (Manikandan, M. Sabarimalai)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>22</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>3</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>722-732</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2017.2686436</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2018 MAY</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>113</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>130</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
62</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>39</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Objective: Automatic detection and classification of noises can play a vital role in the development of robust unsupervised electrocardiogram (ECG) analysis systems. This paper proposes a novel unified framework for automatic detection, localization, and classification of single and combined ECG noises. Methods: The proposed framework consists of the modified ensemble empirical mode decomposition (CEEMD), the short-term temporal feature extraction, and the decision-rule-based noise detection and classification. In the proposed framework, ECG signals are first decomposed using the modified CEEMD algorithm for discriminating the ECG components from the noises and artifacts. Then, the short-term temporal features such as maximum absolute amplitude, number of zerocrossings, and local maximum peak amplitude of the autocorelation function are computed from the extracted high-frequency and low-frequency signals. Finally, a decision rule-based algorithm is presented for detecting the presence of noises and classifying the processed ECG signals into six signal groups: noise-free ECG, ECG+BW, ECG+MA, ECG+PLI, ECG+BW+PLI, and ECG+BW+MA. Results: The proposed framework is rigorously evaluated on five benchmark ECG databases and the real-time ECG signals. The proposed framework achieves an average sensitivity of 99.12%, specificity of 98.56%, and overall accuracy of 98.90% in detecting the presence of noises. Classification results show that the framework achieves an average sensitivity, positive predictivity, and classification accuracy of 98.93%, 98.39%, and 97.38%, respectively. Conclusion: The proposed framework not only achieves better noise detection and classification rates than the current state-of-the-art methods but also accurately localizes short bursts of noises with low end-point delineation errors. Significance: Extensive studies on benchmark databases demonstrate that the proposed framework is more suitable for reducing false alarm rates and selecting appropriate noise-specific denoising techniques in automated ECG analysis applications.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000431374500010</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>28333651</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Baseline wander; ECG denoising; ECG noise detection and classification; ECG signal quality assessment; muscle artifacts</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SIGNAL-QUALITY INDEXES; REAL-TIME; ELECTROCARDIOGRAM SIGNAL; DATA FUSION; UNIT</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Satija, Udit; Ramkumar, Barathram; Manikandan, M. Sabarimalai] Indian Inst Technol Bhubaneswar, Sch Elect Sci, Bhubaneswar 751013, India. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Satija, U (corresponding author), Indian Inst Technol Bhubaneswar, Sch Elect Sci, Bhubaneswar 751013, India.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
us11@iitbbs.ac.in; barathram@iitbbs.ac.in; msm@iitbbs.ac.in</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Bhubaneswar</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Manikandan, M Sabarimalai</display_name>&nbsp;</td><td>V-6236-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Manikandan, M Sabarimalai</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6878-4911&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>SATIJA, UDIT</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3851-765X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>SATIJA, UDIT</display_name>&nbsp;</td><td>AAA-5332-2021&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>GE6XN</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 30 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Automated cardiac segmentation of cross-modal medical images using unsupervised multi-domain adaptation and spatial neural attention structure</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Liu, JP (Liu, Jinping); Liu, H (Liu, Hui); Gong, SB (Gong, Subo); Tang, ZH (Tang, Zhaohui); Xie, YF (Xie, Yongfang); Yin, HZ (Yin, Huazhan); Niyoyita, JP (Niyoyita, Jean Paul)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>72</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>102135</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2021.102135</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JUN 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 AUG</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>35</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>42</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
10</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
65</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>54</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Accurate cardiac segmentation of multimodal images, e.g., magnetic resonance (MR), computed tomography (CT) images, plays a pivot role in auxiliary diagnoses, treatments and postoperative assessments of cardiovascular diseases. However, training a well-behaved segmentation model for the cross-modal cardiac image analysis is challenging, due to their diverse appearances/distributions from different devices and acquisition conditions. For instance, a well-trained segmentation model based on the source domain of MR images is often failed in the segmentation of CT images. In this work, a cross-modal images oriented cardiac segmentation scheme is proposed using a symmetric full convolutional neural network (SFCNN) with the unsupervised multi-domain adaptation (UMDA) and a spatial neural attention (SNA) structure, termed UMDA-SNA-SFCNN, having the merits of without the requirement of any annotation on the test domain. Specifically, UMDA-SNA-SFCNN incorporates SNA to the classic adversarial domain adaptation network to highlight the relevant regions, while restraining the irrelevant areas in the cross modal images, so as to suppress the negative transfer in the process of unsupervised domain adaptation. In addition, the multi-layer feature discriminators and a predictive segmentation-mask discriminator are established to connect the multi-layer features and segmentation mask of the backbone network, SFCNN, to realize the fine-grained alignment of unsupervised cross-modal feature domains. Extensive confirmative and comparative experiments on the benchmark Multi-Modality Whole Heart Challenge dataset show that the proposed model is superior to the state-of-the-art cross-modal segmentation methods. (c) 2021 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000681314900010</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34182202</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cross-modal cardiac image segmentation; Unsupervised multi-domain adaptation; Spatial neural attention; Symmetric full convolutional neural; network</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
DOMAIN ADAPTATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Liu, Jinping; Liu, Hui; Yin, Huazhan] Hunan Normal Univ, Hunan Prov Key Lab Intelligent Comp &amp; Language In, Changsha 410081, Peoples R China. <br>
[Liu, Jinping; Liu, Hui] Hunan Normal Univ, Minist Educ, Key Lab Comp &amp; Stochast Math, Changsha 410081, Peoples R China. <br>
[Liu, Jinping] Hunan Normal Univ, Hunan Xiangjiang Artificial Intelligence Acad, Changsha 410081, Peoples R China. <br>
[Gong, Subo] Cent South Univ, Xiangya Hosp 2, Dept Geriatr Med, Changsha 410011, Peoples R China. <br>
[Tang, Zhaohui; Xie, Yongfang] Cent South Univ, Sch Automat, Changsha 410083, Peoples R China. <br>
[Yin, Huazhan] Hunan Normal Univ, Cognit &amp; Human Behav Key Lab Hunan Prov, Changsha 410081, Peoples R China. <br>
[Niyoyita, Jean Paul] Univ Rwanda, Coll Sci &amp; Technol, Kigali 3286, Rwanda. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Liu, JP (corresponding author), Hunan Normal Univ, Coll Informat Sci &amp; Engn, Hunan Prov Key Lab Intelligent Comp &amp; Language In, HN731, Changsha, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
ljp202518@163.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Hunan Normal University; Hunan Normal University; Hunan Normal University; Central South University; Central South University; Hunan Normal University; University of Rwanda</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Jinping</display_name>&nbsp;</td><td>AAM-7723-2021&nbsp;</td><td>0000-0002-8669-882X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liu, Hui</display_name>&nbsp;</td><td>G-2051-2014&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Niyoyita, Jean Paul</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5281-459X&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>TU8XW</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China (NSFC)</grant_agency>&nbsp;</td><td>
<div>61971188&nbsp;</div>
<div>61771492&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Science Fund for Distinguished Young Scholars</grant_agency>&nbsp;</td><td>
<div>61725306&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NSFC</grant_agency>&nbsp;</td><td>
<div>U1701261&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Guangdong provincial government</grant_agency>&nbsp;</td><td>
<div>U1701261&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>project of Educational Commission of Hunan Province of China</grant_agency>&nbsp;</td><td>
<div>19B364&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the National Natural Science Foundation of China (NSFC) under Grant Nos. 61971188, 61771492, the National Science Fund for Distinguished Young Scholars under grant No. 61725306 and the joint fund of NSFC and Guangdong provincial government under grant No. U1701261, in part by the project of Educational Commission of Hunan Province of China un-der grant No. 19B364.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 31 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>ST-GAN: A Swin Transformer-Based Generative Adversarial Network for Unsupervised Domain Adaptation of Cross-Modality Cardiac Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhang, YF (Zhang, Yifan); Wang, YH (Wang, Yonghui); Xu, LS (Xu, Lisheng); Yao, YD (Yao, Yudong); Qian, W (Qian, Wei); Qi, L (Qi, Lin)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>28</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>2</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>893-904</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2023.3336965</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 FEB</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>3</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>3</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
47</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>50</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Unsupervised domain adaptation (UDA) methods have shown great potential in cross-modality medical image segmentation tasks, where target domain labels are unavailable. However, the domain shift among different image modalities remains challenging, because the conventional UDA methods are based on convolutional neural networks (CNNs), which tend to focus on the texture of images and cannot establish the global semantic relevance of features due to the locality of CNNs. This paper proposes a novel end-to-end Swin Transformer-based generative adversarial network (ST-GAN) for cross-modality cardiac segmentation. In the generator of ST-GAN, we utilize the local receptive fields of CNNs to capture spatial information and introduce the Swin Transformer to extract global semantic information, which enables the generator to better extract the domain-invariant features in UDA tasks. In addition, we design a multi-scale feature fuser to sufficiently fuse the features acquired at different stages and improve the robustness of the UDA network. We extensively evaluated our method with two cross-modality cardiac segmentation tasks on the MS-CMR 2019 dataset and the M&amp;Ms dataset. The results of two different tasks show the validity of ST-GAN compared with the state-of-the-art cross-modality cardiac image segmentation methods.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001203362500022</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>38019618</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Adversarial learning; cross-modality cardiac segmentation; multi-scale fusion; swin transformer; unsupervised domain adaptation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
IMAGE</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhang, Yifan; Wang, Yonghui; Xu, Lisheng; Qian, Wei; Qi, Lin] Northeastern Univ, Coll Med &amp; Biol Informat Engn, Shenyang 110004, Peoples R China. <br>
[Xu, Lisheng; Qi, Lin] Minist Educ, Engn Res Ctr Med Imaging &amp; Intelligent Anal, Shenyang 110169, Peoples R China. <br>
[Xu, Lisheng; Qi, Lin] Northeastern Univ, Key Lab Med Image Comp, Minist Educ, Shenyang 110169, Peoples R China. <br>
[Yao, Yudong] Stevens Inst Technol, Elect &amp; Comp Engn Dept, Hoboken, NJ 07030 USA. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Qi, L (corresponding author), Northeastern Univ, Coll Med &amp; Biol Informat Engn, Shenyang 110004, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
zyf0lzh@gmail.com; wang18852865993@gmail.com; xuls@bmie.neu.edu.cn; Yu-Dong.Yao@stevens.edu; wqian@bmie.neu.edu.cn; qilin@bmie.neu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Northeastern University - China; Northeastern University - China; Stevens Institute of Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>XU, Lisheng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-8360-3605&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Yifan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0141-1536&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>XU, Lisheng</display_name>&nbsp;</td><td>C-2974-2008&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>NW0A0</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Development Program of China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>No Statement Available</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 32 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Universal ventricular coordinates: A generic framework for describing position within the heart and transferring data</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Bayer, J (Bayer, Jason); Prassl, AJ (Prassl, Anton J.); Pashaei, A (Pashaei, Ali); Gomez, JF (Gomez, Juan F.); Frontera, A (Frontera, Antonio); Neic, A (Neic, Aurel); Plank, G (Plank, Gernot); Vigmond, EJ (Vigmond, Edward J.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>45</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>83-93</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2018.01.005</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2018 APR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>79</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>87</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
0</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>26</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Being able to map a particular set of cardiac ventricles to a generic topologically equivalent representation has many applications, including facilitating comparison of different hearts, as well as mapping quantities and structures of interest between them. In this paper we describe Universal Ventricular Coordinates (UVC), which can be used to describe position within any biventricular heart. UVC comprise four unique coordinates that we have chosen to be intuitive, well defined, and relevant for physiological descriptions. We describe how to determine these coordinates for any volumetric mesh by illustrating how to properly assign boundary conditions and utilize solutions to Laplace's equation. Using UVC, we transferred scalar, vector, and tensor data between four unstructured ventricular meshes from three different species. Performing the mappings was very fast, on the order of a few minutes, since mesh nodes were searched in a KD tree. Distance errors in mapping mesh nodes back and forth between meshes were less than the size of an element. Analytically derived fiber directions were also mapped across meshes and compared, showing &lt;5 degrees difference over most of the ventricles. The ability to transfer gradients was also demonstrated. Topologically variable structures, like papillary muscles, required further definition outside of the UVC framework. In conclusion, UVC can aid in transferring many types of data between different biventricular geometries. (C) 2018 The Author(s). Published by Elsevier B.V.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000427664400007</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>29414438</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Mapping; Coordinates; Volumetric meshes; Deformation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
REPOLARIZATION GRADIENTS; FIBER ORIENTATION; MODELS; ANATOMY; FAILURE</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Bayer, Jason; Pashaei, Ali; Gomez, Juan F.; Frontera, Antonio; Vigmond, Edward J.] Bordeaux Fdn, LIRYC Electrophysiol &amp; Heart Modeling Inst, Ave Haut Leveque, F-33600 Pessac, France. <br>
[Bayer, Jason; Pashaei, Ali; Gomez, Juan F.; Vigmond, Edward J.] Univ Bordeaux, IMB Bordeaux Inst Math, 351 Cours Liberat, F-33405 Talence, France. <br>
[Prassl, Anton J.; Neic, Aurel; Plank, Gernot] Med Univ Graz, Gottfried Schatz Res Ctr, Biophys, Neue Stiftingtalstr 6, A-8010 Graz, Austria. <br>
[Frontera, Antonio] Hop Haut Leveque, Dept Electrophysiol, 1 Ave Magellan, F-33100 Pessac, France. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Vigmond, EJ (corresponding author), Bordeaux Fdn, LIRYC Electrophysiol &amp; Heart Modeling Inst, Ave Haut Leveque, F-33600 Pessac, France.<br>Vigmond, EJ (corresponding author), Univ Bordeaux, IMB Bordeaux Inst Math, 351 Cours Liberat, F-33405 Talence, France.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
jason.bayer@ihu-liryc.fr; anton.prassl@medunigraz.at; ali.pashaei@u-bordeaux.fr; juan.gomez@ihu-liryc.fr; a.frontera@gmail.com; aurel.neic@medunigraz.at; gernot.plank@medunigraz.at; edward.vigmond@u-bordeaux.fr</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
CHU Bordeaux; Universite de Bordeaux; Medical University of Graz; Universite de Bordeaux; CHU Bordeaux</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Neic, Aurel</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5192-1307&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>F Gomez, Juan</display_name>&nbsp;</td><td>B-5228-2017&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Frontera, Antonio</display_name>&nbsp;</td><td>AAG-6538-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Plank, Gernot</display_name>&nbsp;</td><td>C-9498-2011&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bayer, Jason</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0269-3499&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Vigmond, Edward</display_name>&nbsp;</td><td>E-8988-2012&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bayer, Jason</display_name>&nbsp;</td><td>HKV-2373-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gomez, Juan F</display_name>&nbsp;</td><td>B-5228-2017&nbsp;</td><td>0000-0003-0253-4842&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Frontera, Antonio</display_name>&nbsp;</td><td>HIR-6883-2022&nbsp;</td><td>0000-0002-0372-4480&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Vigmond, Edward</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1388-3589&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Prassl, Anton J</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1920-1377&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER SCIENCE BV</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>FZ5VM</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Agence Nationale de Recherche (ANR) as part of the Investissements d'Avenir program</grant_agency>&nbsp;</td><td>
<div>ANR-10-IAHU-04&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>ANR</grant_agency>&nbsp;</td><td>
<div>ANR-16-CE19-0009&nbsp;</div>
<div>ANR-13-MONU-0004-02&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Whitaker International Program</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Lefoulon-Delalande Foundation</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Austrian Science Fund (FWF)</grant_agency>&nbsp;</td><td>
<div>F3210-N18&nbsp;</div>
<div>12760-B30&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EU</grant_agency>&nbsp;</td><td>
<div>CardioProof 611232&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>ERACoSysMed PUSHCART project</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Austrian Science Fund (FWF)</grant_agency>&nbsp;</td><td>
<div>I2760&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Agence Nationale de la Recherche (ANR)</grant_agency>&nbsp;</td><td>
<div>ANR-16-CE19-0009&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was funded in part by the Agence Nationale de Recherche (ANR) as part of the Investissements d'Avenir program, grant ANR-10-IAHU-04. J.Bayer was supported in part by the ANR grant ANR-16-CE19-0009, the Whitaker International Program administered by the Institute of International Education, and by the Lefoulon-Delalande Foundation administered by the Institute of France. A. Pashaei was supported by the ANR grant ANR-13-MONU-0004-02. Funding to G Plank was provided by the grants F3210-N18 and 12760-B30 from the Austrian Science Fund (FWF) and the EU grant CardioProof 611232. E. Vigmond and G. Plank were also supported by the ERACoSysMed PUSHCART project. Simulations for this study were performed on the high performance computing platform Avakas, which is maintained by the Mesocentre de Calcul Intensif Aquitain (MCIA). We would also like to acknowledge PRACE support for computations performed on Marconi@CINECA, Italy and ARCHER, UK.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>hybrid, Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 33 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Unsupervised Domain Adaptation From Axial to Short-Axis Multi-Slice Cardiac MR Images by Incorporating Pretrained Task Networks</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Koehler, S (Koehler, Sven); Hussain, T (Hussain, Tarique); Blair, Z (Blair, Zach); Huffaker, T (Huffaker, Tyler); Ritzmann, F (Ritzmann, Florian); Tandon, A (Tandon, Animesh); Pickardt, T (Pickardt, Thomas); Sarikouch, S (Sarikouch, Samir); Latus, H (Latus, Heiner); Greil, G (Greil, Gerald); Wolf, I (Wolf, Ivo); Engelhardt, S (Engelhardt, Sandy)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>10</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2939-2953</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3052972</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>10</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
14</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>44</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Anisotropic multi-slice Cardiac Magnetic Resonance (CMR) Images are conventionally acquired in patient-specific short-axis (SAX) orientation. In specific cardiovascular diseases that affect right ventricular (RV) morphology, acquisitions in standard axial (AX) orientation are preferred by some investigators, due to potential superiority in RV volume measurement for treatment planning. Unfortunately, due to the rare occurrence of these diseases, data in this domain is scarce. Recent research in deep learning-based methods mainly focused on SAX CMR images and they had proven to be very successful. In this work, we show that there is a considerable domain shift between AX and SAX images, and therefore, direct application of existing models yield sub-optimal results on AX samples. We propose a novel unsupervised domain adaptation approach, which uses task-related probabilities in an attention mechanism. Beyond that, cycle consistency is imposed on the learned patient-individual 3D rigid transformation to improve stability when automatically re-sampling the AX images to SAX orientations. The network was trained on 122 registered 3D AX-SAX CMR volume pairs from a multi-centric patient cohort. A mean 3D Dice of 0.86 +/- 0.06 for the left ventricle, 0.65 +/- 0.08 for the myocardium, and 0.77 +/- 0.10 for the right ventricle could be achieved. This is an improvement of 25% in Dice for RV in comparison to direct application on axial slices. To conclude, our pre-trained task module has neither seen CMR images nor labels from the target domain, but is able to segment them after the domain gap is reduced. Code: https://github.com/Cardio-AI/3d-mri-domain-adaptation</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000702638800033</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33471750</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Task analysis; Heart; Image segmentation; Three-dimensional displays; Deep learning; Training; Biomedical imaging; Cardiac magnetic resonance; short axis images; spatial transformer networks; unsupervised domain adaptation; competence network for congenital heart defects</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SEGMENTATION; ORIENTATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Koehler, Sven; Ritzmann, Florian; Engelhardt, Sandy] Univ Heidelberg Hosp, Dept Internal Med 3, Artificial Intelligence Cardiovasc Med Grp, D-69120 Heidelberg, Germany. <br>
[Koehler, Sven; Ritzmann, Florian; Engelhardt, Sandy] German Ctr Cardiovasc Res DZHK, D-68167 Heidelberg, Germany. <br>
[Hussain, Tarique; Tandon, Animesh; Greil, Gerald] Univ Texas Southwestern Med Ctr Dallas, Dept Pediat, Dallas, TX 75390 USA. <br>
[Hussain, Tarique; Tandon, Animesh; Greil, Gerald] Univ Texas Southwestern Med Ctr Dallas, Div Cardiol, Dallas, TX 75390 USA. <br>
[Hussain, Tarique; Tandon, Animesh; Greil, Gerald] Univ Texas Southwestern Med Ctr Dallas, Dept Radiol, Dallas, TX 75390 USA. <br>
[Hussain, Tarique; Tandon, Animesh; Greil, Gerald] Univ Texas Southwestern Med Ctr Dallas, Adv Imaging Res Ctr, Dallas, TX 75390 USA. <br>
[Blair, Zach; Huffaker, Tyler] Univ Texas Southwestern Med Ctr Dallas, Dept Pediat, Dallas, TX 75390 USA. <br>
[Pickardt, Thomas] German Competence Network Congenital Heart, D-13353 Berlin, Germany. <br>
[Pickardt, Thomas] German Ctr Cardiovasc Res DZHK, D-68167 Berlin, Germany. <br>
[Sarikouch, Samir] Hannover Med Sch, Dept Cardiothorac, Transplantat &amp; Vasc Surg, D-30625 Hannover, Germany. <br>
[Sarikouch, Samir] German Competence Network Congenital Heart Defect, D-13353 Berlin, Germany. <br>
[Sarikouch, Samir] German Ctr Cardiovasc Res DZHK, D-68167 Berlin, Germany. <br>
[Latus, Heiner] Tech Univ Munich, Dept Paediat &amp; Congenital Heart Defects, German Heart Ctr Munich, D-80636 Munich, Germany. <br>
[Wolf, Ivo] Mannheim Univ Appl Sci, Dept Comp Sci, D-68163 Mannheim, Germany. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Engelhardt, S (corresponding author), Univ Heidelberg Hosp, Dept Internal Med 3, Artificial Intelligence Cardiovasc Med Grp, D-69120 Heidelberg, Germany.<br>Engelhardt, S (corresponding author), German Ctr Cardiovasc Res DZHK, D-68167 Heidelberg, Germany.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
sven.koehler@med.uni-heidelberg.de; mohammad.hussain@utsouthwestern.edu; zachary.blair@utsouthwestern.edu; tyler.huffaker@utsouthwestern.edu; florian.ritzmann2@hs-mannheim.de; animesh.tandon@utsouthwestern.edu; pickardt@kompetenznetz-ahf.de; sarikouch.samir@mh-hannover.de; latus@dhm.mhn.de; gerald.greil@utsouthwestern.edu; i.wolf@hs-mannheim.de; sandy.engelhardt@med.uni-heidelberg.de</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Ruprecht Karls University Heidelberg; German Centre for Cardiovascular Research; University of Texas System; University of Texas Southwestern Medical Center; University of Texas System; University of Texas Southwestern Medical Center; University of Texas System; University of Texas Southwestern Medical Center; University of Texas System; University of Texas Southwestern Medical Center; University of Texas System; University of Texas Southwestern Medical Center; German Centre for Cardiovascular Research; Hannover Medical School; German Centre for Cardiovascular Research; Technical University of Munich; German Heart Centre Munich</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Koehler, Sven</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4989-8766&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Koehler, Sven</display_name>&nbsp;</td><td>HMP-6265-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Greil, Gerald</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7288-6566&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hussain, Tariq</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1332-2418&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Huffaker, Tyler</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9442-8600&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Pickardt, Thomas</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0019-6325&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tandon, Animesh</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9769-8801&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wolf, Ivo</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6519-6484&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hussain, Tarique</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4091-992X&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>WA1FC</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Informatics for Life Project through the Klaus Tschira Foundation</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Competence Network for Congenital Heart Defects through the Federal Ministry of Education and Research</grant_agency>&nbsp;</td><td>
<div>01GI0601&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>German Centre for Cardiovascular Research (DZHK)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the Informatics for Life Project through the Klaus Tschira Foundation, in part by the Competence Network for Congenital Heart Defects through the Federal Ministry of Education and Research under Grant 01GI0601, and in part by the German Centre for Cardiovascular Research (DZHK).</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted, Green Accepted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 34 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>I-Vector-Based Patient Adaptation of Deep Neural Networks for Automatic Heartbeat Classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Xu, SS (Xu, Sean Shensheng); Mak, MW (Mak, Man-Wai); Cheung, CC (Cheung, Chi-Chung)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>24</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>3</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>717-727</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2019.2919732</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>22</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>24</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
33</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>36</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Automatic classification of electrocardiogram (ECG) signals is important for diagnosing heart arrhythmias. A big challenge in automatic ECG classification is the variation in the waveforms and characteristics of ECG signals among different patients. To address this issue, this paper proposes adapting a patient-independent deep neural network (DNN) using the information in the patient-dependent identity vectors (i-vectors). The adapted networks, namely i-vector adapted patient-specific DNNs (iAP-DNNs), are tuned toward the ECG characteristics of individual patients. For each patient, his/her ECG waveforms are compressed into an i-vector using a factor analysis model. Then, this i-vector is injected into the middle hidden layer of the patient-independent DNN. Stochastic gradient descent is then applied to fine-tune the whole network to form a patient-specific classifier. As a result, the adaptation makes use of not only the raw ECG waveforms from the specific patient but also the compact representation of his/her ECG characteristics through the i-vector. Analysis on the hidden-layer activations shows that by leveraging the information in the i-vectors, the iAP-DNNs are more capable of discriminating normal heartbeats against arrhythmic heartbeats than the networks that use the patient-specific ECG only for the adaptation. Experimental results based on the MIT-BIH database suggest that the iAP-DNNs perform better than existing patient-specific classifiers in terms of various performance measures. In particular, the sensitivity and specificity of the existing methods are all under the receiver operating characteristic curves of the iAP-DNNs.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000519730300008</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>31150349</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiography; Statistics; Training; Sociology; Heart rate variability; Feature extraction; Heart beat; ECG classification; Arrhythmias; deep neural networks; i-vectors; DNN adaptation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ECG CLASSIFICATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Xu, Sean Shensheng; Mak, Man-Wai; Cheung, Chi-Chung] Hong Kong Polytech Univ, Dept Elect &amp; Informat Engn, Hong Kong, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Mak, MW (corresponding author), Hong Kong Polytech Univ, Dept Elect &amp; Informat Engn, Hong Kong, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
seanssx@yahoo.com; enmwmak@polyu.edu.hk; lawrence.chi-chung.cheung@polyu.edu.hk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Hong Kong Polytechnic University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Mak, Man-Wai</display_name>&nbsp;</td><td>C-3750-2014&nbsp;</td><td>0000-0001-8854-3760&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Mak, Manwai</display_name>&nbsp;</td><td>C-3750-2014&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>XU, SHENSHENG</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-8846-5061&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>KU5DO</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>RGC of Hong Kong</grant_agency>&nbsp;</td><td>
<div>PolyU152137/17E&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the RGC of Hong Kong, under Grant PolyU152137/17E.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Accepted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 35 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Towards federated transfer learning in electrocardiogram signal analysis</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Chorney, W (Chorney, Wesley); Wang, HF (Wang, Haifeng)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>COMPUTERS IN BIOLOGY AND MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>170</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>107984</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.compbiomed.2024.107984</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JAN 2024</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>7</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>10</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
6</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
20</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>79</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Modern methods in artificial intelligence perform very well on many healthcare datasets, at times outperforming trained doctors. However, many assumptions made in model training are not justifiable in clinical settings. In this work, we propose a method to train classifiers for electrocardiograms, able to deal with data of disparate input dimensions, distributed across different institutions, and able to protect patient privacy. In addition, we propose a simple method for creating federated datasets from any centralized dataset. We use autoencoders in conjunction with federated learning to model a highly heterogeneous modeling problem using the Massachusetts Institute of Technology Beth Israel Hospital Arrhythmia dataset, the Computing in Cardiology 2017 challenge dataset, and the PTB-XL dataset. For an encoding dimension of 1000, our federated classifier achieves an accuracy, precision, recall, and F1 score of 73.0%, 66.6%, 73.0%, and 69.7%, respectively. Our results suggest that dropping commonly made assumptions significantly complicate training and that as a result, estimates of performance of many machine learning models may overestimate performance when adopted for clinical settings.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001168093000001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>38244469</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Federated transfer learning; Electrocardiograms; Autoencoders; Data privacy; Healthcare</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ATRIAL-FIBRILLATION; ECG SIGNALS; NONINVASIVE ASSESSMENT; MYOCARDIAL-INFARCTION; HELICOBACTER-PYLORI; DIAGNOSIS; AI; ARRHYTHMIAS; CHALLENGES</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Chorney, Wesley] Mississippi State Univ, Computat Engn, Mississippi State, MS 39762 USA. <br>
[Wang, Haifeng] Mississippi State Univ, Ind &amp; Syst Engn, Mississippi State, MS 39762 USA. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Chorney, W (corresponding author), Mississippi State Univ, Computat Engn, Mississippi State, MS 39762 USA.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
wwc102@msstate.edu; wang@ise.msstate.edu</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Mississippi State University; Mississippi State University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chorney, Wesley</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0008-2598-6837&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chorney, Wesley</display_name>&nbsp;</td><td>IWV-4143-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Life Sciences &amp; Biomedicine - Other Topics; Computer Science; Engineering; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>IR6J4</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0010-4825</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-0534</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>COMPUT BIOL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Comput. Biol. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 36 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>sCL-ST: Supervised Contrastive Learning With Semantic Transformations for Multiple Lead ECG Arrhythmia Classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Le, DC (Le, Duc); Truong, S (Truong, Sang); Brijesh, P (Brijesh, Patel); Adjeroh, DA (Adjeroh, Donald A.); Le, N (Le, Ngan)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>27</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>6</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2818-2828</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2023.3246241</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 JUN</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>16</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>20</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
41</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>53</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
The automatic classification of electrocardiogram (ECG) signals has played an important role in cardiovascular diseases diagnosis and prediction. With recent advancements in deep neural networks (DNNs), particularly Convolutional Neural Networks (CNNs), learning deep features automatically from the original data is becoming an effective and widespread approach in a variety of intelligent tasks including biomedical and health informatics. However, most of the existing approaches are trained on either 1D CNNs or 2D CNNs, and they suffer from the limitations of random phenomena (i.e. random initial weights). Furthermore, the ability to train such DNNs in a supervised manner in healthcare is often limited due to the scarcity of labeled training data. To address the problems of weight initialization and limited annotated data, in this work, we leverage recent self-supervised learning technique, namely, contrastive learning, and present supervised contrastive learning (sCL). Different from existing self-supervised contrastive learning approaches, which often generate false negatives because of random selection of negative anchors, our contrastive learning makes use of labeled data to pull the same class closer together and push different classes far apart to avoid potential false negatives. Furthermore, unlike other kinds of signals (e.g. speech, image, video), ECG signal is sensitive to changes, and inappropriate transformation could directly affect diagnosis results. To deal with this issue, we present two semantic transformations, i.e. semantic split-join and semantic weighted peaks noise smoothing. The proposed deep neural network sCL-ST with supervised contrastive learning and semantic transformations is trained as an end-to-end framework for the multi-label classification of 12-lead ECGs. Our sCL-ST network contains two sub-networks i.e. pre-text task and down-stream task. Our experimental results have been evaluated on 12-lead PhysioNet 2020 dataset and shown that our proposed network outperforms the state-of-the-art existing approaches.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001004541400023</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37028019</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
ECG; arrhythmia classification; multiple lead; contrastive learning; self-supervised learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
DEEP; ALGORITHM</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Le, Duc; Truong, Sang; Le, Ngan] Univ Arkansas, Dept Comp Sci &amp; Comp Engn, Fayetteville, AR 72703 USA. <br>
[Brijesh, Patel] West Virginia Univ, Sch Med, Div Cardiol, Morgantown, WV 26506 USA. <br>
[Adjeroh, Donald A.] West Virginia Univ, Dept Comp Sci &amp; Elect Engn LCSEE, Morgantown, WV 26506 USA. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Le, N (corresponding author), Univ Arkansas, Dept Comp Sci &amp; Comp Engn, Fayetteville, AR 72703 USA.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
minhducl@uark.edu; sangt@uark.edu; brijesh.patel@wvumedicine.org; Donald.Adjeroh@mail.wvu.edu; thile@uark.edu</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Arkansas System; University of Arkansas Fayetteville; West Virginia University; West Virginia University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Le, Duc</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7771-7729&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Le, Ngan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2571-0511&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>I7KP3</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>U.S. National Science Foundation</grant_agency>&nbsp;</td><td>
<div>OIA-1946391&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NSF</grant_agency>&nbsp;</td><td>
<div>1920920&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by U.S. National Science Foundation under Award OIA-1946391 and in part by NSF under Grant 1920920.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 37 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Scaling Representation Learning From Ubiquitous ECG With State-Space Models</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Avramidis, K (Avramidis, Kleanthis); Kunc, D (Kunc, Dominika); Perz, B (Perz, Bartosz); Adsul, K (Adsul, Kranti); Feng, TT (Feng, Tiantian); Kazienko, P (Kazienko, Przemyslaw); Saganowski, S (Saganowski, Stanislaw); Narayanan, S (Narayanan, Shrikanth)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>28</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>10</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>5877-5889</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2024.3416897</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>4</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>4</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
8</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
18</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>82</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Ubiquitous sensing from wearable devices in the wild holds promise for enhancing human well-being, from diagnosing clinical conditions and measuring stress to building adaptive health promoting scaffolds. But the large volumes of data therein across heterogeneous contexts pose challenges for conventional supervised learning approaches. Representation Learning from biological signals is an emerging realm catalyzed by the recent advances in computational modeling and the abundance of publicly shared databases. The electrocardiogram (ECG) is the primary researched modality in this context, with applications in health monitoring, stress and affect estimation. Yet, most studies are limited by small-scale controlled data collection and over-parameterized architecture choices. We introduce &lt;bold&gt;WildECG&lt;/bold&gt;, a pre-trained state-space model for representation learning from ECG signals. We train this model in a self-supervised manner with 275 000 10 s ECG recordings collected in the wild and evaluate it on a range of downstream tasks. The proposed model is a robust backbone for ECG analysis, providing competitive performance on most of the tasks considered, while demonstrating efficacy in low-resource regimes.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001329782300043</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>38935470</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiography; Task analysis; Biological system modeling; Data models; Bioinformatics; Training; State-space methods; ubiquitous computing; self-supervised learning; state-space models</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ARTIFICIAL-INTELLIGENCE; ELECTROCARDIOGRAM; CLASSIFICATION; EMOTION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Avramidis, Kleanthis; Adsul, Kranti; Feng, Tiantian; Narayanan, Shrikanth] Univ Southern Calif, Viterbi Sch Engn, Los Angeles, CA 90089 USA. <br>
[Kunc, Dominika; Perz, Bartosz; Kazienko, Przemyslaw; Saganowski, Stanislaw] Wroclaw Univ Sci &amp; Technol, Dept Artificial Intelligence, PL-50370 Wroclaw, Poland. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Avramidis, K (corresponding author), Univ Southern Calif, Viterbi Sch Engn, Los Angeles, CA 90089 USA.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
avramidi@usc.edu; dominika.kunc@pwr.edu.pl; bartosz.perz@pwr.edu.pl; kadsul@usc.edu; tiantiaf@usc.edu; kazienko@pwr.edu.pl; stanislaw.saganowski@pwr.edu.pl; shri@ee.usc.edu</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Southern California; Wroclaw University of Science &amp; Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Perz, Bartosz</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9940-5117&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Kazienko, Przemysław</display_name>&nbsp;</td><td>F-1849-2014&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Kazienko, Przemyslaw</display_name>&nbsp;</td><td>F-1849-2014&nbsp;</td><td>0000-0001-5868-356X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Kunc, Dominika</display_name>&nbsp;</td><td>LIH-0162-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Kunc, Dominika</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2918-0423&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Perz, Bartosz</display_name>&nbsp;</td><td>AHE-2470-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Feng, Tiantian</display_name>&nbsp;</td><td>X-4695-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Saganowski, Stanisław</display_name>&nbsp;</td><td>AAF-1696-2019&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>I4D7I</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NSF SCH</grant_agency>&nbsp;</td><td>
<div>2204942&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>DARPA</grant_agency>&nbsp;</td><td>
<div>N660012324006&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Toyota</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Science Centre, Poland</grant_agency>&nbsp;</td><td>
<div>2020/37/B/ST6/03806&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NAWA STER Programme Internationalisation of Wroclaw University of Science and Technology Doctoral School</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Polish National Agency for Academic Exchange (NAWA) - the Bekker Programme</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was conducted at USC SAIL and supported in part by NSF SCH under Grant 2204942, in part by DARPA under Cooperative Agreement number N660012324006, in part by Toyota, in part by National Science Centre, Poland under Project 2020/37/B/ST6/03806,in part by the NAWA STER Programme Internationalisation of Wroclaw University of Science and Technology Doctoral School, and in part by the Polish National Agency for Academic Exchange (NAWA) - the BekkerProgramme.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 38 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Improving electrocardiogram-based detection of rare genetic heart disease using transfer learning: An application to phospholamban p.Arg14del mutation carriers</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Lopes, RR (Lopes, Ricardo R.); Bleijendaal, H (Bleijendaal, Hidde); Ramos, LA (Ramos, Lucas A.); Verstraelen, TE (Verstraelen, Tom E.); Amin, AS (Amin, Ahmad S.); Wilde, AAM (Wilde, Arthur A. M.); Pinto, YM (Pinto, Yigal M.); de Mol, BAJM (de Mol, Bas A. J. M.); Marquering, HA (Marquering, Henk A.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>COMPUTERS IN BIOLOGY AND MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>131</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>104262</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.compbiomed.2021.104262</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>FEB 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 APR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>30</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>35</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
10</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>31</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
The pathogenic mutation p.Arg14del in the gene encoding Phospholamban (PLN) is known to cause cardiomyopathy and leads to increased risk of sudden cardiac death. Automatic tools might improve the detection of patients with this rare disease. Deep learning is currently the state-of-the-art in signal processing but requires large amounts of data to train the algorithms. In situations with relatively small amounts of data, like PLN, transfer learning may improve accuracy. We propose an ECG-based detection of the PLN mutation using transfer learning from a model originally trained for sex identification. The sex identification model was trained with 256,278 ECGs and subsequently finetuned for PLN detection (155 ECGs of patients with PLN) with two control groups: a balanced age/sex matched group and a randomly selected imbalanced population. The data was split in 10 folds and 20% of the training data was used for validation and early stopping. The models were evaluated with the area under the receiver operating characteristic curve (AUROC) of the testing data. We used gradient activation for explanation of the prediction models. The models trained with transfer learning outperformed the models trained from scratch for both the balanced (AUROC 0.87 vs AUROC 0.71) and imbalanced (AUROC 0.0.90 vs AUROC 0.65) population. The proposed approach was able to improve the accuracy of a rare disease detection model by transfer learning information from a non-manual annotated and abundant label with only limited data available.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000631651900003</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33607378</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Phospholamban; Deep learning; Transfer learning; ECG analysis; Cardiomyopathy; Genetic heart disease</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Lopes, Ricardo R.; Ramos, Lucas A.; Marquering, Henk A.] Univ Amsterdam, Dept Biomed Engn &amp; Phys, Amsterdam UMC, Meibergdreef 9, NL-1105 AZ Amsterdam, Netherlands. <br>
[Lopes, Ricardo R.; Marquering, Henk A.] Univ Amsterdam, Dept Radiol &amp; Nucl Med, Amsterdam UMC, Amsterdam, Netherlands. <br>
[Bleijendaal, Hidde; Ramos, Lucas A.] Univ Amsterdam, Dept Clin Epidemiol Biostat &amp; Bioinformat, Amsterdam UMC, Amsterdam, Netherlands. <br>
[Bleijendaal, Hidde; Verstraelen, Tom E.; Amin, Ahmad S.; Wilde, Arthur A. M.; Pinto, Yigal M.; de Mol, Bas A. J. M.] Univ Amsterdam, Amsterdam UMC, Dept Clin &amp; Expt Cardiol, Amsterdam Cardiovasc Sci,Heart Ctr, Amsterdam, Netherlands. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Lopes, RR (corresponding author), Univ Amsterdam, Dept Biomed Engn &amp; Phys, Amsterdam UMC, Meibergdreef 9, NL-1105 AZ Amsterdam, Netherlands.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
r.riccilopes@amsterdamumc.nl</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Amsterdam; University of Amsterdam; University of Amsterdam; University of Amsterdam</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Verstraelen, Tom</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-4340-6815&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bleijendaal, Hidde</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1506-8385&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ramos, Lucas</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7738-9200&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ramos, Lucas</display_name>&nbsp;</td><td>W-7401-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Verstraelen, Tom</display_name>&nbsp;</td><td>ABE-5949-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ricci Lopes, Ricardo</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5515-1488&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>de Mol, Bastian</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-6888-9430&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Marquering, Henk</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1414-6313&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Amin, Ahmad</display_name>&nbsp;</td><td>NFT-0652-2025&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Marquering, Henk</display_name>&nbsp;</td><td>B-9954-2013&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lopes, Ricardo</display_name>&nbsp;</td><td>Y-9109-2019&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Life Sciences &amp; Biomedicine - Other Topics; Computer Science; Engineering; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>RA8EI</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0010-4825</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-0534</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>COMPUT BIOL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Comput. Biol. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>8</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>ITEA3 PARTNER</grant_agency>&nbsp;</td><td>
<div>16017&nbsp;</div>
<div>14003&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>University of Amsterdam Research Priority Area Medical Integromics</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>Part of this work was funded by ITEA3 PARTNER (16017), ITEA3 Medolution (14003) and University of Amsterdam Research Priority Area Medical Integromics.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>hybrid</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 39 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Heartbeats Classification Using Hybrid Time-Frequency Analysis and Transfer Learning Based on ResNet</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhang, YT (Zhang, Yatao); Li, JY (Li, Junyan); Wei, SS (Wei, Shoushui); Zhou, FY (Zhou, Fengyu); Li, D (Li, Dong)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>25</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>11</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>4175-4184</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2021.3085318</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 NOV</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>56</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>66</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
90</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>33</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
The classification of heartbeats is an important method for cardiac arrhythmia analysis. This study proposes a novel heartbeat classification method using hybrid time-frequency analysis and transfer learning based on ResNet-101. The proposed method has the following major advantages over the afore-mentioned methods: it avoids the need for manual features extraction in the traditional machine learning method, and it utilizes 2-D time-frequency diagrams which provide not only frequency and energy information but also preserve the morphological characteristic within the ECG recordings, and it owns enough deep to make better use of performance of CNN. The method deploys a hybrid time-frequency analysis of the Hilbert transform (HT) and the Wigner-Ville distribution (WVD) to transform 1-D ECG recordings into 2-D time-frequency diagrams which were then fed into a transfer learning classifier based on ResNet-101 for two classification tasks (i.e., 5 heartbeat categories assigned by the ANSI/AAMI standard (i.e., N, V, S, Q and F) and 14 original beat kinds of the MIT/BIH arrhythmia database). For 5 heartbeat categories classification, the results show the F1-score of N, V, S, Q and F categories are F-N 0.9899, F-V 0.9845, F-S 0.9376, F-Q 0.9968, F-F 0.8889, respectively, and the overall F1-score is 0.9595 using the combination data balancing. The results show the average values for accuracy, sensitivity, specificity, predictive value and F1-score on test set for 14 beat kinds the MIT-BIH arrhythmia database are 99.75%, 91.36%, 99.85%, 90.81% and 0.9016, respectively. Compared with other methods, the proposed method can yield more accurate results.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000714714200016</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34077377</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Heartbeat classification; arrhythmias; time-frequency analysis; Transfer learning; ResNet-101</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ATRIAL-FIBRILLATION; NEURAL-NETWORK; ECG</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhang, Yatao; Li, Dong] Shandong Univ, Sch Mech Elect &amp; Informat Engn, Weihai 264209, Peoples R China. <br>
[Li, Junyan] Weihaiwei Peoples Hosp, Dept Neurol, Weihai 264209, Peoples R China. <br>
[Wei, Shoushui; Zhou, Fengyu] Shandong Univ, Sch Control Sci &amp; Engn, Jinan 17923, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhang, YT (corresponding author), Shandong Univ, Sch Mech Elect &amp; Informat Engn, Weihai 264209, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
zytboy@sdu.edu.cn; whkunyushan@163.com; sswei@sdu.edu.cn; zhoufengyu@sdu.edu.cn; dongli@sdu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Shandong University; Shandong University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Jiang, Bin</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6621-3979&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>zhang, yatao</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6152-0806&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhou, Fengyu</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5140-7036&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>WR7ZD</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>82072014&nbsp;</div>
<div>62076149&nbsp;</div>
<div>61702138&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>China Postdoctoral Science Foundation</grant_agency>&nbsp;</td><td>
<div>2017M612280&nbsp;</div>
<div>2020T130368&nbsp;</div>
<div>2019M662360&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Intergovernmental Project of National Key Research, and Development Program/Hong Kong, Macao, and Taiwan key projects</grant_agency>&nbsp;</td><td>
<div>SQ2019YFE010670&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key R&amp;D project of Shandong Province</grant_agency>&nbsp;</td><td>
<div>2018GSF118133&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Young Scholars Program of Shandong University, Weihai</grant_agency>&nbsp;</td><td>
<div>1050501318006&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Science and Technology Development Plan of Weihai City</grant_agency>&nbsp;</td><td>
<div>1050413421912&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under Grants 82072014, 62076149, and 61702138, in part by the China Postdoctoral Science Foundation under Grants 2017M612280, 2020T130368, and 2019M662360, in part by the Intergovernmental Project of National Key Research, and Development Program/Hong Kong, Macao, and Taiwan key projects under Grant SQ2019YFE010670, in part by the Key R&amp;D project of Shandong Province under Grant 2018GSF118133, in part by the Young Scholars Program of Shandong University, Weihai under Grant 1050501318006, and in part by the Science and Technology Development Plan of Weihai City under Grant 1050413421912.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 40 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A MIL-based framework via contrastive instance learning and multimodal learning for long-term ECG classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Han, HZ (Han, Haozhan); Lian, C (Lian, Cheng); Xu, BR (Xu, Bingrong); Zeng, ZG (Zeng, Zhigang); Alhudhaif, A (Alhudhaif, Adi); Polat, K (Polat, Kemal)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>APPLIED SOFT COMPUTING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>167</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>112372</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.asoc.2024.112372</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>NOV 2024</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 DEC</value>&nbsp;&nbsp;<b>Part:</b> 
<value>B</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
7</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
21</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>47</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Recently, deep learning-based models are widely employed for electrocardiogram (ECG) classification. However, classifying long-term ECGs, which contain vast amounts of data, is challenging. Due to the limitation of memory with respect to the original data size, preprocessing techniques such as resizing or cropping are often applied, leading to information loss. Therefore, introducing multi-instance learning (MIL) to address longterm ECG classification problems is crucial. However, a major drawback of employing MIL is the destruction of sample integrity, which consequently hinders the interaction among instances. To tackle this challenge, we proposed a multimodal MIL neural network named CIMIL, which consists of three key components: an instance interactor, a feature fusion method based on attention mechanisms, and a multimodal contrastive instance loss. First, we designed an instance interactor to improve the interaction and keep continuity among instances. Second, we proposed a novel feature fusion method based on attention mechanisms to effectively aggregate multimodal instance features for final classification, which selects key instances within each class, not only enhances the performance of our model but also reduces the number of parameters. Third, a multimodal contrastive instance loss is proposed to enhance the model's ability to distinguish positive and negative multimodal instances. Finally, we evaluated CIMIL on both intrapatient and interpatient patterns of two commonly used ECG datasets. The experimental results show that the proposed CIMIL outperforms existing state-of-the-art methods on long-term ECG tasks.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001350540800001</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Long-term ECG; Multi-instance learning; Attention mechanism; Multimodal learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CNN</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Han, Haozhan; Lian, Cheng; Xu, Bingrong] Wuhan Univ Technol, Sch Automat, Wuhan 430074, Peoples R China. <br>
[Zeng, Zhigang] Huazhong Univ Sci &amp; Technol, Sch Artificial Intelligence &amp; Automat, Wuhan 430074, Peoples R China. <br>
[Alhudhaif, Adi] Prince Sattam bin Abdulaziz Univ, Coll Comp Engn &amp; Sci Al kharj, Dept Comp Sci, POB 151, Al kharj 11942, Saudi Arabia. <br>
[Polat, Kemal] Bolu Abant Izzet Baysal Univ, Fac Engn, Dept Elect &amp; Elect Engn, Bolu, Turkiye. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Lian, C (corresponding author), Wuhan Univ Technol, Sch Automat, Wuhan 430074, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
chenglian@whut.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Wuhan University of Technology; Huazhong University of Science &amp; Technology; Prince Sattam Bin Abdulaziz University; Abant Izzet Baysal University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Polat, Kemal</display_name>&nbsp;</td><td>AGZ-2143-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Alhudhaif, Adi</display_name>&nbsp;</td><td>AAN-6541-2021&nbsp;</td><td>0000-0002-7201-6963&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zeng, Zhigang</display_name>&nbsp;</td><td>A-1794-2013&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lian, Cheng</display_name>&nbsp;</td><td>KIE-6538-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>L4P0D</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1568-4946</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1872-9681</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>APPL SOFT COMPUT</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Appl. Soft. Comput.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>62176193&nbsp;</div>
<div>62206204&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>&lt;B&gt;Acknowledgments&lt;/B&gt; This work was supported by the Natural Science Foundation of China under Grants 62176193 and 62206204.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 41 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>MVKT-ECG: Efficient single-lead ECG classification for multi-label arrhythmia by multi-view knowledge transferring</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Qin, YZ (Qin, Yuzhen); Sun, L (Sun, Li); Chen, H (Chen, Hui); Yang, WM (Yang, Wenming); Zhang, WQ (Zhang, Wei-Qiang); Fei, JT (Fei, Jintao); Wang, GJ (Wang, Guijin)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>COMPUTERS IN BIOLOGY AND MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>166</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>107503</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.compbiomed.2023.107503</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>OCT 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 NOV</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
14</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
91</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>48</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Electrocardiogram (ECG) is a widely used technique for diagnosing cardiovascular disease. The widespread emergence of smart ECG devices has sparked the demand for intelligent single-lead ECG-based diagnostic systems. However, it is challenging to develop a single-lead-based ECG interpretation model for multiple disease diagnosis due to the lack of some key disease information. We aim to improve the diagnostic capabilities of single-lead ECG for multi-label disease classification in a new teacher-student manner, where the teacher trained by multi-lead ECG educates a student who observes only single-lead ECG We present a new disease aware Contrastive Lead-information Transferring (CLT) to improve the mutual disease information between the single-lead-based ECG interpretation model and multi-lead-based ECG interpretation model. Moreover, We modify the traditional Knowledge Distillation into Multi-label disease Knowledge Distillation (MKD) to make it applicable for multi-label disease diagnosis. The whole knowledge transferring process is inter-lead Multi -View Knowledge Transferring of ECG (MVKT-ECG). By employing the training strategy, we can effectively transfer comprehensive disease knowledge from various views of ECG, such as the 12-lead ECG, to a single-lead-based ECG interpretation model. This enables the model to extract intricate details from single-lead ECG signals and enhances the model's capability of diagnosing and identifying single-lead signals. Extensive experiments on two commonly used public multi-label datasets, ICBEB2018 and PTB-XL demonstrate that our MVKT-ECG yields exceptional diagnostic performance improvements for single-lead ECG. The student outperforms its baseline observably on the PTB-XL dataset (1.3 % on PTB.super, and 1.4 % on PTB.sub), and on ICBEB2018 dataset (3.2 %).</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001088270400001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37806055</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Single-lead Electrocardiogram; Arrhythmia classification; Deep learning; Knowledge transfer; Neural network</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Qin, Yuzhen; Yang, Wenming] Tsinghua Univ, Shenzhen Int Grad Sch, Shenzhen 518071, Peoples R China. <br>
[Sun, Li; Chen, Hui; Zhang, Wei-Qiang; Wang, Guijin] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China. <br>
[Fei, Jintao] Beijing Tsinghua Changgung Hosp, Beijing 102218, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Wang, GJ (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
wangguijin@tsinghua.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Tsinghua University; Tsinghua University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Yang, Wenming</display_name>&nbsp;</td><td>HJH-8634-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Life Sciences &amp; Biomedicine - Other Topics; Computer Science; Engineering; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>U9XR8</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0010-4825</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-0534</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>COMPUT BIOL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Comput. Biol. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foun-dation of China</grant_agency>&nbsp;</td><td>
<div>62276153&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This research was supported by the National Natural Science Foun-dation of China under Grant No. 62276153.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 42 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Disentangled representation learning in cardiac image analysis</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Chartsias, A (Chartsias, Agisilaos); Joyce, T (Joyce, Thomas); Papanastasiou, G (Papanastasiou, Giorgos); Semple, S (Semple, Scott); Williams, M (Williams, Michelle); Newby, DE (Newby, David E.); Dharmakumar, R (Dharmakumar, Rohan); Tsaftaris, SA (Tsaftaris, Sotirios A.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>58</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>101535</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2019.101535</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2019 DEC</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>123</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>133</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
40</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>49</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Typically, a medical image offers spatial information on the anatomy (and pathology) modulated by imaging specific characteristics. Many imaging modalities including Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) can be interpreted in this way. We can venture further and consider that a medical image naturally factors into some spatial factors depicting anatomy and factors that denote the imaging characteristics. Here, we explicitly learn this decomposed (disentangled) representation of imaging data, focusing in particular on cardiac images. We propose Spatial Decomposition Network (SDNet), which factorises 2D medical images into spatial anatomical factors and non-spatial modality factors. We demonstrate that this high-level representation is ideally suited for several medical image analysis tasks, such as semi-supervised segmentation, multi-task segmentation and regression, and image-to-image synthesis. Specifically, we show that our model can match the performance of fully supervised segmentation models, using only a fraction of the labelled images. Critically, we show that our factorised representation also benefits from supervision obtained either when we use auxiliary tasks to train the model in a multi-task setting (e.g. regressing to known cardiac indices), or when aggregating multimodal data from different sources (e.g. pooling together MRI and CT data). To explore the properties of the learned factorisation, we perform latent-space arithmetic and show that we can synthesise CT from MR and vice versa, by swapping the modality factors. We also demonstrate that the factor holding image specific information can be used to predict the input modality with high accuracy. Code will be made available at https://github.comiagis85/anatomy_modality_decomposition. (C) 2019 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000496605700025</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>31351230</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Disentangled representation learning; Cardiac magnetic resonance imaging; Semi-supervised segmentation; Multitask learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
WHOLE HEART SEGMENTATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Chartsias, Agisilaos; Joyce, Thomas; Tsaftaris, Sotirios A.] Univ Edinburgh, Inst Digital Commun, Sch Engn, West Mains Rd, Edinburgh EH9 3FB, Midlothian, Scotland. <br>
[Papanastasiou, Giorgos; Semple, Scott; Williams, Michelle; Newby, David E.] Edinburgh Imaging Facil QMRI, Edinburgh EH16 4TJ, Midlothian, Scotland. <br>
[Papanastasiou, Giorgos; Semple, Scott; Williams, Michelle; Newby, David E.] Ctr Cardiovasc Sci, Edinburgh EH16 4TJ, Midlothian, Scotland. <br>
[Dharmakumar, Rohan] Cedars Sinai Med Ctr, Los Angeles, CA 90048 USA. <br>
[Tsaftaris, Sotirios A.] Alan Turing Inst, London, England. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Chartsias, A (corresponding author), Univ Edinburgh, Inst Digital Commun, Sch Engn, West Mains Rd, Edinburgh EH9 3FB, Midlothian, Scotland.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
agis.chartsias@ed.ac.uk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Edinburgh; Cedars Sinai Medical Center; Alan Turing Institute</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Newby, David</display_name>&nbsp;</td><td>AAB-1364-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Papanastasiou, Giorgos</display_name>&nbsp;</td><td>ABH-8943-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Williams, Michelle</display_name>&nbsp;</td><td>K-7555-2012&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Newby, David</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7971-4628&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Tsaftaris, Sotirios</display_name>&nbsp;</td><td>E-3725-2010&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Papanastasiou, Giorgos</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1939-296X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Joyce, Thomas</display_name>&nbsp;</td><td>IWU-5793-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>JN0PE</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>US National Institutes of Health</grant_agency>&nbsp;</td><td>
<div>1R01HL136578-01&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>UK EPSRC</grant_agency>&nbsp;</td><td>
<div>EP/P022928/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Royal Academy of Engineering</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EPSRC</grant_agency>&nbsp;</td><td>
<div>EP/P022928/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>MRC</grant_agency>&nbsp;</td><td>
<div>G0701127&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>British Heart Foundation</grant_agency>&nbsp;</td><td>
<div>CH/09/002/26360&nbsp;</div>
<div>RG/16/10/32375&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Engineering and Physical Sciences Research Council</grant_agency>&nbsp;</td><td>
<div>EP/P022928/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Medical Research Council</grant_agency>&nbsp;</td><td>
<div>G0701127&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the US National Institutes of Health (1R01HL136578-01) and UK EPSRC (EP/P022928/1), and used resources provided by the Edinburgh Compute and Data Facility (http://www.ecdf.ed.ac.uk/). S.A.Tsaftaris acknowledges the support of the Royal Academy of Engineering and the Research Chairs and Senior Research Fellowships scheme.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted, Green Accepted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 43 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Acoustic feature based unsupervised approach of heart sound event detection</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Das, S (Das, Sangita); Pal, S (Pal, Saurabh); Mitra, M (Mitra, Madhuchhanda)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>COMPUTERS IN BIOLOGY AND MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>126</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>103990</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.compbiomed.2020.103990</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 NOV</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>28</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>29</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
56</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>46</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This paper represents an unsupervised approach to detect the positions of S1, S2 heart sound events in a Phonocardiogram (PCG) recording. Insufficiency of correctly annotated heart sound database drives us to investigate unsupervised techniques. Gammatone filter bank features are used to characterize the spectral pattern of fundamental heart sound events from noise contaminated PCG data. An unsupervised spectral clustering technique is employed for segmentation of S1/S2 and non-S1/S2 heart sound events. A Feature winning score is computed to identify the S1/52 and non-S1/S2 frames. Finally, time based threshold is applied to detect the accurate positions of S1 and S2 heart sounds. The performance of spectral clustering is compared with other clustering methods. The proposed method offers a maximum Fl-score of 98% and 92.5% for normal and abnormal PCG data respectively on 2016 PhysioNet/CinC challenge dataset. The heart sound annotation algorithm provided by PhysioNet has been used as the ground truth after hand correction.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000582723600001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>32987200</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Heart sound; Phonocardiogram (PCG); Spectral clustering; Heart sound segmentation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NEURAL-NETWORK CLASSIFICATION; SEGMENTATION; RECOGNITION; NOISE; IDENTIFICATION; SEPARATION; IMAGE</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Das, Sangita; Pal, Saurabh; Mitra, Madhuchhanda] Univ Calcutta, Dept Appl Phys, 92APC Rd, Kolkata 700009, W Bengal, India. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Mitra, M (corresponding author), Univ Calcutta, Dept Appl Phys, 92APC Rd, Kolkata 700009, W Bengal, India.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
mmaphy@caluniv.ac.in</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Calcutta</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Pal, Saurabh</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5139-6573&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Life Sciences &amp; Biomedicine - Other Topics; Computer Science; Engineering; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>OH6RT</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0010-4825</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-0534</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>COMPUT BIOL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Comput. Biol. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Council of Scientific and Industrial Research (CSIR)</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The authors thank Dr. Santanu Guha, Professor and Head, Department of Cardiology, Medical College, Kolkata for his supports and valuable suggestions. We gratefully acknowledge Council of Scientific and Industrial Research (CSIR) for their financial support.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 44 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Inter-Patient ECG Classification With Symbolic Representations and Multi-Perspective Convolutional Neural Networks</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Niu, JH (Niu, Jinghao); Tang, YQ (Tang, Yongqiang); Sun, ZY (Sun, Zhengya); Zhang, WS (Zhang, Wensheng)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>24</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>5</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>1321-1332</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2019.2942938</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 MAY</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>104</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>112</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
85</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>47</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This paper presents a novel deep learning framework for the inter-patient electrocardiogram (ECG) heartbeat classification. A symbolization approach especially designed for ECG is introduced, which can jointly represent the morphology and rhythm of the heartbeat and alleviate the influence of inter-patient variation through baseline correction. The symbolic representation of the heartbeat is used by a multi-perspective convolutional neural network (MPCNN) to learn features automatically and classify the heartbeat. We evaluate our method for the detection of the supraventricular ectopic beat (SVEB) and ventricular ectopic beat (VEB) on MIT-BIH arrhythmia dataset. Compared with the state-of-the-art methods based on manual features or deep learning models, our method shows superior performance: the overall accuracy of 96.4%, F1 scores for SVEB and VEB of 76.6% and 89.7%, respectively. The ablation study on our method validates the effectiveness of the proposed symbolization approach and joint representation architecture, which can help the deep learning model to learn more general features and improve the ability of generalization for unseen patients. Because our method achieves a competitive inter-patient heartbeat classification performance without complex handcrafted features or the intervention of the human expert, it can also be adjusted to handle various other tasks relative to ECG classification.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000535614100009</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>31545750</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Heart beat; Electrocardiography; Heart rate variability; Deep learning; Feature extraction; Task analysis; Informatics; ECG classification; biomedical monitoring; convolutional neural network; deep learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
HEARTBEAT CLASSIFICATION; ARRHYTHMIA DETECTION; FEATURES</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Niu, Jinghao; Tang, Yongqiang; Sun, Zhengya; Zhang, Wensheng] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China. <br>
[Niu, Jinghao; Tang, Yongqiang; Sun, Zhengya; Zhang, Wensheng] Univ Chinese Acad Sci, Beijing 100049, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhang, WS (corresponding author), Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
niujinghao2015@ia.ac.cn; tangyongqiang2014@ia.ac.cn; zhengya.sun@ia.ac.cn; zhangwenshengia@hotmail.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Chinese Academy of Sciences; Institute of Automation, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Niu, Jinghao</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9598-297X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>tang, yong qiang</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-9333-8200&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>LR3SW</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key R&amp;D Program of China</grant_agency>&nbsp;</td><td>
<div>2017YFC0803700&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61432008&nbsp;</div>
<div>61876183&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Municipal Natural Science Foundation</grant_agency>&nbsp;</td><td>
<div>4172063&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Key R&amp;D Program of China (2017YFC0803700), in part by the National Natural Science Foundation of China under Grant 61432008 and Grant 61876183, and in part by Beijing Municipal Natural Science Foundation under Grant 4172063.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 45 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A probabilistic deep motion model for unsupervised cardiac shape anomaly assessment</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zakeri, A (Zakeri, Arezoo); Hokmabadi, A (Hokmabadi, Alireza); Ravikumar, N (Ravikumar, Nishant); Frangi, AF (Frangi, Alejandro F.); Gooya, A (Gooya, Ali)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>75</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>102276</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2021.102276</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>NOV 2021</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2022 JAN</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>8</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>8</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
10</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>54</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Automatic shape anomaly detection in large-scale imaging data can be useful for screening suboptimal segmentations and pathologies altering the cardiac morphology without intensive manual labour. We propose a deep probabilistic model for local anomaly detection in sequences of heart shapes, modelled as point sets, in a cardiac cycle. A deep recurrent encoder-decoder network captures the spatio-temporal dependencies to predict the next shape in the cycle and thus derive the outlier points that are attributed to excessive deviations from the network prediction. A predictive mixture distribution models the inlier and outlier classes via Gaussian and uniform distributions, respectively. A Gibbs sampling Expectation Maximisation (EM) algorithm computes soft anomaly scores of the points via the posterior probabilities of each class in the E-step and estimates the parameters of the network and the predictive distribution in the M-step. We demonstrate the versatility of the method using two shape datasets derived from: (i) one million biventricular CMR images from 20,0 0 0 participants in the UK Biobank (UKB), and (ii) routine diagnostic imaging from Multi-Centre, Multi-Vendor, and Multi-Disease Cardiac Image (M&amp;Ms). Experiments show that the detected shape anomalies in the UKB dataset are mostly associated with poor segmentation quality, and the predicted shape sequences show significant improvement over the input sequences. Furthermore, evaluations on U-Net based shapes from the M&amp;Ms dataset reveals that the anomalies are attributable to the underlying pathologies that affect the ventricles. The proposed model can therefore be used as an effective mechanism to sift shape anomalies in large-scale cardiac imaging pipelines for further analysis. (c) 2021 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000718407400014</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>34753021</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac shape quality control; Deep learning; Expectation-maximisation; Probabilistic model; Spatio-temporal anomaly detection; UK Biobank</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
MR-IMAGES; ATLAS; ABNORMALITIES</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zakeri, Arezoo; Hokmabadi, Alireza; Ravikumar, Nishant; Frangi, Alejandro F.; Gooya, Ali] Univ Leeds, Ctr Computat Imaging &amp; Simulat Technol Biomed CIS, Sch Comp, Leeds, W Yorkshire, England. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zakeri, A; Gooya, A (corresponding author), Univ Leeds, Ctr Computat Imaging &amp; Simulat Technol Biomed CIS, Sch Comp, Leeds, W Yorkshire, England.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
a.zakeri@leeds.ac.uk; a.gooya@leeds.ac.uk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Leeds</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Hokmabadi, Alireza</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1407-4540&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Gooya, Ali</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-5135-4800&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Frangi, Alejandro</display_name>&nbsp;</td><td>C-6500-2008&nbsp;</td><td>0000-0002-2675-528X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zakeri, Arezoo</display_name>&nbsp;</td><td>HKV-6795-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ravikumar, Nishant</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0134-107X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zakeri, Arezoo</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6011-2333&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>WX2BN</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Engineering and Physical Sciences Research Council (EPSRC)</grant_agency>&nbsp;</td><td>
<div>EP/S012796/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Royal Academy of Engineering Chair in Emerging Technologies Scheme</grant_agency>&nbsp;</td><td>
<div>CiET1819/19&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>CardioX</grant_agency>&nbsp;</td><td>
<div>GrowMedTech POC041&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EPSRC</grant_agency>&nbsp;</td><td>
<div>EP/S012796/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Medical Research Council</grant_agency>&nbsp;</td><td>
<div>MC_PC_17228&nbsp;</div>
<div>MC_qA137853&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the Engineering and Physical Sciences Research Council (EPSRC) (grant number EP/S012796/1). AFF is partially supported by a Royal Academy of Engineering Chair in Emerging Technologies Scheme (CiET1819/19) and CardioX (GrowMedTech POC041). The authors would like to thank Dr. Rahman Attar for making the UKB shape dataset available. The UKB CMR dataset and the ground-truth contours have been provided under UK Biobank Access Application #11350. The authors thank all UK Biobank participants and staff.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 46 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Assessing the signal quality of electrocardiograms from varied acquisition sources: A generic machine learning pipeline for model generation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Albaba, A (Albaba, Adnan); Simo, N (Simo, Neide); Wang, YY (Wang, Yuyang); Hendriks, RC (Hendriks, Richard C.); De Raedt, W (De Raedt, Walter); Van Hoof, C (Van Hoof, Chris)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>COMPUTERS IN BIOLOGY AND MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>130</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>104164</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.compbiomed.2020.104164</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>17</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>17</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
16</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>43</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Background and objective: Long-term electrocardiogram monitoring comes at the expense of signal quality. During unconstrained movements, the electrocardiogram is often corrupted by motion artefacts, which can lead to inaccurate physiological information. In this situation, automated quality assessment methods are useful to increase the reliability of the measurements. A generic machine learning pipeline that generates classification models for electrocardiogram quality assessment is presented in this article. The presented pipeline is tested on signals from varied acquisition sources, towards selecting segments that can be used for heart rate analysis in lifestyle applications.
<br>Methods: Electrocardiogram recordings from traditional, wearable and ubiquitous devices, are segmented in 10 s windows and manually labeled by experienced researchers into two quality classes. To capture the electrocardiogram dynamics, a comprehensive set of 43 features is extracted from each segment, based on the time-domain signal, its Fast Fourier Transform, the Autocorrelation function and the Stationary Wavelet Transform. To select the most relevant features for each acquisition source we employ both a customized hybrid approach and the state-of-the-art Neighborhood Component Analysis method and compare them. Support Vector Machines (SVM), Decision Trees, K-Nearest-Neighbors and supervised ensemble methods are tested as possible binary classifiers.
<br>Results: The results for the best performing models on traditional, wearable and ubiquitous electrocardiogram datasets are, respectively: balanced-accuracy: 89%, F1-score: 93% with the Fine Gaussian SVM model and 10 features; balanced-accuracy: 93%, F1-score: 93% with the Fine Gaussian SVM model and 11 features; balanced accuracy: 95%, F1-score: 86%, with the Fine Gaussian SVM model and 8 features.
<br>Conclusions: According to the results, our generic pipeline can generate classification models tailored to individual acquisition sources, provided that a standard Lead I or Lead II is available. Such models accurately establish whether the electrocardiogram quality is good or bad for heart rate analysis. Furthermore, removing bad quality segments decreases errors in heart rate calculation.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000623917000009</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33360108</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Electrocardiogram; Wearables; Ubiquitous; Non-contact; Classification; Feature selection; Motion artefact; Signal quality</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
QRS DETECTION; ECG</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Albaba, Adnan; Simo, Neide; Van Hoof, Chris] Univ Leuven, Dept Elect Engn, Leuven, Belgium. <br>
[Albaba, Adnan; Simo, Neide; De Raedt, Walter; Van Hoof, Chris] IMEC, Connected Hlth Solut Grp, Leuven, Belgium. <br>
[Wang, Yuyang; Hendriks, Richard C.] Delft Univ Technol, Dept Elect Engn, Delft, Netherlands. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
De Raedt, W (corresponding author), IMEC, Connected Hlth Solut Grp, Leuven, Belgium.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
adnan.albaba@imec.be; neide.simoescapela@kuleuven.be; y.wang-54@student.tudelft.nl; r.c.hendriks@tudelft.nl; walter.deraedt@imec.be; chris.vanhoof@imec.be</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
KU Leuven; Interuniversity Microelectronics Centre; Delft University of Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>De Raedt, Walter</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-7117-7976&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Van Hoof, Chris</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-4645-3326&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Albaba, Adnan</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9945-2650&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Simoes-Capela, Neide</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0550-4964&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Albaba, Adnan</display_name>&nbsp;</td><td>MAH-3139-2025&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Life Sciences &amp; Biomedicine - Other Topics; Computer Science; Engineering; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>QP6AG</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0010-4825</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-0534</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>COMPUT BIOL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Comput. Biol. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Open Access:</b>

<value>hybrid</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 47 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Deep Representation Learning With Sample Generation and Augmented Attention Module for Imbalanced ECG Classification</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zubair, M (Zubair, Muhammad); Woo, S (Woo, Sungpil); Lim, S (Lim, Sunhwan); Kim, D (Kim, Daeyoung)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>28</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>5</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2461-2472</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2023.3325540</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 MAY</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>10</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>10</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
42</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>61</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Developing an efficient heartbeat monitoring system has become a focal point in numerous healthcare applications. Specifically, in the last few years, heartbeat classification for arrhythmia detection has gained considerable interest from researchers. This paper presents a novel deep representation learning method for the efficient detection of arrhythmic beats. To mitigate the issues associated with the imbalanced data distribution, a novel re-sampling strategy is introduced. Unlike the existing oversampling methods, the proposed technique transforms majority-class samples into minority-class samples with a novel translation loss function. This approach assists the model in learning a more generalized representation of crucially important minority class samples. Moreover, by exploiting an auxiliary feature, an augmented attention module is designed that focuses on the most relevant and target-specific information. We adopted an inter-patient classification paradigm to evaluate the proposed method. The experimental results of this study on the MIT-BIH arrhythmia database clearly indicate that the proposed model with augmented attention mechanism and over-sampling strategy significantly learns a balanced deep representation and improves the classification performance of vital heartbeats.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001221547700062</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37851553</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Arrhythmia detection; beat classification; imbalanced learning; remote health monitoring</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CONVOLUTIONAL NEURAL-NETWORK; HEARTBEAT CLASSIFICATION; MORPHOLOGY; FEATURES; MODEL</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zubair, Muhammad; Woo, Sungpil; Lim, Sunhwan] Elect &amp; Telecommun Res Inst ETRI, Autonomous IoT Res Sect, Daejeon 34129, South Korea. <br>
[Woo, Sungpil; Kim, Daeyoung] Korea Adv Inst Sci &amp; Technol KAIST, Dept Sch Comp, Daejeon 34141, South Korea. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Woo, S (corresponding author), Elect &amp; Telecommun Res Inst ETRI, Autonomous IoT Res Sect, Daejeon 34129, South Korea.<br>Woo, S (corresponding author), Korea Adv Inst Sci &amp; Technol KAIST, Dept Sch Comp, Daejeon 34141, South Korea.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
zubair5608@etri.re.kr; woosungpil@etri.re.kr; shlim@etri.re.kr; kimd@kaist.ac.kr</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Electronics &amp; Telecommunications Research Institute - Korea (ETRI); Korea Advanced Institute of Science &amp; Technology (KAIST)</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zubair, Muhammad</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-3595-4969&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>ZUBAIR, MUHAMMAD</display_name>&nbsp;</td><td>JVN-7799-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>QN4V6</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Institute of Information &amp; Communications Technology Planning Evaluation</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>No Statement Available</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Bronze</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 48 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>A Generic Quality Control Framework for Fetal Ultrasound Cardiac Four-Chamber Planes</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Dong, JB (Dong, Jinbao); Liu, SF (Liu, Shengfeng); Liao, YM (Liao, Yimei); Wen, HX (Wen, Huaxuan); Lei, BY (Lei, Baiying); Li, SL (Li, Shengli); Wang, TF (Wang, Tianfu)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>24</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>4</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>931-942</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2019.2948316</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 APR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>72</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>95</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
55</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>52</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Quality control/assessment of ultrasound (US) images is an essential step in clinical diagnosis. This process is usually done manually, suffering from some drawbacks, such as dependence on operator's experience and extensive labors, as well as high inter- and intra-observer variation. Automatic quality assessment of US images is therefore highly desirable. Fetal US cardiac four-chamber plane (CFP) is one of the most commonly used cardiac views, which was used in the diagnosis of heart anomalies in the early 1980s. In this paper, we propose a generic deep learning framework for automatic quality control of fetal US CFPs. The proposed framework consists of three networks: (1) a basic CNN (B-CNN), roughly classifying four-chamber views from the raw data; (2) a deeper CNN (D-CNN), determining the gain and zoom of the target images in a multi-task learning manner; and (3) the aggregated residual visual block net (ARVBNet), detecting the key anatomical structures on a plane. Based on the output of the three networks, overall quantitative score of each CFP is obtained, so as to achieve fully automatic quality control. Experiments on a fetal US dataset demonstrated our proposed method achieved a highest mean average precision (mAP) of 93.52% at a fast speed of 101 frames per second (FPS). In order to demonstrate the adaptability and generalization capacity, the proposed detection network (i.e., ARVBNet) has also been validated on the PASCAL VOC dataset, obtaining a highest mAP of 81.2% when input size is approximately 300 x 300.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000525354900001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>31634851</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Quality control; Anatomical structure; Quality assessment; Ultrasonic imaging; Real-time systems; Quality control; cardiac four-chamber planes (CFPs); convolutional neural network (CNN); real-time object detection; aggregated residual visual block (ARVB)</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
HEART</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Dong, Jinbao; Liu, Shengfeng; Lei, Baiying; Wang, Tianfu] Shenzhen Univ, Natl Reg Key Technol Engn Lab Med Ultrasound, Guangdong Prov Key Lab Biomed Measurements &amp; Ultr, Sch Biomed Engn,Hlth Sci Ctr, Shenzhen 518060, Peoples R China. <br>
[Liao, Yimei; Wen, Huaxuan; Li, Shengli] Southern Med Univ, Shenzhen Matern &amp; Child Healthcare Hosp, Dept Ultrasound, Shenzhen 518028, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Wang, TF (corresponding author), Shenzhen Univ, Natl Reg Key Technol Engn Lab Med Ultrasound, Guangdong Prov Key Lab Biomed Measurements &amp; Ultr, Sch Biomed Engn,Hlth Sci Ctr, Shenzhen 518060, Peoples R China.<br>Li, SL (corresponding author), Southern Med Univ, Shenzhen Matern &amp; Child Healthcare Hosp, Dept Ultrasound, Shenzhen 518028, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
995238847@qq.com; liusf2009@163.com; liaoyimei1987@qq.com; whxwell@126.com; leiby@szu.edu.cn; lishengli63@126.com; tfwang@szu.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Shenzhen University; Southern Medical University - China; Shenzhen Maternity &amp; Child Healthcare Hospital</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>liu, sheng feng</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-6902-3329&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>liu, shengfeng</display_name>&nbsp;</td><td>N-2303-2018&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lei, Baiying</display_name>&nbsp;</td><td>GQO-8422-2022&nbsp;</td><td>0000-0002-3087-2550&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Liao, Yimei</display_name>&nbsp;</td><td>ABG-8261-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Li, Shengli</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0570-4165&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>LC5GX</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>81571758&nbsp;</div>
<div>81771922&nbsp;</div>
<div>61871274&nbsp;</div>
<div>61801305&nbsp;</div>
<div>61501305&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key Research and Develop Program</grant_agency>&nbsp;</td><td>
<div>2016YFC0104700&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Natural Science Foundation of China under Grant 81571758, Grant 81771922, Grant 61871274, Grant 61801305, and Grant 61501305; and in part by the National Key Research and Develop Program (2016YFC0104700).</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 49 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Learning-Based Regularization for Cardiac Strain Analysis via Domain Adaptation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Lu, AE (Lu, Allen); Ahn, SS (Ahn, Shawn S.); Ta, K (Ta, Kevinminh); Parajuli, N (Parajuli, Nripesh); Stendahl, JC (Stendahl, John C.); Liu, Z (Liu, Zhao); Boutagy, NE (Boutagy, Nabil E.); Jeng, GS (Jeng, Geng-Shi); Staib, LH (Staib, Lawrence H.); O'Donnell, M (O'Donnell, Matthew); Sinusas, AJ (Sinusas, Albert J.); Duncan, JS (Duncan, James S.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>9</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2233-2245</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2021.3074033</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 SEP</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>14</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>15</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
15</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>48</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Reliable motion estimation and strain analysis using 3D+ time echocardiography (4DE) for localization and characterization of myocardial injury is valuable for early detection and targeted interventions. However, motion estimation is difficult due to the low-SNR that stems from the inherent image properties of 4DE, and intelligent regularization is critical for producing reliable motion estimates. In this work, we incorporated the notion of domain adaptation into a supervised neural network regularization framework. We first propose a semi-supervised Multi-Layered Perceptron (MLP) network with biomechanical constraints for learning a latent representation that is shown to have more physiologically plausible displacements. We extended this framework to include a supervised loss term on synthetic data and showed the effects of biomechanical constraints on the network's ability for domain adaptation. We validated the semi-supervised regularization method on in vivo data with implanted sonomicrometers. Finally, we showed the ability of our semi-supervised learning regularization approach to identify infarct regions using estimated regional strain maps with good agreement to manually traced infarct regions from postmortem excised hearts.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000692208500005</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33872145</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Strain; Adaptation models; Myocardium; Finite element analysis; Feature extraction; Estimation; Data models; Cardiac function; echocardiography; motion analysis; machine learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
SPECKLE TRACKING; NONRIGID REGISTRATION; DEFORMATION; IMAGES; MOTION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Lu, Allen; Ahn, Shawn S.; Ta, Kevinminh; Staib, Lawrence H.; Duncan, James S.] Yale Univ, Dept Biomed Engn, New Haven, CT 06511 USA. <br>
[Parajuli, Nripesh] Capt Hlth, San Francisco, CA 94132 USA. <br>
[Stendahl, John C.; Boutagy, Nabil E.; Sinusas, Albert J.] Yale Univ, Sect Cardiovasc Med, Dept Internal Med, New Haven, CT 06511 USA. <br>
[Liu, Zhao; Staib, Lawrence H.; Sinusas, Albert J.; Duncan, James S.] Yale Univ, Dept Radiol &amp; Biomed Imaging, New Haven, CT 06511 USA. <br>
[Jeng, Geng-Shi] Natl Yang Ming Chiao Tung Univ, Inst Elect, Hsinchu 30010, Taiwan. <br>
[Staib, Lawrence H.; Duncan, James S.] Yale Univ, Dept Elect Engn, New Haven, CT 06511 USA. <br>
[O'Donnell, Matthew] Univ Washington, Dept Bioengn, Seattle, WA 98015 USA. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Ahn, SS (corresponding author), Yale Univ, Dept Biomed Engn, New Haven, CT 06511 USA.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
haiyinglu.allen@gmail.com; shawn.ahn@yale.edu; kevinminh.ta@yale.edu; nripesh.parajuli.21@gmail.com; john.stendahl@yale.edu; zhao.liu@yale.edu; nabil.boutagy@yale.edu; jeng@nctu.edu.tw; lawrence.staib@yale.edu; odonnel@uw.edu; albert.sinusas@yale.edu; james.duncan@yale.edu</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Yale University; Yale University; Yale University; National Yang Ming Chiao Tung University; Yale University; University of Washington; University of Washington Seattle</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ahn, Shawn</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5961-3376&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Staib, Lawrence</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9516-5136&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Sinusas, Albert</display_name>&nbsp;</td><td>A-7235-2009&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>, Geng-Shi</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4105-573X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Stendahl, John</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-1568-9280&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>UK8IN</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>13</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Institute of Health</grant_agency>&nbsp;</td><td>
<div>R01HL121226&nbsp;</div>
<div>T32HL098069&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Institute of Health Medical Scientist Training Program</grant_agency>&nbsp;</td><td>
<div>T32GM007205&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Heart Lung and Blood Institute</grant_agency>&nbsp;</td><td>
<div>R01HL121226&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Institute of General Medical Sciences</grant_agency>&nbsp;</td><td>
<div>T32GM136651&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Institute of Health under Grant R01HL121226 and Grant T32HL098069 and in part by the National Institute of Health Medical Scientist Training Program under Grant T32GM007205.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>hybrid, Green Accepted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 50 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Improving the Quality of Fetal Heart Ultrasound Imaging With Multihead Enhanced Self-Attention and Contrastive Learning</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhang, YY (Zhang, Yingying); Zhu, HG (Zhu, Haogang); Cheng, J (Cheng, Jian); Wang, JY (Wang, Jingyi); Gu, XY (Gu, Xiaoyan); Han, JC (Han, Jiancheng); Zhang, Y (Zhang, Ye); Zhao, Y (Zhao, Ying); He, YH (He, Yihua); Zhang, HJ (Zhang, Hongjia)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>27</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>11</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>5518-5529</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2023.3303573</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 NOV</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>9</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>10</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
4</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
22</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>51</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Fetal congenital heart disease (FCHD) is a common, serious birth defect affecting similar to 1% of newborns annually. Fetal echocardiography is the most effective and important technique for prenatal FCHD diagnosis. The pre-requisites for accurate ultrasound FCHD diagnosis are accurate view recognition and high-quality diagnostic view extraction. However, these manual clinical procedures have drawbacks such as, varying technical capabilities and in-efficiency. Therefore, the automatic identification of high-quality multiview fetal heart scan images is highly desirable to improve prenatal diagnosis efficiency and accuracy of FCHD. Here, we present a framework for multiview fetal heart ultrasound image recognition and quality assessment that comprises two parts: a multiview classification and localization network (MCLN) and an improved contrastive learning network (ICLN). In the MCLN, a multihead enhanced self-attention mechanism is applied to construct the classification network and identify six accurate and interpretable views of the fetal heart. In the ICLN, anatomical structure standardization and image clarity are considered. With contrastive learning, the absolute loss, feature relative loss and predicted value relative loss are combined to achieve favorable quality assessment results. Experiments show that the MCLN outperforms other state-of-the-art networks by 1.52-13.61% when determining the F1 score in six standard view recognition tasks, and the ICLN is comparable to the performance of expert cardiologists in the quality assessment of fetal heart ultrasound images, reaching 97% on a test set within 2 points for the four-chamber view task. Thus, our architecture offers great potential in helping cardiologists improve quality control for fetal echocardiographic images in clinical practice.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001129955100029</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37556337</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Contrastive learning; fetal congenital heart disease; fetal echocardiography; view recognition; quality assessment; multihead enhanced self-attention</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NEURAL-NETWORKS; ECHOCARDIOGRAPHY; DISEASE; MANAGEMENT</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhang, Yingying] Beihang Univ, Sch Biol Sci &amp; Med Engn, Beijing 100191, Peoples R China. <br>
[Zhu, Haogang; Cheng, Jian] Beihang Univ, Sch Comp Sci &amp; Engn, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China. <br>
[Zhu, Haogang; Cheng, Jian] Zhongguancun Lab, Beijing 102206, Peoples R China. <br>
[Wang, Jingyi; Gu, Xiaoyan; Han, Jiancheng; Zhang, Ye; Zhao, Ying; He, Yihua] Capital Med Univ, Beijing Anzhen Hosp, Echocardiog Med Ctr, Beijing 100054, Peoples R China. <br>
[Zhang, Hongjia] Beijing Lab Cardiovasc Precis Med, Beijing 100029, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhu, HG (corresponding author), Beihang Univ, Sch Comp Sci &amp; Engn, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.<br>Zhu, HG (corresponding author), Zhongguancun Lab, Beijing 102206, Peoples R China.<br>He, YH (corresponding author), Capital Med Univ, Beijing Anzhen Hosp, Echocardiog Med Ctr, Beijing 100054, Peoples R China.<br>Zhang, HJ (corresponding author), Beijing Lab Cardiovasc Precis Med, Beijing 100029, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
zhangyingying@buaa.edu.cn; haogangzhu@buaa.edu.cn; jian_cheng@buaa.edu.cn; wangjingyianzhen@163.com; xiaoyan_gu@yahoo.com; han_jc1977@hotmail.com; zhang3389@qq.com; yingzhaoecho@163.com; heyihuae-cho@hotmail.com; zhanghongjia722@hotmail.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Beihang University; Beihang University; Zhongguancun Laboratory; Capital Medical University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>贺, 艺华</display_name>&nbsp;</td><td>AFV-8567-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cheng, Jian</display_name>&nbsp;</td><td>J-9124-2017&nbsp;</td><td>0000-0003-1435-673X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Jingyi</display_name>&nbsp;</td><td>AAS-7653-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>zhang, yingying</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0964-1774&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhang, Jian</display_name>&nbsp;</td><td>F-7865-2015&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>DC9R2</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Key R&amp;D Program of China</grant_agency>&nbsp;</td><td>
<div>2021ZD0140407&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>U21A20523&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Natural Science Foundation</grant_agency>&nbsp;</td><td>
<div>L222152&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Municipal Administration of Hospitals Incubating Program</grant_agency>&nbsp;</td><td>
<div>PX2022026&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Fundamental Research Funds for the Central Universities, Beijing Advanced Innovation Center for Big Data-Based Precision Medicine, Beihang University, Beijing, China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>State Key Laboratory of Software Development Environment, Beihang University, Beijing, China, Beijing Lab for Cardiovascular Precision Medicine</grant_agency>&nbsp;</td><td>
<div>PXM2018_014226_000013&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Key Laboratory of Maternal-Fetal Medicine in Fetal Heart Disease</grant_agency>&nbsp;</td><td>
<div>BZ0308&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the National Key R&amp;D Program of China under Grant 2021ZD0140407, in part by the National Natural Science Foundation of China under Grant U21A20523, in part by the Beijing Natural Science Foundation under Grant L222152, in part by the Beijing Municipal Administration of Hospitals Incubating Program under Grant PX2022026, in part by the Fundamental Research Funds for the Central Universities, Beijing Advanced Innovation Center for Big Data-Based Precision Medicine, Beihang University, Beijing, China, in part by the State Key Laboratory of Software Development Environment, Beihang University, Beijing, China, Beijing Lab for Cardiovascular Precision Medicine under Grant PXM2018_014226_000013, and in part by the Beijing Key Laboratory of Maternal-Fetal Medicine in Fetal Heart Disease under Grant BZ0308.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Bronze</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 51 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Non-Rigid Respiratory Motion Estimation of Whole-Heart Coronary MR Images Using Unsupervised Deep Learning</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Qi, HK (Qi, Haikun); Fuin, N (Fuin, Niccolo); Cruz, G (Cruz, Gastao); Pan, JZ (Pan, Jiazhen); Kuestner, T (Kuestner, Thomas); Bustin, A (Bustin, Aurelien); Botnar, RM (Botnar, Rene M.); Prieto, C (Prieto, Claudia)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>1</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>444-454</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2020.3029205</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 JAN</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>36</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>38</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
5</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
31</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>52</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Non-rigid motion-corrected reconstruction has been proposed to account for the complex motion of the heart in free-breathing 3D coronary magnetic resonance angiography (CMRA). This reconstruction framework requires efficient and accurate estimation of non-rigid motion fields from undersampled images at different respiratory positions (or bins). However, state-of-the-art registration methods can be time-consuming. This article presents a novel unsupervised deep learning-based strategy for fast estimation of inter-bin 3D non-rigid respiratory motion fields for motion-corrected free-breathing CMRA. The proposed 3D respiratory motion estimation network (RespME-net) is trained as a deep encoder-decoder network, taking pairs of 3D image patches extracted from CMRA volumes as input and outputting the motion field between image patches. Using image warping by the estimated motion field, a loss function that imposes image similarity and motion smoothness is adopted to enable training without ground truth motion field. RespME-net is trained patch-wise to circumvent the challenges of training a 3D network volume-wise which requires large amounts of GPU memory and 3D datasets. We perform 5-fold cross-validation with 45 CMRA datasets and demonstrate that RespME-net can predict 3D non-rigid motion fields with subpixel accuracy (0.44 +/- 0.38 mm) within similar to 10 seconds, being similar to 20 times faster than a GPU-implemented state-of-the-art non-rigid registration method. Moreover, we perform non-rigid motion-compensated CMRA reconstruction for 9 additional patients. The proposed RespME-net has achieved similar motion-corrected CMRA image quality to the conventional registration method regarding coronary artery length and sharpness.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000604883800038</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33021937</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Three-dimensional displays; Motion estimation; Image reconstruction; Two dimensional displays; Biomedical imaging; Image registration; Optimization; Motion estimation; deep learning; motion-compensated reconstruction; coronary magnetic resonance angiography</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
MAGNETIC-RESONANCE; OPTICAL-FLOW; QUANTITATIVE-ANALYSIS; REGISTRATION; DEFORMATION; ANGIOGRAPHY; ALIGNMENT; MODELS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Qi, Haikun; Fuin, Niccolo; Cruz, Gastao; Pan, Jiazhen; Kuestner, Thomas; Bustin, Aurelien; Botnar, Rene M.; Prieto, Claudia] Kings Coll London, Sch Biomed Engn &amp; Imaging Sci, London SE1 7EH, England. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Qi, HK (corresponding author), Kings Coll London, Sch Biomed Engn &amp; Imaging Sci, London SE1 7EH, England.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
haikun.qi@kcl.ac.uk; niccolo.fuin@kcl.ac.uk; gastao.cruz@kcl.ac.uk; jiazhen.pan@gmx.de; thomas.kuestner@kcl.ac.uk; aurelien.bustin@kcl.ac.uk; rene.botnar@kcl.ac.uk; claudia.prieto@kcl.ac.uk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of London; King's College London</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Qi, Haikun</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4709-5185&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bustin, Aurelien</display_name>&nbsp;</td><td>AAC-9237-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Kuestner, Thomas</display_name>&nbsp;</td><td>ABE-7866-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Botnar, Rene</display_name>&nbsp;</td><td>AAZ-2112-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cruz, Gastao</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-7397-9104&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Prieto, Claudia</display_name>&nbsp;</td><td>F-8308-2013&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Botnar, Rene</display_name>&nbsp;</td><td>E-6875-2012&nbsp;</td><td>0000-0003-2811-2509&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cruz, Gastao</display_name>&nbsp;</td><td>KSM-1438-2024&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>PO0TG</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Engineering and Physical Sciences Research Council (EPSRC)</grant_agency>&nbsp;</td><td>
<div>EP/P032311/1&nbsp;</div>
<div>EP/P001009/1&nbsp;</div>
<div>EP/P007619/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>British Heart Foundation (BHF)</grant_agency>&nbsp;</td><td>
<div>PG/18/59/33955&nbsp;</div>
<div>RG/20/1/34802&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>King's BHF Centre of Research Excellence</grant_agency>&nbsp;</td><td>
<div>RE/18/2/34213&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Wellcome EPSRC Centre for Medical Engineering</grant_agency>&nbsp;</td><td>
<div>NS/A000049/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Department of Health via the National Institute for Health Research (NIHR) Cardiovascular Health Technology Cooperative (HTC) and Comprehensive Biomedical Research Centre</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>King's College London</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>King's College Hospital NHS Foundation Trust</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Engineering and Physical Sciences Research Council</grant_agency>&nbsp;</td><td>
<div>EP/P001009/1&nbsp;</div>
<div>EP/P007619/1&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EPSRC</grant_agency>&nbsp;</td><td>
<div>EP/P032311/1&nbsp;</div>
<div>EP/P001009/1&nbsp;</div>
<div>EP/P007619/1&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>Thiswork was supported in part by the Engineering and Physical Sciences Research Council (EPSRC) under Grant EP/P032311/1, Grant EP/P001009/1, and Grant EP/P007619/1; in part by the British Heart Foundation (BHF) under Grant PG/18/59/33955 and Grant RG/20/1/34802; in part by the King's BHF Centre of Research Excellence under Grant RE/18/2/34213; in part by theWellcome EPSRC Centre for Medical Engineering under Grant NS/A000049/1; and in part by the Department of Health via the National Institute for Health Research (NIHR) Cardiovascular Health Technology Cooperative (HTC) and Comprehensive Biomedical Research Centre awarded to the Guy's and St Thomas' NHS Foundation Trust in partnership with the King's College London and the King's College Hospital NHS Foundation Trust.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 52 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Robust Optical Flow Estimation in Cardiac Ultrasound Images Using a Sparse Representation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Ouzir, N (Ouzir, Nora); Basarab, A (Basarab, Adrian); Lairez, O (Lairez, Olivier); Tourneret, JY (Tourneret, Jean-Yves)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>38</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>3</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>741-752</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2018.2870947</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2019 MAR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>25</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>26</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
24</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>45</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This paper introduces a robust 2-D cardiac motion estimation method. The problem is formulated as an energy minimization with an optical flow-based data fidelity term and two regularization terms imposing spatial smoothness and the sparsity of the motion field in an appropriate cardiac motion dictionary. Robustness to outliers, such as imaging artefacts and anatomical motion boundaries, is introduced using robust weighting functions for the data fidelity term as well as for the spatial and sparse regularizations. The motion fields and the weights are computed jointly using an iteratively re-weighted minimization strategy. The proposed robust approach is evaluated on synthetic data and realistic simulation sequences with available ground-truth by comparing the performance with state-of-the-art algorithms. Finally, the proposed method is validated using two sequences of in vivo images. The obtained results show the interest of the proposed approach for 2-D cardiac ultrasound imaging.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000460662400009</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>30235121</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac ultrasound; robust motion estimation; optical flow; sparse regularization; dictionary learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
MOTION ESTIMATION; B-MODE; TISSUE DOPPLER; NONRIGID REGISTRATION; STRAIN ESTIMATION; ECHOCARDIOGRAPHY; OPTIMIZATION</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Ouzir, Nora; Tourneret, Jean-Yves] Univ Toulouse, Signal &amp; Image Dept, IRIT INP ENSEEIHT Tesa, F-31071 Toulouse, France. <br>
[Basarab, Adrian] Univ Toulouse, CNRS, Signal &amp; Image Dept, IRIT,UMR 5505, F-31062 Toulouse, France. <br>
[Lairez, Olivier] Univ Paul Sabatier, CHU Toulouse, INSERM, UMR 1048,Inst Malad Metab &amp; Cardiovasc, Toulouse, France. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Ouzir, N (corresponding author), Univ Toulouse, Signal &amp; Image Dept, IRIT INP ENSEEIHT Tesa, F-31071 Toulouse, France.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
nora.ouzir@enseeiht.fr; adrian.basarab@irit.fr; jean-yves.tourneret@enseeiht.fr</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Universite Federale Toulouse Midi-Pyrenees (ComUE); Universite de Toulouse; Institut National Polytechnique de Toulouse; Universite Toulouse III - Paul Sabatier; Universite de Toulouse; Universite Federale Toulouse Midi-Pyrenees (ComUE); Universite Toulouse III - Paul Sabatier; Institut National Polytechnique de Toulouse; Universite Toulouse 1 Capitole; Universite de Toulouse - Jean Jaures; Centre National de la Recherche Scientifique (CNRS); CNRS - Institute for Information Sciences &amp; Technologies (INS2I); Universite de Toulouse; Universite Toulouse III - Paul Sabatier; CHU de Toulouse; Institut National de la Sante et de la Recherche Medicale (Inserm)</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Basarab, Adrian</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5642-7244&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>O, Lairez</display_name>&nbsp;</td><td>B-7152-2016&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ouzir, Nora</display_name>&nbsp;</td><td>ACS-1544-2022&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>HO1JV</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>thematic trimester on image processing of the CIMI Labex, Toulouse, France</grant_agency>&nbsp;</td><td>
<div>ANR-11-LABX-0040-CIMI&nbsp;</div>
<div>ANR-11-IDEX-0002-02&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the thematic trimester on image processing of the CIMI Labex, Toulouse, France, underGrant ANR-11-LABX-0040-CIMI within the Program ANR-11-IDEX-0002-02.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 53 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Co-attention spatial transformer network for unsupervised motion tracking and cardiac strain analysis in 3D echocardiography</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Ahn, SS (Ahn, Shawn S.); Ta, K (Ta, Kevinminh); Thorn, SL (Thorn, Stephanie L.); Onofrey, JA (Onofrey, John A.); Melvinsdottir, IH (Melvinsdottir, Inga H.); Lee, SP (Lee, Supum); Langdon, J (Langdon, Jonathan); Sinusas, AJ (Sinusas, Albert J.); Duncan, JS (Duncan, James S.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>84</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>102711</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2022.102711</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>DEC 2022</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 FEB</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
18</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>47</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Myocardial ischemia/infarction causes wall-motion abnormalities in the left ventricle. Therefore, reliable motion estimation and strain analysis using 3D+time echocardiography for localization and characterization of myocardial injury is valuable for early detection and targeted interventions. Previous unsupervised cardiac motion tracking methods rely on heavily-weighted regularization functions to smooth out the noisy displacement fields in echocardiography. In this work, we present a Co-Attention Spatial Transformer Network (STN) for improved motion tracking and strain analysis in 3D echocardiography. Co-Attention STN aims to extract inter-frame dependent features between frames to improve the motion tracking in otherwise noisy 3D echocardiography images. We also propose a novel temporal constraint to further regularize the motion field to produce smooth and realistic cardiac displacement paths over time without prior assumptions on cardiac motion. Our experimental results on both synthetic and in vivo 3D echocardiography datasets demonstrate that our Co-Attention STN provides superior performance compared to existing methods. Strain analysis from Co-Attention STNs also correspond well with the matched SPECT perfusion maps, demonstrating the clinical utility for using 3D echocardiography for infarct localization.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000911016400001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>36525845</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Unsupervised motion tracking; Spatiotemporal attention; Echocardiography</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
GLOBAL LONGITUDINAL STRAIN; SPECKLE-TRACKING; DEFORMATION; HEART; MRI</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Ahn, Shawn S.; Ta, Kevinminh; Onofrey, John A.; Sinusas, Albert J.; Duncan, James S.] Yale Univ, Dept Biomed Engn, New Haven, CT 06520 USA. <br>
[Thorn, Stephanie L.; Melvinsdottir, Inga H.; Lee, Supum; Sinusas, Albert J.] Yale Univ, Dept Internal Med, Sect Cardiovasc Med, New Haven, CT USA. <br>
[Onofrey, John A.; Langdon, Jonathan; Sinusas, Albert J.; Duncan, James S.] Yale Univ, Dept Radiol &amp; Biomed Imaging, New Haven, CT USA. <br>
[Duncan, James S.] Yale Univ, Dept Elect Engn, New Haven, CT USA. <br>
[Duncan, James S.] 300 Cedar St, New Haven, CT 06519 USA. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Ahn, SS; Duncan, JS (corresponding author), Yale Univ, Dept Biomed Engn, New Haven, CT 06520 USA.<br>Duncan, JS (corresponding author), Yale Univ, Dept Radiol &amp; Biomed Imaging, New Haven, CT USA.<br>Duncan, JS (corresponding author), Yale Univ, Dept Elect Engn, New Haven, CT USA.<br>Duncan, JS (corresponding author), 300 Cedar St, New Haven, CT 06519 USA.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
shawn.ahn@yale.edu; james.duncan@yale.edu</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Yale University; Yale University; Yale University; Yale University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Lee, Supum</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5017-9032&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Onofrey, John</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9432-0448&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ahn, Shawn</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5961-3376&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Duncan, James</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-5167-9856&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Langdon, Jonathan</display_name>&nbsp;</td><td>JGL-9505-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Onofrey, John</display_name>&nbsp;</td><td>T-9841-2019&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>7S8QJ</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>10</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NIH, USA</grant_agency>&nbsp;</td><td>
<div>R01HL121226&nbsp;</div>
<div>R01HL137365&nbsp;</div>
<div>T32HL098069&nbsp;</div>
<div>S10RR02555&nbsp;</div>
<div>1S10OD028738-01A1&nbsp;</div>
<div>F30HL158154&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>NIH Medical Scientist Training Program</grant_agency>&nbsp;</td><td>
<div>T32GM007205&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The authors are immensely thankful for the past and present members of the Yale Translational Research Imaging Center (YTRIC) who were involved in the image acquisition process. This research was made possible through the utilization of the Yale Translational Research Imaging Center. This work was supported in part by the NIH, USA grants R01HL121226, R01HL137365, T32HL098069, S10RR02555, 1S10OD028738-01A1, F30HL158154 and NIH Medical Scientist Training Program Grant T32GM007205.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 54 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>rU-Net, Multi-Scale Feature Fusion and Transfer Learning: Unlocking the Potential of Cuffless Blood Pressure Monitoring With PPG and ECG</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Chen, JM (Chen, Jiaming); Zhou, XL (Zhou, Xueling); Feng, L (Feng, Lei); Ling, BWK (Ling, Bingo Wing-Kuen); Han, LY (Han, Lianyi); Zhang, HT (Zhang, Hongtao)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>29</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>1</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>166-176</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2024.3483301</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2025 JAN</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>0</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
13</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
28</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>52</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
This study introduces an innovative deep-learning model for cuffless blood pressure estimation using PPG and ECG signals, demonstrating state-of-the-art performance on the largest clean dataset, PulseDB. The rU-Net architecture, a fusion of U-Net and ResNet, enhances both generalization and feature extraction accuracy. Accurate multi-scale feature capture is facilitated by short-time Fourier transform (STFT) time-frequency distributions and multi-head attention mechanisms, allowing data-driven feature selection. The inclusion of demographic parameters as supervisory information further elevates performance. On the calibration-based dataset, our model excels, achieving outstanding accuracy (SBP MAE +/- std: 4.49 +/- 4.86 mmHg, DBP MAE +/- std: 2.69 +/- 3.10 mmHg), surpassing AAMI standards and earning a BHS Grade A rating. Addressing the challenge of calibration-free data, we propose a fine-tuning-based transfer learning approach. Remarkably, with only 10% data transfer, our model attains exceptional accuracy (SBP MAE +/- std: 4.14 +/- 5.01 mmHg, DBP MAE +/- std: 2.48 +/- 2.93 mmHg). This study sets the stage for the development of highly accurate and reliable wearable cuffless blood pressure monitoring devices.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001394517600007</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>39423074</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Feature extraction; Accuracy; Estimation; Electrocardiography; Blood pressure; Time series analysis; Data models; Time-frequency analysis; Monitoring; electrocardiogram; photoplethysmography; STFT; transfer learning; transfer learning</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
WAVE-FORM; PHOTOPLETHYSMOGRAPHY</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Chen, Jiaming; Zhou, Xueling; Zhang, Hongtao] Fudan Univ, Sch Informat Sci &amp; Technol, Shanghai 200437, Peoples R China. <br>
[Chen, Jiaming; Zhou, Xueling; Feng, Lei; Han, Lianyi; Zhang, Hongtao] Greater Bay Area Inst Precis Med, Guangzhou 511462, Peoples R China. <br>
[Ling, Bingo Wing-Kuen] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Peoples R China. <br>
[Han, Lianyi] Fudan Univ, Huashan Hosp, Sch Life Sci, Dept Dermatol, Shanghai 200437, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhang, HT (corresponding author), Fudan Univ, Sch Informat Sci &amp; Technol, Shanghai 200437, Peoples R China.<br>Han, LY (corresponding author), Fudan Univ, Huashan Hosp, Sch Life Sci, Dept Dermatol, Shanghai 200437, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
jmchen22@m.fudan.edu.cn; xueling_zhou@fudan.edu.cn; fenglei@ipm-gba.org.cn; yongquanling@gdut.edu.cn; hanlianyi@fudan.edu.cn; zhanghongtao@ipm-gba.org.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Fudan University; Guangdong University of Technology; Fudan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Feng, Lei</display_name>&nbsp;</td><td>AAV-7856-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>zhang, hongtao</display_name>&nbsp;</td><td>NXB-9922-2025&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Chen, Jiaming</display_name>&nbsp;</td><td>GXM-7165-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Han, Lianyi</display_name>&nbsp;</td><td>D-1499-2009&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>R9J4Q</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 55 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Learning Spatio-Temporal Pulse Representation With Global-Local Interaction and Supervision for Remote Prediction of Heart Rate</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Zhao, CC (Zhao, Changchen); Zhou, MH (Zhou, Menghao); Zhao, Z (Zhao, Zheng); Huang, B (Huang, Bin); Rao, B (Rao, Bing)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>28</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>2</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>609-620</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/JBHI.2023.3252091</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2024 FEB</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>12</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>12</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
6</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
18</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>52</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Recent studies have demonstrated the benefit of extracting and fusing pulse signals from multi-scale region-of-interests (ROIs). However, these methods suffer from heavy computational load. This paper aims to effectively utilize multi-scale rPPG features with a more compact architecture. Inspired by recent research works exploring two-path architecture that leverages global and local information with bidirectional bridge in between. This paper designs a novel architecture Global-Local Interaction and Supervision Network (GLISNet), which uses a local path to learn representations in the original scale and a global path to learn representations in the other scale capturing multi-scale information. A light-weight rPPG signal generation block is attached to the output of each path that maps the pulse representation to the pulse output. A hybrid loss function is utilized enabling the local and global representations to learn directly from the training data. Extensive experiments are conducted on two publicly available datasets, and results demonstrate that GLISNet achieves superior performance in terms of signal-to-noise ratio (SNR), mean absolute error (MAE), and root mean squared error (RMSE). In terms of SNR, GLISNet has an increase of 4.41% compared with the second best algorithm PhysNet on PURE dataset. The MAE has a decrease of 13.16% compared with the second best algorithm DeeprPPG on UBFC-rPPG dataset. The RMSE has a decrease of 26.29% compared with the second best algorithm PhysNet on UBFC-rPPG dataset. Experiments on MIHR dataset demonstrates the robustness of GLISNet under low-light environment.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001203362500041</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37028087</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Remote photoplethysmography; heart rate estimation; pulse representation; CNN; long-range dependency</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Zhao, Changchen; Zhao, Zheng; Huang, Bin] Beihang Univ, Hangzhou Innovat Inst, Hangzhou 310051, Peoples R China. <br>
[Zhou, Menghao] Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Peoples R China. <br>
[Rao, Bing] Hangzhou City Univ, Hangzhou 310015, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Rao, B (corresponding author), Hangzhou City Univ, Hangzhou 310015, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
cczhao@zjut.edu.cn; tracker.z@qq.com; zhaozhengbuaa@qq.com; marshuangbin@buaa.edu.cn; raob@zucc.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Beihang University; Zhejiang University of Technology; Hangzhou City University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Huang, Bin</display_name>&nbsp;</td><td>ISA-9354-2023&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhao, Changchen</display_name>&nbsp;</td><td>AEV-3957-2022&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Huang, Bin</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-0894-5335&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhao, Changchen</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0546-6016&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Rao, Bing</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3760-8979&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Mathematical &amp; Computational Biology; Medical Informatics</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>NW0A0</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>2168-2194</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>2168-2208</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE J BIOMED HEALTH</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE J. Biomed. Health Inform.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>No Statement Available</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 56 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Reconstruction and completion of high-resolution 3D cardiac shapes using anisotropic CMRI segmentations and continuous implicit neural representations</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Sander, J (Sander, Jorg); de Vos, BD (de Vos, Bob D.); Bruns, S (Bruns, Steffen); Planken, N (Planken, Nils); Viergever, MA (Viergever, Max A.); Leiner, T (Leiner, Tim); Isgum, I (Isgum, Ivana)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>COMPUTERS IN BIOLOGY AND MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>164</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>107266</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.compbiomed.2023.107266</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JUL 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 SEP</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>7</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>8</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
16</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>47</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Since the onset of computer-aided diagnosis in medical imaging, voxel-based segmentation has emerged as the primary methodology for automatic analysis of left ventricle (LV) function and morphology in cardiac magnetic resonance images (CMRI). In standard clinical practice, simultaneous multi-slice 2D cine short-axis MR imaging is performed under multiple breath-holds resulting in highly anisotropic 3D images. Furthermore, sparse-view CMRI often lacks whole heart coverage caused by large slice thickness and often suffers from inter -slice misalignment induced by respiratory motion. Therefore, these volumes only provide limited information about the true 3D cardiac anatomy which may hamper highly accurate assessment of functional and anatomical abnormalities. To address this, we propose a method that learns a continuous implicit function representing 3D LV shapes by training an auto-decoder. For training, high-resolution segmentations from cardiac CT angiography are used. The ability of our approach to reconstruct and complete high-resolution shapes from manually or automatically obtained sparse-view cardiac shape information is evaluated by using paired high-and low-resolution CMRI LV segmentations. The results show that the reconstructed LV shapes have an unconstrained subvoxel resolution and appear smooth and plausible in through-plane direction. Furthermore, Bland-Altman analysis reveals that reconstructed high-resolution ventricle volumes are closer to the corresponding reference volumes than reference low-resolution volumes with bias of [limits of agreement] -3.51 [-18.87, 11.85] mL, and 12.96 [-10.01, 35.92] mL respectively. Finally, the results demonstrate that the proposed approach allows recovering missing shape information and can indirectly correct for limited motion-induced artifacts.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001048414600001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37494823</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Cardiac MRI; Neural implicit function; Super-resolution; Shape completion; Shape reconstruction</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
HEART</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Sander, Jorg; de Vos, Bob D.; Bruns, Steffen; Isgum, Ivana] Locat Univ Amsterdam, Dept Biomed Engn &amp; Phys, Amsterdam Univ Med Ctr, Amsterdam, Netherlands. <br>
[Sander, Jorg; Isgum, Ivana] Amsterdam Cardiovasc Sci, Amsterdam, Netherlands. <br>
[Planken, Nils; Isgum, Ivana] Locat Univ Amsterdam, Dept Radiol &amp; Nucl Med, Amsterdam Univ Med Ctr, Amsterdam, Netherlands. <br>
[Sander, Jorg; Isgum, Ivana] Univ Amsterdam, Informat Inst, Amsterdam, Netherlands. <br>
[Viergever, Max A.] Univ Med Ctr Utrecht, Image Sci Inst, Utrecht, Netherlands. <br>
[Leiner, Tim] Mayo Clin, Dept Radiol, Rochester, MN USA. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Sander, J (corresponding author), Locat Univ Amsterdam, Dept Biomed Engn &amp; Phys, Amsterdam Univ Med Ctr, Amsterdam, Netherlands.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
j.sander1@amsterdamumc.nl</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
University of Amsterdam; Utrecht University; Utrecht University Medical Center; Mayo Clinic</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Planken, R. Nils</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3940-4670&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Viergever, Max</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-2582-042X&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Isgum, Ivana</display_name>&nbsp;</td><td>H-8659-2014&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Planken, RN</display_name>&nbsp;</td><td>JAC-4538-2023&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Life Sciences &amp; Biomedicine - Other Topics; Computer Science; Engineering; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>P1OX0</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0010-4825</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-0534</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>COMPUT BIOL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Comput. Biol. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>15</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Dutch Technology Foundation</grant_agency>&nbsp;</td><td>
<div>P15-26&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>Acknowledgments This study was performed within the DLMedIA program (P15-26) funded by Dutch Technology Foundation with participation of Pie Medical Imaging.</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>hybrid</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 57 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Low-dimensional representation of cardiac motion using Barycentric Subspaces: A new group-wise paradigm for estimation, analysis, and reconstruction</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Roh&eacute;, MM (Rohe, Marc-Michel); Sermesant, M (Sermesant, Maxime); Pennec, X (Pennec, Xavier)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>MEDICAL IMAGE ANALYSIS</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>45</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>1-12</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.media.2017.12.008</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2018 APR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>8</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>9</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
8</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>26</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
One major challenge when trying to build low-dimensional representation of the cardiac motion is its natural circular pattern during a cycle, therefore making the mean image a poor descriptor of the whole sequence. Therefore, traditional approaches for the analysis of the cardiac deformation use one specific frame of the sequence - the end-diastolic (ED) frame - as a reference to study the whole motion. Consequently, this methodology is biased by this empirical choice. Moreover, the ED image might be a poor reference when looking at large deformation for example at the end-systolic (ES) frame. In this paper, we propose a novel approach to study cardiac motion in 4D image sequences using low-dimensional sub-space analysis. Instead of building subspaces relying on a mean value we use a novel type of subspaces called Barycentric Subspaces which are implicitly defined as the weighted Karcher means of k + 1 reference images instead of being defined with respect to one reference image. In the first part of this article, we introduce the methodological framework and the algorithms used to manipulate images within these new subspaces: how to compute the projection of a given image on the Barycentric Subspace with its coordinates, and the opposite operation of computing an image from a set of references and coordinates. Then we show how this framework can be applied to cardiac motion problems and lead to significant improvements over the single reference method. Firstly, by computing the low-dimensional representation of two populations we show that the parameters extracted correspond to relevant cardiac motion features leading to an efficient representation and discrimination of both groups. Secondly, in motion estimation, we use the projection on this low-dimensional subspace as an additional prior on the regularization in cardiac motion tracking, efficiently reducing the error of the registration between the ED and ES by almost 30%. We also derive a symmetric and transitive formulation of the registration that can be used both for frame-to-frame and frame-to-reference registration. Finally, we look at the reconstruction of the images using our proposed low-dimensional representation and show that this multi-references method using Barycentric Subspaces performs better than traditional approaches based on a single reference. (C) 2018 Elsevier B.V. All rights reserved.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000427664400001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>29324241</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Low-dimensional analysis; Cardiac motion; Registration; Image synthesis</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
DIFFEOMORPHIC REGISTRATION; DEFORMATION ALGORITHMS; DEMONS</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Rohe, Marc-Michel; Sermesant, Maxime; Pennec, Xavier] Univ Cote Dazur, INRIA, Asclepios Res Grp, Nice, France. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Roh&eacute;, MM (corresponding author), Univ Cote Dazur, INRIA, Asclepios Res Grp, Nice, France.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
marc-michel.rohe@inria.fr</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Inria; Universite Cote d'Azur</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Pennec, Xavier</display_name>&nbsp;</td><td>L-2537-2013&nbsp;</td><td>0000-0002-6617-7664&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Sermesant, Maxime</display_name>&nbsp;</td><td>AAC-4870-2019&nbsp;</td><td>0000-0002-6256-8350&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>ELSEVIER SCIENCE BV</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>FZ5VM</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>1361-8415</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1361-8423</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>MED IMAGE ANAL</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Med. Image Anal.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>EU FP7</grant_agency>&nbsp;</td><td>
<div>600932&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>The authors acknowledge the partial funding by the EU FP7-funded project MD-Paedigree (Grant agreement 600932)</p>
</span></td>
</tr>
<tr>
<td>
<b>Open Access:</b>

<value>Green Submitted</value>
</td>
</tr>

<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 58 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>CF Distance: A New Domain Discrepancy Metric and Application to Explicit Domain Adaptation for Cross-Modality Cardiac Image Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Wu, FP (Wu, Fuping); Zhuang, XH (Zhuang, Xiahai)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>39</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>12</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>4274-4285</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2020.3016144</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 DEC</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>64</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>69</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
0</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
44</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>42</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Domain adaptation has great values in unpaired cross-modality image segmentation, where the training images with gold standard segmentation are not available from the target image domain. The aim is to reduce the distribution discrepancy between the source and target domains. Hence, an effective measurement for this discrepancy is critical. In this work, we propose a new metric based on characteristic functions of distributions. This metric, referred to as CF distance, enables explicit domain adaptation, in contrast to the implicit manners minimizing domain discrepancy via adversarial training. Based on this CF distance, we propose an unsupervised domain adaptation framework for cross-modality cardiac segmentation, which consists of image reconstruction and prior distribution matching. We validated the method on two tasks, i.e., the CT-MR cross-modality segmentation and the multi-sequence cardiac MR segmentation. Results showed that the proposed explicit metric was effective in domain adaptation, and the segmentation method delivered promising and superior performance, compared to other state-of-the-art techniques. The data and source code of this work has been released via https://zmiclab.github.io/projects.html.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000595547500045</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>32784131</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Measurement; Training; Image segmentation; Neural networks; Task analysis; Image reconstruction; Optimization; Cardiacsegmentation; omain adaptation; domain discrepancy; characteristic function</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
NETWORK</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Wu, Fuping] Fudan Univ, Dept Stat, Sch Management, Shanghai 200433, Peoples R China. <br>
[Wu, Fuping; Zhuang, Xiahai] Fudan Univ, Sch Data Sci, Shanghai 200433, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhuang, XH (corresponding author), Fudan Univ, Sch Data Sci, Shanghai 200433, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
17110690006@fudan.edu.cn; zxh@fudan.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Fudan University; Fudan University</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Zhuang, Xiahai</display_name>&nbsp;</td><td>AAH-6334-2019&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wu, Fuping</display_name>&nbsp;</td><td>ABG-4545-2021&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wu, Fuping</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0001-7179-4766&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>PA3OL</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>61971142&nbsp;</div>
<div>11871165&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported by the National Natural Science Foundation of China under Grant 61971142 and Grant 11871165.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 59 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Automatic sleep-stage classification of heart rate and actigraphy data using deep and transfer learning approaches</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Ma, YJX (Ma, Yaopeng J. X.); Zschocke, J (Zschocke, Johannes); Glos, M (Glos, Martin); Kluge, M (Kluge, Maria); Penzel, T (Penzel, Thomas); Kantelhardt, JW (Kantelhardt, Jan W.); Bartsch, RP (Bartsch, Ronny P.)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>COMPUTERS IN BIOLOGY AND MEDICINE</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>163</value>&nbsp;&nbsp;<b>Article Number:</b> 
<value>107193</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1016/j.compbiomed.2023.107193</value>&nbsp;&nbsp;<b>Early Access Date:</b> 
<value>JUL 2023</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2023 SEP</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>13</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
3</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
34</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>64</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Manual sleep-stage scoring based on full-night polysomnography data recorded in a sleep lab has been the gold standard of clinical sleep medicine. This costly and time-consuming approach is unfit for long-term studies as well as assessment of sleep on a population level. With the vast amount of physiological data becoming available from wrist-worn devices, deep learning techniques provide an opportunity for fast and reliable automatic sleep-stage classification tasks. However, training a deep neural network requires large annotated sleep databases, which are not available for long-term epidemiological studies. In this paper, we introduce an end-to-end temporal convolutional neural network able to automatically score sleep stages from raw heartbeat RR interval (RRI) and wrist actigraphy data. Moreover, a transfer learning approach enables the training of the network on a large public database (Sleep Heart Health Study, SHHS) and its subsequent application to a much smaller database recorded by a wristband device. The transfer learning significantly shortens training time and improves sleep-scoring accuracy from 68.9% to 73.8% and inter-rater reliability (Cohen's kappa) from 0.51 to 0.59. We also found that for the SHHS database, automatic sleep-scoring accuracy using deep learning shows a logarithmic relationship with the training size. Although deep learning approaches for automatic sleep scoring are not yet comparable to the inter-rater reliability among sleep technicians, performance is expected to significantly improve in the near future when more large public databases become available. We anticipate those deep learning techniques, when combined with our transfer learning approach, will leverage automatic sleep scoring of physiological data from wearable devices and enable the investigation of sleep in large cohort studies.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:001039211500001</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>37421734</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Sleep-stage scoring; Heart-rate variability; Wrist actigraphy; Deep learning; Transfer learning; Convolutional neural network; Epidemiological studies</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
RECHTSCHAFFEN; VARIABILITY; DYNAMICS; DESIGN; KALES; AASM</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Ma, Yaopeng J. X.; Bartsch, Ronny P.] Bar Ilan Univ, Dept Phys, Ramat Gan, Israel. <br>
[Zschocke, Johannes] Martin Luther Univ Halle Wittenberg, Interdisciplinary Ctr Hlth Sci, Inst Med Epidemiol Biometr &amp; Informat IMEBI, Halle, Germany. <br>
[Zschocke, Johannes; Kantelhardt, Jan W.] Martin Luther Univ Halle Wittenberg, Inst Phys, Halle, Germany. <br>
[Glos, Martin; Kluge, Maria; Penzel, Thomas] Charite Univ Med Berlin, Interdisciplinary Sleep Med Ctr, Berlin, Germany. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Bartsch, RP (corresponding author), Bar Ilan Univ, Dept Phys, Ramat Gan, Israel.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
yaopeng.ma97@gmail.com; bartsch.ronny@gmail.com</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Bar Ilan University; Martin Luther University Halle Wittenberg; Martin Luther University Halle Wittenberg; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Bartsch, Ronny</display_name>&nbsp;</td><td>E-7117-2012&nbsp;</td><td>0000-0001-8336-5141&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Penzel, Thomas</display_name>&nbsp;</td><td>M-2344-2014&nbsp;</td><td>0000-0002-4304-0112&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Kluge, Maria</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0008-6714-4478&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ma, Yaopeng J. X.</display_name>&nbsp;</td><td>KBQ-9248-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Ma, Yaopeng J. X.</display_name>&nbsp;</td><td>&nbsp;</td><td>0009-0004-6484-0129&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Kantelhardt, Jan W.</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-9293-0293&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Kantelhardt, Jan</display_name>&nbsp;</td><td>AAF-7955-2019&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>PERGAMON-ELSEVIER SCIENCE LTD</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Life Sciences &amp; Biomedicine - Other Topics; Computer Science; Engineering; Mathematical &amp; Computational Biology</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>N8BW3</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0010-4825</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1879-0534</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>COMPUT BIOL MED</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>Comput. Biol. Med.</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>11</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>German Israeli Foundation (GIF)</grant_agency>&nbsp;</td><td>
<div>I-1372-303.7/2016&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Heart, Lung, and Blood Institute</grant_agency>&nbsp;</td><td>
<div>U01HL53916&nbsp;</div>
<div>U01HL53931&nbsp;</div>
<div>U01HL53934&nbsp;</div>
<div>U01HL53937&nbsp;</div>
<div>U01HL64360&nbsp;</div>
<div>U01HL53938&nbsp;</div>
<div>U01HL53940&nbsp;</div>
<div>U01HL53941&nbsp;</div>
<div>U01HL63463&nbsp;</div>
<div>R24 HL114473&nbsp;</div>
<div>75N92019R002&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>&amp; nbsp;This work was supported by the German Israeli Foundation (GIF) Grant no I-1372-303.7/2016. The Sleep Heart Health Study (SHHS) was supported by National Heart, Lung, and Blood Institute cooperative agreements U01HL53916 (University of California, Davis) , U01HL53931 (New York University) , U01HL53934 (University of Minnesota) , U01HL53937 and U01HL64360 (Johns Hopkins University) , U01HL53938 (University of Arizona) , U01HL53940 (University of Washington) , U01HL53941 (Boston University) , and U01HL63463 (Case Western Reserve University) . The National Sleep Research Resource was supported by the National Heart, Lung, and Blood Institute (R24 HL114473, 75N92019R002) .</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 60 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Dual-Teacher plus plus : Exploiting Intra-Domain and Inter-Domain Knowledge With Reliable Transfer for Cardiac Segmentation</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Li, K (Li, Kang); Wang, SJ (Wang, Shujun); Yu, LQ (Yu, Lequan); Heng, PA (Heng, Pheng Ann)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>40</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>10</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>2771-2782</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2020.3038828</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2021 OCT</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>24</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>27</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
1</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
37</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>61</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Annotation scarcity is a long-standing problem in medical image analysis area. To efficiently leverage limited annotations, abundant unlabeled data are additionally exploited in semi-supervised learning, while well-established cross-modality data are investigated in domain adaptation. In this paper, we aim to explore the feasibility of concurrently leveraging both unlabeled data and cross-modality data for annotation-efficient cardiac segmentation. To this end, we propose a cutting-edge semi-supervised domain adaptation framework, namely Dual-Teacher++. Besides directly learning from limited labeled target domain data (e.g., CT) via a student model adopted by previous literature, we design novel dual teacher models, including an inter-domain teacher model to explore cross-modality priors from source domain (e.g., MR) and an intra-domain teacher model to investigate the knowledge beneath unlabeled target domain. In this way, the dual teacher models would transfer acquired inter- and intra-domain knowledge to the student model for further integration and exploitation. Moreover, to encourag reliable dual-domain knowledge transfer, we enhance the inter-domain knowledge transfer on the samples with higher similarity to target domain after appearance alignment, and also strengthen intra-domain knowledge transfer of unlabeled target data with higher prediction confidence. In this way, the student model can obtain reliable dual-domain knowledge and yield improved performance on target domain data. We extensively evaluated the feasibility of our method on the MM-WHS 2017 challenge dataset. The experiments have demonstrated the superiority of our framework over other semi-supervised learning and domain adaptation methods. Moreover, our performance gains could be yielded in bidirections, i.e., adapting from MR to CT, and from CT to MR. Our code will be available at https://github.com/kli-lalala/Dual-Teacher-.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000702638800020</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>33201808</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Adaptation models; Data models; Reliability; Predictive models; Computed tomography; Annotations; Semisupervised learning; Semi-supervised domain adaptation; cross-modality; cardiac segmentation</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
ADAPTATION; IMAGE</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Li, Kang; Wang, Shujun; Heng, Pheng Ann] Chinese Univ Hong Kong, Dept Comp Sci Engn, Hong Kong, Peoples R China. <br>
[Yu, Lequan] Stanford Univ, Dept Radiat Oncol, Palo Alto, CA 94306 USA. <br>
[Heng, Pheng Ann] Chinese Acad Sci, Shenzhen Inst Adv Technol, Guangdong Prov Key Lab Comp Vis &amp; Virtual Real, Shenzhen 518055, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Yu, LQ (corresponding author), Stanford Univ, Dept Radiat Oncol, Palo Alto, CA 94306 USA.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
kli@cse.cuhk.edu.hk; sjwang@cse.cuhk.edu.hk; lequany@stanford.edu; pheng@cse.cuhk.edu.hk</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Chinese University of Hong Kong; Stanford University; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Yu, Lequan</display_name>&nbsp;</td><td>U-5377-2019&nbsp;</td><td>0000-0002-9315-6527&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>WANG, Shujun</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-1495-3278&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Li, Kang</display_name>&nbsp;</td><td>LMN-3556-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Wang, Shujun</display_name>&nbsp;</td><td>AAD-7001-2020&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>LI, Kang</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0149-6912&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Heng, Pheng</display_name>&nbsp;</td><td>KJL-6056-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Heng, Pheng Ann</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-3055-5034&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>WA1FC</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>12</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Key-Area Research and Development Program of GuangdongProvince, China</grant_agency>&nbsp;</td><td>
<div>2020B010165004&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Hong Kong Innovation and Technology Fund</grant_agency>&nbsp;</td><td>
<div>ITS/311/18FP&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation of China</grant_agency>&nbsp;</td><td>
<div>U1813204&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the Key-Area Research and Development Program of GuangdongProvince, China, under Project 2020B010165004, in part by the Hong Kong Innovation and Technology Fund under Project ITS/311/18FP, and in part by the National Natural Science Foundation of China under Project U1813204.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr><table>
<tr>
<td><b>Record 61 of 61</b></td>
</tr>
<tr>
<td>
<b>Title:</b>

<value>Fetal Congenital Heart Disease Echocardiogram Screening Based on DGACNN: Adversarial One-Class Classification Combined with Video Transfer Learning</value>
</td>
</tr>

<tr>
<td>
<b>Author(s):</b>
Gong, YX (Gong, Yuxin); Zhang, YY (Zhang, Yingying); Zhu, HG (Zhu, Haogang); Lv, J (Lv, Jing); Cheng, Q (Cheng, Qian); Zhang, HJ (Zhang, Hongjia); He, YH (He, Yihua); Wang, SL (Wang, Shuliang)</td>
</tr>

<tr>
<td><b>Source:</b> 
<value>IEEE TRANSACTIONS ON MEDICAL IMAGING</value>&nbsp;&nbsp;<b>Volume:</b> 
<value>39</value>&nbsp;&nbsp;<b>Issue:</b> 
<value>4</value>&nbsp;&nbsp;<b>Pages:</b> 
<value>1206-1222</value>&nbsp;&nbsp;<b>DOI:</b> 
<value>10.1109/TMI.2019.2946059</value>&nbsp;&nbsp;<b>Published Date:</b> 
<value>2020 APR</value>&nbsp;&nbsp;</td>
</tr>
<tr>
<td>
<b>Times Cited in Web of Science Core Collection:</b>

<value>67</value>
</td>
</tr>

<tr>
<td>
<b>Total Times Cited:</b>

<value>78</value>
</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Last 180 days):</b>
2</td>
</tr>

<tr>
<td>
<b>Usage Count
    (Since 2013):</b>
55</td>
</tr>

<tr>
<td>
<b>Cited Reference Count:</b>

<value>39</value>
</td>
</tr>

<tr>
<td>
<b>Abstract:</b>
Fetal congenital heart disease (FHD) is a common and serious congenital malformation in children. In Asia, FHD birth defect rates have reached as high as 9.3 0025. For the early detection of birth defects and mortality, echocardiography remains the most effective method for screening fetal heart malformations. However, standard echocardiograms of the fetal heart, especially four-chamber view images, are difficult to obtain. In addition, the pathophysiological changes in fetal hearts during different pregnancy periods lead to ever-changing two-dimensional fetal heart structures and hemodynamics, and it requires extensive professional knowledge to recognize and judge disease development. Thus, research on the automatic screening for FHD is necessary. In this paper, we proposed a new model named DGACNN that shows the best performance in recognizing FHD, achieving a rate of 85. The motivation for this network is to deal with the problem that there are insufficient training datasets to train a robust model. There are many unlabeled video slices, but they are tough and time-consuming to annotate. Thus, how to use these un-annotated video slices to improve the DGACNN capability for recognizing FHD, in terms of both recognition accuracy and robustness, is very meaningful for FHD screening. The architecture of DGACNN comprises two parts, that is, DANomaly and GACNN (Wgan-GP and CNN). DANomaly, similar to the ALOCC network, but incorporates cycle adversarial learning to train an end-to-end one-class classification (OCC) network that is more robust and has a higher accuracy than ALOCC in screening video slices. For the GACNN architecture, we use FCH (four chamber heart) video slices at around the end-systole, as screened by DANomaly, to train a WGAN-GP for the purpose of obtaining ideal low-level features that can robustly improve the FHD recognition accuracy. A few annotated video slices, as screened by DANomaly, can also be used for data augmentation so as to improve the FHD recognition further. The experiments show that the DGACNN outperforms other state-of-the-art networks by 10025; in recognizing FHD. A comparison experiment shows that the proposed network already outperforms the performance of expert cardiologists in recognizing FHD, reaching 84 025; in a test. Thus, the proposed architecture has high potential for helping cardiologists complete early FHD screenings.</td>
</tr>

<tr>
<td>
<b>Accession Number:</b>

<value>WOS:000525265800036</value>
</td>
</tr>

<tr>
<td>
<b>PubMed ID:</b>

<value>31603775</value>
</td>
</tr>

<tr>
<td>
<b>Language:</b>
English</td>
</tr>

<tr>
<td>
<b>Document Type:</b>
Article</td>
</tr>

<tr>
<td>
<b>Author Keywords:</b>
Fetal congenital heart disease; one-class classification; generative adversarial network; transfer learning; echocardiography; four-chamber heart</td>
</tr>

<tr>
<td>
<b>KeyWords Plus:</b>
CONVOLUTIONAL NEURAL-NETWORKS; UNITED-STATES</td>
</tr>

<tr>
<td>
<b>Addresses:</b>
[Gong, Yuxin; Zhang, Yingying; Zhu, Haogang; Cheng, Qian] Beihang Univ, Sch Comp Sci &amp; Engn, State Key Lab Software Dev Environm, Beijing 100083, Peoples R China. <br>
[Gong, Yuxin; Zhang, Yingying] Beihang Univ, Sch Biol Sci &amp; Med Engn, Beijing 100083, Peoples R China. <br>
[Zhu, Haogang] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Beijing 100083, Peoples R China. <br>
[Zhu, Haogang] Beihang Univiers, Hefei Innovat Res Inst, Beijing 100083, Peoples R China. <br>
[Lv, Jing; Zhang, Hongjia; He, Yihua] Capital Med Univ, Beijing Anzhen Hosp, Dept Ultrasound, Beijing 100069, Peoples R China. <br>
[Wang, Shuliang] Beijing Inst Technol, Sch Comp Sci &amp; Technol, Beijing 100811, Peoples R China. </td>
</tr>

<tr>
<td>
<b>Corresponding Address:</b>
Zhu, HG (corresponding author), Beihang Univ, Sch Comp Sci &amp; Engn, State Key Lab Software Dev Environm, Beijing 100083, Peoples R China.<br>He, YH (corresponding author), Capital Med Univ, Beijing Anzhen Hosp, Dept Ultrasound, Beijing 100069, Peoples R China.<br>Wang, SL (corresponding author), Beijing Inst Technol, Sch Comp Sci &amp; Technol, Beijing 100811, Peoples R China.</td>
</tr>

<tr>
<td>
<b>E-mail Addresses:</b>
gongyuxinbuaa@163.com; haogangzhu@buaa.edu.cn; heyihuaecho@hotmail.com; slwang2011@bit.edu.cn</td>
</tr>

<tr>
<td>
<b>Affiliations:</b>
Beihang University; Beihang University; Beihang University; Capital Medical University; Beijing Institute of Technology</td>
</tr>

<tr>
<td><span class="FR_label"><b>Author Identifiers:</b></span></td>
</tr>
<tr>
<td><span style="display" name="show_resc_blurb" id="show_resc_blurb">
<table class="FR_table_borders" border="1" cellpadding="0" cellspacing="0">
<tr>
<th><span class="FR_label">Author</span></th><th><span class="FR_label">Web of Science ResearcherID</span></th><th><span class="FR_label">ORCID Number</span></th>
</tr>
<tr class="fr_data_row">
<td>
<display_name>lv, jing</display_name>&nbsp;</td><td>JXM-6679-2024&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>Cheng, Qian</display_name>&nbsp;</td><td>M-6702-2017&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>gong, yuxin</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0003-4692-8931&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>zhang, yingying</display_name>&nbsp;</td><td>&nbsp;</td><td>0000-0002-0964-1774&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<display_name>WANG, Shuliang</display_name>&nbsp;</td><td>A-2626-2012&nbsp;</td><td>&nbsp;</td>
</tr>
</table>
</span></td>
</tr>
<tr>
<td>
<b>Publisher:</b>

<value>IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC</value>
</td>
</tr>

<tr>
<td>
<b>Publisher Address:</b>

<value>445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Index:</b>

<value>Science Citation Index Expanded (SCI-EXPANDED)</value>
</td>
</tr>

<tr>
<td>
<b>Web of Science Categories:</b>
Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Engineering, Electrical &amp; Electronic; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>Research Areas:</b>
Computer Science; Engineering; Imaging Science &amp; Photographic Technology; Radiology, Nuclear Medicine &amp; Medical Imaging</td>
</tr>

<tr>
<td>
<b>IDS Number:</b>

<value>LC4AC</value>
</td>
</tr>

<tr>
<td>
<b>ISSN:</b>

<value>0278-0062</value>
</td>
</tr>

<tr>
<td>
<b>eISSN:</b>

<value>1558-254X</value>
</td>
</tr>

<tr>
<td>
<b>29-char Source Abbrev.:</b>

<value>IEEE T MED IMAGING</value>
</td>
</tr>

<tr>
<td>
<b>ISO Source Abbrev.:</b>

<value>IEEE Trans. Med. Imaging</value>
</td>
</tr>

<tr>
<td>
<b>Source Item Page Count:</b>

<value>17</value>
</td>
</tr>

<tr>
<td class="fr_data_row"><span class="FR_label"><b>Funding:</b></span></td>
</tr>
<tr>
<td>
<table cellpadding="3" cellspacing="0" border="1">
<tr>
<td class="fr_dataTable_head" nowrap="true" valign="top"><b>Funding Agency</b></td><td class="fr_dataTable_head" nowrap="true" valign="top"><b>Grant Number</b></td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>State Key Laboratory of Software Development Environment, Beihang University, Beijing, China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Hefei Innovation Research Institute, Beihang University, China</grant_agency>&nbsp;</td><td>&nbsp;</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>National Natural Science Foundation</grant_agency>&nbsp;</td><td>
<div>61702027&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Science and Technology Plan Project</grant_agency>&nbsp;</td><td>
<div>Z171100000117022&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Municipal Science &amp; Technology Commission</grant_agency>&nbsp;</td><td>
<div>Z181100001918008&nbsp;</div>
</td>
</tr>
<tr class="fr_data_row">
<td>
<grant_agency>Beijing Lab for Cardiovascular Precision Medicine</grant_agency>&nbsp;</td><td>
<div>PXM2018014226000013&nbsp;</div>
</td>
</tr>
</table>
</td>
</tr>
<tr>
<td class="fr_data_row"><span name="show_fund_blurb" id="show_fund_blurb">
<p>This work was supported in part by the State Key Laboratory of Software Development Environment, Beihang University, Beijing, China, in part by the Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, China, in part by the Hefei Innovation Research Institute, Beihang University, China, in part by the National Natural Science Foundation under Grant 61702027, in part by the Beijing Science and Technology Plan Project under Grant Z171100000117022, in part by the Beijing Municipal Science &amp; Technology Commission under Grant Z181100001918008, and in part by the Beijing Lab for Cardiovascular Precision Medicine under Grant PXM2018014226000013.</p>
</span></td>
</tr>
<tr>
<td>
<b>Output Date:</b>

<value>2025-10-01</value>
</td>
</tr>

</table><hr>
<table xmlns:bean="http://ts.thomson.com/ua/bean">
<tr>
<td>End of File</td>
</tr>
</table><div style="background-color: #000000; padding: 10px; color: #FFFFFF; font-family: arial, sans-serif;">
<div style="height: 25px; width: 100px;">
<mat-icon data-mat-icon-name="clarivate" data-mat-icon-type="svg" aria-hidden="true" class="mat-icon notranslate clarivate-logo mat-icon-no-color" svgicon="clarivate" role="img">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" focusable="false" preserveAspectRatio="xMidYMid meet" version="1.1" viewBox="0 0 92 18" height="100%" width="100%">
<title>Clarivate</title>
<g fill-rule="evenodd" fill="none" stroke-width="1" stroke="none">
<g fill-rule="nonzero" fill="#FFFFFF" transform="translate(-19.000000, -8.000000)">
<g transform="translate(1.000000, 1.000000)">
<g transform="translate(18.000000, 7.000000)">
<path d="M26.6812194,13.2997252 C28.2949641,13.3845068 29.7591419,12.3596036 30.2318671,10.8143235 L33.0910469,10.8143235 C32.3628779,13.742285 29.6973379,15.7705498 26.6812194,15.6916944 C24.8651813,15.7485215 23.1057028,15.0559504 21.8156554,13.7764967 C20.5256081,12.4970431 19.8185526,10.7433351 19.8604035,8.9268901 C19.8185367,7.11043445 20.5255848,5.35671042 21.8156337,4.07724261 C23.1056826,2.7977748 24.8651702,2.10519376 26.6812194,2.16201887 C29.6973451,2.0831702 32.3628861,4.11144761 33.0910469,7.03941847 L30.2318671,7.03941847 C29.7591419,5.49413828 28.2949641,4.46923515 26.6812194,4.55401674 C25.5407067,4.54133389 24.4470406,5.00703241 23.6657805,5.83803342 C22.8845203,6.66903442 22.487126,7.78932829 22.5700912,8.9268901 C22.4871313,10.064447 22.8845287,11.184734 23.6657888,12.0157277 C24.447049,12.8467215 25.540712,13.312413 26.6812194,13.2997252 L26.6812194,13.2997252 Z"/>
<polygon points="36.8477342 15.4674945 34.4371264 15.4674945 34.4371264 2.38628571 36.8477342 2.38628571"/>
<path d="M43.5380316,9.76781183 C43.5380316,9.15114738 43.0522397,8.75870193 42.1178663,8.75870193 C41.2070757,8.82048057 40.3236107,9.0957548 39.5389268,9.5622602 L38.5858286,7.73092465 C39.6930919,7.06514423 40.9567617,6.70409618 42.2486241,6.68441302 C44.1921648,6.68441302 45.9674886,7.58137515 45.9674886,9.84255787 L45.9674886,15.4674945 L43.5380316,15.4674945 L43.5380316,14.6639362 C42.9494098,15.3673061 42.0613957,15.7488608 41.146005,15.6917231 C40.3900371,15.7421039 39.645831,15.484584 39.0826798,14.9777443 C38.5195286,14.4709046 38.1853154,13.7578403 38.1560675,13.0007601 C38.1560675,11.3749188 39.3519468,10.3658089 41.2581433,10.3658089 L42.9400537,10.3658089 C43.3511665,10.3658089 43.5379934,10.1789247 43.5379934,9.86128266 L43.5380316,9.76781183 Z M43.5380316,12.4027631 L43.5380316,11.786089 C43.321275,11.9402969 43.0543042,12.0070182 42.790485,11.9729159 L41.8748173,11.9729159 C41.1086607,11.9729159 40.6602036,12.3092922 40.6602036,12.9072893 C40.6602036,13.486619 41.1272707,13.9164566 41.8748173,13.9164566 C42.303867,13.9699481 42.7348632,13.8332333 43.0546312,13.5422121 C43.3743992,13.2511908 43.5509896,12.8349402 43.5380316,12.4027631 L43.5380316,12.4027631 Z"/>
<path d="M52.6579104,9.3006299 L51.6301236,9.3006299 C50.3966703,9.3006299 49.8361037,9.8799596 49.8361037,11.3749188 L49.8361037,15.4674945 L47.4066179,15.4674945 L47.4066179,6.90863203 L49.7612715,6.90863203 L49.7612715,8.27284306 C50.1001881,7.34759017 51.0007831,6.74968637 51.9850429,6.79648425 C52.2115562,6.79362484 52.4375557,6.81874947 52.6579104,6.87128771 L52.6579104,9.3006299 Z"/>
<path d="M57.4232866,15.4674945 L54.9939445,15.4674945 L54.9939445,8.96425355 L53.7979312,8.96425355 L53.7979312,6.90863203 L57.4232866,6.90863203 L57.4232866,15.4674945 Z M56.0964104,2.38628347 C56.5129556,2.38558064 56.9126431,2.55074046 57.2071855,2.84528284 C57.5017278,3.13982521 57.6668877,3.53951271 57.6661848,3.95605794 C57.6609778,4.814152 56.9638874,5.50702694 56.1057775,5.50702694 C55.2476677,5.50702694 54.5505773,4.814152 54.5453585,3.95605794 C54.5417726,3.09491157 55.2352828,2.39302469 56.0964104,2.38628347 Z"/>
<polygon points="62.8802456 12.8512776 64.8236715 6.90863203 67.3838767 6.90863203 64.33787 15.4674945 61.3292077 15.4674945 58.4139588 6.90863203 61.0488526 6.90863203"/>
<path d="M72.8783522,9.76781183 C72.8783522,9.15114738 72.3924359,8.75870193 71.4580625,8.75870193 C70.5472784,8.82049943 69.6638208,9.09577238 68.8791325,9.5622602 L67.9261491,7.73092465 C69.0333627,7.06513461 70.2969953,6.70408494 71.5888202,6.68441302 C73.5323609,6.68441302 75.3076848,7.58137515 75.3076848,9.84255787 L75.3076848,15.4674945 L72.8783522,15.4674945 L72.8783522,14.6639362 C72.2896971,15.3672586 71.4017035,15.7487939 70.4863256,15.6916944 C69.7303436,15.7420941 68.986117,15.4845835 68.4229464,14.9777426 C67.8597758,14.4709017 67.5255471,13.7578265 67.4962924,13.0007314 C67.4962924,11.3748901 68.6923056,10.3657802 70.5984925,10.3657802 L72.2802785,10.3657802 C72.6913914,10.3657802 72.8783426,10.1788959 72.8783426,9.86125395 L72.8783522,9.76781183 Z M72.8783522,12.4027631 L72.8783522,11.786089 C72.6615874,11.9402794 72.3946236,12.006999 72.1308056,11.9729159 L71.2151378,11.9729159 C70.4488664,11.9729159 70.0004093,12.3092922 70.0004093,12.9072893 C70.0004093,13.486619 70.4676008,13.9164566 71.2151378,13.9164566 C71.6441833,13.9699279 72.0751679,13.8332061 72.394931,13.5421893 C72.7146941,13.2511724 72.8912904,12.8349341 72.8783522,12.4027631 L72.8783522,12.4027631 Z"/>
<path d="M79.9985637,3.65701635 L79.9985637,6.90863203 L81.8485762,6.90863203 L81.8485762,8.96425355 L79.9985637,8.96425355 L79.9985637,12.8325433 C79.9985637,13.3745286 80.4282865,13.4492747 80.8020646,13.4492747 C81.418729,13.4492747 81.9232553,13.3932056 81.9232553,13.3932056 L81.9232553,15.4674945 C81.9232553,15.4674945 80.7459859,15.5796423 80.0357932,15.5796423 C78.8211795,15.5796423 77.5691354,15.3740811 77.5691354,13.6548263 L77.5691354,8.96425355 L76.22363,8.96425355 L76.22363,6.90863203 L77.5691163,6.90863203 L77.5691163,3.65701635 L79.9985637,3.65701635 Z"/>
<path d="M91.5475359,11.8981794 L85.1751771,11.8981794 C85.3031552,12.7204351 85.9194738,13.3815958 86.7307322,13.5669136 C87.5419905,13.7522314 88.3842592,13.4242593 88.856573,12.7391298 L91.3793191,13.0007601 C90.4933306,14.9536735 88.3725856,16.0321989 86.2725384,15.5978628 C84.1724912,15.1635268 82.6535603,13.3322361 82.6149337,11.188092 C82.567807,9.98960603 83.0193435,8.82515843 83.8621298,7.97175307 C84.7049161,7.1183477 85.8636189,6.65226701 87.0626009,6.68438432 C89.4171397,6.68438432 91.5475359,8.21674525 91.5475359,11.8047373 L91.5475359,11.8981794 Z M85.1189837,10.2723955 L88.9499864,10.2723955 C88.8059978,9.34848922 87.9973156,8.67588427 87.0626392,8.70263282 C86.1147409,8.67034807 85.2869107,9.33893202 85.1189837,10.2723955 Z"/>
<path d="M12.6820274,9.85132226 C10.6885049,11.8556057 8.11575776,13.1830474 5.32707189,13.6462054 C5.77780891,14.8758828 6.40559556,16.0331959 7.19058498,17.0815575 C10.3903106,16.2989026 13.3004311,14.619851 15.5794509,12.2414352 C15.0651988,11.0374085 14.3787129,9.91449973 13.5415112,8.90790698 C13.271174,9.23328 12.9846793,9.54772625 12.6820274,9.85124571"/>
<path d="M5.32722498,13.6460332 C4.21304566,10.5852611 4.22627578,7.22758116 5.3645406,4.17568425 C4.07298567,3.95802358 2.75701252,3.92542943 1.45626578,4.07888372 C0.536506305,7.22972054 0.525090565,10.5762272 1.42333236,13.7332656 C2.72217338,13.8896343 4.03666286,13.8602685 5.32722498,13.6460524"/>
<path d="M7.25919787,0.751096346 C6.46424104,1.79423541 5.8259601,2.94792723 5.36457887,4.17561728 C8.13918123,4.64457901 10.6977043,5.96938232 12.6820178,7.96458738 C12.9850078,8.2673988 13.2715025,8.58184824 13.5415017,8.90793568 C14.3788161,7.90142183 15.0653154,6.77849641 15.5794509,5.57440744 C13.3171586,3.21319806 10.4324457,1.54091896 7.25919787,0.751096346"/>
</g>
</g>
</g>
</g>
</svg>
</mat-icon>
</div>
<path d="M5.32722498,13.6460332 C4.21304566,10.5852611 4.22627578,7.22758116 5.3645406,4.17568425 C4.07298567,3.95802358 2.75701252,3.92542943 1.45626578,4.07888372 C0.536506305,7.22972054 0.525090565,10.5762272 1.42333236,13.7332656 C2.72217338,13.8896343 4.03666286,13.8602685 5.32722498,13.6460524"></path>
<path d="M7.25919787,0.751096346 C6.46424104,1.79423541 5.8259601,2.94792723 5.36457887,4.17561728 C8.13918123,4.64457901 10.6977043,5.96938232 12.6820178,7.96458738 C12.9850078,8.2673988 13.2715025,8.58184824 13.5415017,8.90793568 C14.3788161,7.90142183 15.0653154,6.77849641 15.5794509,5.57440744 C13.3171586,3.21319806 10.4324457,1.54091896 7.25919787,0.751096346"></path>
</div>
